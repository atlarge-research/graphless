

Container: container_1533735211869_0003_01_000001 on graphalytics-giraph-slave10_46663
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:2248
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/11/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Aug 08, 2018 1:37:41 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver as a provider class
Aug 08, 2018 1:37:41 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
Aug 08, 2018 1:37:41 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices as a root resource class
Aug 08, 2018 1:37:41 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.9 09/02/2011 11:17 AM'
Aug 08, 2018 1:37:41 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
Aug 08, 2018 1:37:41 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
Aug 08, 2018 1:37:41 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices to GuiceManagedComponentProvider with the scope "PerRequest"
log4j:WARN No appenders could be found for logger (org.apache.hadoop.ipc.Server).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:118124
Log Contents:
2018-08-08 13:37:39,074 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1533735211869_0003_000001
2018-08-08 13:37:39,262 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens:
2018-08-08 13:37:39,262 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 3 cluster_timestamp: 1533735211869 } attemptId: 1 } keyId: -63235253)
2018-08-08 13:37:39,463 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Using mapred newApiCommitter.
2018-08-08 13:37:39,465 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config null
2018-08-08 13:37:39,543 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:40,000 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is org.apache.giraph.io.internal.WrappedVertexOutputFormat$2
2018-08-08 13:37:40,148 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler
2018-08-08 13:37:40,149 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher
2018-08-08 13:37:40,150 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher
2018-08-08 13:37:40,150 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher
2018-08-08 13:37:40,151 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler
2018-08-08 13:37:40,155 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher
2018-08-08 13:37:40,155 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter
2018-08-08 13:37:40,156 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter
2018-08-08 13:37:40,185 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 13:37:40,200 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 13:37:40,214 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 13:37:40,224 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled
2018-08-08 13:37:40,258 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler
2018-08-08 13:37:40,321 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:40,374 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:40,374 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MRAppMaster metrics system started
2018-08-08 13:37:40,382 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for job_1533735211869_0003 to jobTokenSecretManager
2018-08-08 13:37:40,478 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing job_1533735211869_0003 because: not enabled; too many maps; too much RAM;
2018-08-08 13:37:40,492 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job job_1533735211869_0003 = 0. Number of splits = 14
2018-08-08 13:37:40,492 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job job_1533735211869_0003 = 0
2018-08-08 13:37:40,492 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0003Job Transitioned from NEW to INITED
2018-08-08 13:37:40,493 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job job_1533735211869_0003.
2018-08-08 13:37:40,515 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2018-08-08 13:37:40,523 INFO [Socket Reader #1 for port 39521] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 39521
2018-08-08 13:37:40,562 INFO [main] org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server
2018-08-08 13:37:40,563 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-08-08 13:37:40,563 INFO [IPC Server listener on 39521] org.apache.hadoop.ipc.Server: IPC Server listener on 39521: starting
2018-08-08 13:37:40,564 INFO [main] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at graphalytics-giraph-slave10/10.164.0.12:39521
2018-08-08 13:37:40,623 INFO [main] org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-08-08 13:37:40,629 INFO [main] org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-08-08 13:37:40,633 INFO [main] org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined
2018-08-08 13:37:40,638 INFO [main] org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-08-08 13:37:40,643 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce
2018-08-08 13:37:40,644 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static
2018-08-08 13:37:40,646 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /mapreduce/*
2018-08-08 13:37:40,647 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-08-08 13:37:40,866 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-08-08 13:37:40,868 INFO [main] org.apache.hadoop.http.HttpServer2: Jetty bound to port 40249
2018-08-08 13:37:40,868 INFO [main] org.mortbay.log: jetty-6.1.26
2018-08-08 13:37:40,892 INFO [main] org.mortbay.log: Extract jar:file:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar!/webapps/mapreduce to /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000001/tmp/Jetty_0_0_0_0_40249_mapreduce____.fzekrm/webapp
2018-08-08 13:37:41,731 INFO [main] org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:40249
2018-08-08 13:37:41,731 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Web app mapreduce started at 40249
2018-08-08 13:37:41,733 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: JOB_CREATE job_1533735211869_0003
2018-08-08 13:37:41,735 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 3000
2018-08-08 13:37:41,735 INFO [Socket Reader #1 for port 35241] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 35241
2018-08-08 13:37:41,743 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-08-08 13:37:41,743 INFO [IPC Server listener on 35241] org.apache.hadoop.ipc.Server: IPC Server listener on 35241: starting
2018-08-08 13:37:41,784 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true
2018-08-08 13:37:41,784 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: maxTaskFailuresPerNode is 3
2018-08-08 13:37:41,784 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: blacklistDisablePercent is 33
2018-08-08 13:37:41,822 INFO [main] org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at graphalytics-giraph/10.164.0.2:8030
2018-08-08 13:37:41,893 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: maxContainerCapability: <memory:57344, vCores:32>
2018-08-08 13:37:41,893 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: queue: default
2018-08-08 13:37:41,897 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500
2018-08-08 13:37:41,897 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: The thread pool initial size is 10
2018-08-08 13:37:41,900 INFO [main] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2018-08-08 13:37:41,907 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0003Job Transitioned from INITED to SETUP
2018-08-08 13:37:41,910 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_SETUP
2018-08-08 13:37:41,937 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0003Job Transitioned from SETUP to RUNNING
2018-08-08 13:37:41,956 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000000 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,956 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000001 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,957 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000002 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,957 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000003 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,957 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000004 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,957 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000005 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,957 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000006 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,958 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000007 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,958 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000008 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,958 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000009 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,958 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000010 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,959 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000011 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,960 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000012 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,961 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000013 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:37:41,962 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,962 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000001_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,963 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000002_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,963 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000003_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,963 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000004_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,963 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000005_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,963 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000006_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,963 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000007_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,963 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000008_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,964 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000009_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,964 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000010_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,964 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000011_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,964 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000012_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,964 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000013_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:37:41,966 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: mapResourceRequest:<memory:57344, vCores:1>
2018-08-08 13:37:41,978 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1533735211869_0003, File: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0003/job_1533735211869_0003_1.jhist
2018-08-08 13:37:42,896 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:14 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:37:42,925 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1533735211869_0003: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:858112, vCores:1> knownNMs=15
2018-08-08 13:37:43,952 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 14
2018-08-08 13:37:43,953 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave15 to /default-rack
2018-08-08 13:37:43,954 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave1 to /default-rack
2018-08-08 13:37:43,954 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave13 to /default-rack
2018-08-08 13:37:43,954 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave2 to /default-rack
2018-08-08 13:37:43,954 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave7 to /default-rack
2018-08-08 13:37:43,955 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave5 to /default-rack
2018-08-08 13:37:43,955 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave11 to /default-rack
2018-08-08 13:37:43,955 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave6 to /default-rack
2018-08-08 13:37:43,955 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave4 to /default-rack
2018-08-08 13:37:43,955 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave9 to /default-rack
2018-08-08 13:37:43,955 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave14 to /default-rack
2018-08-08 13:37:43,955 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave3 to /default-rack
2018-08-08 13:37:43,955 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave8 to /default-rack
2018-08-08 13:37:43,955 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave12 to /default-rack
2018-08-08 13:37:43,956 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000002 to attempt_1533735211869_0003_m_000000_0
2018-08-08 13:37:43,958 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000003 to attempt_1533735211869_0003_m_000001_0
2018-08-08 13:37:43,958 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000004 to attempt_1533735211869_0003_m_000002_0
2018-08-08 13:37:43,958 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000005 to attempt_1533735211869_0003_m_000003_0
2018-08-08 13:37:43,958 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000006 to attempt_1533735211869_0003_m_000004_0
2018-08-08 13:37:43,959 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000007 to attempt_1533735211869_0003_m_000005_0
2018-08-08 13:37:43,959 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000008 to attempt_1533735211869_0003_m_000006_0
2018-08-08 13:37:43,959 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000009 to attempt_1533735211869_0003_m_000007_0
2018-08-08 13:37:43,959 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000010 to attempt_1533735211869_0003_m_000008_0
2018-08-08 13:37:43,960 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000011 to attempt_1533735211869_0003_m_000009_0
2018-08-08 13:37:43,960 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000012 to attempt_1533735211869_0003_m_000010_0
2018-08-08 13:37:43,960 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000013 to attempt_1533735211869_0003_m_000011_0
2018-08-08 13:37:43,960 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000015 to attempt_1533735211869_0003_m_000012_0
2018-08-08 13:37:43,960 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0003_01_000016 to attempt_1533735211869_0003_m_000013_0
2018-08-08 13:37:43,960 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:14 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:37:43,993 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave15 to /default-rack
2018-08-08 13:37:44,006 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-jar file on the remote FS is hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0003/job.jar
2018-08-08 13:37:44,009 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0003/job.xml
2018-08-08 13:37:44,011 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Adding #0 tokens and #1 secret keys for NM use for launching container
2018-08-08 13:37:44,011 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Size of containertokens_dob is 1
2018-08-08 13:37:44,011 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Putting shuffle token in serviceData
2018-08-08 13:37:44,035 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,038 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave1 to /default-rack
2018-08-08 13:37:44,039 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,039 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave13 to /default-rack
2018-08-08 13:37:44,040 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,040 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave2 to /default-rack
2018-08-08 13:37:44,041 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000003_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,041 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave7 to /default-rack
2018-08-08 13:37:44,041 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000004_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,041 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave5 to /default-rack
2018-08-08 13:37:44,042 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000005_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,042 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave11 to /default-rack
2018-08-08 13:37:44,042 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000006_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,042 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave6 to /default-rack
2018-08-08 13:37:44,043 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000007_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,043 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave4 to /default-rack
2018-08-08 13:37:44,043 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000008_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,043 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave9 to /default-rack
2018-08-08 13:37:44,044 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000009_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,044 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave14 to /default-rack
2018-08-08 13:37:44,046 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000010_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,046 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave3 to /default-rack
2018-08-08 13:37:44,046 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000011_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,046 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave8 to /default-rack
2018-08-08 13:37:44,047 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000012_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,047 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave12 to /default-rack
2018-08-08 13:37:44,047 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000013_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:37:44,049 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000002 taskAttempt attempt_1533735211869_0003_m_000000_0
2018-08-08 13:37:44,050 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000003 taskAttempt attempt_1533735211869_0003_m_000001_0
2018-08-08 13:37:44,050 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000004 taskAttempt attempt_1533735211869_0003_m_000002_0
2018-08-08 13:37:44,051 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000005 taskAttempt attempt_1533735211869_0003_m_000003_0
2018-08-08 13:37:44,052 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000006 taskAttempt attempt_1533735211869_0003_m_000004_0
2018-08-08 13:37:44,052 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000007 taskAttempt attempt_1533735211869_0003_m_000005_0
2018-08-08 13:37:44,052 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000008 taskAttempt attempt_1533735211869_0003_m_000006_0
2018-08-08 13:37:44,054 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000009 taskAttempt attempt_1533735211869_0003_m_000007_0
2018-08-08 13:37:44,055 INFO [ContainerLauncher Event Handler] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Setting ContainerLauncher pool size to 21 as number-of-nodes to talk to is 11
2018-08-08 13:37:44,056 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000011 taskAttempt attempt_1533735211869_0003_m_000009_0
2018-08-08 13:37:44,056 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000012 taskAttempt attempt_1533735211869_0003_m_000010_0
2018-08-08 13:37:44,056 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000013 taskAttempt attempt_1533735211869_0003_m_000011_0
2018-08-08 13:37:44,056 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000009_0
2018-08-08 13:37:44,056 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000015 taskAttempt attempt_1533735211869_0003_m_000012_0
2018-08-08 13:37:44,056 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000012_0
2018-08-08 13:37:44,056 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000010_0
2018-08-08 13:37:44,056 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000000_0
2018-08-08 13:37:44,057 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000007_0
2018-08-08 13:37:44,057 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000010 taskAttempt attempt_1533735211869_0003_m_000008_0
2018-08-08 13:37:44,057 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000011_0
2018-08-08 13:37:44,057 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000008_0
2018-08-08 13:37:44,057 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000002_0
2018-08-08 13:37:44,056 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000005_0
2018-08-08 13:37:44,056 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000004_0
2018-08-08 13:37:44,057 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave9:37771
2018-08-08 13:37:44,056 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000001_0
2018-08-08 13:37:44,057 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0003_01_000016 taskAttempt attempt_1533735211869_0003_m_000013_0
2018-08-08 13:37:44,057 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000003_0
2018-08-08 13:37:44,057 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000006_0
2018-08-08 13:37:44,057 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0003_m_000013_0
2018-08-08 13:37:44,074 INFO [ContainerLauncher #13] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave12:33893
2018-08-08 13:37:44,077 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave11:46641
2018-08-08 13:37:44,079 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave2:43787
2018-08-08 13:37:44,082 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave1:33157
2018-08-08 13:37:44,084 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave7:43383
2018-08-08 13:37:44,085 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave5:46217
2018-08-08 13:37:44,086 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave13:40615
2018-08-08 13:37:44,089 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave4:46069
2018-08-08 13:37:44,090 INFO [ContainerLauncher #11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave3:42077
2018-08-08 13:37:44,091 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave15:37797
2018-08-08 13:37:44,097 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave6:36387
2018-08-08 13:37:44,099 INFO [ContainerLauncher #10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave14:35219
2018-08-08 13:37:44,102 INFO [ContainerLauncher #12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave8:41519
2018-08-08 13:37:44,178 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000001_0 : 13562
2018-08-08 13:37:44,178 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000013_0 : 13562
2018-08-08 13:37:44,178 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000010_0 : 13562
2018-08-08 13:37:44,178 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000005_0 : 13562
2018-08-08 13:37:44,178 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000000_0 : 13562
2018-08-08 13:37:44,178 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000006_0 : 13562
2018-08-08 13:37:44,178 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000011_0 : 13562
2018-08-08 13:37:44,178 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000002_0 : 13562
2018-08-08 13:37:44,179 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000012_0 : 13562
2018-08-08 13:37:44,179 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000004_0 : 13562
2018-08-08 13:37:44,180 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000003_0 : 13562
2018-08-08 13:37:44,180 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000009_0 : 13562
2018-08-08 13:37:44,180 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000008_0 : 13562
2018-08-08 13:37:44,181 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000001_0] using containerId: [container_1533735211869_0003_01_000003 on NM: [graphalytics-giraph-slave1:33157]
2018-08-08 13:37:44,181 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0003_m_000007_0 : 13562
2018-08-08 13:37:44,183 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000001_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,184 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000002_0] using containerId: [container_1533735211869_0003_01_000004 on NM: [graphalytics-giraph-slave13:40615]
2018-08-08 13:37:44,184 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000002_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,185 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000011_0] using containerId: [container_1533735211869_0003_01_000013 on NM: [graphalytics-giraph-slave3:42077]
2018-08-08 13:37:44,185 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000011_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,185 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000006_0] using containerId: [container_1533735211869_0003_01_000008 on NM: [graphalytics-giraph-slave11:46641]
2018-08-08 13:37:44,185 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000006_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,185 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000000_0] using containerId: [container_1533735211869_0003_01_000002 on NM: [graphalytics-giraph-slave15:37797]
2018-08-08 13:37:44,185 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,185 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000005_0] using containerId: [container_1533735211869_0003_01_000007 on NM: [graphalytics-giraph-slave5:46217]
2018-08-08 13:37:44,185 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000005_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,186 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000010_0] using containerId: [container_1533735211869_0003_01_000012 on NM: [graphalytics-giraph-slave14:35219]
2018-08-08 13:37:44,186 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000010_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,186 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000013_0] using containerId: [container_1533735211869_0003_01_000016 on NM: [graphalytics-giraph-slave12:33893]
2018-08-08 13:37:44,186 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000013_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,186 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000012_0] using containerId: [container_1533735211869_0003_01_000015 on NM: [graphalytics-giraph-slave8:41519]
2018-08-08 13:37:44,186 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000012_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,186 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000004_0] using containerId: [container_1533735211869_0003_01_000006 on NM: [graphalytics-giraph-slave7:43383]
2018-08-08 13:37:44,186 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000004_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,186 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000003_0] using containerId: [container_1533735211869_0003_01_000005 on NM: [graphalytics-giraph-slave2:43787]
2018-08-08 13:37:44,187 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000003_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,187 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000009_0] using containerId: [container_1533735211869_0003_01_000011 on NM: [graphalytics-giraph-slave9:37771]
2018-08-08 13:37:44,188 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000009_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,188 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000008_0] using containerId: [container_1533735211869_0003_01_000010 on NM: [graphalytics-giraph-slave4:46069]
2018-08-08 13:37:44,188 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000008_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,189 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0003_m_000007_0] using containerId: [container_1533735211869_0003_01_000009 on NM: [graphalytics-giraph-slave6:36387]
2018-08-08 13:37:44,189 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000007_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000001 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000002 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000011 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000006 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000000 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000005 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000010 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000013 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000012 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000004 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000003 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000009 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000008 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,191 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000007 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:37:44,963 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1533735211869_0003: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:55296, vCores:1> knownNMs=15
2018-08-08 13:37:45,710 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,727 INFO [IPC Server handler 0 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000012 asked for a task
2018-08-08 13:37:45,728 INFO [IPC Server handler 0 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000012 given task: attempt_1533735211869_0003_m_000010_0
2018-08-08 13:37:45,796 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,807 INFO [IPC Server handler 0 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000008 asked for a task
2018-08-08 13:37:45,808 INFO [IPC Server handler 0 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000008 given task: attempt_1533735211869_0003_m_000006_0
2018-08-08 13:37:45,810 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,817 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,824 INFO [IPC Server handler 1 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000004 asked for a task
2018-08-08 13:37:45,825 INFO [IPC Server handler 1 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000004 given task: attempt_1533735211869_0003_m_000002_0
2018-08-08 13:37:45,828 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,828 INFO [IPC Server handler 2 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000006 asked for a task
2018-08-08 13:37:45,829 INFO [IPC Server handler 2 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000006 given task: attempt_1533735211869_0003_m_000004_0
2018-08-08 13:37:45,829 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,831 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,838 INFO [IPC Server handler 3 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000015 asked for a task
2018-08-08 13:37:45,839 INFO [IPC Server handler 3 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000015 given task: attempt_1533735211869_0003_m_000012_0
2018-08-08 13:37:45,841 INFO [IPC Server handler 4 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000009 asked for a task
2018-08-08 13:37:45,841 INFO [IPC Server handler 4 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000009 given task: attempt_1533735211869_0003_m_000007_0
2018-08-08 13:37:45,842 INFO [IPC Server handler 5 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000002 asked for a task
2018-08-08 13:37:45,843 INFO [IPC Server handler 5 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000002 given task: attempt_1533735211869_0003_m_000000_0
2018-08-08 13:37:45,847 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,850 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,859 INFO [IPC Server handler 6 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000013 asked for a task
2018-08-08 13:37:45,859 INFO [IPC Server handler 6 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000013 given task: attempt_1533735211869_0003_m_000011_0
2018-08-08 13:37:45,861 INFO [IPC Server handler 7 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000007 asked for a task
2018-08-08 13:37:45,861 INFO [IPC Server handler 7 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000007 given task: attempt_1533735211869_0003_m_000005_0
2018-08-08 13:37:45,878 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,889 INFO [IPC Server handler 8 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000005 asked for a task
2018-08-08 13:37:45,889 INFO [IPC Server handler 8 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000005 given task: attempt_1533735211869_0003_m_000003_0
2018-08-08 13:37:45,900 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,912 INFO [IPC Server handler 9 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000011 asked for a task
2018-08-08 13:37:45,912 INFO [IPC Server handler 9 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000011 given task: attempt_1533735211869_0003_m_000009_0
2018-08-08 13:37:45,930 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,941 INFO [IPC Server handler 10 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000016 asked for a task
2018-08-08 13:37:45,941 INFO [IPC Server handler 10 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000016 given task: attempt_1533735211869_0003_m_000013_0
2018-08-08 13:37:45,951 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,953 INFO [Socket Reader #1 for port 35241] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0003 (auth:SIMPLE)
2018-08-08 13:37:45,963 INFO [IPC Server handler 11 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000003 asked for a task
2018-08-08 13:37:45,964 INFO [IPC Server handler 11 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000003 given task: attempt_1533735211869_0003_m_000001_0
2018-08-08 13:37:45,965 INFO [IPC Server handler 12 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0003_m_000010 asked for a task
2018-08-08 13:37:45,966 INFO [IPC Server handler 12 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0003_m_000010 given task: attempt_1533735211869_0003_m_000008_0
2018-08-08 13:37:52,382 INFO [IPC Server handler 14 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000010_0 is : 1.0
2018-08-08 13:37:52,486 INFO [IPC Server handler 16 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000012_0 is : 1.0
2018-08-08 13:37:52,491 INFO [IPC Server handler 17 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000006_0 is : 1.0
2018-08-08 13:37:52,518 INFO [IPC Server handler 20 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000004_0 is : 1.0
2018-08-08 13:37:52,531 INFO [IPC Server handler 21 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000000_0 is : 1.0
2018-08-08 13:37:52,540 INFO [IPC Server handler 22 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000002_0 is : 1.0
2018-08-08 13:37:52,546 INFO [IPC Server handler 23 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000005_0 is : 1.0
2018-08-08 13:37:52,578 INFO [IPC Server handler 24 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000007_0 is : 1.0
2018-08-08 13:37:52,594 INFO [IPC Server handler 25 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000011_0 is : 1.0
2018-08-08 13:37:52,601 INFO [IPC Server handler 26 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000009_0 is : 1.0
2018-08-08 13:37:52,612 INFO [IPC Server handler 27 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000003_0 is : 1.0
2018-08-08 13:37:52,658 INFO [IPC Server handler 28 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000013_0 is : 1.0
2018-08-08 13:37:52,682 INFO [IPC Server handler 29 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000008_0 is : 1.0
2018-08-08 13:37:52,709 INFO [IPC Server handler 0 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000001_0 is : 1.0
2018-08-08 13:37:54,735 INFO [IPC Server handler 1 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000001_0 is : 1.0
2018-08-08 13:37:54,760 INFO [IPC Server handler 2 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000001_0
2018-08-08 13:37:54,761 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000001_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:54,761 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000001_0 given a go for committing the task output.
2018-08-08 13:37:54,762 INFO [IPC Server handler 3 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000001_0
2018-08-08 13:37:54,763 INFO [IPC Server handler 3 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000001_0:true
2018-08-08 13:37:54,791 INFO [IPC Server handler 4 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000001_0 is : 1.0
2018-08-08 13:37:54,793 INFO [IPC Server handler 5 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000001_0
2018-08-08 13:37:54,795 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000001_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:54,795 INFO [ContainerLauncher #14] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000003 taskAttempt attempt_1533735211869_0003_m_000001_0
2018-08-08 13:37:54,796 INFO [ContainerLauncher #14] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000001_0
2018-08-08 13:37:54,796 INFO [ContainerLauncher #14] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave1:33157
2018-08-08 13:37:54,813 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000001_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:54,821 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000001_0
2018-08-08 13:37:54,821 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000001 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:54,824 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 1
2018-08-08 13:37:54,829 INFO [IPC Server handler 6 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000012_0 is : 1.0
2018-08-08 13:37:54,852 INFO [IPC Server handler 7 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000012_0
2018-08-08 13:37:54,854 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000012_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:54,854 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000012_0 given a go for committing the task output.
2018-08-08 13:37:54,854 INFO [IPC Server handler 8 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000012_0
2018-08-08 13:37:54,854 INFO [IPC Server handler 8 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000012_0:true
2018-08-08 13:37:54,870 INFO [IPC Server handler 9 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000009_0 is : 1.0
2018-08-08 13:37:54,880 INFO [IPC Server handler 10 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000012_0 is : 1.0
2018-08-08 13:37:54,882 INFO [IPC Server handler 11 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000012_0
2018-08-08 13:37:54,883 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000012_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:54,883 INFO [IPC Server handler 12 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000008_0 is : 1.0
2018-08-08 13:37:54,883 INFO [ContainerLauncher #15] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000015 taskAttempt attempt_1533735211869_0003_m_000012_0
2018-08-08 13:37:54,884 INFO [ContainerLauncher #15] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000012_0
2018-08-08 13:37:54,885 INFO [ContainerLauncher #15] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave8:41519
2018-08-08 13:37:54,894 INFO [IPC Server handler 13 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000009_0
2018-08-08 13:37:54,895 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000009_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:54,895 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000009_0 given a go for committing the task output.
2018-08-08 13:37:54,896 INFO [IPC Server handler 14 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000009_0
2018-08-08 13:37:54,897 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000012_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:54,897 INFO [IPC Server handler 14 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000009_0:true
2018-08-08 13:37:54,897 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000012_0
2018-08-08 13:37:54,897 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000012 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:54,897 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 2
2018-08-08 13:37:54,906 INFO [IPC Server handler 15 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000008_0
2018-08-08 13:37:54,907 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000008_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:54,907 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000008_0 given a go for committing the task output.
2018-08-08 13:37:54,908 INFO [IPC Server handler 16 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000008_0
2018-08-08 13:37:54,908 INFO [IPC Server handler 16 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000008_0:true
2018-08-08 13:37:54,922 INFO [IPC Server handler 17 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000009_0 is : 1.0
2018-08-08 13:37:54,924 INFO [IPC Server handler 18 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000009_0
2018-08-08 13:37:54,925 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000009_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:54,926 INFO [ContainerLauncher #16] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000011 taskAttempt attempt_1533735211869_0003_m_000009_0
2018-08-08 13:37:54,926 INFO [ContainerLauncher #16] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000009_0
2018-08-08 13:37:54,926 INFO [ContainerLauncher #16] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave9:37771
2018-08-08 13:37:54,928 INFO [IPC Server handler 19 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000013_0 is : 1.0
2018-08-08 13:37:54,936 INFO [IPC Server handler 20 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000008_0 is : 1.0
2018-08-08 13:37:54,937 INFO [IPC Server handler 21 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000008_0
2018-08-08 13:37:54,937 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000009_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:54,938 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000008_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:54,938 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000009_0
2018-08-08 13:37:54,938 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000009 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:54,938 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 3
2018-08-08 13:37:54,940 INFO [ContainerLauncher #17] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000010 taskAttempt attempt_1533735211869_0003_m_000008_0
2018-08-08 13:37:54,941 INFO [ContainerLauncher #17] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000008_0
2018-08-08 13:37:54,941 INFO [ContainerLauncher #17] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave4:46069
2018-08-08 13:37:54,948 INFO [IPC Server handler 22 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000013_0
2018-08-08 13:37:54,949 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000013_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:54,949 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000013_0 given a go for committing the task output.
2018-08-08 13:37:54,950 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000008_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:54,950 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000008_0
2018-08-08 13:37:54,950 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000008 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:54,951 INFO [IPC Server handler 23 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000013_0
2018-08-08 13:37:54,951 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 4
2018-08-08 13:37:54,951 INFO [IPC Server handler 23 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000013_0:true
2018-08-08 13:37:54,974 INFO [IPC Server handler 24 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000013_0 is : 1.0
2018-08-08 13:37:54,976 INFO [IPC Server handler 25 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000013_0
2018-08-08 13:37:54,977 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000013_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:54,977 INFO [ContainerLauncher #18] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000016 taskAttempt attempt_1533735211869_0003_m_000013_0
2018-08-08 13:37:54,977 INFO [ContainerLauncher #18] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000013_0
2018-08-08 13:37:54,978 INFO [ContainerLauncher #18] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave12:33893
2018-08-08 13:37:54,990 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000013_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:54,990 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000013_0
2018-08-08 13:37:54,990 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000013 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:54,990 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 5
2018-08-08 13:37:54,991 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:14 AssignedReds:0 CompletedMaps:5 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:37:54,997 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000003
2018-08-08 13:37:54,998 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000015
2018-08-08 13:37:54,998 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000010
2018-08-08 13:37:54,998 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000011
2018-08-08 13:37:54,998 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:10 AssignedReds:0 CompletedMaps:5 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:37:54,998 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000001_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:54,998 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000012_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:54,998 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000008_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:54,998 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000009_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:55,035 INFO [IPC Server handler 26 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000007_0 is : 1.0
2018-08-08 13:37:55,062 INFO [IPC Server handler 27 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000007_0
2018-08-08 13:37:55,063 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000007_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:55,063 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000007_0 given a go for committing the task output.
2018-08-08 13:37:55,065 INFO [IPC Server handler 28 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000007_0
2018-08-08 13:37:55,065 INFO [IPC Server handler 28 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000007_0:true
2018-08-08 13:37:55,079 INFO [IPC Server handler 29 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000005_0 is : 1.0
2018-08-08 13:37:55,080 INFO [IPC Server handler 0 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000006_0 is : 1.0
2018-08-08 13:37:55,093 INFO [IPC Server handler 1 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000004_0 is : 1.0
2018-08-08 13:37:55,095 INFO [IPC Server handler 2 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000007_0 is : 1.0
2018-08-08 13:37:55,096 INFO [IPC Server handler 3 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000003_0 is : 1.0
2018-08-08 13:37:55,098 INFO [IPC Server handler 4 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000007_0
2018-08-08 13:37:55,098 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000007_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:55,098 INFO [IPC Server handler 5 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000010_0 is : 1.0
2018-08-08 13:37:55,099 INFO [ContainerLauncher #19] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000009 taskAttempt attempt_1533735211869_0003_m_000007_0
2018-08-08 13:37:55,099 INFO [ContainerLauncher #19] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000007_0
2018-08-08 13:37:55,099 INFO [ContainerLauncher #19] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave6:36387
2018-08-08 13:37:55,102 INFO [IPC Server handler 6 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000011_0 is : 1.0
2018-08-08 13:37:55,103 INFO [IPC Server handler 7 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000005_0
2018-08-08 13:37:55,103 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000005_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:55,103 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000005_0 given a go for committing the task output.
2018-08-08 13:37:55,104 INFO [IPC Server handler 8 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000006_0
2018-08-08 13:37:55,104 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000006_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:55,104 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000006_0 given a go for committing the task output.
2018-08-08 13:37:55,105 INFO [IPC Server handler 9 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000005_0
2018-08-08 13:37:55,105 INFO [IPC Server handler 9 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000005_0:true
2018-08-08 13:37:55,105 INFO [IPC Server handler 9 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000006_0
2018-08-08 13:37:55,105 INFO [IPC Server handler 9 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000006_0:true
2018-08-08 13:37:55,112 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000007_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:55,112 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000007_0
2018-08-08 13:37:55,112 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000007 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:55,114 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 6
2018-08-08 13:37:55,115 INFO [IPC Server handler 11 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000004_0
2018-08-08 13:37:55,115 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000004_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:55,115 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000004_0 given a go for committing the task output.
2018-08-08 13:37:55,116 INFO [IPC Server handler 12 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000004_0
2018-08-08 13:37:55,117 INFO [IPC Server handler 12 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000004_0:true
2018-08-08 13:37:55,122 INFO [IPC Server handler 13 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000003_0
2018-08-08 13:37:55,122 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000003_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:55,122 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000003_0 given a go for committing the task output.
2018-08-08 13:37:55,122 INFO [IPC Server handler 14 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000010_0
2018-08-08 13:37:55,122 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000010_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:55,122 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000010_0 given a go for committing the task output.
2018-08-08 13:37:55,123 INFO [IPC Server handler 15 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000003_0
2018-08-08 13:37:55,124 INFO [IPC Server handler 15 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000003_0:true
2018-08-08 13:37:55,124 INFO [IPC Server handler 16 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000010_0
2018-08-08 13:37:55,124 INFO [IPC Server handler 16 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000010_0:true
2018-08-08 13:37:55,126 INFO [IPC Server handler 17 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000011_0
2018-08-08 13:37:55,126 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000011_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:55,126 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000011_0 given a go for committing the task output.
2018-08-08 13:37:55,128 INFO [IPC Server handler 18 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000011_0
2018-08-08 13:37:55,128 INFO [IPC Server handler 18 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000011_0:true
2018-08-08 13:37:55,130 INFO [IPC Server handler 19 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000006_0 is : 1.0
2018-08-08 13:37:55,132 INFO [IPC Server handler 20 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000006_0
2018-08-08 13:37:55,132 INFO [IPC Server handler 21 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000005_0 is : 1.0
2018-08-08 13:37:55,132 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000006_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:55,133 INFO [ContainerLauncher #20] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000008 taskAttempt attempt_1533735211869_0003_m_000006_0
2018-08-08 13:37:55,133 INFO [ContainerLauncher #20] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000006_0
2018-08-08 13:37:55,133 INFO [ContainerLauncher #20] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave11:46641
2018-08-08 13:37:55,134 INFO [IPC Server handler 22 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000005_0
2018-08-08 13:37:55,134 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000005_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:55,134 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000007 taskAttempt attempt_1533735211869_0003_m_000005_0
2018-08-08 13:37:55,134 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000005_0
2018-08-08 13:37:55,135 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave5:46217
2018-08-08 13:37:55,141 INFO [IPC Server handler 23 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000004_0 is : 1.0
2018-08-08 13:37:55,142 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000006_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:55,143 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000006_0
2018-08-08 13:37:55,143 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000006 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:55,144 INFO [IPC Server handler 24 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000004_0
2018-08-08 13:37:55,144 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 7
2018-08-08 13:37:55,144 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000004_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:55,145 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000006 taskAttempt attempt_1533735211869_0003_m_000004_0
2018-08-08 13:37:55,145 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000005_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:55,145 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000004_0
2018-08-08 13:37:55,145 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave7:43383
2018-08-08 13:37:55,145 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000005_0
2018-08-08 13:37:55,145 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000005 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:55,146 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 8
2018-08-08 13:37:55,149 INFO [IPC Server handler 25 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000010_0 is : 1.0
2018-08-08 13:37:55,150 INFO [IPC Server handler 26 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000010_0
2018-08-08 13:37:55,150 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000010_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:55,150 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000012 taskAttempt attempt_1533735211869_0003_m_000010_0
2018-08-08 13:37:55,150 INFO [IPC Server handler 27 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000003_0 is : 1.0
2018-08-08 13:37:55,151 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000010_0
2018-08-08 13:37:55,151 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave14:35219
2018-08-08 13:37:55,152 INFO [IPC Server handler 28 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000003_0
2018-08-08 13:37:55,153 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000003_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:55,153 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000005 taskAttempt attempt_1533735211869_0003_m_000003_0
2018-08-08 13:37:55,153 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000003_0
2018-08-08 13:37:55,154 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave2:43787
2018-08-08 13:37:55,155 INFO [IPC Server handler 29 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000011_0 is : 1.0
2018-08-08 13:37:55,155 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000004_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:55,156 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000004_0
2018-08-08 13:37:55,156 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000004 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:55,156 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 9
2018-08-08 13:37:55,156 INFO [IPC Server handler 0 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000011_0
2018-08-08 13:37:55,157 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000011_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:55,157 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000013 taskAttempt attempt_1533735211869_0003_m_000011_0
2018-08-08 13:37:55,157 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000011_0
2018-08-08 13:37:55,158 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave3:42077
2018-08-08 13:37:55,164 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000010_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:55,165 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000010_0
2018-08-08 13:37:55,165 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000010 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:55,165 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 10
2018-08-08 13:37:55,166 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000003_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:55,166 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000003_0
2018-08-08 13:37:55,166 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000003 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:55,166 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 11
2018-08-08 13:37:55,168 INFO [IPC Server handler 1 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000002_0 is : 1.0
2018-08-08 13:37:55,170 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000011_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:55,170 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000011_0
2018-08-08 13:37:55,170 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000011 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:55,171 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 12
2018-08-08 13:37:55,189 INFO [IPC Server handler 2 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0003_m_000002_0
2018-08-08 13:37:55,189 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000002_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:37:55,190 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0003_m_000002_0 given a go for committing the task output.
2018-08-08 13:37:55,191 INFO [IPC Server handler 3 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0003_m_000002_0
2018-08-08 13:37:55,191 INFO [IPC Server handler 3 on 35241] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0003_m_000002_0:true
2018-08-08 13:37:55,214 INFO [IPC Server handler 4 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000002_0 is : 1.0
2018-08-08 13:37:55,216 INFO [IPC Server handler 5 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000002_0
2018-08-08 13:37:55,216 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000002_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:55,216 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000004 taskAttempt attempt_1533735211869_0003_m_000002_0
2018-08-08 13:37:55,216 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000002_0
2018-08-08 13:37:55,216 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave13:40615
2018-08-08 13:37:55,225 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000002_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:55,225 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000002_0
2018-08-08 13:37:55,225 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000002 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:55,225 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 13
2018-08-08 13:37:55,553 INFO [IPC Server handler 6 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000000_0 is : 1.0
2018-08-08 13:37:55,998 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:10 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:37:56,001 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000004
2018-08-08 13:37:56,001 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000012
2018-08-08 13:37:56,001 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000016
2018-08-08 13:37:56,001 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000008
2018-08-08 13:37:56,001 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000009
2018-08-08 13:37:56,001 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000006
2018-08-08 13:37:56,001 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000007
2018-08-08 13:37:56,001 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000005
2018-08-08 13:37:56,001 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000002_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:56,001 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000013
2018-08-08 13:37:56,001 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:37:56,001 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000010_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:56,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000013_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:56,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000006_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:56,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000007_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:56,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000004_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:56,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000005_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:56,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000003_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:56,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000011_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:57,530 INFO [IPC Server handler 6 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000000_0 is : 1.0
2018-08-08 13:37:57,559 INFO [IPC Server handler 10 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0003_m_000000_0 is : 1.0
2018-08-08 13:37:57,561 INFO [IPC Server handler 7 on 35241] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0003_m_000000_0
2018-08-08 13:37:57,561 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000000_0 TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:37:57,561 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0003_01_000002 taskAttempt attempt_1533735211869_0003_m_000000_0
2018-08-08 13:37:57,562 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0003_m_000000_0
2018-08-08 13:37:57,562 INFO [ContainerLauncher #10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave15:37797
2018-08-08 13:37:57,571 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0003_m_000000_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:37:57,571 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0003_m_000000_0
2018-08-08 13:37:57,571 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0003_m_000000 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:37:57,571 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 14
2018-08-08 13:37:57,572 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0003Job Transitioned from RUNNING to COMMITTING
2018-08-08 13:37:57,573 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_COMMIT
2018-08-08 13:37:57,690 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Calling handler for JobFinishedEvent 
2018-08-08 13:37:57,690 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0003Job Transitioned from COMMITTING to SUCCEEDED
2018-08-08 13:37:57,691 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: We are finishing cleanly so this is the last retry
2018-08-08 13:37:57,691 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true
2018-08-08 13:37:57,691 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: RMCommunicator notified that shouldUnregistered is: true
2018-08-08 13:37:57,691 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true
2018-08-08 13:37:57,691 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true
2018-08-08 13:37:57,691 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
2018-08-08 13:37:57,692 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0
2018-08-08 13:37:57,821 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0003/job_1533735211869_0003_1.jhist to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0003-1533735457826-hduser-GraphalyticsBenchmark%3A+LocalClusteringCoefficientJ-1533735477688-14-0-SUCCEEDED-default-1533735461903.jhist_tmp
2018-08-08 13:37:57,919 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0003-1533735457826-hduser-GraphalyticsBenchmark%3A+LocalClusteringCoefficientJ-1533735477688-14-0-SUCCEEDED-default-1533735461903.jhist_tmp
2018-08-08 13:37:57,922 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0003/job_1533735211869_0003_1_conf.xml to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0003_conf.xml_tmp
2018-08-08 13:37:58,004 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:14 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:37:58,008 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0003_01_000002
2018-08-08 13:37:58,008 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:14 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:37:58,008 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0003_m_000000_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:37:58,022 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0003_conf.xml_tmp
2018-08-08 13:37:58,026 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0003.summary_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0003.summary
2018-08-08 13:37:58,028 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0003_conf.xml_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0003_conf.xml
2018-08-08 13:37:58,030 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0003-1533735457826-hduser-GraphalyticsBenchmark%3A+LocalClusteringCoefficientJ-1533735477688-14-0-SUCCEEDED-default-1533735461903.jhist_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0003-1533735457826-hduser-GraphalyticsBenchmark%3A+LocalClusteringCoefficientJ-1533735477688-14-0-SUCCEEDED-default-1533735461903.jhist
2018-08-08 13:37:58,031 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()
2018-08-08 13:37:58,036 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Setting job diagnostics to 
2018-08-08 13:37:58,037 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: History url is http://graphalytics-giraph-slave10:19888/jobhistory/job/job_1533735211869_0003
2018-08-08 13:37:58,043 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Waiting for application to be successfully unregistered.
2018-08-08 13:37:59,045 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:14 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:37:59,046 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://graphalytics-giraph:9000 /tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0003
2018-08-08 13:37:59,050 INFO [Thread-94] org.apache.hadoop.ipc.Server: Stopping server on 35241
2018-08-08 13:37:59,051 INFO [IPC Server listener on 35241] org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 35241
2018-08-08 13:37:59,052 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-08-08 13:37:59,052 INFO [TaskHeartbeatHandler PingChecker] org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted
End of LogType:syslog



Container: container_1533735211869_0003_01_000008 on graphalytics-giraph-slave11_46641
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:19548
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 795 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 313 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,804.00
               min = 16.00
               max = 6651.00
              mean = 119.56
            stddev = 733.21
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2409.84
              99% <= 6651.00
            99.9% <= 6651.00
             count = 82

  remote-requests:
    count = 0

  requests-received:
             count = 82
         mean rate = 101.38 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 121.41 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.63
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 795

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 313

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 101 ms
  compute all partitions: 16 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 2585 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 16

  compute-per-partition-ms:
               sum = 47.00
               min = 0.00
               max = 5.00
              mean = 1.42
            stddev = 1.39
            median = 2.00
              75% <= 2.50
              95% <= 3.60
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 129

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 47.00
               min = 2.00
               max = 5.00
              mean = 4.27
            stddev = 1.01
            median = 5.00
              75% <= 5.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,963.00
               min = 16.00
               max = 6651.00
              mean = 157.25
            stddev = 875.97
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5601.08
              99% <= 6651.00
            99.9% <= 6651.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 394.16 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 401.11 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,810.00
               min = 16.00
               max = 1473.00
              mean = 65.69
            stddev = 190.26
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 101

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 2585

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 64 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 3915 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 10.00
               min = 0.00
               max = 6.00
              mean = 0.30
            stddev = 1.07
            median = 0.00
              75% <= 0.00
              95% <= 2.50
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 435

  messages-sent:
    count = 5

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 10.00
               min = 0.00
               max = 6.00
              mean = 0.91
            stddev = 1.81
            median = 0.00
              75% <= 1.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 9,263.00
               min = 16.00
               max = 6651.00
              mean = 151.85
            stddev = 854.93
            median = 16.00
              75% <= 82.50
              95% <= 91.70
              98% <= 5076.84
              99% <= 6651.00
            99.9% <= 6651.00
             count = 61

  remote-requests:
    count = 5

  requests-received:
             count = 61
         mean rate = 578.74 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 62
         mean rate = 588.10 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 5

  sent-bytes:
               sum = 4,158.00
               min = 16.00
               max = 1473.00
              mean = 67.06
            stddev = 184.30
            median = 20.50
              75% <= 89.00
              95% <= 92.00
              98% <= 1113.94
              99% <= 1473.00
            99.9% <= 1473.00
             count = 62

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 64

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 5

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 3915

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 136 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 164 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 1.00
              mean = 0.15
            stddev = 0.36
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 195

  messages-sent:
    count = 5

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.45
            stddev = 0.69
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 9,071.00
               min = 16.00
               max = 6651.00
              mean = 148.70
            stddev = 847.10
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5076.12
              99% <= 6651.00
            99.9% <= 6651.00
             count = 61

  remote-requests:
    count = 5

  requests-received:
             count = 61
         mean rate = 355.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 62
         mean rate = 361.37 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 5

  sent-bytes:
               sum = 3,918.00
               min = 16.00
               max = 1473.00
              mean = 63.19
            stddev = 184.17
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1113.16
              99% <= 1473.00
            99.9% <= 1473.00
             count = 62

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 136

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 5

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 164

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 140 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 216 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.27
            stddev = 0.47
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 925.88
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 292.78 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 298.50 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 140

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 216

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.9566441005744

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:67879
Log Contents:
2018-08-08 13:37:45,440 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,503 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,503 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,505 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,505 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,675 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:45,887 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,062 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,510 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,522 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,668 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,683 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,711 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,711 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,719 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,725 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,725 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 6 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,731 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,731 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave11
INFO    2018-08-08 13:37:46,731 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,731 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,731 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,731 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000008:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000008/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,731 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000008:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,731 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000008/tmp
INFO    2018-08-08 13:37:46,731 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,731 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,731 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,732 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,732 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,732 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,732 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000008
INFO    2018-08-08 13:37:46,732 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,745 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,746 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,752 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3001e, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,753 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:46,860 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:46,876 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:46,925 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave11/10.164.0.13:30006 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:46,929 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:46,930 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:46,951 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:46,962 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:46,965 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:46,968 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:46,974 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave11_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=6, port=30006)
INFO    2018-08-08 13:37:47,368 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,460 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,468 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,469 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,472 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,473 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,473 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,474 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,475 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,477 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,477 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,484 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,487 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,488 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,490 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,490 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,491 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,495 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,495 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,495 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,495 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,560 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,618 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.057281706 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05125152 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050325368 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.049514044 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048266664 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047679897 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04704231 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,619 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046381883 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,619 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045437705 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,619 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044522423 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,619 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044588353 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,622 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.054
MBytes/sec sent = 0.0048, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.055
INFO    2018-08-08 13:37:47,624 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,630 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004430463 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,630 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004734469 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,630 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 8.81001E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004886052 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,633 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005458315 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,633 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005049889 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,633 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004966673 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,634 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.007604306 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,634 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00422333 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,634 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003849022 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003697114 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,636 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.014, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0219, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.011
INFO    2018-08-08 13:37:47,636 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:37:47,671 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,675 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,684 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,685 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.81M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,686 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0028, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.061
MBytes/sec sent = 0.0042, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.061
INFO    2018-08-08 13:37:47,686 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,696 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,696 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.81M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,708 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,749 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,754 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@55120f99,outgoing=org.apache.giraph.conf.DefaultMessageClasses@794b435f)
WARN    2018-08-08 13:37:47,759 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,772 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,772 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,774 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave11_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=6, port=30006)
INFO    2018-08-08 13:37:47,824 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,825 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,825 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,826 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.13
MBytes/sec sent = 0.0107, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.13
INFO    2018-08-08 13:37:47,829 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,831 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,831 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:37:47,840 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,852 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006846985 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,853 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011486322 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,853 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006562756 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,853 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009596718 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,853 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010610063 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,853 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004224026 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,853 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008859478 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,853 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009355967 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,853 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005932333 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,853 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007661116 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,853 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004735077 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,857 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50569.20M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,860 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0196, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 13:37:47,860 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,867 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:37:47,868 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 3 , message bytes = 129 , Memory (free/total/max) = 50569.20M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,873 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,904 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,906 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@73aff8f1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf)
INFO    2018-08-08 13:37:47,914 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,916 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave11_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=6, port=30006)
INFO    2018-08-08 13:37:47,953 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,954 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,954 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,956 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.088
MBytes/sec sent = 0.0158, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.088
INFO    2018-08-08 13:37:47,958 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,959 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,961 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,965 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002047307 secs for 9 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00258216 secs for 21 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001537033 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001366867 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,966 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002607499 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001744955 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002324215 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001540508 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,968 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00144085 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,969 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001975302 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,969 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008224893 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,970 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50428.40M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,974 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0877, MBytesSent = 0.0004, ave sent req MBytes = 0.0001, secs waited = 0.004
INFO    2018-08-08 13:37:47,974 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,978 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:47,979 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 5 , message bytes = 435 , Memory (free/total/max) = 50428.40M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,984 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,011 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,014 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4a1e3ac1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5)
INFO    2018-08-08 13:37:48,020 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,037 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave11_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=6, port=30006)
WARN    2018-08-08 13:37:48,100 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,128 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,128 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,128 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,129 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:37:48,132 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,135 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,139 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,144 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004336773 secs for 11 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,144 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001293137 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,144 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002424904 secs for 12 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,144 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001526003 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,144 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001900136 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,145 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001256221 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,145 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00136988 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,148 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001251627 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,149 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001911795 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,149 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004190331 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,149 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001450613 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,149 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.60M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,149 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0127, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.035, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:48,149 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,156 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0283, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0901, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 13:37:48,156 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 5 , message bytes = 195 , Memory (free/total/max) = 50287.60M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,161 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,185 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,188 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4248ed58,outgoing=org.apache.giraph.conf.DefaultMessageClasses@712ca57b)
INFO    2018-08-08 13:37:48,193 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,211 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave11_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=6, port=30006)
INFO    2018-08-08 13:37:48,228 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,277 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,306 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,306 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,307 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,307 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.151
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.151
INFO    2018-08-08 13:37:48,312 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,314 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,319 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,323 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002770965 secs for 15 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,323 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003506837 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,323 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001774627 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,323 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002325936 secs for 10 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,324 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002400136 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,326 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004134217 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,326 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004431424 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,327 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004166034 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,327 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004230279 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,327 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00350753 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,327 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003369663 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,328 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50146.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,328 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:37:48,328 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,334 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:48,334 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50146.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,340 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,361 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,364 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@1623bbe5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7af1cd63)
INFO    2018-08-08 13:37:48,368 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,368 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,368 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,370 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:48,397 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,444 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,450 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,453 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,675 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,675 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:37:50,679 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,864 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,864 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,866 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/6_worker
INFO    2018-08-08 13:37:50,868 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3001e closed
INFO    2018-08-08 13:37:50,868 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,870 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,873 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:55,087 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:55,092 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000006_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:55,115 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000006_0 is allowed to commit now
INFO    2018-08-08 13:37:55,123 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000006_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000006
INFO    2018-08-08 13:37:55,141 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000006_0' done.
INFO    2018-08-08 13:37:55,146 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000006_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128704
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=91
		CPU time spent (ms)=4650
		Physical memory (bytes) snapshot=1112293376
		Virtual memory (bytes) snapshot=58915143680
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000016 on graphalytics-giraph-slave12_33893
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:19537
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 612 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 668 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,673.00
               min = 16.00
               max = 6651.00
              mean = 117.96
            stddev = 730.94
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2327.34
              99% <= 6651.00
            99.9% <= 6651.00
             count = 82

  remote-requests:
    count = 0

  requests-received:
             count = 82
         mean rate = 130.69 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 96
         mean rate = 153.49 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,520.00
               min = 16.00
               max = 1473.00
              mean = 47.08
            stddev = 149.14
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 172.04
              99% <= 1473.00
            99.9% <= 1473.00
             count = 96

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 612

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 668

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 103 ms
  compute all partitions: 18 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 954 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 18

  compute-per-partition-ms:
               sum = 50.00
               min = 0.00
               max = 3.00
              mean = 1.52
            stddev = 1.20
            median = 2.00
              75% <= 3.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 50.00
               min = 2.00
               max = 6.00
              mean = 4.55
            stddev = 1.69
            median = 5.00
              75% <= 6.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 928.01
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 353.52 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 360.42 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.68
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 103

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 954

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 66 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 216 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 1.00
              mean = 0.15
            stddev = 0.36
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.67
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 926.29
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 486.38 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 495.90 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 66

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 216

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 135 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 300 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.12
            stddev = 0.33
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.67
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 926.02
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 298.72 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 304.64 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 135

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 300

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 141 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 169 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.03
            stddev = 0.17
            median = 0.00
              75% <= 0.00
              95% <= 0.30
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 925.88
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 291.31 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 297.00 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 141

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 169

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.29722608498993

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:67712
Log Contents:
2018-08-08 13:37:45,533 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,601 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,602 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,604 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,604 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,787 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:46,019 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,207 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,675 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,687 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,837 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,853 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,881 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,882 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,891 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,898 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,898 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 13 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,904 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,904 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave12
INFO    2018-08-08 13:37:46,904 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,904 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,904 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,904 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000016:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000016/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,905 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000016:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,905 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000016/tmp
INFO    2018-08-08 13:37:46,905 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,905 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,905 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,905 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,905 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,905 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,905 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000016
INFO    2018-08-08 13:37:46,906 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,919 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,919 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,925 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30027, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,926 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:47,031 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:47,048 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:47,102 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave12/10.164.0.14:30013 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:47,106 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:47,108 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:47,127 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:47,138 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:47,141 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,144 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,150 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave12_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=13, port=30013)
INFO    2018-08-08 13:37:47,363 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,461 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,470 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,471 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,471 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,473 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,473 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,474 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,475 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,475 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,484 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,487 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,488 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,488 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,488 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,494 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,560 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,611 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.049217097 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,626 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05776841 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,626 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.057057552 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,631 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.061395895 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,631 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.06097152 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.060519498 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.059821557 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.059495904 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,633 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05909988 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,633 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.058660183 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,633 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.058069944 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0025, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.139
MBytes/sec sent = 0.0091, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.139
INFO    2018-08-08 13:37:47,636 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,639 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003320705 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,641 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003270628 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,641 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003279503 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,642 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003295479 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,643 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002953504 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,644 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002876839 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,645 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002824354 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,646 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002636175 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,646 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002866187 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,648 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003527486 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,648 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00426188 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,649 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:37:47,649 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:37:47,665 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,670 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:37:47,671 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50863.58M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,672 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0011, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.026
MBytes/sec sent = 0.0018, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.026
INFO    2018-08-08 13:37:47,672 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,690 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,691 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50863.58M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,702 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,743 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,748 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4fcc529,outgoing=org.apache.giraph.conf.DefaultMessageClasses@25cc7470)
WARN    2018-08-08 13:37:47,752 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,768 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,769 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,772 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave12_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=13, port=30013)
INFO    2018-08-08 13:37:47,821 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,821 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,821 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,822 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.131
MBytes/sec sent = 0.0106, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.131
INFO    2018-08-08 13:37:47,825 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,826 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,834 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,849 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004496708 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003905806 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007182411 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011405735 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010686538 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003704117 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010425882 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012947082 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009704558 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008935907 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006306725 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,854 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50722.78M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,855 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0065, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.027
MBytes/sec sent = 0.0351, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.028
INFO    2018-08-08 13:37:47,855 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,864 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.022, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.008
MBytes/sec sent = 0.07, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.009
INFO    2018-08-08 13:37:47,864 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.78M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,868 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,899 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,901 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@40620d8e)
INFO    2018-08-08 13:37:47,908 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,911 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave12_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=13, port=30013)
INFO    2018-08-08 13:37:47,947 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,948 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,948 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,949 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.085
MBytes/sec sent = 0.0163, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.085
INFO    2018-08-08 13:37:47,952 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,953 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,956 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,960 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00247978 secs for 12 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002077088 secs for 5 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003263451 secs for 14 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001452111 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001784487 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00190417 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002509841 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003196829 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004764916 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003649545 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004429568 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50581.97M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,966 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:37:47,966 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,974 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,974 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50581.97M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,981 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,005 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,008 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7d151a)
INFO    2018-08-08 13:37:48,014 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,034 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave12_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=13, port=30013)
INFO    2018-08-08 13:37:48,047 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,094 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,123 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,124 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,124 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,125 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.151
INFO    2018-08-08 13:37:48,129 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,130 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,132 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,137 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001720587 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001226025 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004541125 secs for 10 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00258109 secs for 7 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002196227 secs for 14 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00194469 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,140 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003045326 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,140 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001856429 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002319827 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002830801 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002269218 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50428.37M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,142 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0166, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0926, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.01
INFO    2018-08-08 13:37:48,142 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,149 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,149 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50428.37M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,152 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,179 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,182 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@54534abf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@51745f40)
INFO    2018-08-08 13:37:48,186 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,205 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave12_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=13, port=30013)
INFO    2018-08-08 13:37:48,222 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,271 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,301 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,301 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,301 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,302 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.153
MBytes/sec sent = 0.0091, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.153
INFO    2018-08-08 13:37:48,307 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,308 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,312 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,315 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002108985 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,315 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001679123 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,315 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00252952 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003284202 secs for 29 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,318 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003538458 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,319 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004204355 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,319 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004245657 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,319 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00403702 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004380725 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003947948 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004477841 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50287.57M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,321 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:37:48,321 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,328 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,328 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.57M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,334 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,355 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,358 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@37d00a23)
INFO    2018-08-08 13:37:48,362 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,362 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,362 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,364 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:48,391 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,438 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,444 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,446 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,668 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,669 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 13:37:50,672 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,707 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,708 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,710 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/13_worker
INFO    2018-08-08 13:37:50,712 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30027 closed
INFO    2018-08-08 13:37:50,712 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,714 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,717 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:54,930 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:54,932 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000013_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:54,955 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000013_0 is allowed to commit now
INFO    2018-08-08 13:37:54,964 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000013_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000013
INFO    2018-08-08 13:37:54,980 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000013_0' done.
INFO    2018-08-08 13:37:54,985 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000013_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128705
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=93
		CPU time spent (ms)=4360
		Physical memory (bytes) snapshot=1052270592
		Virtual memory (bytes) snapshot=58894950400
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000004 on graphalytics-giraph-slave13_40615
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:19548
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 717 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 272 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,788.00
               min = 16.00
               max = 6651.00
              mean = 113.81
            stddev = 713.81
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1840.26
              99% <= 6651.00
            99.9% <= 6651.00
             count = 86

  remote-requests:
    count = 0

  requests-received:
             count = 86
         mean rate = 117.65 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 134.27 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.69
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 717

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 272

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 100 ms
  compute all partitions: 14 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 2562 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 14

  compute-per-partition-ms:
               sum = 33.00
               min = 0.00
               max = 4.00
              mean = 1.00
            stddev = 1.14
            median = 1.00
              75% <= 2.00
              95% <= 3.30
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 86

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 32.00
               min = 0.00
               max = 6.00
              mean = 2.91
            stddev = 1.87
            median = 3.00
              75% <= 4.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,899.00
               min = 16.00
               max = 6562.00
              mean = 158.91
            stddev = 873.40
            median = 32.00
              75% <= 80.00
              95% <= 89.00
              98% <= 5655.78
              99% <= 6562.00
            99.9% <= 6562.00
             count = 56

  remote-requests:
    count = 2

  requests-received:
             count = 56
         mean rate = 389.99 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 389.87 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,746.00
               min = 16.00
               max = 1473.00
              mean = 66.89
            stddev = 193.55
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 100

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 2562

  worker-context-post-superstep:
    value = 6

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 64 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 319 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 16.00
               min = 0.00
               max = 7.00
              mean = 0.48
            stddev = 1.28
            median = 0.00
              75% <= 1.00
              95% <= 3.50
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 213

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 16.00
               min = 0.00
               max = 7.00
              mean = 1.45
            stddev = 2.42
            median = 0.00
              75% <= 4.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 9,079.00
               min = 16.00
               max = 6562.00
              mean = 156.53
            stddev = 868.22
            median = 34.50
              75% <= 89.00
              95% <= 92.00
              98% <= 5397.40
              99% <= 6562.00
            99.9% <= 6562.00
             count = 58

  remote-requests:
    count = 3

  requests-received:
             count = 58
         mean rate = 561.01 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 560.93 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,894.00
               min = 16.00
               max = 1473.00
              mean = 67.14
            stddev = 190.29
            median = 20.50
              75% <= 76.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 64

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 319

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 135 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 211 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 117

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,951.00
               min = 16.00
               max = 6562.00
              mean = 154.33
            stddev = 893.56
            median = 30.00
              75% <= 62.00
              95% <= 89.00
              98% <= 5396.86
              99% <= 6562.00
            99.9% <= 6562.00
             count = 58

  remote-requests:
    count = 3

  requests-received:
             count = 58
         mean rate = 339.22 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 339.06 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,798.00
               min = 16.00
               max = 1473.00
              mean = 65.48
            stddev = 190.27
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 135

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 211

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 142 ms
  compute all partitions: 6 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 139 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 6

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 926.36
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 291.46 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 297.15 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 142

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 139

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.95680262572574

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:67849
Log Contents:
2018-08-08 13:37:45,449 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,510 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,510 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,512 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,512 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,683 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:45,901 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,087 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,550 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,562 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,712 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,728 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,758 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,759 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,770 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,781 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,781 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 2 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,789 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,789 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave13
INFO    2018-08-08 13:37:46,789 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,789 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,789 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,789 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000004:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000004/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,790 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000004:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,790 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000004/tmp
INFO    2018-08-08 13:37:46,790 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,790 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,790 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,790 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,790 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,790 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,790 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000004
INFO    2018-08-08 13:37:46,791 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,808 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,808 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,815 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30022, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,817 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:46,927 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:46,944 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:46,995 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave13/10.164.0.15:30002 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:47,000 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:47,001 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:47,022 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:47,031 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:47,034 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,037 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,042 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave13_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=2, port=30002)
INFO    2018-08-08 13:37:47,361 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,453 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,463 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,464 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,466 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,469 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,469 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,470 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,470 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,471 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,471 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,473 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,473 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,473 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,473 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,474 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,475 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,479 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,551 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,593 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041345425 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,605 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047734696 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,605 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047413673 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,606 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046990193 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,606 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046764705 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,607 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04659319 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,607 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04598375 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,607 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04525483 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,608 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04478028 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,609 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04552858 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,611 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046683706 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,611 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.054
MBytes/sec sent = 0.0048, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.054
INFO    2018-08-08 13:37:47,612 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,616 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00307731 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002854367 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002890221 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002983889 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,620 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003799055 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,621 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00475298 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,622 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004859499 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,622 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004034939 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,623 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003612009 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,625 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005225591 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,625 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004448649 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,625 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.014, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0219, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.011
INFO    2018-08-08 13:37:47,626 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:37:47,664 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,668 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,676 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,677 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,677 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0026, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0041, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.063
INFO    2018-08-08 13:37:47,678 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,688 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,688 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,697 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,742 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,747 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@38f2e97e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@779dfe55)
WARN    2018-08-08 13:37:47,751 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,765 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,766 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,768 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave13_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=2, port=30002)
INFO    2018-08-08 13:37:47,817 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,817 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,817 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,818 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.13
MBytes/sec sent = 0.0107, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.13
INFO    2018-08-08 13:37:47,820 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,824 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:37:47,831 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,842 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00138041 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,842 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004202577 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,842 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00226217 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,843 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006920898 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,843 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009550392 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010863734 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007277458 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005300682 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009622569 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,845 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004966556 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,845 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007452022 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,846 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,848 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0183, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:37:47,848 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,860 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:37:47,861 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 2 , message bytes = 86 , Memory (free/total/max) = 50582.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,867 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,897 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,899 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@27ead29e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f)
INFO    2018-08-08 13:37:47,907 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,909 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave13_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=2, port=30002)
INFO    2018-08-08 13:37:47,946 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,946 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,946 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,947 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.086
MBytes/sec sent = 0.0161, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.086
INFO    2018-08-08 13:37:47,949 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,950 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,954 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,960 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00386566 secs for 8 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003226111 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00494881 secs for 16 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004368471 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005833633 secs for 6 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003649279 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004504293 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002750967 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003591615 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008897552 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004776335 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,964 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,965 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0229, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0725, MBytesSent = 0.0002, ave sent req MBytes = 0.0001, secs waited = 0.002
INFO    2018-08-08 13:37:47,965 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,971 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:47,971 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 3 , message bytes = 213 , Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,976 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,004 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,007 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@56febdc,outgoing=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898)
INFO    2018-08-08 13:37:48,012 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,030 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave13_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=2, port=30002)
WARN    2018-08-08 13:37:48,092 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,120 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,120 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,121 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,121 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:37:48,123 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,128 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,128 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:37:48,131 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,135 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00187424 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,135 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003904336 secs for 13 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,136 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002324433 secs for 13 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,136 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001461623 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,136 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001306861 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001037145 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001486302 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00105577 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001361068 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001762202 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001248314 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,140 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,140 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0092, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0252, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:37:48,140 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,148 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:48,148 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 3 , message bytes = 117 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,151 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,178 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,180 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4564e94b,outgoing=org.apache.giraph.conf.DefaultMessageClasses@54534abf)
INFO    2018-08-08 13:37:48,184 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,202 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave13_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=2, port=30002)
INFO    2018-08-08 13:37:48,220 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,270 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,299 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,299 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,299 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,300 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.152
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.152
INFO    2018-08-08 13:37:48,305 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,306 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,310 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,313 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002084416 secs for 14 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,313 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001704087 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,313 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002757977 secs for 16 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,313 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001289439 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,314 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001490109 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,314 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00127947 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,314 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001264496 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,315 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001270744 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,315 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 9.74588E-4 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,315 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 9.0431E-4 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001528317 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50146.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,317 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0183, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0926, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.01
INFO    2018-08-08 13:37:48,317 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,326 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,326 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50146.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,329 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,354 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,356 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4351171a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1)
INFO    2018-08-08 13:37:48,360 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,360 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,360 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,362 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
WARN    2018-08-08 13:37:48,437 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,442 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,444 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,766 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,766 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:37:50,769 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,946 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,946 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,948 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/2_worker
INFO    2018-08-08 13:37:50,950 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30022 closed
INFO    2018-08-08 13:37:50,950 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,952 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,956 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:55,167 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:55,171 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000002_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:55,193 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000002_0 is allowed to commit now
INFO    2018-08-08 13:37:55,202 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000002_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000002
INFO    2018-08-08 13:37:55,218 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000002_0' done.
INFO    2018-08-08 13:37:55,223 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000002_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128704
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=21
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=98
		CPU time spent (ms)=4520
		Physical memory (bytes) snapshot=1099636736
		Virtual memory (bytes) snapshot=58902863872
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000012 on graphalytics-giraph-slave14_35219
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:19546
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 938 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 281 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,772.00
               min = 16.00
               max = 6651.00
              mean = 117.73
            stddev = 726.64
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2281.32
              99% <= 6651.00
            99.9% <= 6651.00
             count = 83

  remote-requests:
    count = 0

  requests-received:
             count = 83
         mean rate = 85.62 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 101.19 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.66
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 938

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 281

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 83 ms
  compute all partitions: 16 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 3282 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 16

  compute-per-partition-ms:
               sum = 48.00
               min = 0.00
               max = 5.00
              mean = 1.45
            stddev = 1.07
            median = 2.00
              75% <= 2.00
              95% <= 3.60
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 43

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 47.00
               min = 2.00
               max = 5.00
              mean = 4.27
            stddev = 1.19
            median = 5.00
              75% <= 5.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,787.00
               min = 16.00
               max = 6651.00
              mean = 168.98
            stddev = 936.50
            median = 16.00
              75% <= 80.00
              95% <= 89.00
              98% <= 6257.28
              99% <= 6651.00
            99.9% <= 6651.00
             count = 52

  remote-requests:
    count = 1

  requests-received:
             count = 52
         mean rate = 411.68 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 419.41 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,666.00
               min = 16.00
               max = 1473.00
              mean = 69.17
            stddev = 198.78
            median = 25.00
              75% <= 71.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 83

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 3282

  worker-context-post-superstep:
    value = 6

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 64 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 165 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 8.00
               min = 0.00
               max = 1.00
              mean = 0.24
            stddev = 0.44
            median = 0.00
              75% <= 0.50
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 8.00
               min = 0.00
               max = 2.00
              mean = 0.73
            stddev = 1.01
            median = 0.00
              75% <= 2.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,863.00
               min = 16.00
               max = 6651.00
              mean = 170.44
            stddev = 921.06
            median = 34.50
              75% <= 89.00
              95% <= 90.05
              98% <= 6257.46
              99% <= 6651.00
            99.9% <= 6651.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 509.17 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 519.44 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,634.00
               min = 16.00
               max = 1473.00
              mean = 68.57
            stddev = 198.90
            median = 16.00
              75% <= 71.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 64

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 165

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 136 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 160 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 11.00
               min = 0.00
               max = 4.00
              mean = 0.33
            stddev = 0.82
            median = 0.00
              75% <= 0.00
              95% <= 2.60
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 39

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 10.00
               min = 0.00
               max = 4.00
              mean = 0.91
            stddev = 1.58
            median = 0.00
              75% <= 1.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,787.00
               min = 16.00
               max = 6651.00
              mean = 168.98
            stddev = 918.31
            median = 16.00
              75% <= 80.00
              95% <= 89.00
              98% <= 6257.28
              99% <= 6651.00
            99.9% <= 6651.00
             count = 52

  remote-requests:
    count = 1

  requests-received:
             count = 52
         mean rate = 302.40 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 308.26 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,662.00
               min = 16.00
               max = 1473.00
              mean = 69.09
            stddev = 198.86
            median = 25.00
              75% <= 71.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 136

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 160

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 140 ms
  compute all partitions: 13 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 212 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 13

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 925.88
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 292.23 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 297.99 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 140

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 212

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.95681134163608

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:67652
Log Contents:
2018-08-08 13:37:45,376 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,435 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,435 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,437 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,437 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,590 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:45,801 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:45,958 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,383 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,394 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,528 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,540 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,565 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,565 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,572 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,578 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,578 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 10 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave14
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000012:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000012/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000012:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000012/tmp
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,584 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000012
INFO    2018-08-08 13:37:46,585 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,596 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,596 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,603 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3001c, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,604 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:46,705 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:46,721 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:46,773 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave14/10.164.0.16:30010 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:46,777 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:46,778 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:46,805 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:46,814 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:46,824 [main-EventThread] org.apache.giraph.bsp.BspService  - process: applicationAttemptChanged signaled
WARN    2018-08-08 13:37:46,838 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:46,843 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave14_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010)
INFO    2018-08-08 13:37:47,363 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,454 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,461 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,463 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,464 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,466 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,466 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,466 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,466 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,467 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,470 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,472 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,473 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,484 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,487 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,487 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,488 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,490 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,491 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,491 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,491 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,491 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,583 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,610 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.025797728 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,610 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0190268 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,612 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.019050036 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,612 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0186628 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.017768532 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.014810329 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.014228515 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.013650236 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.013235093 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.012796811 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.01180498 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,624 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.032
MBytes/sec sent = 0.0079, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.032
INFO    2018-08-08 13:37:47,625 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,628 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002853386 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,629 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00213829 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004469818 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004506245 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,633 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 7.73626E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,634 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004579638 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,634 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004150976 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,634 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003712455 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003994868 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003511037 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006719038 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,636 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0186, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.009
MBytes/sec sent = 0.0262, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.009
INFO    2018-08-08 13:37:47,636 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:37:47,666 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,669 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,676 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,677 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,678 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0033, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.051
MBytes/sec sent = 0.005, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.051
INFO    2018-08-08 13:37:47,678 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,691 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:47,691 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50710.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,700 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,745 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,749 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@38f2e97e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@779dfe55)
INFO    2018-08-08 13:37:47,785 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,785 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,789 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave14_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010)
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,825 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.133
MBytes/sec sent = 0.0105, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.133
INFO    2018-08-08 13:37:47,827 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,828 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,834 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,848 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00904749 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006633512 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005216662 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004462503 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007527616 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008292879 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009647371 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0102283 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007732073 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012316292 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004745738 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50569.29M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,854 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0025, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0076, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:47,855 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,863 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:37:47,864 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 1 , message bytes = 43 , Memory (free/total/max) = 50569.29M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,869 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,900 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,902 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@27ead29e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f)
INFO    2018-08-08 13:37:47,910 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,913 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave14_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010)
INFO    2018-08-08 13:37:47,949 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,950 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,950 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,951 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.087
MBytes/sec sent = 0.016, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.087
INFO    2018-08-08 13:37:47,953 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,954 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,957 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,961 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004064554 secs for 10 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003367446 secs for 8 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003119108 secs for 11 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002585906 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003254745 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002089266 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001857081 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002635239 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001734616 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001613162 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001848445 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50428.49M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,967 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:37:47,967 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,974 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:47,974 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50428.49M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,979 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,007 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,008 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@56febdc,outgoing=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898)
INFO    2018-08-08 13:37:48,015 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,034 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave14_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010)
INFO    2018-08-08 13:37:48,048 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,096 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,124 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,124 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,124 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,125 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.151
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.151
INFO    2018-08-08 13:37:48,128 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,131 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,134 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,141 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004590537 secs for 16 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004228339 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003379026 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006073295 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003659082 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003416866 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001366036 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,144 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002531745 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,145 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003812835 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,145 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003516897 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,146 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003230819 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,146 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,146 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0025, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.007, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:48,146 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,151 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0331, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.1051, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:48,152 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 1 , message bytes = 39 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,157 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,181 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,183 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4564e94b,outgoing=org.apache.giraph.conf.DefaultMessageClasses@54534abf)
INFO    2018-08-08 13:37:48,189 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,206 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave14_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010)
INFO    2018-08-08 13:37:48,224 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,273 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,302 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,302 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,302 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,304 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.152
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.152
INFO    2018-08-08 13:37:48,309 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,310 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,313 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,316 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002623615 secs for 20 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001718495 secs for 13 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,317 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001403375 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004884 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005339302 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,322 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005298148 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,322 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005149447 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,322 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005689588 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,325 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003601613 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,325 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00296896 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,326 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003825112 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50146.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0108, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.016
MBytes/sec sent = 0.0599, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.016
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,329 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0661, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.2101, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:48,329 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50146.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,335 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,357 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,360 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4351171a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1)
INFO    2018-08-08 13:37:48,363 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,363 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,364 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,366 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:48,393 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,440 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,446 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,448 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,670 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,670 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:37:50,674 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,877 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,877 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,879 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/10_worker
INFO    2018-08-08 13:37:50,881 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3001c closed
INFO    2018-08-08 13:37:50,882 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,884 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,887 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:55,100 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:55,104 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000010_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:55,129 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000010_0 is allowed to commit now
INFO    2018-08-08 13:37:55,138 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000010_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000010
INFO    2018-08-08 13:37:55,155 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000010_0' done.
INFO    2018-08-08 13:37:55,160 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000010_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128705
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=6
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=92
		CPU time spent (ms)=4460
		Physical memory (bytes) snapshot=1114865664
		Virtual memory (bytes) snapshot=58894225408
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000002 on graphalytics-giraph-slave15_37797
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:04 +0000 2018
LogLength:6820
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
superstep time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave13_2
  largest: 0 ms from graphalytics-giraph-slave13_2
compute all partitions
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave13_2
  largest: 0 ms from graphalytics-giraph-slave13_2
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave13_2
  largest: 0 ms from graphalytics-giraph-slave13_2
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave13_2
  largest: 0 us from graphalytics-giraph-slave13_2
wait requests time
  mean: 345.9230769230769 us
  smallest: 668 us from graphalytics-giraph-slave12_13
  largest: 262 us from graphalytics-giraph-slave8_12
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave13_2
  largest: 0 bytes from graphalytics-giraph-slave13_2
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave13_2
  largest: 0 bytes from graphalytics-giraph-slave13_2
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave13_2
  largest: 100.0 % from graphalytics-giraph-slave13_2

--- METRICS: superstep 0 ---
superstep time
  mean: 99.46153846153847 ms
  smallest: 104 ms from graphalytics-giraph-slave8_12
  largest: 83 ms from graphalytics-giraph-slave14_10
compute all partitions
  mean: 16.692307692307693 ms
  smallest: 19 ms from graphalytics-giraph-slave5_5
  largest: 14 ms from graphalytics-giraph-slave13_2
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave13_2
  largest: 0 ms from graphalytics-giraph-slave13_2
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave13_2
  largest: 0 us from graphalytics-giraph-slave13_2
wait requests time
  mean: 1993.923076923077 us
  smallest: 4713 us from graphalytics-giraph-slave6_7
  largest: 226 us from graphalytics-giraph-slave3_11
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave13_2
  largest: 0 bytes from graphalytics-giraph-slave13_2
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave13_2
  largest: 0 bytes from graphalytics-giraph-slave13_2
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave13_2
  largest: 100.0 % from graphalytics-giraph-slave13_2

--- METRICS: superstep 1 ---
superstep time
  mean: 63.46153846153846 ms
  smallest: 66 ms from graphalytics-giraph-slave12_13
  largest: 59 ms from graphalytics-giraph-slave4_8
compute all partitions
  mean: 9.846153846153847 ms
  smallest: 14 ms from graphalytics-giraph-slave9_9
  largest: 7 ms from graphalytics-giraph-slave8_12
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave13_2
  largest: 0 ms from graphalytics-giraph-slave13_2
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave13_2
  largest: 0 us from graphalytics-giraph-slave13_2
wait requests time
  mean: 982.2307692307693 us
  smallest: 3915 us from graphalytics-giraph-slave11_6
  largest: 165 us from graphalytics-giraph-slave14_10
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave13_2
  largest: 0 bytes from graphalytics-giraph-slave13_2
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave13_2
  largest: 0 bytes from graphalytics-giraph-slave13_2
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave13_2
  largest: 100.0 % from graphalytics-giraph-slave13_2

--- METRICS: superstep 2 ---
superstep time
  mean: 135.46153846153845 ms
  smallest: 137 ms from graphalytics-giraph-slave3_11
  largest: 134 ms from graphalytics-giraph-slave6_7
compute all partitions
  mean: 9.846153846153847 ms
  smallest: 12 ms from graphalytics-giraph-slave5_5
  largest: 7 ms from graphalytics-giraph-slave8_12
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave13_2
  largest: 0 ms from graphalytics-giraph-slave13_2
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave13_2
  largest: 0 us from graphalytics-giraph-slave13_2
wait requests time
  mean: 209.23076923076923 us
  smallest: 450 us from graphalytics-giraph-slave7_4
  largest: 148 us from graphalytics-giraph-slave6_7
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave13_2
  largest: 0 bytes from graphalytics-giraph-slave13_2
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave13_2
  largest: 0 bytes from graphalytics-giraph-slave13_2
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave13_2
  largest: 100.0 % from graphalytics-giraph-slave13_2

--- METRICS: superstep 3 ---
superstep time
  mean: 139.92307692307693 ms
  smallest: 142 ms from graphalytics-giraph-slave13_2
  largest: 137 ms from graphalytics-giraph-slave1_1
compute all partitions
  mean: 8.76923076923077 ms
  smallest: 13 ms from graphalytics-giraph-slave14_10
  largest: 6 ms from graphalytics-giraph-slave13_2
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave13_2
  largest: 0 ms from graphalytics-giraph-slave13_2
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave13_2
  largest: 0 us from graphalytics-giraph-slave13_2
wait requests time
  mean: 189.15384615384616 us
  smallest: 272 us from graphalytics-giraph-slave6_7
  largest: 139 us from graphalytics-giraph-slave13_2
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave13_2
  largest: 0 bytes from graphalytics-giraph-slave13_2
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave13_2
  largest: 0 bytes from graphalytics-giraph-slave13_2
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave13_2
  largest: 100.0 % from graphalytics-giraph-slave13_2
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:04 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:04 +0000 2018
LogLength:55986
Log Contents:
2018-08-08 13:37:45,468 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,526 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,526 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,528 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,528 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,699 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:45,922 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,097 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,539 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,551 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,695 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,708 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,735 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,736 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceMaster (master thread)...
INFO    2018-08-08 13:37:46,743 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,749 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,749 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 0 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,755 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,755 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave15
INFO    2018-08-08 13:37:46,755 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,755 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,755 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,755 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000002:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000002/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,755 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000002:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,755 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000002/tmp
INFO    2018-08-08 13:37:46,755 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,755 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,756 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,756 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,756 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,756 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,756 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000002
INFO    2018-08-08 13:37:46,756 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.master.BspServiceMaster@db44aa2
INFO    2018-08-08 13:37:46,768 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,769 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,775 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3001f, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,776 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:46,783 [main] org.apache.giraph.graph.GraphTaskManager  - map: No need to do anything when not a worker
INFO    2018-08-08 13:37:46,783 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for MASTER_ONLY
INFO    2018-08-08 13:37:46,806 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - becomeMaster: First child is '/_hadoopBsp/job_1533735211869_0003/_masterElectionDir/graphalytics-giraph-slave15_00000000000' and my bid is '/_hadoopBsp/job_1533735211869_0003/_masterElectionDir/graphalytics-giraph-slave15_00000000000'
INFO    2018-08-08 13:37:46,814 [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:46,821 [main-EventThread] org.apache.giraph.bsp.BspService  - process: applicationAttemptChanged signaled
INFO    2018-08-08 13:37:46,911 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:46,928 [org.apache.giraph.master.MasterThread] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:46,970 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave15/10.164.0.17:30000 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:46,976 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:46,977 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:46,979 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - becomeMaster: I am now the master!
INFO    2018-08-08 13:37:46,982 [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,276 [org.apache.giraph.master.MasterThread] org.apache.giraph.io.formats.GiraphFileInputFormat  - Total input paths to process : 1
INFO    2018-08-08 13:37:47,291 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - generateVERTEXInputSplits: Got 1 input splits for 143 input threads
WARN    2018-08-08 13:37:47,291 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - createVERTEXInputSplits: Number of inputSplits=1 < 143=total number of input threads, some threads will be not used
INFO    2018-08-08 13:37:47,312 [org.apache.giraph.master.MasterThread] org.apache.giraph.io.formats.GiraphFileInputFormat  - Total input paths to process : 1
INFO    2018-08-08 13:37:47,315 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - generateEDGEInputSplits: Got 1 input splits for 143 input threads
WARN    2018-08-08 13:37:47,315 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - createEDGEInputSplits: Number of inputSplits=1 < 143=total number of input threads, some threads will be not used
INFO    2018-08-08 13:37:47,349 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,351 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,351 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,351 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,352 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,353 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,353 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,353 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,353 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,353 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,353 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,353 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,354 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,358 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,359 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - computePartitionCount: Creating 429 partitions.
INFO    2018-08-08 13:37:47,377 [org.apache.giraph.master.MasterThread] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.timeout is deprecated. Instead, use mapreduce.task.timeout
INFO    2018-08-08 13:37:47,378 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep -1 on path /_hadoopBsp/job_1533735211869_0003/_inputSplitsWorkerDoneDir
INFO    2018-08-08 13:37:47,468 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,470 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,475 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,488 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,574 [netty-server-worker-3] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0003, ave received req MBytes = 0.0003, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,665 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep -1 on path /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerFinishedDir
INFO    2018-08-08 13:37:47,734 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) on superstep = -1
INFO    2018-08-08 13:37:47,741 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep -1 took 0.426 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 0
WARN    2018-08-08 13:37:47,751 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,807 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,808 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:37:47,809 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=6, port=30006):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=3, port=30003):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=2, port=30002):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=9, port=30009):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=11, port=30011):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004):(v=1, e=4),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=5, port=30005):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008):(v=1, e=1),]
INFO    2018-08-08 13:37:47,809 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008) - 1
INFO    2018-08-08 13:37:47,810 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 1, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004) - 4
INFO    2018-08-08 13:37:47,875 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 13 out of 13 workers finished on superstep 0 on path /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerFinishedDir
INFO    2018-08-08 13:37:47,878 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: Waiting on []
INFO    2018-08-08 13:37:47,889 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) on superstep = 0
INFO    2018-08-08 13:37:47,896 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 0 took 0.154 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 1
INFO    2018-08-08 13:37:47,940 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,940 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:37:47,941 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=6, port=30006):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=3, port=30003):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=2, port=30002):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=9, port=30009):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=11, port=30011):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004):(v=1, e=4),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=5, port=30005):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008):(v=1, e=1),]
INFO    2018-08-08 13:37:47,941 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008) - 1
INFO    2018-08-08 13:37:47,941 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 1, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004) - 4
INFO    2018-08-08 13:37:47,947 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 1 on path /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerFinishedDir
INFO    2018-08-08 13:37:47,999 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) on superstep = 1
INFO    2018-08-08 13:37:48,003 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0
INFO    2018-08-08 13:37:48,093 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 1 took 0.196 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 2
INFO    2018-08-08 13:37:48,115 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,115 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:37:48,115 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=6, port=30006):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=3, port=30003):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=2, port=30002):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=9, port=30009):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=11, port=30011):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004):(v=1, e=4),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=5, port=30005):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008):(v=1, e=1),]
INFO    2018-08-08 13:37:48,115 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008) - 1
INFO    2018-08-08 13:37:48,115 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 1, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004) - 4
INFO    2018-08-08 13:37:48,121 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 2 on path /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerFinishedDir
INFO    2018-08-08 13:37:48,173 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) on superstep = 2
INFO    2018-08-08 13:37:48,177 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1
INFO    2018-08-08 13:37:48,271 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 2 took 0.176 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 3
INFO    2018-08-08 13:37:48,292 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,292 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:37:48,293 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=6, port=30006):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=3, port=30003):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=2, port=30002):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=9, port=30009):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=11, port=30011):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004):(v=1, e=4),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=5, port=30005):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008):(v=1, e=1),]
INFO    2018-08-08 13:37:48,293 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008) - 1
INFO    2018-08-08 13:37:48,293 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 1, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004) - 4
INFO    2018-08-08 13:37:48,299 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 3 on path /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerFinishedDir
INFO    2018-08-08 13:37:48,350 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) on superstep = 3
INFO    2018-08-08 13:37:48,353 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2
INFO    2018-08-08 13:37:48,438 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 3 took 0.166 seconds ended with state ALL_SUPERSTEPS_DONE and is now on superstep 4
INFO    2018-08-08 13:37:48,439 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - setJobState: {"_applicationAttemptKey":-1,"_stateKey":"FINISHED","_superstepKey":-1} on superstep 4
INFO    2018-08-08 13:37:48,442 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - setJobState: {"_applicationAttemptKey":-1,"_stateKey":"FINISHED","_superstepKey":-1}
INFO    2018-08-08 13:37:48,450 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/0_master
INFO    2018-08-08 13:37:48,451 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Node /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir already exists, no need to create.
INFO    2018-08-08 13:37:48,452 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 1 of 14 desired children from /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir
INFO    2018-08-08 13:37:48,452 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir to change since only got 1 nodes.
INFO    2018-08-08 13:37:50,512 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:37:50,514 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 2 of 14 desired children from /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir
INFO    2018-08-08 13:37:50,514 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir to change since only got 2 nodes.
INFO    2018-08-08 13:37:50,607 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:37:50,609 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 3 of 14 desired children from /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir
INFO    2018-08-08 13:37:50,609 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir to change since only got 3 nodes.
INFO    2018-08-08 13:37:50,648 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:37:50,650 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 4 of 14 desired children from /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir
INFO    2018-08-08 13:37:50,650 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir to change since only got 4 nodes.
INFO    2018-08-08 13:37:50,662 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:37:50,663 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 5 of 14 desired children from /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir
INFO    2018-08-08 13:37:50,663 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir to change since only got 5 nodes.
INFO    2018-08-08 13:37:50,708 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:37:50,710 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 6 of 14 desired children from /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir
INFO    2018-08-08 13:37:50,710 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir to change since only got 6 nodes.
INFO    2018-08-08 13:37:50,813 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:37:50,815 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 7 of 14 desired children from /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir
INFO    2018-08-08 13:37:50,815 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir to change since only got 7 nodes.
INFO    2018-08-08 13:37:50,857 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:37:50,859 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 9 of 14 desired children from /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir
INFO    2018-08-08 13:37:50,859 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir to change since only got 9 nodes.
INFO    2018-08-08 13:37:50,871 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:37:50,873 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 11 of 14 desired children from /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir
INFO    2018-08-08 13:37:50,873 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir to change since only got 11 nodes.
INFO    2018-08-08 13:37:50,875 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:37:50,878 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 13 of 14 desired children from /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir
INFO    2018-08-08 13:37:50,878 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir to change since only got 13 nodes.
INFO    2018-08-08 13:37:50,948 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:37:50,949 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 14 of 14 desired children from /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir
INFO    2018-08-08 13:37:50,949 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanupZooKeeper: Removing the following path and all children - /_hadoopBsp/job_1533735211869_0003 from ZooKeeper list graphalytics-giraph:2181
INFO    2018-08-08 13:37:51,043 [main-EventThread] org.apache.giraph.bsp.BspService  - process: masterElectionChildrenChanged signaled
INFO    2018-08-08 13:37:51,052 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:37:51,098 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanup: Removed HDFS checkpoint directory (_bsp/_checkpoints//job_1533735211869_0003) with return = false since the job GraphalyticsBenchmark: LocalClusteringCoefficientJob succeeded 
INFO    2018-08-08 13:37:51,098 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:51,101 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:53,306 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:53,306 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:53,310 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:57,524 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:57,527 [org.apache.giraph.master.MasterThread] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3001f closed
INFO    2018-08-08 13:37:57,527 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:57,527 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - setup: Took 0.068 seconds.
INFO    2018-08-08 13:37:57,528 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - input superstep: Took 0.426 seconds.
INFO    2018-08-08 13:37:57,528 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 0: Took 0.154 seconds.
INFO    2018-08-08 13:37:57,528 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 1: Took 0.196 seconds.
INFO    2018-08-08 13:37:57,528 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 2: Took 0.176 seconds.
INFO    2018-08-08 13:37:57,528 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 3: Took 0.166 seconds.
INFO    2018-08-08 13:37:57,528 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - shutdown: Took 9.09 seconds.
INFO    2018-08-08 13:37:57,528 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - total: Took 10.281 seconds.
INFO    2018-08-08 13:37:57,528 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Joined with master thread
INFO    2018-08-08 13:37:57,532 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000000_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:57,563 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000000_0' done.
INFO    2018-08-08 13:37:57,569 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000000_0: Counters: 49
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128704
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=92
		CPU time spent (ms)=4910
		Physical memory (bytes) snapshot=1088823296
		Virtual memory (bytes) snapshot=58921660416
		Total committed heap usage (bytes)=55163486208
	Giraph Stats
		Aggregate bytes loaded from local disks (out-of-core)=0
		Aggregate bytes stored to local disks (out-of-core)=0
		Aggregate edges=17
		Aggregate finished vertices=10
		Aggregate sent message bytes=4019
		Aggregate sent messages=73
		Aggregate vertices=10
		Current master task partition=0
		Current workers=13
		Last checkpointed superstep=0
		Lowest percentage of graph in memory so far (out-of-core)=100
		Sent message bytes=0
		Sent messages=0
		Superstep=4
	Giraph Timers
		Initialize (ms)=464
		Input superstep (ms)=426
		Setup (ms)=68
		Shutdown (ms)=9089
		Superstep 0 DirectedLocalClusteringCoefficientComputation (ms)=154
		Superstep 1 DirectedLocalClusteringCoefficientComputation (ms)=196
		Superstep 2 DirectedLocalClusteringCoefficientComputation (ms)=176
		Superstep 3 DirectedLocalClusteringCoefficientComputation (ms)=166
		Total (ms)=10281
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000003 on graphalytics-giraph-slave1_33157
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:04 +0000 2018
LogLength:19544
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 530 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 332 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  received-bytes:
               sum = 9,995.00
               min = 16.00
               max = 6651.00
              mean = 112.30
            stddev = 701.66
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1472.60
              99% <= 6651.00
            99.9% <= 6651.00
             count = 89

  remote-requests:
    count = 8

  requests-received:
             count = 89
         mean rate = 163.08 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 106
         mean rate = 194.69 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 5,065.00
               min = 16.00
               max = 1473.00
              mean = 47.78
            stddev = 142.08
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 92.44
              99% <= 1376.40
            99.9% <= 1473.00
             count = 106

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 530

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 8

  wait-requests-us:
    value = 332

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 100 ms
  compute all partitions: 18 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 282 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 18

  compute-per-partition-ms:
               sum = 62.00
               min = 0.00
               max = 5.00
              mean = 1.88
            stddev = 1.79
            median = 2.00
              75% <= 3.50
              95% <= 4.30
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 60.00
               min = 3.00
               max = 7.00
              mean = 5.45
            stddev = 1.30
            median = 5.00
              75% <= 7.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6562.00
              mean = 168.67
            stddev = 910.84
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6173.62
              99% <= 6562.00
            99.9% <= 6562.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 360.18 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 359.97 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.68
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 100

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.44
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 282

  worker-context-post-superstep:
    value = 10

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 63 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 299 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 6.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.39
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 6.00
               min = 0.00
               max = 3.00
              mean = 0.55
            stddev = 1.04
            median = 0.00
              75% <= 1.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6562.00
              mean = 168.67
            stddev = 907.34
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6173.62
              99% <= 6562.00
            99.9% <= 6562.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 505.86 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 505.11 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 63

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 299

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 135 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 182 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.27
            stddev = 0.47
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6562.00
              mean = 168.67
            stddev = 904.50
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6173.62
              99% <= 6562.00
            99.9% <= 6562.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 298.14 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 298.04 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.75
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 135

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 182

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 137 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 231 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.12
            stddev = 0.33
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.27
            stddev = 0.47
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 925.88
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 296.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 302.52 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.75
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 137

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 231

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.32784855858833

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = 0.0

  edges-loaded:
             count = 17
         mean rate = 4.73 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:04 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:04 +0000 2018
LogLength:68057
Log Contents:
2018-08-08 13:37:45,555 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,624 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,624 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,626 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,626 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,808 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:46,051 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,246 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,722 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,735 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,894 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,909 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,939 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,940 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,948 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,955 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,955 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 1 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,961 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,961 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave1
INFO    2018-08-08 13:37:46,961 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,961 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,961 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,961 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000003:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000003/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,962 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000003:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,962 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000003/tmp
INFO    2018-08-08 13:37:46,962 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,962 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,962 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,962 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,962 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,962 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,962 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000003
INFO    2018-08-08 13:37:46,963 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,977 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,978 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,985 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30029, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,986 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:47,105 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:47,123 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:47,181 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave1/10.164.0.3:30001 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:47,186 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:47,187 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:47,210 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:47,221 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:47,225 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,228 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,235 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave1_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001)
INFO    2018-08-08 13:37:47,363 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,458 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,468 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,470 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,472 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,472 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,473 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,474 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,477 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,477 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,487 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,487 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,487 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,488 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,492 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,554 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,595 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03994064 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,595 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031344675 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,595 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.029720012 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,595 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030553637 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,595 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.032502916 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,596 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.02942062 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,596 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.02846757 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,597 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028561251 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,597 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.027322168 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,597 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028066896 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,598 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.027053872 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,601 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0044, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.037
MBytes/sec sent = 0.0069, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.037
INFO    2018-08-08 13:37:47,602 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,608 [load-0] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/example-directed.e:0+70'
INFO    2018-08-08 13:37:47,610 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00612001 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00706105 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006580187 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006452086 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,614 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005888301 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,614 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005028475 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005983732 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004884837 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,619 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004813253 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,619 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003565727 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,638 [load-0] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=0, e=17)
INFO    2018-08-08 13:37:47,640 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 0.037572827 secs, (v=0, e=17) 0.0 vertices/sec, 452.45465 edges/sec
INFO    2018-08-08 13:37:47,654 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0094, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.037, MBytesSent = 0.0005, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:37:47,655 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=17)
INFO    2018-08-08 13:37:47,666 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,670 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:37:47,672 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50879.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,672 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0039, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.03
MBytes/sec sent = 0.0155, MBytesSent = 0.0005, ave sent req MBytes = 0.0001, secs waited = 0.03
INFO    2018-08-08 13:37:47,672 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,692 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:37:47,692 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50879.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,704 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,744 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,749 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4fcc529,outgoing=org.apache.giraph.conf.DefaultMessageClasses@25cc7470)
WARN    2018-08-08 13:37:47,753 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,770 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,771 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,773 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave1_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001)
INFO    2018-08-08 13:37:47,819 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,819 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,819 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,820 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.128
MBytes/sec sent = 0.0109, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.128
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,826 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,835 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,851 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009655775 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01131844 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012322266 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01047589 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007472699 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008010116 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0134547 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004277027 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,852 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005815282 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,852 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006503965 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0094118 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,854 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,855 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0065, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.028
MBytes/sec sent = 0.0351, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.028
INFO    2018-08-08 13:37:47,855 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,862 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:37:47,862 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,869 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,899 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,901 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@40620d8e)
INFO    2018-08-08 13:37:47,910 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,914 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave1_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001)
INFO    2018-08-08 13:37:47,947 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,948 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,948 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,950 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.086
MBytes/sec sent = 0.0161, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.087
INFO    2018-08-08 13:37:47,952 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,953 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,956 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,961 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00295355 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003726368 secs for 13 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005025825 secs for 13 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003426267 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003707631 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0036391 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002765859 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,964 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002525218 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0028936 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001566364 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,966 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001167506 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,968 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,968 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0122, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.014
MBytes/sec sent = 0.0679, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.014
INFO    2018-08-08 13:37:47,968 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,973 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:47,973 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,978 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,005 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,009 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7d151a)
INFO    2018-08-08 13:37:48,015 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,035 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave1_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001)
INFO    2018-08-08 13:37:48,047 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,094 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,122 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,122 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,122 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,123 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:37:48,126 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,130 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,133 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,137 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001308769 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003695247 secs for 23 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001107327 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002204014 secs for 7 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,138 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001907217 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,138 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001006478 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001427069 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,140 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001220687 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002155547 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001105254 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,143 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003100528 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,144 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50444.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,144 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:37:48,145 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,150 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:48,150 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50444.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,156 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,179 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,184 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@54534abf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@51745f40)
INFO    2018-08-08 13:37:48,191 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,210 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave1_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=1, port=30001)
INFO    2018-08-08 13:37:48,222 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,272 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,300 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,301 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,301 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,302 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.152
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.152
INFO    2018-08-08 13:37:48,307 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,308 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,312 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,315 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00166956 secs for 10 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,315 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00266413 secs for 22 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,315 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001308771 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,315 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001518574 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001318772 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001436757 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,317 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001438281 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,317 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001259766 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,318 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001279084 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,318 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001174593 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002465168 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,321 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:37:48,321 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,328 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:48,328 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,334 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,356 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,359 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@37d00a23)
INFO    2018-08-08 13:37:48,363 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,363 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,363 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,366 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:48,391 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,438 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,444 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,447 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,470 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,471 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 13:37:50,474 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,511 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,512 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,514 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/1_worker
INFO    2018-08-08 13:37:50,516 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30029 closed
INFO    2018-08-08 13:37:50,516 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,518 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,522 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:54,736 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:54,741 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000001_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:54,767 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000001_0 is allowed to commit now
INFO    2018-08-08 13:37:54,777 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000001_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000001
INFO    2018-08-08 13:37:54,797 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000001_0' done.
INFO    2018-08-08 13:37:54,803 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000001_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128704
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=114
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=95
		CPU time spent (ms)=4760
		Physical memory (bytes) snapshot=1065136128
		Virtual memory (bytes) snapshot=58897543168
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000005 on graphalytics-giraph-slave2_43787
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:19552
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 628 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 339 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,804.00
               min = 16.00
               max = 6651.00
              mean = 114.00
            stddev = 714.01
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1795.12
              99% <= 6651.00
            99.9% <= 6651.00
             count = 86

  remote-requests:
    count = 0

  requests-received:
             count = 86
         mean rate = 133.97 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 152.99 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.69
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 628

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 339

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 102 ms
  compute all partitions: 18 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 2718 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 18

  compute-per-partition-ms:
               sum = 53.00
               min = 0.00
               max = 5.00
              mean = 1.61
            stddev = 1.48
            median = 2.00
              75% <= 3.00
              95% <= 4.30
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 129

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 53.00
               min = 1.00
               max = 6.00
              mean = 4.82
            stddev = 1.72
            median = 6.00
              75% <= 6.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,819.00
               min = 16.00
               max = 6562.00
              mean = 160.35
            stddev = 887.69
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 5785.24
              99% <= 6562.00
            99.9% <= 6562.00
             count = 55

  remote-requests:
    count = 3

  requests-received:
             count = 55
         mean rate = 380.35 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 55
         mean rate = 380.40 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,762.00
               min = 16.00
               max = 1473.00
              mean = 68.40
            stddev = 195.09
            median = 48.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1306.92
              99% <= 1473.00
            99.9% <= 1473.00
             count = 55

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 102

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 2718

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 63 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 166 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 11.00
               min = 0.00
               max = 4.00
              mean = 0.33
            stddev = 0.82
            median = 0.00
              75% <= 0.00
              95% <= 2.60
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 213

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 11.00
               min = 0.00
               max = 4.00
              mean = 1.00
            stddev = 1.55
            median = 0.00
              75% <= 3.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 9,071.00
               min = 16.00
               max = 6562.00
              mean = 156.40
            stddev = 859.38
            median = 34.50
              75% <= 89.00
              95% <= 92.00
              98% <= 5397.40
              99% <= 6562.00
            99.9% <= 6562.00
             count = 58

  remote-requests:
    count = 3

  requests-received:
             count = 58
         mean rate = 565.28 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 565.38 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,894.00
               min = 16.00
               max = 1473.00
              mean = 67.14
            stddev = 190.22
            median = 20.50
              75% <= 76.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 63

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 166

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 135 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 159 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 8.00
               min = 0.00
               max = 4.00
              mean = 0.24
            stddev = 0.75
            median = 0.00
              75% <= 0.00
              95% <= 1.90
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 117

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 8.00
               min = 0.00
               max = 4.00
              mean = 0.73
            stddev = 1.27
            median = 0.00
              75% <= 1.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,951.00
               min = 16.00
               max = 6651.00
              mean = 157.04
            stddev = 921.74
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5601.08
              99% <= 6651.00
            99.9% <= 6651.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 330.61 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 336.39 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,798.00
               min = 16.00
               max = 1473.00
              mean = 65.48
            stddev = 190.25
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 135

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 159

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 139 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 170 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 925.88
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 294.64 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 300.40 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 139

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 170

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.9870463705411

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:67875
Log Contents:
2018-08-08 13:37:45,511 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,574 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,574 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,576 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,576 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,751 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:45,972 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,169 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,636 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,649 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,807 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,822 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,851 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,852 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,859 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,866 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,866 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 3 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,874 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,874 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave2
INFO    2018-08-08 13:37:46,874 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,874 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,874 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,874 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000005:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000005/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,874 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000005:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,875 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000005/tmp
INFO    2018-08-08 13:37:46,875 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,875 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,875 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,875 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,875 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,875 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,875 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000005
INFO    2018-08-08 13:37:46,875 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,890 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,890 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,897 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30026, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,898 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:47,019 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:47,037 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:47,089 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave2/10.164.0.4:30003 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:47,095 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:47,096 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:47,117 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:47,128 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:47,131 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,134 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,141 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave2_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=3, port=30003)
INFO    2018-08-08 13:37:47,365 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,459 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,469 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,471 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,473 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,473 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,475 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,488 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,489 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,489 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,490 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,490 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,491 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,493 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,493 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,493 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,493 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,496 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,496 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,496 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,498 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,567 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,617 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048664343 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04027896 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041140366 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038551867 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037793387 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036322508 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.035386708 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,620 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.035481907 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,620 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.034666304 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,620 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.033715498 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,622 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03461585 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,623 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0028, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.124
MBytes/sec sent = 0.0102, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.125
INFO    2018-08-08 13:37:47,624 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,628 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001156107 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,630 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003912197 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,630 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001107481 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,631 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002936058 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.007410444 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002697905 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,634 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004079523 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003812948 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001434263 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003145177 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,639 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006998502 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,639 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.012, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0187, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.013
INFO    2018-08-08 13:37:47,640 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:37:47,670 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,675 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,683 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,685 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50738.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,685 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0028, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.059
MBytes/sec sent = 0.0044, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.059
INFO    2018-08-08 13:37:47,685 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,694 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,694 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,707 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,748 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,753 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@55120f99,outgoing=org.apache.giraph.conf.DefaultMessageClasses@794b435f)
WARN    2018-08-08 13:37:47,757 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,771 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,772 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,774 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave2_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=3, port=30003)
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,825 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.129
MBytes/sec sent = 0.0108, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.129
INFO    2018-08-08 13:37:47,828 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,830 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,830 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:37:47,839 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,855 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011296387 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,855 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005069145 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,855 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012425912 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,855 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010888973 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,855 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006989137 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,855 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007470239 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,855 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010121666 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,856 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009624013 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,855 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014188586 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,856 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005028346 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,856 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006284222 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,859 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50598.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,861 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0065, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0196, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 13:37:47,861 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,867 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0283, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0901, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 13:37:47,869 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 3 , message bytes = 129 , Memory (free/total/max) = 50598.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,873 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,903 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,905 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@73aff8f1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf)
INFO    2018-08-08 13:37:47,914 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,919 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave2_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=3, port=30003)
INFO    2018-08-08 13:37:47,952 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,952 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,952 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,953 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.084
MBytes/sec sent = 0.0165, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.084
INFO    2018-08-08 13:37:47,956 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,957 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,960 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,966 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002613089 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004695745 secs for 25 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00147115 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002290103 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004335638 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002946977 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006612017 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,968 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001141155 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,969 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001490564 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,970 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003369762 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,971 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002938561 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,971 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50457.19M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,971 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0092, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0435, MBytesSent = 0.0002, ave sent req MBytes = 0.0001, secs waited = 0.004
INFO    2018-08-08 13:37:47,972 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,977 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:47,977 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 3 , message bytes = 213 , Memory (free/total/max) = 50457.19M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,982 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,010 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,013 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4a1e3ac1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5)
INFO    2018-08-08 13:37:48,018 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,039 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave2_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=3, port=30003)
WARN    2018-08-08 13:37:48,099 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,127 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,127 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,127 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,128 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.151
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.151
INFO    2018-08-08 13:37:48,131 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,134 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,137 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,142 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003142626 secs for 16 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002663005 secs for 8 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001778547 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002209497 secs for 8 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,143 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004876458 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,144 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001637799 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,145 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002181693 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,145 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001286306 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,146 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002069559 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,145 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003076533 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,147 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002033854 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,148 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50303.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,148 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.021, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:48,148 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,154 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0331, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.1051, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:48,154 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 3 , message bytes = 117 , Memory (free/total/max) = 50303.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,160 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,184 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,187 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4248ed58,outgoing=org.apache.giraph.conf.DefaultMessageClasses@712ca57b)
INFO    2018-08-08 13:37:48,193 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,212 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave2_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=3, port=30003)
INFO    2018-08-08 13:37:48,227 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,276 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,304 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,305 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,305 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,306 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.152
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.152
INFO    2018-08-08 13:37:48,311 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,313 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,317 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,320 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001710954 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002393114 secs for 9 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003315038 secs for 22 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001970912 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,322 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001997104 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,322 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001451105 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,323 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001470103 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,323 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001441553 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,324 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001738051 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,325 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001379676 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,327 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003012187 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50162.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,332 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,332 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50162.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,338 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,360 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,363 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@1623bbe5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7af1cd63)
INFO    2018-08-08 13:37:48,366 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,367 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,367 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,369 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:48,396 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,443 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,449 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,451 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,673 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,673 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:37:50,677 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,876 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,877 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,879 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/3_worker
INFO    2018-08-08 13:37:50,881 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30026 closed
INFO    2018-08-08 13:37:50,881 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,883 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,887 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:55,101 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:55,107 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000003_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:55,132 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000003_0 is allowed to commit now
INFO    2018-08-08 13:37:55,142 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000003_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000003
INFO    2018-08-08 13:37:55,161 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000003_0' done.
INFO    2018-08-08 13:37:55,166 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000003_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128704
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=22
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=99
		CPU time spent (ms)=4970
		Physical memory (bytes) snapshot=1107537920
		Virtual memory (bytes) snapshot=58922631168
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000013 on graphalytics-giraph-slave3_42077
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:19545
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 677 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 265 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,727.00
               min = 16.00
               max = 6651.00
              mean = 126.32
            stddev = 753.86
            median = 32.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2982.44
              99% <= 6651.00
            99.9% <= 6651.00
             count = 77

  remote-requests:
    count = 0

  requests-received:
             count = 77
         mean rate = 111.43 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 97
         mean rate = 140.55 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,536.00
               min = 16.00
               max = 1473.00
              mean = 46.76
            stddev = 148.40
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 144.36
              99% <= 1473.00
            99.9% <= 1473.00
             count = 97

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 677

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 265

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 102 ms
  compute all partitions: 16 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 226 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 16

  compute-per-partition-ms:
               sum = 41.00
               min = 0.00
               max = 4.00
              mean = 1.24
            stddev = 0.90
            median = 1.00
              75% <= 2.00
              95% <= 2.60
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 39.00
               min = 0.00
               max = 5.00
              mean = 3.55
            stddev = 1.81
            median = 4.00
              75% <= 5.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,867.00
               min = 16.00
               max = 6651.00
              mean = 167.30
            stddev = 908.21
            median = 48.00
              75% <= 71.00
              95% <= 89.00
              98% <= 6126.04
              99% <= 6651.00
            99.9% <= 6651.00
             count = 53

  remote-requests:
    count = 0

  requests-received:
             count = 53
         mean rate = 364.62 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 54
         mean rate = 371.33 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,650.00
               min = 16.00
               max = 1473.00
              mean = 67.59
            stddev = 197.15
            median = 16.00
              75% <= 62.00
              95% <= 89.00
              98% <= 1334.60
              99% <= 1473.00
            99.9% <= 1473.00
             count = 54

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 102

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 226

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 64 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1399 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 12.00
               min = 0.00
               max = 7.00
              mean = 0.36
            stddev = 1.25
            median = 0.00
              75% <= 0.00
              95% <= 2.80
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 126

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 12.00
               min = 0.00
               max = 8.00
              mean = 1.09
            stddev = 2.43
            median = 0.00
              75% <= 2.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 8,971.00
               min = 16.00
               max = 6651.00
              mean = 163.11
            stddev = 892.41
            median = 16.00
              75% <= 89.00
              95% <= 89.60
              98% <= 5863.92
              99% <= 6651.00
            99.9% <= 6651.00
             count = 55

  remote-requests:
    count = 2

  requests-received:
             count = 55
         mean rate = 532.36 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 539.99 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,786.00
               min = 16.00
               max = 1473.00
              mean = 67.61
            stddev = 193.51
            median = 20.50
              75% <= 68.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 64

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1399

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 137 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 193 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 1.00
              mean = 0.15
            stddev = 0.36
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 78

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.67
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,891.00
               min = 16.00
               max = 6651.00
              mean = 161.65
            stddev = 891.71
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5863.56
              99% <= 6651.00
            99.9% <= 6651.00
             count = 55

  remote-requests:
    count = 2

  requests-received:
             count = 55
         mean rate = 322.33 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 328.20 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,738.00
               min = 16.00
               max = 1473.00
              mean = 66.75
            stddev = 193.56
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 137

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 193

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 140 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 208 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 926.40
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 293.79 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 299.43 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 140

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 208

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.2548677468822

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:67693
Log Contents:
2018-08-08 13:37:45,453 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,519 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,519 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,521 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,521 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,700 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:45,943 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,133 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,604 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,615 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,765 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,779 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,806 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,807 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,814 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,820 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,820 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 11 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,826 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,826 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave3
INFO    2018-08-08 13:37:46,826 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,826 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,826 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,826 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000013:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000013/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,827 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000013:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,827 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000013/tmp
INFO    2018-08-08 13:37:46,827 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,827 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,827 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,827 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,827 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,827 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,827 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000013
INFO    2018-08-08 13:37:46,828 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,840 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,841 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,846 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30024, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,847 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:46,964 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:46,982 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:47,033 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave3/10.164.0.5:30011 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:47,038 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:47,039 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:47,063 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:47,074 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:47,077 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,080 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,087 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave3_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=11, port=30011)
INFO    2018-08-08 13:37:47,363 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,457 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,467 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,468 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,470 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,470 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,472 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,472 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,472 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,473 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,474 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,475 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,477 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,483 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,484 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,487 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,488 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,490 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,552 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,594 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040898316 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,610 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05047263 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,610 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.049572524 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,611 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048517417 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,611 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047425643 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,612 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046918787 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,612 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046104576 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045609303 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044911105 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04413092 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04332536 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,614 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0028, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.124
MBytes/sec sent = 0.0102, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.124
INFO    2018-08-08 13:37:47,615 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,620 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00372957 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,622 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004408972 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,622 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.41038E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,630 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.011227147 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,630 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.011020471 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,630 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.010339306 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,631 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.013103934 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,631 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.009805812 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00977435 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.009122249 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00762916 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,633 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0099, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.016
MBytes/sec sent = 0.0154, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.016
INFO    2018-08-08 13:37:47,633 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:37:47,665 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,669 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:37:47,670 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50879.70M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,670 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.053
MBytes/sec sent = 0.0049, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.053
INFO    2018-08-08 13:37:47,671 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,690 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:37:47,690 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50879.70M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,702 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,743 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,747 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4fcc529,outgoing=org.apache.giraph.conf.DefaultMessageClasses@25cc7470)
WARN    2018-08-08 13:37:47,752 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,767 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,768 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,770 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave3_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=11, port=30011)
INFO    2018-08-08 13:37:47,819 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,819 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,819 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,820 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.13
MBytes/sec sent = 0.0107, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.13
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,825 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,835 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,849 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002120712 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005847957 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010142037 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004761186 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007459908 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011921542 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008667298 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003581924 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010841011 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009054954 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005167259 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,852 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,853 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0065, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.027
MBytes/sec sent = 0.0364, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.027
INFO    2018-08-08 13:37:47,853 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,861 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:37:47,862 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,867 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,898 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,900 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@40620d8e)
INFO    2018-08-08 13:37:47,909 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,913 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave3_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=11, port=30011)
INFO    2018-08-08 13:37:47,947 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,947 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,947 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,948 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.086
MBytes/sec sent = 0.0161, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.086
INFO    2018-08-08 13:37:47,951 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,952 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,955 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,960 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003101408 secs for 14 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003614454 secs for 15 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002908495 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002348271 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00228025 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002323938 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001603973 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001060235 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001336217 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001531923 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010150489 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,966 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50585.29M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,967 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0102, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0432, MBytesSent = 0.0001, ave sent req MBytes = 0.0001, secs waited = 0.002
INFO    2018-08-08 13:37:47,968 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,972 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:47,972 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 2 , message bytes = 126 , Memory (free/total/max) = 50585.29M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,980 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,004 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,008 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7d151a)
INFO    2018-08-08 13:37:48,014 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,033 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave3_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=11, port=30011)
INFO    2018-08-08 13:37:48,046 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,093 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,121 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,122 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,122 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,123 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:37:48,128 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,129 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,132 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,137 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003792224 secs for 9 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00233709 secs for 8 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001829249 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,138 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002939049 secs for 12 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,138 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001722803 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001706704 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001761447 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002031934 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001568917 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,143 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002900912 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,143 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003356097 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,143 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50444.49M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,144 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0044, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.012, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 13:37:48,144 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,151 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:48,151 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 2 , message bytes = 78 , Memory (free/total/max) = 50444.49M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,156 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,178 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,181 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@54534abf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@51745f40)
INFO    2018-08-08 13:37:48,187 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,206 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave3_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=11, port=30011)
INFO    2018-08-08 13:37:48,221 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,270 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,299 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,299 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,299 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,300 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.149
MBytes/sec sent = 0.0094, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.149
INFO    2018-08-08 13:37:48,302 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,307 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,313 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,316 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002981879 secs for 22 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00211982 secs for 9 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001707547 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,317 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00223413 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,317 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001901423 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,318 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002189639 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,319 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002446203 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002185266 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00404495 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001784677 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,322 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002936195 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,322 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,323 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0114, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.015
MBytes/sec sent = 0.0637, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.015
INFO    2018-08-08 13:37:48,323 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,333 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,355 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,358 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@37d00a23)
INFO    2018-08-08 13:37:48,361 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,361 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,361 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,364 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:48,390 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,437 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,443 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,446 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,667 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,668 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:37:50,671 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,876 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,876 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,878 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/11_worker
INFO    2018-08-08 13:37:50,880 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30024 closed
INFO    2018-08-08 13:37:50,880 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,882 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,886 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:55,101 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:55,105 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000011_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:55,131 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000011_0 is allowed to commit now
INFO    2018-08-08 13:37:55,140 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000011_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000011
INFO    2018-08-08 13:37:55,159 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000011_0' done.
INFO    2018-08-08 13:37:55,165 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000011_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128705
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=103
		CPU time spent (ms)=4840
		Physical memory (bytes) snapshot=1082048512
		Virtual memory (bytes) snapshot=58878533632
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000010 on graphalytics-giraph-slave4_46069
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:19540
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 579 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 411 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,772.00
               min = 16.00
               max = 6651.00
              mean = 117.73
            stddev = 726.44
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2230.32
              99% <= 6651.00
            99.9% <= 6651.00
             count = 83

  remote-requests:
    count = 0

  requests-received:
             count = 83
         mean rate = 139.51 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 165.08 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.64
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 579

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 411

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 98 ms
  compute all partitions: 17 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1973 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 17

  compute-per-partition-ms:
               sum = 48.00
               min = 0.00
               max = 5.00
              mean = 1.45
            stddev = 1.58
            median = 1.00
              75% <= 3.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 43

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 43.00
               min = 3.00
               max = 5.00
              mean = 3.91
            stddev = 0.83
            median = 4.00
              75% <= 5.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,787.00
               min = 16.00
               max = 6651.00
              mean = 168.98
            stddev = 917.89
            median = 16.00
              75% <= 80.00
              95% <= 89.00
              98% <= 6257.28
              99% <= 6651.00
            99.9% <= 6651.00
             count = 52

  remote-requests:
    count = 1

  requests-received:
             count = 52
         mean rate = 358.81 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 365.25 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,666.00
               min = 16.00
               max = 1473.00
              mean = 69.17
            stddev = 198.77
            median = 25.00
              75% <= 71.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 98

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.45
            stddev = 0.82
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  wait-requests-us:
    value = 1973

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 59 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 168 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 2.00
              mean = 0.18
            stddev = 0.60
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,863.00
               min = 16.00
               max = 6651.00
              mean = 170.44
            stddev = 920.32
            median = 34.50
              75% <= 89.00
              95% <= 90.05
              98% <= 6257.46
              99% <= 6651.00
            99.9% <= 6651.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 529.45 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 539.79 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,634.00
               min = 16.00
               max = 1473.00
              mean = 68.57
            stddev = 198.95
            median = 16.00
              75% <= 71.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 59

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 168

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 135 ms
  compute all partitions: 12 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 172 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 12

  compute-per-partition-ms:
               sum = 6.00
               min = 0.00
               max = 3.00
              mean = 0.18
            stddev = 0.58
            median = 0.00
              75% <= 0.00
              95% <= 1.60
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 39

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 3.00
              mean = 0.45
            stddev = 0.93
            median = 0.00
              75% <= 1.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 8,787.00
               min = 16.00
               max = 6651.00
              mean = 168.98
            stddev = 966.73
            median = 16.00
              75% <= 80.00
              95% <= 89.00
              98% <= 6257.28
              99% <= 6651.00
            99.9% <= 6651.00
             count = 52

  remote-requests:
    count = 1

  requests-received:
             count = 52
         mean rate = 302.42 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 308.22 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,662.00
               min = 16.00
               max = 1473.00
              mean = 69.09
            stddev = 198.79
            median = 25.00
              75% <= 71.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 135

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 172

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 139 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 180 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.03
            stddev = 0.17
            median = 0.00
              75% <= 0.00
              95% <= 0.30
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 925.88
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 294.46 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 300.22 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.77
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 139

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 180

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.9872124369127

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:67826
Log Contents:
2018-08-08 13:37:45,560 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,627 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,627 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,629 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,629 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,814 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:46,041 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,225 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,691 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,703 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,860 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,874 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,903 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,903 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,911 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,918 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,918 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 8 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave4
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000010:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000010/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000010:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000010/tmp
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,924 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000010
INFO    2018-08-08 13:37:46,925 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,938 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,939 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,945 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30028, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,947 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:47,059 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:47,077 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:47,131 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave4/10.164.0.6:30008 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:47,135 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:47,136 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:47,157 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:47,169 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:47,173 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,175 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,182 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave4_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008)
INFO    2018-08-08 13:37:47,358 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,456 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,466 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,467 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,469 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,471 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,472 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,474 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,474 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,475 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,477 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,484 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,484 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,485 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,489 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,553 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,604 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050604377 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,604 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043590505 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,604 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0430515 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,604 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04249841 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,605 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041949537 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,605 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04078105 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,605 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04021801 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,605 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038611505 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,607 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040177483 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,608 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039611757 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,608 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038804278 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,610 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0034, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.049
MBytes/sec sent = 0.0052, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.049
INFO    2018-08-08 13:37:47,611 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,615 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003613965 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,616 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001351614 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003097915 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004858565 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,620 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004388619 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,620 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003815298 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,620 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003174448 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,621 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002865545 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,624 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005097604 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,625 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002714552 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,626 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003093087 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,627 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0119, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:47,628 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:37:47,662 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,667 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,678 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,679 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,680 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0008, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.057
MBytes/sec sent = 0.0012, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.058
INFO    2018-08-08 13:37:47,680 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,686 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,686 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,699 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,740 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,745 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@55120f99,outgoing=org.apache.giraph.conf.DefaultMessageClasses@794b435f)
WARN    2018-08-08 13:37:47,749 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,764 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,765 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,768 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave4_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008)
INFO    2018-08-08 13:37:47,817 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,818 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,818 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,819 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.133
MBytes/sec sent = 0.0105, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.133
INFO    2018-08-08 13:37:47,822 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,830 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,844 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004149861 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008792876 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007345483 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010553335 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005490585 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003770945 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009734619 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006314296 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005763374 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008333134 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,844 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011876691 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,850 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0076, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:47,850 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,857 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,858 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 1 , message bytes = 43 , Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,863 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,895 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,897 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@73aff8f1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf)
INFO    2018-08-08 13:37:47,911 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,913 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave4_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008)
INFO    2018-08-08 13:37:47,944 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,945 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,945 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,946 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.088
MBytes/sec sent = 0.0158, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.088
INFO    2018-08-08 13:37:47,948 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,949 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,951 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,956 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003740608 secs for 13 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,956 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002797331 secs for 16 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,956 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002252474 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,956 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002539563 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,957 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001932696 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,957 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001306122 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,958 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002294247 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,959 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00190537 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,959 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001575838 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,959 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00115505 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002751928 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50457.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,962 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:37:47,962 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,970 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,970 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50457.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,977 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,002 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,005 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4a1e3ac1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5)
INFO    2018-08-08 13:37:48,011 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,029 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave4_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008)
INFO    2018-08-08 13:37:48,043 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,090 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,119 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,119 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,119 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,120 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:37:48,123 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,126 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,129 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,134 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003870195 secs for 16 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,135 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002980297 secs for 12 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,134 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002501186 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,135 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001995935 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,135 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005011872 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,136 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00233495 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001989158 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001388535 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,137 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003122461 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,138 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00169842 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003961217 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,142 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0019, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.0052, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 13:37:48,142 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,146 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,146 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 1 , message bytes = 39 , Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,152 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,176 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,179 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4248ed58,outgoing=org.apache.giraph.conf.DefaultMessageClasses@712ca57b)
INFO    2018-08-08 13:37:48,185 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,205 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave4_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008)
INFO    2018-08-08 13:37:48,218 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,268 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,296 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,297 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,297 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,297 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.151
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.151
INFO    2018-08-08 13:37:48,300 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,304 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,309 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,312 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003051825 secs for 22 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,312 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002347369 secs for 10 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,312 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001627786 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,313 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001332288 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,313 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001588187 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,314 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001050179 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,314 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001371899 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,315 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001317495 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,315 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001662294 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001212887 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,317 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002350951 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,317 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50162.87M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,317 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:37:48,317 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,324 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,324 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50162.87M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,330 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,352 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,355 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@1623bbe5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7af1cd63)
INFO    2018-08-08 13:37:48,358 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,359 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,359 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,362 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:48,387 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,435 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,440 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,443 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,466 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,467 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:37:50,470 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,658 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,658 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,660 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/8_worker
INFO    2018-08-08 13:37:50,662 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30028 closed
INFO    2018-08-08 13:37:50,662 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,664 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,668 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:54,881 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:54,884 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000008_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:54,909 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000008_0 is allowed to commit now
INFO    2018-08-08 13:37:54,918 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000008_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000008
INFO    2018-08-08 13:37:54,937 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000008_0' done.
INFO    2018-08-08 13:37:54,942 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000008_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128704
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=6
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=98
		CPU time spent (ms)=4850
		Physical memory (bytes) snapshot=1082916864
		Virtual memory (bytes) snapshot=58878758912
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000007 on graphalytics-giraph-slave5_46217
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:19553
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 735 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 312 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 10.0

  received-bytes:
               sum = 10,011.00
               min = 16.00
               max = 6651.00
              mean = 106.50
            stddev = 682.93
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 825.30
              99% <= 6651.00
            99.9% <= 6651.00
             count = 94

  remote-requests:
    count = 9

  requests-received:
             count = 94
         mean rate = 125.34 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 107
         mean rate = 142.93 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 9

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 5,047.00
               min = 16.00
               max = 1473.00
              mean = 47.17
            stddev = 141.26
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 89.00
              99% <= 1362.28
            99.9% <= 1473.00
             count = 107

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 735

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 10

  wait-requests-us:
    value = 312

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 101 ms
  compute all partitions: 19 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 361 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 19

  compute-per-partition-ms:
               sum = 40.00
               min = 0.00
               max = 4.00
              mean = 1.21
            stddev = 1.24
            median = 1.00
              75% <= 2.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 39.00
               min = 0.00
               max = 7.00
              mean = 3.55
            stddev = 2.16
            median = 4.00
              75% <= 5.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 9,011.00
               min = 16.00
               max = 6562.00
              mean = 158.09
            stddev = 868.17
            median = 48.00
              75% <= 71.00
              95% <= 89.00
              98% <= 5526.32
              99% <= 6562.00
            99.9% <= 6562.00
             count = 57

  remote-requests:
    count = 0

  requests-received:
             count = 57
         mean rate = 387.16 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 57
         mean rate = 387.07 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,698.00
               min = 16.00
               max = 1473.00
              mean = 64.88
            stddev = 192.17
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1251.56
              99% <= 1473.00
            99.9% <= 1473.00
             count = 57

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 101

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 361

  worker-context-post-superstep:
    value = 9

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 61 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 3445 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 13.00
               min = 0.00
               max = 8.00
              mean = 0.39
            stddev = 1.41
            median = 0.00
              75% <= 0.00
              95% <= 3.10
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 435

  messages-sent:
    count = 5

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 13.00
               min = 0.00
               max = 8.00
              mean = 1.18
            stddev = 2.36
            median = 0.00
              75% <= 1.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 9,087.00
               min = 16.00
               max = 6562.00
              mean = 151.45
            stddev = 844.12
            median = 16.00
              75% <= 85.75
              95% <= 89.00
              98% <= 5138.60
              99% <= 6562.00
            99.9% <= 6562.00
             count = 60

  remote-requests:
    count = 5

  requests-received:
             count = 60
         mean rate = 600.68 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 60
         mean rate = 600.62 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 5

  sent-bytes:
               sum = 4,126.00
               min = 16.00
               max = 1473.00
              mean = 68.77
            stddev = 187.10
            median = 39.00
              75% <= 89.00
              95% <= 92.00
              98% <= 1169.18
              99% <= 1473.00
            99.9% <= 1473.00
             count = 60

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 61

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 5

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 3445

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 135 ms
  compute all partitions: 12 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 243 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 12

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 117

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 9,039.00
               min = 16.00
               max = 6651.00
              mean = 153.20
            stddev = 865.42
            median = 44.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5338.60
              99% <= 6651.00
            99.9% <= 6651.00
             count = 59

  remote-requests:
    count = 3

  requests-received:
             count = 59
         mean rate = 342.81 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 60
         mean rate = 348.72 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,830.00
               min = 16.00
               max = 1473.00
              mean = 63.83
            stddev = 187.30
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1168.52
              99% <= 1473.00
            99.9% <= 1473.00
             count = 60

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 135

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 243

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 140 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 163 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 925.99
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 293.43 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 299.06 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 140

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 163

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.25469792440279

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = 0.0

  vertices-loaded:
             count = 10
         mean rate = 2.43 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:68077
Log Contents:
2018-08-08 13:37:45,479 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,544 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,544 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,546 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,546 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,721 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:45,937 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,112 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,560 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,571 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,719 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,732 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,759 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,760 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,768 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,774 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,774 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 5 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave5
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000007:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000007/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000007:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000007/tmp
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,780 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000007
INFO    2018-08-08 13:37:46,781 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,793 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,794 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,800 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30021, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,801 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:46,908 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:46,924 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:46,977 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave5/10.164.0.7:30005 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:46,982 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:46,983 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:47,005 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:47,016 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:47,019 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,022 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,027 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave5_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=5, port=30005)
INFO    2018-08-08 13:37:47,361 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,457 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,468 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,470 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,470 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,472 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,472 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,474 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,474 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,475 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,477 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,484 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,487 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,488 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,492 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,554 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,594 [load-0] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/example-directed.v:0+21'
INFO    2018-08-08 13:37:47,608 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0469486 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,608 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04619264 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,608 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044565503 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,608 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045323964 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,609 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044542722 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,609 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043915417 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,609 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043546025 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,610 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04322096 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,610 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04210174 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,610 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04257178 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-0] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=10, e=0)
INFO    2018-08-08 13:37:47,619 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 0.06527453 secs, (v=10, e=0) 153.19911 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,628 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0172, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.0515, MBytesSent = 0.0005, ave sent req MBytes = 0.0001, secs waited = 0.008
INFO    2018-08-08 13:37:47,629 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,632 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001017563 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,633 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002493735 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,633 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.38478E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003065 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006145352 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,638 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005354035 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,638 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004716385 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,639 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004342203 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,640 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004515598 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,640 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003222866 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,641 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003095983 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,641 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.014, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0219, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.011
INFO    2018-08-08 13:37:47,641 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=10, e=0)
INFO    2018-08-08 13:37:47,666 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,670 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:37:47,671 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50879.61M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,671 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.004, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.041
MBytes/sec sent = 0.0062, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.041
INFO    2018-08-08 13:37:47,672 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,690 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,690 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50879.61M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,702 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,744 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,748 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4ad4936c,outgoing=org.apache.giraph.conf.DefaultMessageClasses@29d37757)
WARN    2018-08-08 13:37:47,753 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,769 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,770 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,772 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave5_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=5, port=30005)
INFO    2018-08-08 13:37:47,819 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,819 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,819 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,820 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.13
MBytes/sec sent = 0.0107, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.13
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,825 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,826 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:37:47,835 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,848 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009737557 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005133791 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005994174 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011426698 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001858396 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009480721 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004656243 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010126522 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00949062 secs for 7 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,852 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007021297 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,855 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00786291 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,855 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50738.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,856 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0059, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.03
MBytes/sec sent = 0.0329, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.03
INFO    2018-08-08 13:37:47,856 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,861 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0331, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.1051, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:47,862 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,867 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,898 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,902 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27ead29e)
INFO    2018-08-08 13:37:47,913 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,915 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave5_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=5, port=30005)
INFO    2018-08-08 13:37:47,948 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,948 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,948 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,949 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.087
MBytes/sec sent = 0.016, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.087
INFO    2018-08-08 13:37:47,952 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,953 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,955 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,960 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001699063 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003171002 secs for 6 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003642392 secs for 18 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00241801 secs for 5 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002576681 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002657428 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00229703 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002058366 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,964 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002251836 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001302327 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009817334 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,966 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50585.20M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,970 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0877, MBytesSent = 0.0004, ave sent req MBytes = 0.0001, secs waited = 0.005
INFO    2018-08-08 13:37:47,970 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,973 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0496, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.1576, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:37:47,973 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 5 , message bytes = 435 , Memory (free/total/max) = 50585.20M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,981 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,005 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,008 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@56febdc)
INFO    2018-08-08 13:37:48,014 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,031 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave5_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=5, port=30005)
WARN    2018-08-08 13:37:48,094 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,122 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,122 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,122 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,123 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:37:48,126 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,129 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,133 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,136 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00223462 secs for 19 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,136 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003461825 secs for 14 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,138 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001087315 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00247962 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002203323 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001728814 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001415134 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001325645 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,143 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001455593 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,144 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001527427 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,145 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002828243 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,146 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50444.40M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,146 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0046, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.009
MBytes/sec sent = 0.0126, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.009
INFO    2018-08-08 13:37:48,146 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,149 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0496, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.1576, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:37:48,149 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 3 , message bytes = 117 , Memory (free/total/max) = 50444.40M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,152 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,179 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,182 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@712ca57b,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4564e94b)
INFO    2018-08-08 13:37:48,188 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,207 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave5_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=5, port=30005)
INFO    2018-08-08 13:37:48,222 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,271 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,300 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,300 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,300 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,301 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.152
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.152
INFO    2018-08-08 13:37:48,303 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,308 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,312 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,316 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002755919 secs for 13 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003663594 secs for 16 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002094146 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001440881 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,317 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001627817 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,317 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001275058 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,318 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001444561 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,318 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001182233 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,319 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001539584 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002758206 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002549848 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50303.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,322 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:37:48,322 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,328 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,328 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50303.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,334 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,355 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,358 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7af1cd63,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4351171a)
INFO    2018-08-08 13:37:48,362 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,362 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,362 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,365 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:48,391 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,438 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,444 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,447 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,669 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,669 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:37:50,673 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,857 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,857 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,859 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/5_worker
INFO    2018-08-08 13:37:50,861 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30021 closed
INFO    2018-08-08 13:37:50,861 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,863 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,868 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:55,080 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:55,084 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000005_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:55,109 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000005_0 is allowed to commit now
INFO    2018-08-08 13:37:55,119 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000005_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000005
INFO    2018-08-08 13:37:55,137 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000005_0' done.
INFO    2018-08-08 13:37:55,143 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000005_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128704
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=65
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=89
		CPU time spent (ms)=4670
		Physical memory (bytes) snapshot=1090936832
		Virtual memory (bytes) snapshot=58914754560
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000009 on graphalytics-giraph-slave6_36387
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:19544
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 703 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 395 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,788.00
               min = 16.00
               max = 6651.00
              mean = 119.37
            stddev = 730.80
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2343.84
              99% <= 6651.00
            99.9% <= 6651.00
             count = 82

  remote-requests:
    count = 0

  requests-received:
             count = 82
         mean rate = 114.16 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 136.63 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.69
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 703

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 395

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 98 ms
  compute all partitions: 15 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 4713 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 15

  compute-per-partition-ms:
               sum = 29.00
               min = 0.00
               max = 6.00
              mean = 0.88
            stddev = 1.27
            median = 0.00
              75% <= 2.00
              95% <= 3.20
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 86

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 29.00
               min = 0.00
               max = 6.00
              mean = 2.64
            stddev = 2.01
            median = 3.00
              75% <= 4.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,803.00
               min = 16.00
               max = 6651.00
              mean = 166.09
            stddev = 908.41
            median = 16.00
              75% <= 71.00
              95% <= 89.00
              98% <= 6126.04
              99% <= 6651.00
            99.9% <= 6651.00
             count = 53

  remote-requests:
    count = 2

  requests-received:
             count = 53
         mean rate = 371.03 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 54
         mean rate = 377.68 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,714.00
               min = 16.00
               max = 1473.00
              mean = 68.78
            stddev = 196.91
            median = 36.50
              75% <= 62.00
              95% <= 89.00
              98% <= 1334.60
              99% <= 1473.00
            99.9% <= 1473.00
             count = 54

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 98

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 4713

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 64 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 206 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 7.00
               min = 0.00
               max = 4.00
              mean = 0.21
            stddev = 0.74
            median = 0.00
              75% <= 0.00
              95% <= 1.90
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 126

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 7.00
               min = 0.00
               max = 4.00
              mean = 0.64
            stddev = 1.29
            median = 0.00
              75% <= 1.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,987.00
               min = 16.00
               max = 6651.00
              mean = 163.40
            stddev = 895.98
            median = 16.00
              75% <= 89.00
              95% <= 92.00
              98% <= 5863.92
              99% <= 6651.00
            99.9% <= 6651.00
             count = 55

  remote-requests:
    count = 2

  requests-received:
             count = 55
         mean rate = 530.54 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 538.29 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,786.00
               min = 16.00
               max = 1473.00
              mean = 67.61
            stddev = 193.51
            median = 20.50
              75% <= 68.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 64

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 206

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 134 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 148 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.15
            stddev = 0.44
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 78

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.45
            stddev = 0.82
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,891.00
               min = 16.00
               max = 6651.00
              mean = 161.65
            stddev = 891.71
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5863.56
              99% <= 6651.00
            99.9% <= 6651.00
             count = 55

  remote-requests:
    count = 2

  requests-received:
             count = 55
         mean rate = 323.55 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 329.00 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,738.00
               min = 16.00
               max = 1473.00
              mean = 66.75
            stddev = 193.58
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 134

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 148

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 140 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 272 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.03
            stddev = 0.17
            median = 0.00
              75% <= 0.00
              95% <= 0.30
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 925.88
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 293.57 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 299.32 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.68
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 140

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 272

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.9872115957766

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:67839
Log Contents:
2018-08-08 13:37:45,471 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,534 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,534 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,536 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,536 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,702 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:45,929 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,128 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,595 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,607 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,759 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,773 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,802 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,802 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,810 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,817 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,817 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 7 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,823 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,823 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave6
INFO    2018-08-08 13:37:46,823 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,823 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,823 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,823 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000009:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000009/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,824 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000009:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,824 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000009/tmp
INFO    2018-08-08 13:37:46,824 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,824 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,824 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,824 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,824 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,824 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,824 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000009
INFO    2018-08-08 13:37:46,824 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,837 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,838 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,843 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30023, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,845 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:46,955 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:46,973 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:47,014 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave6/10.164.0.8:30007 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:47,019 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:47,020 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:47,041 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:47,050 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:47,054 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,058 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,065 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave6_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007)
INFO    2018-08-08 13:37:47,366 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,461 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,472 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,474 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,474 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,476 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,477 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,488 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,488 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,488 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,489 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,489 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,490 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,491 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,495 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,560 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,611 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04999676 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,611 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042000555 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,611 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04293274 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04319591 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042594835 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041908465 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041386664 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,614 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040839467 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,614 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040774044 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,614 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039297637 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,614 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03858965 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,616 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0029, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.121
MBytes/sec sent = 0.0105, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.121
INFO    2018-08-08 13:37:47,617 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,622 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004072599 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,622 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003289776 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,623 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002705197 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,623 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002468444 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,627 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005538898 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,627 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005168887 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,628 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004648191 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,628 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004160446 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,629 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004118115 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,629 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004045177 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,630 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00337811 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,631 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.014, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0219, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.012
INFO    2018-08-08 13:37:47,631 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:37:47,669 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,674 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,682 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,684 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,684 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0025, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.065
MBytes/sec sent = 0.004, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.065
INFO    2018-08-08 13:37:47,684 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,694 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,694 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,706 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,747 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,752 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@55120f99,outgoing=org.apache.giraph.conf.DefaultMessageClasses@794b435f)
WARN    2018-08-08 13:37:47,756 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,771 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,772 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,774 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave6_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007)
INFO    2018-08-08 13:37:47,822 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,822 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,822 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.129
MBytes/sec sent = 0.0108, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.129
INFO    2018-08-08 13:37:47,826 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,829 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,829 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:37:47,836 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,848 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009900425 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00887892 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008057683 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003446527 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00735402 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006012853 secs for 7 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002934298 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004457077 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002252375 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009251389 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002639636 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,852 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,856 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0153, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:47,857 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,865 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:37:47,866 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 2 , message bytes = 86 , Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,871 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,902 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,904 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@73aff8f1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf)
INFO    2018-08-08 13:37:47,913 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,917 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave6_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007)
INFO    2018-08-08 13:37:47,951 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,951 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,951 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,953 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.087
MBytes/sec sent = 0.016, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.087
INFO    2018-08-08 13:37:47,955 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,956 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,958 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,963 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0025585 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003650175 secs for 17 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,964 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002195953 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,964 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003014655 secs for 11 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,964 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001856524 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00626195 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002409305 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,966 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00190596 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001101855 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,969 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002117091 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,969 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003416274 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,969 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50444.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,969 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0259, MBytesSent = 0.0001, ave sent req MBytes = 0.0001, secs waited = 0.004
INFO    2018-08-08 13:37:47,969 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,976 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:47,977 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 2 , message bytes = 126 , Memory (free/total/max) = 50444.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,984 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,009 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,012 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4a1e3ac1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5)
INFO    2018-08-08 13:37:48,020 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,038 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave6_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007)
WARN    2018-08-08 13:37:48,097 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,125 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,126 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,126 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,127 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:37:48,129 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,133 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,136 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,141 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002546759 secs for 10 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003453753 secs for 22 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005122348 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002697989 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002388296 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002197886 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,143 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001545013 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,143 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001885314 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,144 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001574195 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,145 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001085543 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,147 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002434299 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,147 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,147 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.014, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:48,147 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,154 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:48,154 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 2 , message bytes = 78 , Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,159 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,183 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,185 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4248ed58,outgoing=org.apache.giraph.conf.DefaultMessageClasses@712ca57b)
INFO    2018-08-08 13:37:48,191 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,210 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave6_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007)
INFO    2018-08-08 13:37:48,225 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,275 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,303 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,303 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,303 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,304 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:37:48,307 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,311 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,317 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,321 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002561688 secs for 8 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002116598 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001459037 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003458834 secs for 19 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,322 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001505463 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,323 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001714763 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,323 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003304684 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,323 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001881704 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,324 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001678897 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,324 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001531847 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,326 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002566872 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,326 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50162.87M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0122, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.014
MBytes/sec sent = 0.0679, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.015
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,331 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,331 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50162.87M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,337 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,359 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,362 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@1623bbe5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7af1cd63)
INFO    2018-08-08 13:37:48,365 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,365 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,365 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,368 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:48,394 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,442 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,447 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,450 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,573 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,573 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:37:50,577 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,814 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,814 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,818 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/7_worker
INFO    2018-08-08 13:37:50,820 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30023 closed
INFO    2018-08-08 13:37:50,820 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,822 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,826 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:55,039 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:55,043 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000007_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:55,072 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000007_0 is allowed to commit now
INFO    2018-08-08 13:37:55,084 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000007_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000007
INFO    2018-08-08 13:37:55,105 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000007_0' done.
INFO    2018-08-08 13:37:55,110 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000007_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128704
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=6
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=97
		CPU time spent (ms)=4640
		Physical memory (bytes) snapshot=1080377344
		Virtual memory (bytes) snapshot=58877612032
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000006 on graphalytics-giraph-slave7_43383
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:19551
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 751 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 343 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,820.00
               min = 16.00
               max = 6651.00
              mean = 115.53
            stddev = 718.11
            median = 25.00
              75% <= 53.00
              95% <= 91.80
              98% <= 1970.28
              99% <= 6651.00
            99.9% <= 6651.00
             count = 85

  remote-requests:
    count = 0

  requests-received:
             count = 85
         mean rate = 110.86 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 128.02 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.66
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 751

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 343

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 101 ms
  compute all partitions: 17 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 4663 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 17

  compute-per-partition-ms:
               sum = 31.00
               min = 0.00
               max = 7.00
              mean = 0.94
            stddev = 1.57
            median = 0.00
              75% <= 2.00
              95% <= 4.90
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 172

  messages-sent:
    count = 4

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 28.00
               min = 0.00
               max = 7.00
              mean = 2.55
            stddev = 2.38
            median = 3.00
              75% <= 4.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 8,979.00
               min = 16.00
               max = 6562.00
              mean = 152.19
            stddev = 857.12
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5267.40
              99% <= 6562.00
            99.9% <= 6562.00
             count = 59

  remote-requests:
    count = 4

  requests-received:
             count = 59
         mean rate = 413.67 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 59
         mean rate = 413.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 4

  sent-bytes:
               sum = 3,858.00
               min = 16.00
               max = 1473.00
              mean = 65.39
            stddev = 188.62
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1196.20
              99% <= 1473.00
            99.9% <= 1473.00
             count = 59

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 101

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 4

  wait-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.27
            stddev = 0.47
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 4663

  worker-context-post-superstep:
    value = 9

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 64 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 2094 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 11.00
               min = 0.00
               max = 8.00
              mean = 0.33
            stddev = 1.41
            median = 0.00
              75% <= 0.00
              95% <= 3.10
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 435

  messages-sent:
    count = 5

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 11.00
               min = 0.00
               max = 8.00
              mean = 1.00
            stddev = 2.41
            median = 0.00
              75% <= 1.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 9,231.00
               min = 16.00
               max = 6651.00
              mean = 151.33
            stddev = 846.86
            median = 16.00
              75% <= 76.00
              95% <= 89.00
              98% <= 5076.84
              99% <= 6651.00
            99.9% <= 6651.00
             count = 61

  remote-requests:
    count = 5

  requests-received:
             count = 61
         mean rate = 583.85 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 62
         mean rate = 593.40 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 5

  sent-bytes:
               sum = 4,158.00
               min = 16.00
               max = 1473.00
              mean = 67.06
            stddev = 184.23
            median = 20.50
              75% <= 89.00
              95% <= 92.00
              98% <= 1113.94
              99% <= 1473.00
            99.9% <= 1473.00
             count = 62

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 64

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 5

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 2094

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 135 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 450 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.15
            stddev = 0.44
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 195

  messages-sent:
    count = 5

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.45
            stddev = 0.82
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 9,071.00
               min = 16.00
               max = 6562.00
              mean = 146.31
            stddev = 828.86
            median = 30.00
              75% <= 53.00
              95% <= 89.00
              98% <= 4879.02
              99% <= 6562.00
            99.9% <= 6562.00
             count = 62

  remote-requests:
    count = 5

  requests-received:
             count = 62
         mean rate = 361.85 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 62
         mean rate = 361.84 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 5

  sent-bytes:
               sum = 3,918.00
               min = 16.00
               max = 1473.00
              mean = 63.19
            stddev = 184.17
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1113.16
              99% <= 1473.00
            99.9% <= 1473.00
             count = 62

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 135

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 5

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 450

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 140 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 166 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 1.00
              mean = 0.15
            stddev = 0.36
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 3.00
              mean = 0.45
            stddev = 1.04
            median = 0.00
              75% <= 0.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 925.88
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 292.34 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 298.05 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 140

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 166

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.98704535537684

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:67853
Log Contents:
2018-08-08 13:37:45,423 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,487 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,487 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,489 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,489 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,674 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:45,908 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,084 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,532 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,543 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,694 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,708 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,736 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,737 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,745 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,752 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,752 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 4 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,758 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,758 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave7
INFO    2018-08-08 13:37:46,758 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,758 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,758 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,758 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000006:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000006/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,759 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000006:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,759 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000006/tmp
INFO    2018-08-08 13:37:46,759 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,759 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,759 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,759 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,759 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,759 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,759 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000006
INFO    2018-08-08 13:37:46,760 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,773 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,774 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,780 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30020, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,781 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:46,892 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:46,910 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:46,960 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave7/10.164.0.9:30004 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:46,965 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:46,966 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:46,989 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:46,999 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:47,002 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,006 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,012 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave7_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004)
INFO    2018-08-08 13:37:47,361 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,458 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,468 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,470 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,470 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,472 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,473 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,477 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,477 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,481 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,484 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,484 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,487 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,487 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,487 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,491 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,557 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,612 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04694851 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,612 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046024714 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,612 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.054557025 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,612 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047858633 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,612 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04587816 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045498665 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04424208 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04334859 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042674303 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,613 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041978776 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,614 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04177156 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0032, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.052
MBytes/sec sent = 0.0049, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.053
INFO    2018-08-08 13:37:47,618 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,623 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004273226 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,623 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003536982 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,624 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003187264 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,625 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002914266 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,625 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002827193 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,626 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002838554 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,627 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002528236 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,628 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003139493 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,629 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002858228 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,630 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003140059 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00356887 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,632 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0095, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:37:47,632 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:37:47,665 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,669 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,677 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,679 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50738.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,679 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0006, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.051
MBytes/sec sent = 0.0009, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.051
INFO    2018-08-08 13:37:47,679 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,689 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,689 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,702 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,743 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,748 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@55120f99,outgoing=org.apache.giraph.conf.DefaultMessageClasses@794b435f)
WARN    2018-08-08 13:37:47,752 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,768 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,769 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,771 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave7_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004)
INFO    2018-08-08 13:37:47,818 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,818 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,818 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,819 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.129
MBytes/sec sent = 0.0108, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.129
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,825 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,825 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:37:47,833 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,845 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01066159 secs for 8 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,845 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006434361 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,845 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002370774 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,845 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009423463 secs for 7 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,846 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002368974 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,846 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002106867 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,847 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009085387 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,847 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006347199 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00730418 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011528597 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003839271 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50598.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,856 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.0229, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 13:37:47,856 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,864 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0248, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.008
MBytes/sec sent = 0.07, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.008
INFO    2018-08-08 13:37:47,865 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 4 , message bytes = 172 , Memory (free/total/max) = 50598.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,868 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,898 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,900 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@73aff8f1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf)
INFO    2018-08-08 13:37:47,909 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,911 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave7_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004)
INFO    2018-08-08 13:37:47,948 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,948 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,948 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,949 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.084
MBytes/sec sent = 0.0165, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.084
INFO    2018-08-08 13:37:47,951 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,952 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,954 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,959 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003245713 secs for 18 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,959 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001910007 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,959 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002449422 secs for 13 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,960 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002553964 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,961 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001728497 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001773881 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00126281 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001319236 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001138735 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009967956 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003061641 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,967 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50444.39M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,969 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0191, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0877, MBytesSent = 0.0004, ave sent req MBytes = 0.0001, secs waited = 0.004
INFO    2018-08-08 13:37:47,969 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,972 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0496, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.1576, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:37:47,973 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 5 , message bytes = 435 , Memory (free/total/max) = 50444.39M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,980 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,005 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,008 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4a1e3ac1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5)
INFO    2018-08-08 13:37:48,014 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,034 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave7_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004)
WARN    2018-08-08 13:37:48,094 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,121 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,122 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,122 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,123 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:37:48,126 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,129 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,133 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,138 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002045141 secs for 7 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002684542 secs for 7 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004878484 secs for 12 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003475464 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,138 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00165622 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,140 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001427227 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,140 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001854844 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002081025 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002044085 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001974774 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001772325 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,143 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50303.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,144 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.035, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:48,144 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,149 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,149 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 5 , message bytes = 195 , Memory (free/total/max) = 50303.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,155 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,179 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,182 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4248ed58,outgoing=org.apache.giraph.conf.DefaultMessageClasses@712ca57b)
INFO    2018-08-08 13:37:48,187 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,207 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave7_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=4, port=30004)
INFO    2018-08-08 13:37:48,221 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,271 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,299 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,300 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,300 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,301 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.152
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.152
INFO    2018-08-08 13:37:48,306 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,308 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,311 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,315 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001963881 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,315 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001573304 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004260047 secs for 14 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003375851 secs for 15 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001350929 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,317 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00272778 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,318 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001926541 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,318 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0025018 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,318 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001625301 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,318 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001293332 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003097742 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50162.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,321 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:37:48,321 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50162.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,334 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,355 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,358 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@1623bbe5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7af1cd63)
INFO    2018-08-08 13:37:48,362 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,362 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,362 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,365 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:48,391 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,438 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,444 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,446 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,670 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,670 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:37:50,673 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,871 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,871 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,873 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/4_worker
INFO    2018-08-08 13:37:50,875 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30020 closed
INFO    2018-08-08 13:37:50,875 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,877 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,881 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:55,093 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:55,097 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000004_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:55,120 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000004_0 is allowed to commit now
INFO    2018-08-08 13:37:55,129 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000004_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000004
INFO    2018-08-08 13:37:55,148 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000004_0' done.
INFO    2018-08-08 13:37:55,153 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000004_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128704
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=93
		CPU time spent (ms)=4910
		Physical memory (bytes) snapshot=1080197120
		Virtual memory (bytes) snapshot=58878791680
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000015 on graphalytics-giraph-slave8_41519
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:19536
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 819 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 262 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,673.00
               min = 16.00
               max = 6651.00
              mean = 119.42
            stddev = 736.23
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2506.36
              99% <= 6651.00
            99.9% <= 6651.00
             count = 81

  remote-requests:
    count = 0

  requests-received:
             count = 81
         mean rate = 97.45 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 96
         mean rate = 115.61 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,520.00
               min = 16.00
               max = 1473.00
              mean = 47.08
            stddev = 149.14
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 172.04
              99% <= 1473.00
            99.9% <= 1473.00
             count = 96

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 819

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 262

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 104 ms
  compute all partitions: 14 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 232 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 14

  compute-per-partition-ms:
               sum = 48.00
               min = 0.00
               max = 4.00
              mean = 1.45
            stddev = 1.42
            median = 1.00
              75% <= 3.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 48.00
               min = 3.00
               max = 6.00
              mean = 4.36
            stddev = 1.12
            median = 4.00
              75% <= 5.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6562.00
              mean = 168.67
            stddev = 904.82
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6173.62
              99% <= 6562.00
            99.9% <= 6562.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 353.07 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 352.79 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 104

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 232

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 64 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 201 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.27
            stddev = 0.47
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 930.25
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 504.53 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 514.94 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 64

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 201

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 137 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 169 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.12
            stddev = 0.33
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.67
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 926.78
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 294.47 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 300.23 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.71
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 137

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 169

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 141 ms
  compute all partitions: 6 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 160 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 6

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 925.89
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 291.90 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 297.59 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 141

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 160

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.29733772405453

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:67697
Log Contents:
2018-08-08 13:37:45,478 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,540 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,540 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,541 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,542 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,701 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:45,912 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,079 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,495 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,506 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,641 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,655 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,680 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,681 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,688 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,694 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,694 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 12 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,699 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,699 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave8
INFO    2018-08-08 13:37:46,699 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,699 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,700 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,700 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000015:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000015/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,700 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000015:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,700 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000015/tmp
INFO    2018-08-08 13:37:46,700 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,700 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,700 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,700 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,700 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,700 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,700 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000015
INFO    2018-08-08 13:37:46,701 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,713 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,713 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,720 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3001d, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,721 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:46,823 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:46,839 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:46,898 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave8/10.164.0.10:30012 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:46,903 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:46,904 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:46,924 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:46,932 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:46,935 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:46,938 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:46,944 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave8_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=12, port=30012)
INFO    2018-08-08 13:37:47,364 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,456 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,464 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,465 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,466 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,468 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,469 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,469 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,469 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,469 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,471 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,471 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,471 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,471 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,472 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,471 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,474 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,477 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,478 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,483 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,487 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,491 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,491 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,491 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,492 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,554 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,617 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.06162744 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05514038 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05464136 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.054045107 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05353456 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.053004153 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.052415296 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.051779535 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.051471177 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,618 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05096166 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,619 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05117976 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,621 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0028, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.059
MBytes/sec sent = 0.0044, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.059
INFO    2018-08-08 13:37:47,622 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,625 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00320506 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,626 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002878834 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,626 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 8.01723E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,627 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002276195 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,628 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002703095 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,628 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 7.73514E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,628 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002456869 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,629 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002725131 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,630 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005761559 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,631 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002790401 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,631 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002338996 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,631 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0186, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.008
MBytes/sec sent = 0.0291, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.008
INFO    2018-08-08 13:37:47,631 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:37:47,667 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,671 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:37:47,672 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50863.64M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,673 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0034, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.049
MBytes/sec sent = 0.0052, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.049
INFO    2018-08-08 13:37:47,673 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,691 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,691 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50863.64M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,700 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,745 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,749 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4fcc529,outgoing=org.apache.giraph.conf.DefaultMessageClasses@25cc7470)
WARN    2018-08-08 13:37:47,754 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,767 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,768 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,770 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave8_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=12, port=30012)
INFO    2018-08-08 13:37:47,821 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,821 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,821 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,822 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.131
MBytes/sec sent = 0.0106, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.131
INFO    2018-08-08 13:37:47,825 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,827 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,836 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,848 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0083957 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,848 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007148339 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004186416 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005656425 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007426269 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011448316 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004922165 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,849 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00899042 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005949334 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007662792 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,850 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011137727 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,851 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50710.03M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,852 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.024
MBytes/sec sent = 0.0407, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.024
INFO    2018-08-08 13:37:47,852 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,863 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,864 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50710.03M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,870 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,900 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,902 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@40620d8e)
INFO    2018-08-08 13:37:47,911 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,913 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave8_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=12, port=30012)
INFO    2018-08-08 13:37:47,949 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,949 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,949 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,950 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.086
MBytes/sec sent = 0.0161, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.086
INFO    2018-08-08 13:37:47,953 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,954 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,958 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,961 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003024974 secs for 16 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002348686 secs for 12 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001593153 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,962 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002076116 secs for 5 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00163502 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001947182 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001665125 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001500632 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001359066 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,964 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001755048 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,966 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002219611 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,966 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50569.23M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,966 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:37:47,966 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,975 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:47,975 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50569.23M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,982 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,006 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,008 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7d151a)
INFO    2018-08-08 13:37:48,013 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,032 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave8_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=12, port=30012)
INFO    2018-08-08 13:37:48,048 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,095 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,123 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,124 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,124 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,125 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:37:48,127 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,130 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,134 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,138 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003143087 secs for 18 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,138 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001688751 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,138 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001262469 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,138 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002042905 secs for 10 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,138 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001399728 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001387751 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00118583 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,139 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001079439 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,140 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 9.85541E-4 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,140 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00163742 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001732996 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50428.43M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,143 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:37:48,143 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,150 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,151 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50428.43M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,153 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,180 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,183 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@54534abf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@51745f40)
INFO    2018-08-08 13:37:48,188 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,206 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave8_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=12, port=30012)
INFO    2018-08-08 13:37:48,223 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,272 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,301 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,301 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,301 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,302 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.151
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.151
INFO    2018-08-08 13:37:48,305 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,309 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,313 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,316 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001508699 secs for 11 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002274087 secs for 22 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00120509 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,316 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001152494 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,317 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001287733 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,317 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001517105 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,318 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001114061 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,318 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001277433 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,319 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001274752 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00169942 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001787048 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50287.62M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,320 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0849, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.011
INFO    2018-08-08 13:37:48,320 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,329 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,329 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.62M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,331 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,357 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,359 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@37d00a23)
INFO    2018-08-08 13:37:48,363 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,363 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,363 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,365 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:48,392 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,439 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,445 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,448 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,569 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,569 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 13:37:50,573 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,608 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,608 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,610 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/12_worker
INFO    2018-08-08 13:37:50,612 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3001d closed
INFO    2018-08-08 13:37:50,612 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,615 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,618 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:54,830 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:54,834 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000012_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:54,859 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000012_0 is allowed to commit now
INFO    2018-08-08 13:37:54,870 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000012_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000012
INFO    2018-08-08 13:37:54,887 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000012_0' done.
INFO    2018-08-08 13:37:54,892 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000012_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128705
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=90
		CPU time spent (ms)=4090
		Physical memory (bytes) snapshot=1089503232
		Virtual memory (bytes) snapshot=58893733888
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0003_01_000011 on graphalytics-giraph-slave9_37771
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:19553
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 659 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 304 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,772.00
               min = 16.00
               max = 6651.00
              mean = 120.64
            stddev = 735.28
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2490.36
              99% <= 6651.00
            99.9% <= 6651.00
             count = 81

  remote-requests:
    count = 0

  requests-received:
             count = 81
         mean rate = 120.13 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 145.59 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.66
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 659

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 304

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 100 ms
  compute all partitions: 19 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1370 us

8/8/18 1:37:47 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 19

  compute-per-partition-ms:
               sum = 48.00
               min = 0.00
               max = 7.00
              mean = 1.45
            stddev = 1.52
            median = 1.00
              75% <= 2.00
              95% <= 4.90
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 43

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 48.00
               min = 3.00
               max = 7.00
              mean = 4.36
            stddev = 1.36
            median = 4.00
              75% <= 6.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 8,883.00
               min = 16.00
               max = 6651.00
              mean = 164.50
            stddev = 902.56
            median = 32.00
              75% <= 62.00
              95% <= 89.00
              98% <= 5994.80
              99% <= 6651.00
            99.9% <= 6651.00
             count = 54

  remote-requests:
    count = 1

  requests-received:
             count = 54
         mean rate = 378.07 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 55
         mean rate = 385.08 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,698.00
               min = 16.00
               max = 1473.00
              mean = 67.24
            stddev = 195.31
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1306.92
              99% <= 1473.00
            99.9% <= 1473.00
             count = 55

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 100

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1370

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 65 ms
  compute all partitions: 14 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 176 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 14

  compute-per-partition-ms:
               sum = 14.00
               min = 0.00
               max = 8.00
              mean = 0.42
            stddev = 1.46
            median = 0.00
              75% <= 0.00
              95% <= 3.80
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 213

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 14.00
               min = 0.00
               max = 8.00
              mean = 1.27
            stddev = 2.45
            median = 0.00
              75% <= 2.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 9,079.00
               min = 16.00
               max = 6651.00
              mean = 159.28
            stddev = 876.53
            median = 16.00
              75% <= 89.00
              95% <= 92.00
              98% <= 5601.56
              99% <= 6651.00
            99.9% <= 6651.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 544.17 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 552.98 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,894.00
               min = 16.00
               max = 1473.00
              mean = 67.14
            stddev = 190.22
            median = 20.50
              75% <= 76.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 65

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 176

  worker-context-post-superstep:
    value = 32

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 136 ms
  compute all partitions: 12 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 169 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 12

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 117

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 3.00
              mean = 0.27
            stddev = 0.90
            median = 0.00
              75% <= 0.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 8,951.00
               min = 16.00
               max = 6651.00
              mean = 157.04
            stddev = 876.15
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5601.08
              99% <= 6651.00
            99.9% <= 6651.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 331.82 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 337.70 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,798.00
               min = 16.00
               max = 1473.00
              mean = 65.48
            stddev = 190.34
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 136

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 169

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 140 ms
  compute all partitions: 12 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 173 us

8/8/18 1:37:48 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 12

  compute-per-partition-ms:
               sum = 7.00
               min = 0.00
               max = 3.00
              mean = 0.21
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.30
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 7.00
               min = 0.00
               max = 4.00
              mean = 0.64
            stddev = 1.43
            median = 0.00
              75% <= 0.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,771.00
               min = 16.00
               max = 6651.00
              mean = 171.98
            stddev = 927.68
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6388.52
              99% <= 6651.00
            99.9% <= 6651.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 292.30 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 297.48 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.68
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 140

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 173

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.98697268411772

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:37:50 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:38:05 +0000 2018
LogLength:67851
Log Contents:
2018-08-08 13:37:45,523 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:37:45,586 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:37:45,586 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:37:45,588 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:37:45,588 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0003, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:37:45,767 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:37:45,992 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003
2018-08-08 13:37:46,162 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:37:46,617 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:37:46,629 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:37:46,786 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:37:46,800 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:37:46,830 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:37:46,831 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:37:46,839 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:37:46,846 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0003/_haltComputation
INFO    2018-08-08 13:37:46,846 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0003, 9 on graphalytics-giraph:2181
INFO    2018-08-08 13:37:46,851 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:37:46,851 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave9
INFO    2018-08-08 13:37:46,851 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:37:46,851 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:37:46,851 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:37:46,851 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000011:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000011/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:37:46,852 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000011:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:37:46,852 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000011/tmp
INFO    2018-08-08 13:37:46,852 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:37:46,852 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:37:46,852 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:37:46,852 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:37:46,852 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:37:46,852 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:37:46,852 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0003/container_1533735211869_0003_01_000011
INFO    2018-08-08 13:37:46,853 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:37:46,865 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:37:46,866 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:37:46,873 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30025, negotiated timeout = 40000
INFO    2018-08-08 13:37:46,874 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:37:46,986 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:37:47,003 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:37:47,055 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave9/10.164.0.11:30009 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:37:47,060 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:37:47,061 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:37:47,083 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:37:47,093 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:47,097 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,099 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:37:47,106 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave9_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=9, port=30009)
INFO    2018-08-08 13:37:47,364 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,459 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:37:47,470 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,472 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,474 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,474 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,475 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,476 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,477 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,479 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,480 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,482 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,485 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,486 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,489 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,489 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:37:47,491 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,492 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,493 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,495 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,496 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,496 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,497 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,497 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,499 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:37:47,559 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,597 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03753754 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,615 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045078095 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,616 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04153517 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,616 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042167973 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,616 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042865705 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,616 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041266985 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,615 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044889007 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,617 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040766213 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,619 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04236447 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,619 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04197794 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,619 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041345343 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,620 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0033, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.05
MBytes/sec sent = 0.0051, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.05
INFO    2018-08-08 13:37:47,621 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:37:47,625 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003898244 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,627 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003807474 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,627 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003442028 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,628 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004279413 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,634 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.009031352 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,634 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.007665911 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.007180629 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006053664 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006780024 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005487177 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,635 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005119205 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:37:47,636 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0025, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.004, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:47,637 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:37:47,668 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:37:47,673 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,683 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:37:47,684 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50738.76M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,685 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0003, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.054
MBytes/sec sent = 0.0004, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.054
INFO    2018-08-08 13:37:47,685 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,692 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,692 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.76M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,705 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:37:47,746 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,751 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@55120f99,outgoing=org.apache.giraph.conf.DefaultMessageClasses@794b435f)
WARN    2018-08-08 13:37:47,755 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:37:47,769 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,770 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,772 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave9_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=9, port=30009)
INFO    2018-08-08 13:37:47,821 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,822 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,822 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,823 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.131
MBytes/sec sent = 0.0106, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.131
INFO    2018-08-08 13:37:47,826 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,828 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,837 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:37:47,852 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004385949 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,852 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004995324 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,852 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013374649 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,852 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010119751 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,852 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012059496 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,852 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008585348 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,854 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005761003 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,854 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012713606 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,854 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007818949 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,854 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005515059 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,856 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010576969 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,857 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50597.96M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,858 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0153, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,858 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,865 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0283, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0901, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 13:37:47,865 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 1 , message bytes = 43 , Memory (free/total/max) = 50597.96M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,871 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:37:47,901 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:47,903 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=731,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@73aff8f1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf)
INFO    2018-08-08 13:37:47,911 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:47,913 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave9_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=9, port=30009)
INFO    2018-08-08 13:37:47,950 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:47,950 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:47,950 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:47,951 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.086
MBytes/sec sent = 0.0161, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.086
INFO    2018-08-08 13:37:47,954 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:47,955 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:47,958 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:37:47,963 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004184399 secs for 15 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,963 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003714017 secs for 14 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,964 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004032322 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,965 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004705737 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,966 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001229976 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,968 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002945928 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,968 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009911466 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,968 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00270592 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,969 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002240156 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,970 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001444754 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,972 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003020938 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:47,972 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50444.35M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,972 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0092, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0435, MBytesSent = 0.0002, ave sent req MBytes = 0.0001, secs waited = 0.004
INFO    2018-08-08 13:37:47,972 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:47,975 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0661, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.2101, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:37:47,976 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 3 , message bytes = 213 , Memory (free/total/max) = 50444.35M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:47,983 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:37:48,008 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,011 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=2196,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4a1e3ac1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5)
INFO    2018-08-08 13:37:48,018 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,036 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave9_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=9, port=30009)
INFO    2018-08-08 13:37:48,049 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,096 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,124 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,125 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,125 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,126 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:37:48,128 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,132 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,135 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:37:48,141 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003031425 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005472117 secs for 20 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,141 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003514566 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002641134 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,142 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001013142 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,145 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003065668 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,145 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004011425 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,146 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002462146 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,147 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004410439 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,147 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003976344 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,148 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002891976 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,149 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50303.55M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,149 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0057, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.0157, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 13:37:48,149 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,154 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0397, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.1051, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:37:48,154 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 3 , message bytes = 117 , Memory (free/total/max) = 50303.55M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,159 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:37:48,182 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,185 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=17,msgCount=28,msgBytesCount=1092,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4248ed58,outgoing=org.apache.giraph.conf.DefaultMessageClasses@712ca57b)
INFO    2018-08-08 13:37:48,190 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 13:37:48,208 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave9_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=9, port=30009)
INFO    2018-08-08 13:37:48,224 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,274 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,302 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave15, MRtaskID=0, port=30000)
INFO    2018-08-08 13:37:48,303 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:37:48,303 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:37:48,303 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.149
MBytes/sec sent = 0.0094, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.149
INFO    2018-08-08 13:37:48,306 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:37:48,311 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:37:48,314 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:37:48,320 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005992245 secs for 18 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005296369 secs for 14 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004219228 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,320 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004563122 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004077355 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,321 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 9.43709E-4 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,323 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002368032 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,326 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003892722 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,326 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004359126 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,326 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003733688 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,326 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002913301 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50162.75M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0108, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.016
MBytes/sec sent = 0.0599, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.016
INFO    2018-08-08 13:37:48,327 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:37:48,330 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:37:48,330 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50162.75M / 52608.00M / 52608.00M
INFO    2018-08-08 13:37:48,336 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:37:48,358 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:37:48,361 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.DirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@1623bbe5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7af1cd63)
INFO    2018-08-08 13:37:48,365 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:37:48,366 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:37:48,366 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:37:48,367 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:37:48,393 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:37:48,441 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0003/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:37:48,446 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:37:48,449 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0003/_masterJobState)
INFO    2018-08-08 13:37:50,472 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:37:50,472 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:37:50,475 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:37:50,650 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:37:50,650 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:37:50,652 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0003/_cleanedUpDir/9_worker
INFO    2018-08-08 13:37:50,654 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30025 closed
INFO    2018-08-08 13:37:50,654 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:37:50,656 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:37:50,660 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:37:54,874 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:37:54,877 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0003_m_000009_0 is done. And is in the process of committing
INFO    2018-08-08 13:37:54,903 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0003_m_000009_0 is allowed to commit now
INFO    2018-08-08 13:37:54,913 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0003_m_000009_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r875189_LCC-example-directed/_temporary/1/task_1533735211869_0003_m_000009
INFO    2018-08-08 13:37:54,930 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0003_m_000009_0' done.
INFO    2018-08-08 13:37:54,936 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0003_m_000009_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128704
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=21
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=92
		CPU time spent (ms)=4870
		Physical memory (bytes) snapshot=1074962432
		Virtual memory (bytes) snapshot=58900258816
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0003=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0003/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog

