

Container: container_1533735211869_0004_01_000002 on graphalytics-giraph-slave10_46663
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:5537
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
superstep time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave7_9
  largest: 0 ms from graphalytics-giraph-slave7_9
compute all partitions
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave7_9
  largest: 0 ms from graphalytics-giraph-slave7_9
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave7_9
  largest: 0 ms from graphalytics-giraph-slave7_9
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave7_9
  largest: 0 us from graphalytics-giraph-slave7_9
wait requests time
  mean: 396.38461538461536 us
  smallest: 903 us from graphalytics-giraph-slave11_7
  largest: 274 us from graphalytics-giraph-slave13_13
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave7_9
  largest: 0 bytes from graphalytics-giraph-slave7_9
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave7_9
  largest: 0 bytes from graphalytics-giraph-slave7_9
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave7_9
  largest: 100.0 % from graphalytics-giraph-slave7_9

--- METRICS: superstep 0 ---
superstep time
  mean: 85.76923076923077 ms
  smallest: 88 ms from graphalytics-giraph-slave8_2
  largest: 83 ms from graphalytics-giraph-slave14_10
compute all partitions
  mean: 15.0 ms
  smallest: 17 ms from graphalytics-giraph-slave15_1
  largest: 12 ms from graphalytics-giraph-slave8_2
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave7_9
  largest: 0 ms from graphalytics-giraph-slave7_9
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave7_9
  largest: 0 us from graphalytics-giraph-slave7_9
wait requests time
  mean: 2094.0 us
  smallest: 7184 us from graphalytics-giraph-slave9_3
  largest: 215 us from graphalytics-giraph-slave3_12
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave7_9
  largest: 0 bytes from graphalytics-giraph-slave7_9
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave7_9
  largest: 0 bytes from graphalytics-giraph-slave7_9
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave7_9
  largest: 100.0 % from graphalytics-giraph-slave7_9

--- METRICS: superstep 1 ---
superstep time
  mean: 56.38461538461539 ms
  smallest: 59 ms from graphalytics-giraph-slave13_13
  largest: 54 ms from graphalytics-giraph-slave15_1
compute all partitions
  mean: 9.384615384615385 ms
  smallest: 13 ms from graphalytics-giraph-slave7_9
  largest: 8 ms from graphalytics-giraph-slave12_5
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave7_9
  largest: 0 ms from graphalytics-giraph-slave7_9
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave7_9
  largest: 0 us from graphalytics-giraph-slave7_9
wait requests time
  mean: 190.46153846153845 us
  smallest: 302 us from graphalytics-giraph-slave3_12
  largest: 158 us from graphalytics-giraph-slave6_6
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave7_9
  largest: 0 bytes from graphalytics-giraph-slave7_9
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave7_9
  largest: 0 bytes from graphalytics-giraph-slave7_9
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave7_9
  largest: 100.0 % from graphalytics-giraph-slave7_9

--- METRICS: superstep 2 ---
superstep time
  mean: 131.6153846153846 ms
  smallest: 133 ms from graphalytics-giraph-slave5_8
  largest: 130 ms from graphalytics-giraph-slave15_1
compute all partitions
  mean: 10.23076923076923 ms
  smallest: 14 ms from graphalytics-giraph-slave13_13
  largest: 7 ms from graphalytics-giraph-slave8_2
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave7_9
  largest: 0 ms from graphalytics-giraph-slave7_9
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave7_9
  largest: 0 us from graphalytics-giraph-slave7_9
wait requests time
  mean: 294.3076923076923 us
  smallest: 1403 us from graphalytics-giraph-slave15_1
  largest: 155 us from graphalytics-giraph-slave6_6
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave7_9
  largest: 0 bytes from graphalytics-giraph-slave7_9
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave7_9
  largest: 0 bytes from graphalytics-giraph-slave7_9
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave7_9
  largest: 100.0 % from graphalytics-giraph-slave7_9
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:52788
Log Contents:
2018-08-08 13:38:47,997 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,060 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,061 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,062 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,062 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,237 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,468 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,680 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:49,170 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,181 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,329 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,344 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,372 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,373 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceMaster (master thread)...
INFO    2018-08-08 13:38:49,381 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,387 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,387 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 0 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave10
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000002:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000002/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000002:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000002/tmp
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,393 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000002
INFO    2018-08-08 13:38:49,394 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.master.BspServiceMaster@3574e198
INFO    2018-08-08 13:38:49,407 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,407 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,415 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30032, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,416 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,423 [main] org.apache.giraph.graph.GraphTaskManager  - map: No need to do anything when not a worker
INFO    2018-08-08 13:38:49,423 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for MASTER_ONLY
INFO    2018-08-08 13:38:49,442 [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,445 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - becomeMaster: First child is '/_hadoopBsp/job_1533735211869_0004/_masterElectionDir/graphalytics-giraph-slave10_00000000000' and my bid is '/_hadoopBsp/job_1533735211869_0004/_masterElectionDir/graphalytics-giraph-slave10_00000000000'
INFO    2018-08-08 13:38:49,452 [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,551 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,568 [org.apache.giraph.master.MasterThread] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,614 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave10/10.164.0.12:30000 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,619 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,620 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,623 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - becomeMaster: I am now the master!
INFO    2018-08-08 13:38:49,625 [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,759 [org.apache.giraph.master.MasterThread] org.apache.giraph.io.formats.GiraphFileInputFormat  - Total input paths to process : 1
INFO    2018-08-08 13:38:49,775 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - generateVERTEXInputSplits: Got 1 input splits for 143 input threads
WARN    2018-08-08 13:38:49,775 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - createVERTEXInputSplits: Number of inputSplits=1 < 143=total number of input threads, some threads will be not used
INFO    2018-08-08 13:38:49,797 [org.apache.giraph.master.MasterThread] org.apache.giraph.io.formats.GiraphFileInputFormat  - Total input paths to process : 1
INFO    2018-08-08 13:38:49,801 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - generateEDGEInputSplits: Got 1 input splits for 143 input threads
WARN    2018-08-08 13:38:49,801 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - createEDGEInputSplits: Number of inputSplits=1 < 143=total number of input threads, some threads will be not used
INFO    2018-08-08 13:38:49,832 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,833 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,834 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,834 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,835 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,836 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,836 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,836 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,836 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,836 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,836 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,836 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,836 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,841 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,842 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - computePartitionCount: Creating 429 partitions.
INFO    2018-08-08 13:38:49,865 [org.apache.giraph.master.MasterThread] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.timeout is deprecated. Instead, use mapreduce.task.timeout
INFO    2018-08-08 13:38:49,866 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep -1 on path /_hadoopBsp/job_1533735211869_0004/_inputSplitsWorkerDoneDir
INFO    2018-08-08 13:38:49,953 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,954 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,954 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,965 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,970 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,981 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,059 [netty-server-worker-5] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0005, ave received req MBytes = 0.0003, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:50,204 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 13 out of 13 workers finished on superstep -1 on path /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerFinishedDir
INFO    2018-08-08 13:38:50,207 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: Waiting on []
INFO    2018-08-08 13:38:50,229 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) on superstep = -1
INFO    2018-08-08 13:38:50,233 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep -1 took 0.431 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 0
WARN    2018-08-08 13:38:50,243 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:50,287 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,288 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:38:50,289 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=6, port=30006):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=3, port=30003):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=9, port=30009):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=2, port=30002):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=4, port=30004):(v=1, e=4),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=8, port=30008):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=11, port=30011):(v=1, e=0),]
INFO    2018-08-08 13:38:50,290 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=11, port=30011) - 1
INFO    2018-08-08 13:38:50,290 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 1, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=4, port=30004) - 4
INFO    2018-08-08 13:38:50,296 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 0 on path /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerFinishedDir
INFO    2018-08-08 13:38:50,359 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) on superstep = 0
INFO    2018-08-08 13:38:50,364 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 0 took 0.13 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 1
INFO    2018-08-08 13:38:50,400 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,400 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:38:50,401 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=6, port=30006):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=3, port=30003):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=9, port=30009):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=2, port=30002):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=4, port=30004):(v=1, e=4),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=8, port=30008):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=11, port=30011):(v=1, e=0),]
INFO    2018-08-08 13:38:50,401 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=11, port=30011) - 1
INFO    2018-08-08 13:38:50,401 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 1, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=4, port=30004) - 4
INFO    2018-08-08 13:38:50,445 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 13 out of 13 workers finished on superstep 1 on path /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerFinishedDir
INFO    2018-08-08 13:38:50,446 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: Waiting on []
INFO    2018-08-08 13:38:50,456 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) on superstep = 1
INFO    2018-08-08 13:38:50,461 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0
INFO    2018-08-08 13:38:50,548 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 1 took 0.183 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 2
INFO    2018-08-08 13:38:50,568 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,568 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:38:50,569 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=6, port=30006):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=3, port=30003):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=9, port=30009):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=2, port=30002):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=4, port=30004):(v=1, e=4),Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=8, port=30008):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=11, port=30011):(v=1, e=0),]
INFO    2018-08-08 13:38:50,569 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=11, port=30011) - 1
INFO    2018-08-08 13:38:50,569 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 1, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=4, port=30004) - 4
INFO    2018-08-08 13:38:50,576 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 2 on path /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerFinishedDir
INFO    2018-08-08 13:38:50,625 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) on superstep = 2
INFO    2018-08-08 13:38:50,628 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1
INFO    2018-08-08 13:38:50,706 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 2 took 0.158 seconds ended with state ALL_SUPERSTEPS_DONE and is now on superstep 3
INFO    2018-08-08 13:38:50,707 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - setJobState: {"_applicationAttemptKey":-1,"_stateKey":"FINISHED","_superstepKey":-1} on superstep 3
INFO    2018-08-08 13:38:50,709 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - setJobState: {"_applicationAttemptKey":-1,"_stateKey":"FINISHED","_superstepKey":-1}
INFO    2018-08-08 13:38:50,716 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/0_master
INFO    2018-08-08 13:38:50,718 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Node /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir already exists, no need to create.
INFO    2018-08-08 13:38:50,719 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 1 of 14 desired children from /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir
INFO    2018-08-08 13:38:50,719 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir to change since only got 1 nodes.
INFO    2018-08-08 13:38:52,784 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:38:52,786 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 2 of 14 desired children from /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir
INFO    2018-08-08 13:38:52,787 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir to change since only got 2 nodes.
INFO    2018-08-08 13:38:52,982 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:38:52,983 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 4 of 14 desired children from /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir
INFO    2018-08-08 13:38:52,983 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir to change since only got 4 nodes.
INFO    2018-08-08 13:38:53,036 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:38:53,038 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 6 of 14 desired children from /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir
INFO    2018-08-08 13:38:53,038 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir to change since only got 6 nodes.
INFO    2018-08-08 13:38:53,129 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:38:53,130 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 7 of 14 desired children from /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir
INFO    2018-08-08 13:38:53,130 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir to change since only got 7 nodes.
INFO    2018-08-08 13:38:53,132 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:38:53,134 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 8 of 14 desired children from /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir
INFO    2018-08-08 13:38:53,134 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir to change since only got 8 nodes.
INFO    2018-08-08 13:38:53,137 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:38:53,138 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 9 of 14 desired children from /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir
INFO    2018-08-08 13:38:53,138 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir to change since only got 9 nodes.
INFO    2018-08-08 13:38:53,140 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:38:53,142 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 10 of 14 desired children from /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir
INFO    2018-08-08 13:38:53,142 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir to change since only got 10 nodes.
INFO    2018-08-08 13:38:53,145 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:38:53,146 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:38:53,146 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 11 of 14 desired children from /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir
INFO    2018-08-08 13:38:53,146 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir to change since only got 11 nodes.
INFO    2018-08-08 13:38:53,147 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 12 of 14 desired children from /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir
INFO    2018-08-08 13:38:53,147 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir to change since only got 12 nodes.
INFO    2018-08-08 13:38:53,150 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:38:53,151 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 13 of 14 desired children from /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir
INFO    2018-08-08 13:38:53,151 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir to change since only got 13 nodes.
INFO    2018-08-08 13:38:53,262 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:38:53,264 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 14 of 14 desired children from /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir
INFO    2018-08-08 13:38:53,264 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanupZooKeeper: Removing the following path and all children - /_hadoopBsp/job_1533735211869_0004 from ZooKeeper list graphalytics-giraph:2181
INFO    2018-08-08 13:38:53,346 [main-EventThread] org.apache.giraph.bsp.BspService  - process: applicationAttemptChanged signaled
INFO    2018-08-08 13:38:53,350 [main-EventThread] org.apache.giraph.bsp.BspService  - process: masterElectionChildrenChanged signaled
INFO    2018-08-08 13:38:53,358 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:38:53,401 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanup: Removed HDFS checkpoint directory (_bsp/_checkpoints//job_1533735211869_0004) with return = false since the job GraphalyticsBenchmark: PageRankJob succeeded 
INFO    2018-08-08 13:38:53,401 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:53,405 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:55,609 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:55,610 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:55,614 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:59,825 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:59,828 [org.apache.giraph.master.MasterThread] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30032 closed
INFO    2018-08-08 13:38:59,828 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:59,828 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - setup: Took 0.074 seconds.
INFO    2018-08-08 13:38:59,829 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - input superstep: Took 0.431 seconds.
INFO    2018-08-08 13:38:59,829 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 0: Took 0.13 seconds.
INFO    2018-08-08 13:38:59,829 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 1: Took 0.183 seconds.
INFO    2018-08-08 13:38:59,829 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 2: Took 0.158 seconds.
INFO    2018-08-08 13:38:59,829 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - shutdown: Took 9.123 seconds.
INFO    2018-08-08 13:38:59,829 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - total: Took 10.101 seconds.
INFO    2018-08-08 13:38:59,829 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Joined with master thread
INFO    2018-08-08 13:38:59,832 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000000_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:59,863 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000000_0' done.
INFO    2018-08-08 13:38:59,868 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000000_0: Counters: 48
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129327
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=108
		CPU time spent (ms)=4640
		Physical memory (bytes) snapshot=1097400320
		Virtual memory (bytes) snapshot=58927800320
		Total committed heap usage (bytes)=55163486208
	Giraph Stats
		Aggregate bytes loaded from local disks (out-of-core)=0
		Aggregate bytes stored to local disks (out-of-core)=0
		Aggregate edges=17
		Aggregate finished vertices=10
		Aggregate sent message bytes=1394
		Aggregate sent messages=34
		Aggregate vertices=10
		Current master task partition=0
		Current workers=13
		Last checkpointed superstep=0
		Lowest percentage of graph in memory so far (out-of-core)=100
		Sent message bytes=0
		Sent messages=0
		Superstep=3
	Giraph Timers
		Initialize (ms)=306
		Input superstep (ms)=431
		Setup (ms)=74
		Shutdown (ms)=9122
		Superstep 0 PageRankComputation (ms)=130
		Superstep 1 PageRankComputation (ms)=183
		Superstep 2 PageRankComputation (ms)=158
		Total (ms)=10101
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000010 on graphalytics-giraph-slave11_46641
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15680
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 593 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 903 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 10,042.00
               min = 16.00
               max = 6653.00
              mean = 128.74
            stddev = 750.49
            median = 25.00
              75% <= 53.00
              95% <= 95.80
              98% <= 2992.04
              99% <= 6653.00
            99.9% <= 6653.00
             count = 78

  remote-requests:
    count = 0

  requests-received:
             count = 78
         mean rate = 128.18 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 161.43 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,580.00
               min = 16.00
               max = 1473.00
              mean = 46.73
            stddev = 147.68
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 593

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 903

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 86 ms
  compute all partitions: 15 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 2667 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 15

  compute-per-partition-ms:
               sum = 33.00
               min = 0.00
               max = 7.00
              mean = 1.00
            stddev = 1.59
            median = 0.00
              75% <= 2.00
              95% <= 4.20
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 82

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 32.00
               min = 0.00
               max = 7.00
              mean = 2.91
            stddev = 2.52
            median = 4.00
              75% <= 5.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 9,057.00
               min = 16.00
               max = 6653.00
              mean = 170.89
            stddev = 908.93
            median = 16.00
              75% <= 71.00
              95% <= 164.60
              98% <= 6148.04
              99% <= 6653.00
            99.9% <= 6653.00
             count = 53

  remote-requests:
    count = 2

  requests-received:
             count = 53
         mean rate = 441.28 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 54
         mean rate = 449.19 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,738.00
               min = 16.00
               max = 1473.00
              mean = 69.22
            stddev = 196.91
            median = 35.50
              75% <= 83.00
              95% <= 89.00
              98% <= 1334.60
              99% <= 1473.00
            99.9% <= 1473.00
             count = 54

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 86

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 2667

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 57 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 162 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 82

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 9,057.00
               min = 16.00
               max = 6653.00
              mean = 170.89
            stddev = 909.19
            median = 16.00
              75% <= 71.00
              95% <= 164.60
              98% <= 6148.04
              99% <= 6653.00
            99.9% <= 6653.00
             count = 53

  remote-requests:
    count = 2

  requests-received:
             count = 53
         mean rate = 566.59 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 54
         mean rate = 577.09 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,738.00
               min = 16.00
               max = 1473.00
              mean = 69.22
            stddev = 196.90
            median = 35.50
              75% <= 83.00
              95% <= 89.00
              98% <= 1334.60
              99% <= 1473.00
            99.9% <= 1473.00
             count = 54

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 57

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 162

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 132 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 160 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.27
            stddev = 0.47
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6653.00
              mean = 176.96
            stddev = 927.04
            median = 16.00
              75% <= 89.00
              95% <= 189.80
              98% <= 6400.52
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 311.08 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 317.20 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.68
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 132

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 160

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.22443992378068

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:59807
Log Contents:
2018-08-08 13:38:48,054 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,117 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,117 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,119 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,119 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,299 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,526 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,717 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:49,178 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,191 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,343 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,359 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,389 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,390 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,397 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,404 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,404 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 7 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,409 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,409 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave11
INFO    2018-08-08 13:38:49,409 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,409 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,409 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,409 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000010:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000010/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,410 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000010:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,410 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000010/tmp
INFO    2018-08-08 13:38:49,410 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,410 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,410 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,410 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,410 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,411 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,411 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000010
INFO    2018-08-08 13:38:49,411 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,424 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,425 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,431 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30034, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,432 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,547 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,564 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,619 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave11/10.164.0.13:30007 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,624 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,624 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,645 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,656 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,660 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,663 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,669 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave11_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007)
INFO    2018-08-08 13:38:49,853 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,947 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,956 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,958 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,960 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,961 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,961 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,969 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,970 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,970 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,970 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,971 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,971 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,971 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,973 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,973 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,975 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,975 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,976 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,976 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,978 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,978 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,983 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,049 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,107 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05685774 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,107 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.049493633 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,107 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04850725 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,107 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05027121 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,107 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04526405 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,108 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044492207 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,107 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04629212 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,107 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04714028 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,108 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04307217 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,108 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043783825 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,108 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042744435 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,112 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.054
MBytes/sec sent = 0.0048, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.055
INFO    2018-08-08 13:38:50,113 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,117 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004122458 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,119 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004682646 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,120 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.72688E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,120 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003890384 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,121 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003795027 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,121 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003746333 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,122 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00108369 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,122 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002544484 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,122 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002486111 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,123 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.007417829 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,125 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003571524 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,126 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:38:50,126 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:38:50,171 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,175 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,183 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,184 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,185 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0005, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0007, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.063
INFO    2018-08-08 13:38:50,185 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,194 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,195 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,206 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,243 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,247 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
WARN    2018-08-08 13:38:50,252 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:50,265 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,266 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,268 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave11_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007)
INFO    2018-08-08 13:38:50,305 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,306 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,306 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,308 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.113
MBytes/sec sent = 0.0123, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.113
INFO    2018-08-08 13:38:50,311 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,313 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,320 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,331 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005554724 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00622869 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,332 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007365739 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008611139 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002110155 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009739785 secs for 8 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004808484 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003838116 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,333 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002538441 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,333 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009293234 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,335 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003016903 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,336 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,339 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0146, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:38:50,339 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,346 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,347 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 2 , message bytes = 82 , Memory (free/total/max) = 50582.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,352 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,374 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,376 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 13:38:50,384 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,386 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave11_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007)
INFO    2018-08-08 13:38:50,415 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,415 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,415 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,416 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.069
MBytes/sec sent = 0.0201, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.069
INFO    2018-08-08 13:38:50,419 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,420 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,424 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,427 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003148393 secs for 18 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001885903 secs for 5 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002255747 secs for 10 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001997604 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002550098 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,430 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00125178 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,430 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001555923 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,430 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001097175 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,431 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001459082 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,433 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002265639 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,433 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002146068 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,433 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,434 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0044, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.011, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 13:38:50,434 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,441 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,441 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 2 , message bytes = 82 , Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,446 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,470 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,473 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 13:38:50,479 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,497 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave11_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007)
INFO    2018-08-08 13:38:50,508 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,556 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,583 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,583 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,583 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,584 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.143
MBytes/sec sent = 0.0098, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.143
INFO    2018-08-08 13:38:50,586 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,589 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,593 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,597 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003902309 secs for 19 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001872895 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00111521 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002232924 secs for 8 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00196211 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,599 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001800261 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,599 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001502201 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,599 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0014449 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,600 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00115228 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,601 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001534094 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,602 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002487367 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,603 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.67M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,603 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:38:50,603 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,611 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,612 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.67M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,614 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,637 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,640 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 13:38:50,643 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,643 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,643 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,646 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,669 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,714 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,719 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,721 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:52,950 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:52,951 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:38:52,954 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:53,136 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:53,136 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:53,138 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/7_worker
INFO    2018-08-08 13:38:53,140 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30034 closed
INFO    2018-08-08 13:38:53,140 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:53,143 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:53,146 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,356 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,362 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000007_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:57,387 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000007_0 is allowed to commit now
INFO    2018-08-08 13:38:57,396 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000007_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000007
INFO    2018-08-08 13:38:57,414 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000007_0' done.
INFO    2018-08-08 13:38:57,419 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000007_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129327
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=22
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=96
		CPU time spent (ms)=4480
		Physical memory (bytes) snapshot=1107193856
		Virtual memory (bytes) snapshot=58894757888
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000008 on graphalytics-giraph-slave12_33893
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15678
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 565 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 384 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,981.00
               min = 16.00
               max = 6653.00
              mean = 123.22
            stddev = 735.91
            median = 25.00
              75% <= 53.00
              95% <= 98.90
              98% <= 2613.32
              99% <= 6653.00
            99.9% <= 6653.00
             count = 81

  remote-requests:
    count = 0

  requests-received:
             count = 81
         mean rate = 139.90 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 97
         mean rate = 167.83 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,564.00
               min = 16.00
               max = 1473.00
              mean = 47.05
            stddev = 148.44
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 144.36
              99% <= 1473.00
            99.9% <= 1473.00
             count = 97

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 565

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 384

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 84 ms
  compute all partitions: 16 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 219 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 16

  compute-per-partition-ms:
               sum = 39.00
               min = 0.00
               max = 4.00
              mean = 1.18
            stddev = 1.22
            median = 1.00
              75% <= 2.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 39.00
               min = 0.00
               max = 6.00
              mean = 3.55
            stddev = 2.25
            median = 4.00
              75% <= 5.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 9,255.00
               min = 16.00
               max = 6564.00
              mean = 162.37
            stddev = 865.11
            median = 46.00
              75% <= 71.00
              95% <= 114.20
              98% <= 5568.32
              99% <= 6564.00
            99.9% <= 6564.00
             count = 57

  remote-requests:
    count = 0

  requests-received:
             count = 57
         mean rate = 476.20 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 57
         mean rate = 475.92 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,726.00
               min = 16.00
               max = 1473.00
              mean = 65.37
            stddev = 192.13
            median = 16.00
              75% <= 67.00
              95% <= 89.00
              98% <= 1251.56
              99% <= 1473.00
            99.9% <= 1473.00
             count = 57

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 84

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 219

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 55 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 192 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 10.00
               min = 0.00
               max = 3.00
              mean = 0.30
            stddev = 0.64
            median = 0.00
              75% <= 0.50
              95% <= 1.60
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 10.00
               min = 0.00
               max = 3.00
              mean = 0.91
            stddev = 1.14
            median = 0.00
              75% <= 2.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 9,255.00
               min = 16.00
               max = 6653.00
              mean = 165.27
            stddev = 886.14
            median = 46.00
              75% <= 53.00
              95% <= 126.80
              98% <= 5769.32
              99% <= 6653.00
            99.9% <= 6653.00
             count = 56

  remote-requests:
    count = 0

  requests-received:
             count = 56
         mean rate = 613.89 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 57
         mean rate = 624.62 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,726.00
               min = 16.00
               max = 1473.00
              mean = 65.37
            stddev = 192.13
            median = 16.00
              75% <= 67.00
              95% <= 89.00
              98% <= 1251.56
              99% <= 1473.00
            99.9% <= 1473.00
             count = 57

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 55

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 192

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 131 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 170 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6564.00
              mean = 173.56
            stddev = 913.19
            median = 34.50
              75% <= 89.00
              95% <= 177.20
              98% <= 6190.62
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 314.52 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 314.54 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.70
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 131

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 170

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.5224936895997

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:59664
Log Contents:
2018-08-08 13:38:48,071 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,136 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,136 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,138 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,138 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,326 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,555 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,751 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:49,219 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,231 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,378 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,393 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,423 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,423 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,431 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,438 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,439 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 5 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,445 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,445 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave12
INFO    2018-08-08 13:38:49,445 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,445 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,445 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,445 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000008:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000008/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,446 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000008:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,446 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000008/tmp
INFO    2018-08-08 13:38:49,446 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,446 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,446 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,446 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,446 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,446 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,446 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000008
INFO    2018-08-08 13:38:49,446 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,459 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,460 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,467 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30036, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,469 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,579 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,596 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,643 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave12/10.164.0.14:30005 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,648 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,649 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,669 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,678 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,682 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,686 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,693 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave12_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005)
INFO    2018-08-08 13:38:49,847 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,940 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,948 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,950 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,952 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,954 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,954 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,956 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,956 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,956 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,957 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,957 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,960 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,961 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,966 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,970 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,971 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,971 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,973 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,984 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,036 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,087 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.049712714 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.060194943 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05995231 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05940842 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05894053 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.058166463 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05731684 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.056616023 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,107 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.054615054 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05524438 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.057929065 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,110 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0025, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.066
MBytes/sec sent = 0.0039, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.066
INFO    2018-08-08 13:38:50,113 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,118 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004334582 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,118 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003158091 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,119 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002576499 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,119 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002659921 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,121 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003289349 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,121 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001785292 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,122 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00300034 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,123 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005164083 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,125 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004884167 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,127 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005602249 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,128 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00273478 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,129 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0102, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0159, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:38:50,129 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:38:50,165 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,169 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:38:50,171 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50879.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,171 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0007, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.045
MBytes/sec sent = 0.001, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.045
INFO    2018-08-08 13:38:50,171 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,188 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,189 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50879.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,201 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,236 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,241 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4ad4936c,outgoing=org.apache.giraph.conf.DefaultMessageClasses@29d37757)
WARN    2018-08-08 13:38:50,246 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:50,265 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,265 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,267 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave12_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005)
INFO    2018-08-08 13:38:50,299 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,299 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,299 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,301 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.112
MBytes/sec sent = 0.0124, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.112
INFO    2018-08-08 13:38:50,304 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,306 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,316 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,328 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009778164 secs for 7 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004250731 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002864354 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007994144 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005696929 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,329 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002997363 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00852613 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002893151 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00603134 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,329 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007481744 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00686797 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,333 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50738.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,333 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0068, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.026
MBytes/sec sent = 0.0377, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.026
INFO    2018-08-08 13:38:50,333 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,339 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,340 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,346 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,368 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,370 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@352e612e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@65f00478)
INFO    2018-08-08 13:38:50,380 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,385 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave12_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005)
INFO    2018-08-08 13:38:50,408 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,409 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,409 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,411 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.071
MBytes/sec sent = 0.0195, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.071
INFO    2018-08-08 13:38:50,414 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,415 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,419 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,423 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003324229 secs for 12 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003089261 secs for 11 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003119986 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002629939 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0015522 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005082272 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002120288 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002496339 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001070992 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003192741 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002223326 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,435 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,436 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,441 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,464 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,467 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@1f86099a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@77bb0ab5)
INFO    2018-08-08 13:38:50,473 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,491 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave12_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005)
INFO    2018-08-08 13:38:50,502 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,550 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,576 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,577 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,577 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,578 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.141
MBytes/sec sent = 0.0099, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.141
INFO    2018-08-08 13:38:50,580 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,583 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,586 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,590 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001320122 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,590 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001818526 secs for 13 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001061621 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,590 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002977163 secs for 18 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,592 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002197931 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001331201 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001136815 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,594 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001373417 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001621013 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001820363 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002945294 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50444.47M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,598 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:38:50,598 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,604 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,605 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50444.47M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,608 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,631 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,634 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@69e308c6,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1a1ed4e5)
INFO    2018-08-08 13:38:50,638 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,638 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,638 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,641 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,663 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,707 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,713 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,715 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:52,846 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:52,846 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:38:52,850 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:53,037 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:53,037 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:53,039 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/5_worker
INFO    2018-08-08 13:38:53,041 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30036 closed
INFO    2018-08-08 13:38:53,041 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:53,044 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:53,048 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,260 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,265 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000005_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:57,292 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000005_0 is allowed to commit now
INFO    2018-08-08 13:38:57,303 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000005_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000005
INFO    2018-08-08 13:38:57,324 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000005_0' done.
INFO    2018-08-08 13:38:57,329 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000005_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129327
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=22
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=94
		CPU time spent (ms)=4580
		Physical memory (bytes) snapshot=1088282624
		Virtual memory (bytes) snapshot=58909749248
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000016 on graphalytics-giraph-slave13_40615
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15680
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 685 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 274 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,927.00
               min = 16.00
               max = 6653.00
              mean = 124.09
            stddev = 740.46
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2739.56
              99% <= 6653.00
            99.9% <= 6653.00
             count = 80

  remote-requests:
    count = 0

  requests-received:
             count = 80
         mean rate = 114.48 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 96
         mean rate = 137.62 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,548.00
               min = 16.00
               max = 1473.00
              mean = 47.38
            stddev = 149.18
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 172.04
              99% <= 1473.00
            99.9% <= 1473.00
             count = 96

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 685

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 274

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 87 ms
  compute all partitions: 14 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 299 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 14

  compute-per-partition-ms:
               sum = 43.00
               min = 0.00
               max = 4.00
              mean = 1.30
            stddev = 1.10
            median = 1.00
              75% <= 2.00
              95% <= 3.30
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 43.00
               min = 0.00
               max = 7.00
              mean = 3.91
            stddev = 2.47
            median = 4.00
              75% <= 6.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6653.00
              mean = 176.96
            stddev = 926.56
            median = 16.00
              75% <= 89.00
              95% <= 189.80
              98% <= 6400.52
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 422.14 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 430.21 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.72
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 87

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 299

  worker-context-post-superstep:
    value = 10

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 59 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 169 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 1.00
              mean = 0.15
            stddev = 0.36
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.45
            stddev = 0.82
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6653.00
              mean = 176.96
            stddev = 974.31
            median = 16.00
              75% <= 89.00
              95% <= 189.80
              98% <= 6400.52
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 542.54 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 553.22 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.68
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 59

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 169

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 133 ms
  compute all partitions: 14 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 162 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 14

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.12
            stddev = 0.33
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.27
            stddev = 0.47
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6653.00
              mean = 176.96
            stddev = 936.93
            median = 16.00
              75% <= 89.00
              95% <= 189.80
              98% <= 6400.52
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 309.11 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 315.22 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.67
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 133

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 162

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:52 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.56475741439783

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:52 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:59691
Log Contents:
2018-08-08 13:38:48,005 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,068 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,068 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,070 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,070 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,236 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,441 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,627 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:49,091 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,102 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,251 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,267 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,295 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,296 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,305 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,311 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,311 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 13 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,317 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,317 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave13
INFO    2018-08-08 13:38:49,317 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,317 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,317 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,317 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000016:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000016/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,318 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000016:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,318 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000016/tmp
INFO    2018-08-08 13:38:49,318 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,318 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,318 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,318 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,318 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,318 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,318 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000016
INFO    2018-08-08 13:38:49,318 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,331 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,332 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,338 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3002e, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,340 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,450 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,468 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,517 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave13/10.164.0.15:30013 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,523 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,524 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,548 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,558 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,562 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,564 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,571 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave13_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013)
INFO    2018-08-08 13:38:49,846 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,938 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,946 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,948 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,950 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,952 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,952 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,952 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,953 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,953 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,953 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,953 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,953 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,954 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,957 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,958 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,962 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,965 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,970 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,972 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,972 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,973 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,982 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,035 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,084 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048703883 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,084 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041854553 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,084 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041080903 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,086 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042014785 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,086 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041739188 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,087 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041574135 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,088 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042035177 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,089 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0413934 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,089 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04152895 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,089 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040838663 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04025986 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,091 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0034, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.048
MBytes/sec sent = 0.0054, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.049
INFO    2018-08-08 13:38:50,091 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,097 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005254443 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,100 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 7.54349E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,100 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006316782 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00720959 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.007537646 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.007457558 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.007465126 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006794671 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.011033854 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004916996 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004460422 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0129, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0202, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.013
INFO    2018-08-08 13:38:50,106 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:38:50,165 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,169 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:38:50,170 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50863.52M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,171 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0022, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.077
MBytes/sec sent = 0.0034, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.078
INFO    2018-08-08 13:38:50,171 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,188 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,188 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50863.52M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,199 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,236 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,241 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4ad4936c,outgoing=org.apache.giraph.conf.DefaultMessageClasses@29d37757)
WARN    2018-08-08 13:38:50,246 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:50,260 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,261 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,263 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave13_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013)
INFO    2018-08-08 13:38:50,300 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,300 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,300 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,301 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.113
MBytes/sec sent = 0.0123, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.113
INFO    2018-08-08 13:38:50,303 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,306 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,316 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,327 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004637674 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007204631 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003967876 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006363644 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00852294 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009246992 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007165779 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010433393 secs for 8 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003068105 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003398942 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006690409 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50722.72M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,331 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.007, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.025
MBytes/sec sent = 0.0392, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.025
INFO    2018-08-08 13:38:50,332 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,339 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,339 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.72M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,342 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,367 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,368 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@352e612e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@65f00478)
INFO    2018-08-08 13:38:50,376 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,378 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave13_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013)
INFO    2018-08-08 13:38:50,408 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,408 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,408 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,409 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.069
MBytes/sec sent = 0.0201, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.069
INFO    2018-08-08 13:38:50,412 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,413 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,418 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,423 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004508269 secs for 15 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003699152 secs for 6 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002943988 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004172599 secs for 8 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001882015 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00281 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00224031 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,425 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002382511 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002299911 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003411224 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003387931 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50581.91M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0122, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.014
MBytes/sec sent = 0.0679, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.014
INFO    2018-08-08 13:38:50,429 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,435 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,435 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50569.11M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,439 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,464 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,466 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@1f86099a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@77bb0ab5)
INFO    2018-08-08 13:38:50,472 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,488 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave13_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013)
INFO    2018-08-08 13:38:50,501 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,549 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,577 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,577 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,578 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,579 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.143
MBytes/sec sent = 0.0098, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.144
INFO    2018-08-08 13:38:50,583 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,584 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,586 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,593 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004399524 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006188634 secs for 13 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004860924 secs for 14 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001516559 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001597846 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,594 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001170615 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003629225 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00365752 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003529363 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,599 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002028974 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,600 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003302087 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,601 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50428.31M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,601 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0108, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.016
MBytes/sec sent = 0.0599, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.016
INFO    2018-08-08 13:38:50,601 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,606 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,606 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50428.31M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,609 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,631 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,633 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@69e308c6,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1a1ed4e5)
INFO    2018-08-08 13:38:50,637 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,637 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,637 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,640 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,662 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,707 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,712 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,715 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:52,745 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:52,745 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 13:38:52,748 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:52,785 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:52,785 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:52,787 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/13_worker
INFO    2018-08-08 13:38:52,789 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3002e closed
INFO    2018-08-08 13:38:52,789 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:52,791 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:52,794 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,005 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,010 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000013_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:57,035 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000013_0 is allowed to commit now
INFO    2018-08-08 13:38:57,043 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000013_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000013
INFO    2018-08-08 13:38:57,061 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000013_0' done.
INFO    2018-08-08 13:38:57,067 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000013_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129328
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=99
		CPU time spent (ms)=3870
		Physical memory (bytes) snapshot=1080111104
		Virtual memory (bytes) snapshot=58908229632
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000013 on graphalytics-giraph-slave14_35219
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15679
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 845 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 299 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 10,026.00
               min = 16.00
               max = 6653.00
              mean = 117.95
            stddev = 720.29
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2108.36
              99% <= 6653.00
            99.9% <= 6653.00
             count = 85

  remote-requests:
    count = 0

  requests-received:
             count = 85
         mean rate = 98.70 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 113.88 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,580.00
               min = 16.00
               max = 1473.00
              mean = 46.73
            stddev = 147.71
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 845

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 299

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 83 ms
  compute all partitions: 14 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 2760 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 14

  compute-per-partition-ms:
               sum = 33.00
               min = 0.00
               max = 5.00
              mean = 1.00
            stddev = 1.48
            median = 0.00
              75% <= 2.00
              95% <= 4.30
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 33.00
               min = 0.00
               max = 6.00
              mean = 3.00
            stddev = 2.68
            median = 3.00
              75% <= 6.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 9,041.00
               min = 16.00
               max = 6653.00
              mean = 173.87
            stddev = 925.92
            median = 16.00
              75% <= 80.00
              95% <= 177.20
              98% <= 6274.28
              99% <= 6653.00
            99.9% <= 6653.00
             count = 52

  remote-requests:
    count = 1

  requests-received:
             count = 52
         mean rate = 440.27 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 447.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,692.00
               min = 16.00
               max = 1473.00
              mean = 69.66
            stddev = 198.77
            median = 25.00
              75% <= 85.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 83

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 2760

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 58 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 205 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 9,041.00
               min = 16.00
               max = 6653.00
              mean = 173.87
            stddev = 925.33
            median = 16.00
              75% <= 80.00
              95% <= 177.20
              98% <= 6274.28
              99% <= 6653.00
            99.9% <= 6653.00
             count = 52

  remote-requests:
    count = 1

  requests-received:
             count = 52
         mean rate = 555.66 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 565.98 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,692.00
               min = 16.00
               max = 1473.00
              mean = 69.66
            stddev = 198.76
            median = 25.00
              75% <= 85.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 58

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 205

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 132 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 164 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 6.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.39
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 6.00
               min = 0.00
               max = 2.00
              mean = 0.55
            stddev = 0.93
            median = 0.00
              75% <= 2.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6653.00
              mean = 176.96
            stddev = 926.59
            median = 16.00
              75% <= 89.00
              95% <= 189.80
              98% <= 6400.52
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 309.67 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 315.87 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.68
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 132

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 164

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.22444386841897

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:59428
Log Contents:
2018-08-08 13:38:47,942 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,000 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,000 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,002 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,002 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,161 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,368 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,535 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:48,953 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:48,964 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,100 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,113 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,140 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,141 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,148 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,154 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,154 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 10 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave14
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000013:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000013/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000013:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000013/tmp
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,160 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000013
INFO    2018-08-08 13:38:49,161 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,173 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,173 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,181 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3002a, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,182 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,287 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,303 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,357 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave14/10.164.0.16:30010 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,361 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,362 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,390 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,410 [main-EventThread] org.apache.giraph.bsp.BspService  - process: applicationAttemptChanged signaled
WARN    2018-08-08 13:38:49,427 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:49,430 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave14_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010)
INFO    2018-08-08 13:38:49,849 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,939 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,947 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,949 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,950 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,952 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,952 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,952 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,952 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,956 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,957 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,958 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,962 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,969 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,972 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,981 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,983 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,983 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,984 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,984 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,986 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,039 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,086 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04605244 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.056902755 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.056550104 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.055918086 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.055276126 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.054420788 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.053881694 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.053254697 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05308488 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05215459 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05264424 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0028, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.06
MBytes/sec sent = 0.0043, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.06
INFO    2018-08-08 13:38:50,107 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,111 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003035925 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,112 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002517468 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,112 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002178042 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,113 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002209222 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,116 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004110534 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,116 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003449508 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,116 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003091128 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,116 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002541142 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,118 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 8.27223E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,119 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002364432 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,119 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004480754 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,120 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0092, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0143, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:38:50,120 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:38:50,166 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,169 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,178 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,179 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,179 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0007, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0011, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.063
INFO    2018-08-08 13:38:50,179 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,190 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,190 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,202 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,238 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,243 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
INFO    2018-08-08 13:38:50,264 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,264 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,266 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave14_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010)
INFO    2018-08-08 13:38:50,302 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,303 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,303 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,304 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.114
MBytes/sec sent = 0.0122, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.114
INFO    2018-08-08 13:38:50,307 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,308 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,316 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,327 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003200465 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008914858 secs for 11 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00620882 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004245435 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007742891 secs for 8 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003012814 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008509517 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003736114 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006578694 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001453297 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00331193 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,334 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0019, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.0055, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 13:38:50,334 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,341 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,342 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,348 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,369 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,371 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 13:38:50,379 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,381 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave14_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010)
INFO    2018-08-08 13:38:50,411 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,411 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,411 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,412 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.07
MBytes/sec sent = 0.0198, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.07
INFO    2018-08-08 13:38:50,415 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,416 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,420 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,424 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002351551 secs for 9 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001325137 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002761433 secs for 8 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003727477 secs for 15 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00173844 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001898228 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00178872 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001471384 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002321687 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00184967 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00250361 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,430 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0088, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:38:50,430 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,437 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,438 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,443 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,466 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,469 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 13:38:50,475 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,493 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave14_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=10, port=30010)
INFO    2018-08-08 13:38:50,504 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,551 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,579 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,579 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,579 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,580 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.142
MBytes/sec sent = 0.0098, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.142
INFO    2018-08-08 13:38:50,582 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,585 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,589 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,593 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001908526 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002409843 secs for 7 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002793435 secs for 9 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001645945 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003640916 secs for 15 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001118515 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,594 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001357775 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001267013 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,596 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001627233 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002804568 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002048221 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,599 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,599 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:38:50,599 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,607 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,607 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,610 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,633 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,636 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 13:38:50,641 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,641 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,641 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,644 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,664 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,709 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,714 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,717 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:52,848 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:52,848 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:38:52,852 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:53,038 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:53,039 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:53,041 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/10_worker
INFO    2018-08-08 13:38:53,043 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3002a closed
INFO    2018-08-08 13:38:53,043 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:53,045 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:53,048 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,260 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,264 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000010_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:57,291 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000010_0 is allowed to commit now
INFO    2018-08-08 13:38:57,301 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000010_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000010
INFO    2018-08-08 13:38:57,321 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000010_0' done.
INFO    2018-08-08 13:38:57,326 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000010_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129328
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=22
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=85
		CPU time spent (ms)=4210
		Physical memory (bytes) snapshot=1114853376
		Virtual memory (bytes) snapshot=58941612032
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000003 on graphalytics-giraph-slave15_37797
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15679
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 758 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 356 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,927.00
               min = 16.00
               max = 6653.00
              mean = 132.36
            stddev = 764.45
            median = 32.00
              75% <= 53.00
              95% <= 105.00
              98% <= 3370.76
              99% <= 6653.00
            99.9% <= 6653.00
             count = 75

  remote-requests:
    count = 0

  requests-received:
             count = 75
         mean rate = 96.87 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 96
         mean rate = 124.23 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,548.00
               min = 16.00
               max = 1473.00
              mean = 47.38
            stddev = 149.15
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 172.04
              99% <= 1473.00
            99.9% <= 1473.00
             count = 96

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 758

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 356

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 84 ms
  compute all partitions: 17 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 233 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 17

  compute-per-partition-ms:
               sum = 58.00
               min = 0.00
               max = 4.00
              mean = 1.76
            stddev = 1.67
            median = 2.00
              75% <= 3.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 58.00
               min = 2.00
               max = 7.00
              mean = 5.27
            stddev = 1.95
            median = 6.00
              75% <= 7.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6564.00
              mean = 173.56
            stddev = 905.01
            median = 34.50
              75% <= 89.00
              95% <= 177.20
              98% <= 6190.62
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 438.79 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 439.45 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.69
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 84

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 233

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 54 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 215 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 1.00
              mean = 0.15
            stddev = 0.37
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.45
            stddev = 0.82
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6564.00
              mean = 173.56
            stddev = 905.44
            median = 34.50
              75% <= 89.00
              95% <= 177.20
              98% <= 6190.62
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 561.85 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 562.11 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.68
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 54

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 215

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 130 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1403 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6564.00
              mean = 173.56
            stddev = 922.44
            median = 34.50
              75% <= 89.00
              95% <= 177.20
              98% <= 6190.62
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 314.86 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 314.92 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.68
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 130

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1403

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:52 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.59549464506534

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:52 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:59724
Log Contents:
2018-08-08 13:38:47,967 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,029 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,029 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,031 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,031 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,193 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,407 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,572 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:49,019 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,031 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,171 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,189 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,218 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,219 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,227 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,234 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,234 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 1 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,240 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,240 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave15
INFO    2018-08-08 13:38:49,240 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,240 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,240 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,240 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000003:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000003/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,241 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000003:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,241 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000003/tmp
INFO    2018-08-08 13:38:49,241 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,241 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,241 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,241 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,241 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,241 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,241 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000003
INFO    2018-08-08 13:38:49,241 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,254 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,255 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,262 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3002c, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,263 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,379 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,398 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,443 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave15/10.164.0.17:30001 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,449 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,450 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,472 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,484 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,488 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,491 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,498 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave15_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001)
INFO    2018-08-08 13:38:49,842 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,941 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,951 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,952 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,954 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,954 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,956 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,958 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,958 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,958 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,960 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,961 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,961 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,962 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,962 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,965 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,970 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,971 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,971 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,976 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,037 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,083 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04451082 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,083 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037652534 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,083 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03740608 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,084 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03676933 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,084 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036467273 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,085 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03473083 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,085 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.035714243 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,085 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03525217 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,085 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03401242 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,087 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03492429 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,087 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03408453 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,089 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.043
MBytes/sec sent = 0.006, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.044
INFO    2018-08-08 13:38:50,090 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,095 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005242314 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,098 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006287319 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,098 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004970325 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,098 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00566832 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,100 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005878429 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,100 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005418445 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,100 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005271595 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004870915 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003506874 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004082288 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003481642 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0238, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.01
INFO    2018-08-08 13:38:50,102 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:38:50,163 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,168 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:38:50,170 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50879.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,170 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0021, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.078
MBytes/sec sent = 0.0033, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.078
INFO    2018-08-08 13:38:50,170 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,186 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,187 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50879.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,199 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,234 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,240 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4ad4936c,outgoing=org.apache.giraph.conf.DefaultMessageClasses@29d37757)
WARN    2018-08-08 13:38:50,244 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:50,265 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,266 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,270 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave15_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001)
INFO    2018-08-08 13:38:50,297 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,297 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,298 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,299 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.112
MBytes/sec sent = 0.0124, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.112
INFO    2018-08-08 13:38:50,302 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,304 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,312 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,327 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008769776 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009548279 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004323053 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008216905 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012229708 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010480478 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006541646 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003767761 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005293565 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011397292 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005148197 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,331 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0068, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.026
MBytes/sec sent = 0.0377, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.026
INFO    2018-08-08 13:38:50,331 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,339 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0248, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.0821, MBytesSent = 0.0007, ave sent req MBytes = 0.0001, secs waited = 0.008
INFO    2018-08-08 13:38:50,340 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,345 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,365 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,369 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@352e612e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@65f00478)
INFO    2018-08-08 13:38:50,378 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,380 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave15_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001)
INFO    2018-08-08 13:38:50,406 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,406 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,406 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,408 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.068
MBytes/sec sent = 0.0204, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.068
INFO    2018-08-08 13:38:50,410 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,412 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,416 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,421 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003353852 secs for 13 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,421 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002793459 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,421 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00429414 secs for 17 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,422 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003017801 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,422 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002257281 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,422 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002966845 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001488432 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001095568 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,425 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00406017 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,425 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002659185 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,425 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00229303 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50585.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0114, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.015
MBytes/sec sent = 0.0637, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.015
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,432 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0397, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.1314, MBytesSent = 0.0007, ave sent req MBytes = 0.0001, secs waited = 0.004
INFO    2018-08-08 13:38:50,432 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50585.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,437 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,462 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,465 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@1f86099a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@77bb0ab5)
INFO    2018-08-08 13:38:50,472 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,492 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave15_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001)
INFO    2018-08-08 13:38:50,500 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,547 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,576 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,576 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,576 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,577 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.145
MBytes/sec sent = 0.0096, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.145
INFO    2018-08-08 13:38:50,581 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,582 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,584 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,589 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004367292 secs for 22 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,589 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001927639 secs for 11 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,589 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00167261 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,589 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001487976 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,589 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001075757 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001313678 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001134826 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002482745 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001143991 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00364975 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003708735 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,596 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50444.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,596 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:38:50,597 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,602 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0397, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.1095, MBytesSent = 0.0007, ave sent req MBytes = 0.0001, secs waited = 0.005
INFO    2018-08-08 13:38:50,602 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50444.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,605 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,629 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,633 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@69e308c6,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1a1ed4e5)
INFO    2018-08-08 13:38:50,638 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,639 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,639 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,640 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,660 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,705 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,710 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,713 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:52,944 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:52,944 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 13:38:52,948 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:52,982 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:52,982 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:52,984 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/1_worker
INFO    2018-08-08 13:38:52,986 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3002c closed
INFO    2018-08-08 13:38:52,986 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:52,988 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:52,992 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,204 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,210 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000001_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:57,238 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000001_0 is allowed to commit now
INFO    2018-08-08 13:38:57,248 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000001_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000001
INFO    2018-08-08 13:38:57,268 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000001_0' done.
INFO    2018-08-08 13:38:57,274 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000001_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129327
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=95
		CPU time spent (ms)=4400
		Physical memory (bytes) snapshot=1089863680
		Virtual memory (bytes) snapshot=58895122432
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000001 on graphalytics-giraph-slave1_33157
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:2248
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/11/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Aug 08, 2018 1:38:43 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver as a provider class
Aug 08, 2018 1:38:43 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
Aug 08, 2018 1:38:43 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices as a root resource class
Aug 08, 2018 1:38:43 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.9 09/02/2011 11:17 AM'
Aug 08, 2018 1:38:43 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
Aug 08, 2018 1:38:43 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
Aug 08, 2018 1:38:44 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices to GuiceManagedComponentProvider with the scope "PerRequest"
log4j:WARN No appenders could be found for logger (org.apache.hadoop.ipc.Server).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:117346
Log Contents:
2018-08-08 13:38:41,359 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1533735211869_0004_000001
2018-08-08 13:38:41,597 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens:
2018-08-08 13:38:41,597 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 4 cluster_timestamp: 1533735211869 } attemptId: 1 } keyId: -63235253)
2018-08-08 13:38:41,834 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Using mapred newApiCommitter.
2018-08-08 13:38:41,837 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config null
2018-08-08 13:38:41,974 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:42,446 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is org.apache.giraph.io.internal.WrappedVertexOutputFormat$2
2018-08-08 13:38:42,593 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler
2018-08-08 13:38:42,594 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher
2018-08-08 13:38:42,595 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher
2018-08-08 13:38:42,596 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher
2018-08-08 13:38:42,597 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler
2018-08-08 13:38:42,603 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher
2018-08-08 13:38:42,603 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter
2018-08-08 13:38:42,604 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter
2018-08-08 13:38:42,632 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 13:38:42,647 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 13:38:42,664 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 13:38:42,671 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled
2018-08-08 13:38:42,716 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler
2018-08-08 13:38:42,803 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:42,855 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:42,855 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MRAppMaster metrics system started
2018-08-08 13:38:42,862 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for job_1533735211869_0004 to jobTokenSecretManager
2018-08-08 13:38:42,954 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing job_1533735211869_0004 because: not enabled; too many maps; too much RAM;
2018-08-08 13:38:42,967 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job job_1533735211869_0004 = 0. Number of splits = 14
2018-08-08 13:38:42,967 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job job_1533735211869_0004 = 0
2018-08-08 13:38:42,967 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0004Job Transitioned from NEW to INITED
2018-08-08 13:38:42,968 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job job_1533735211869_0004.
2018-08-08 13:38:42,998 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2018-08-08 13:38:43,005 INFO [Socket Reader #1 for port 42243] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 42243
2018-08-08 13:38:43,045 INFO [main] org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server
2018-08-08 13:38:43,046 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-08-08 13:38:43,046 INFO [IPC Server listener on 42243] org.apache.hadoop.ipc.Server: IPC Server listener on 42243: starting
2018-08-08 13:38:43,047 INFO [main] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at graphalytics-giraph-slave1/10.164.0.3:42243
2018-08-08 13:38:43,104 INFO [main] org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-08-08 13:38:43,110 INFO [main] org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-08-08 13:38:43,114 INFO [main] org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined
2018-08-08 13:38:43,119 INFO [main] org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-08-08 13:38:43,124 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce
2018-08-08 13:38:43,124 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static
2018-08-08 13:38:43,126 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /mapreduce/*
2018-08-08 13:38:43,126 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-08-08 13:38:43,335 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-08-08 13:38:43,336 INFO [main] org.apache.hadoop.http.HttpServer2: Jetty bound to port 39115
2018-08-08 13:38:43,336 INFO [main] org.mortbay.log: jetty-6.1.26
2018-08-08 13:38:43,360 INFO [main] org.mortbay.log: Extract jar:file:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar!/webapps/mapreduce to /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000001/tmp/Jetty_0_0_0_0_39115_mapreduce____qysysq/webapp
2018-08-08 13:38:44,192 INFO [main] org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:39115
2018-08-08 13:38:44,192 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Web app mapreduce started at 39115
2018-08-08 13:38:44,195 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: JOB_CREATE job_1533735211869_0004
2018-08-08 13:38:44,196 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 3000
2018-08-08 13:38:44,196 INFO [Socket Reader #1 for port 36911] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 36911
2018-08-08 13:38:44,202 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-08-08 13:38:44,202 INFO [IPC Server listener on 36911] org.apache.hadoop.ipc.Server: IPC Server listener on 36911: starting
2018-08-08 13:38:44,260 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true
2018-08-08 13:38:44,260 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: maxTaskFailuresPerNode is 3
2018-08-08 13:38:44,260 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: blacklistDisablePercent is 33
2018-08-08 13:38:44,294 INFO [main] org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at graphalytics-giraph/10.164.0.2:8030
2018-08-08 13:38:44,419 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: maxContainerCapability: <memory:57344, vCores:32>
2018-08-08 13:38:44,419 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: queue: default
2018-08-08 13:38:44,427 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500
2018-08-08 13:38:44,428 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: The thread pool initial size is 10
2018-08-08 13:38:44,468 INFO [main] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2018-08-08 13:38:44,483 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0004Job Transitioned from INITED to SETUP
2018-08-08 13:38:44,485 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_SETUP
2018-08-08 13:38:44,524 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0004Job Transitioned from SETUP to RUNNING
2018-08-08 13:38:44,531 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000000 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,531 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000001 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,531 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000002 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,531 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000003 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,531 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000004 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,532 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000005 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,532 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000006 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,532 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000007 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,532 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000008 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,532 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000009 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,532 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000010 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,533 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000011 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,533 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000012 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,533 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000013 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:38:44,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000001_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000002_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000003_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000004_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000005_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000006_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000007_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000008_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000009_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000010_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000011_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,536 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000012_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,536 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000013_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:38:44,537 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: mapResourceRequest:<memory:57344, vCores:1>
2018-08-08 13:38:44,546 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1533735211869_0004, File: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0004/job_1533735211869_0004_1.jhist
2018-08-08 13:38:45,426 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:14 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:38:45,457 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1533735211869_0004: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:858112, vCores:1> knownNMs=15
2018-08-08 13:38:46,482 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 14
2018-08-08 13:38:46,484 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave10 to /default-rack
2018-08-08 13:38:46,484 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave15 to /default-rack
2018-08-08 13:38:46,484 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave8 to /default-rack
2018-08-08 13:38:46,485 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave9 to /default-rack
2018-08-08 13:38:46,485 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave4 to /default-rack
2018-08-08 13:38:46,485 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave12 to /default-rack
2018-08-08 13:38:46,485 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave6 to /default-rack
2018-08-08 13:38:46,485 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave11 to /default-rack
2018-08-08 13:38:46,485 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave5 to /default-rack
2018-08-08 13:38:46,485 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave7 to /default-rack
2018-08-08 13:38:46,485 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave14 to /default-rack
2018-08-08 13:38:46,485 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave2 to /default-rack
2018-08-08 13:38:46,485 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave3 to /default-rack
2018-08-08 13:38:46,485 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave13 to /default-rack
2018-08-08 13:38:46,487 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000002 to attempt_1533735211869_0004_m_000000_0
2018-08-08 13:38:46,488 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000003 to attempt_1533735211869_0004_m_000001_0
2018-08-08 13:38:46,488 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000005 to attempt_1533735211869_0004_m_000002_0
2018-08-08 13:38:46,488 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000006 to attempt_1533735211869_0004_m_000003_0
2018-08-08 13:38:46,489 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000007 to attempt_1533735211869_0004_m_000004_0
2018-08-08 13:38:46,489 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000008 to attempt_1533735211869_0004_m_000005_0
2018-08-08 13:38:46,489 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000009 to attempt_1533735211869_0004_m_000006_0
2018-08-08 13:38:46,489 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000010 to attempt_1533735211869_0004_m_000007_0
2018-08-08 13:38:46,489 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000011 to attempt_1533735211869_0004_m_000008_0
2018-08-08 13:38:46,489 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000012 to attempt_1533735211869_0004_m_000009_0
2018-08-08 13:38:46,490 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000013 to attempt_1533735211869_0004_m_000010_0
2018-08-08 13:38:46,490 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000014 to attempt_1533735211869_0004_m_000011_0
2018-08-08 13:38:46,490 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000015 to attempt_1533735211869_0004_m_000012_0
2018-08-08 13:38:46,490 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0004_01_000016 to attempt_1533735211869_0004_m_000013_0
2018-08-08 13:38:46,490 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:14 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:38:46,527 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave10 to /default-rack
2018-08-08 13:38:46,542 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-jar file on the remote FS is hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0004/job.jar
2018-08-08 13:38:46,545 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0004/job.xml
2018-08-08 13:38:46,546 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Adding #0 tokens and #1 secret keys for NM use for launching container
2018-08-08 13:38:46,546 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Size of containertokens_dob is 1
2018-08-08 13:38:46,547 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Putting shuffle token in serviceData
2018-08-08 13:38:46,595 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,599 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave15 to /default-rack
2018-08-08 13:38:46,599 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,600 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave8 to /default-rack
2018-08-08 13:38:46,601 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,601 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave9 to /default-rack
2018-08-08 13:38:46,601 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000003_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,601 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave4 to /default-rack
2018-08-08 13:38:46,602 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000004_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,602 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave12 to /default-rack
2018-08-08 13:38:46,603 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000005_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,603 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave6 to /default-rack
2018-08-08 13:38:46,603 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000006_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,604 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave11 to /default-rack
2018-08-08 13:38:46,604 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000007_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,604 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave5 to /default-rack
2018-08-08 13:38:46,605 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000008_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,605 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave7 to /default-rack
2018-08-08 13:38:46,605 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000009_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,605 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave14 to /default-rack
2018-08-08 13:38:46,606 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000010_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,607 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave2 to /default-rack
2018-08-08 13:38:46,607 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000011_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave3 to /default-rack
2018-08-08 13:38:46,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000012_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave13 to /default-rack
2018-08-08 13:38:46,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000013_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:38:46,611 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000002 taskAttempt attempt_1533735211869_0004_m_000000_0
2018-08-08 13:38:46,611 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000003 taskAttempt attempt_1533735211869_0004_m_000001_0
2018-08-08 13:38:46,612 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000005 taskAttempt attempt_1533735211869_0004_m_000002_0
2018-08-08 13:38:46,612 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000006 taskAttempt attempt_1533735211869_0004_m_000003_0
2018-08-08 13:38:46,614 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000007 taskAttempt attempt_1533735211869_0004_m_000004_0
2018-08-08 13:38:46,614 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000009 taskAttempt attempt_1533735211869_0004_m_000006_0
2018-08-08 13:38:46,614 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000008 taskAttempt attempt_1533735211869_0004_m_000005_0
2018-08-08 13:38:46,615 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000010 taskAttempt attempt_1533735211869_0004_m_000007_0
2018-08-08 13:38:46,616 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000011 taskAttempt attempt_1533735211869_0004_m_000008_0
2018-08-08 13:38:46,617 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000012 taskAttempt attempt_1533735211869_0004_m_000009_0
2018-08-08 13:38:46,617 INFO [ContainerLauncher Event Handler] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Setting ContainerLauncher pool size to 21 as number-of-nodes to talk to is 11
2018-08-08 13:38:46,618 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000013 taskAttempt attempt_1533735211869_0004_m_000010_0
2018-08-08 13:38:46,618 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000008_0
2018-08-08 13:38:46,618 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000009_0
2018-08-08 13:38:46,618 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000006_0
2018-08-08 13:38:46,618 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000014 taskAttempt attempt_1533735211869_0004_m_000011_0
2018-08-08 13:38:46,619 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000011_0
2018-08-08 13:38:46,618 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000002_0
2018-08-08 13:38:46,618 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000000_0
2018-08-08 13:38:46,618 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000001_0
2018-08-08 13:38:46,618 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000003_0
2018-08-08 13:38:46,618 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000010_0
2018-08-08 13:38:46,618 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000004_0
2018-08-08 13:38:46,618 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000005_0
2018-08-08 13:38:46,618 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000007_0
2018-08-08 13:38:46,621 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000016 taskAttempt attempt_1533735211869_0004_m_000013_0
2018-08-08 13:38:46,621 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000013_0
2018-08-08 13:38:46,621 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0004_01_000015 taskAttempt attempt_1533735211869_0004_m_000012_0
2018-08-08 13:38:46,621 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0004_m_000012_0
2018-08-08 13:38:46,622 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave5:46217
2018-08-08 13:38:46,644 INFO [ContainerLauncher #12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave3:42077
2018-08-08 13:38:46,646 INFO [ContainerLauncher #13] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave13:40615
2018-08-08 13:38:46,649 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave11:46641
2018-08-08 13:38:46,651 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave12:33893
2018-08-08 13:38:46,654 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave4:46069
2018-08-08 13:38:46,656 INFO [ContainerLauncher #10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave14:35219
2018-08-08 13:38:46,658 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave9:37771
2018-08-08 13:38:46,660 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave15:37797
2018-08-08 13:38:46,664 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave10:46663
2018-08-08 13:38:46,666 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave8:41519
2018-08-08 13:38:46,667 INFO [ContainerLauncher #11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave2:43787
2018-08-08 13:38:46,669 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave6:36387
2018-08-08 13:38:46,672 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave7:43383
2018-08-08 13:38:46,737 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000000_0 : 13562
2018-08-08 13:38:46,737 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000006_0 : 13562
2018-08-08 13:38:46,737 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000002_0 : 13562
2018-08-08 13:38:46,737 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000004_0 : 13562
2018-08-08 13:38:46,737 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000010_0 : 13562
2018-08-08 13:38:46,737 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000001_0 : 13562
2018-08-08 13:38:46,737 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000003_0 : 13562
2018-08-08 13:38:46,746 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000000_0] using containerId: [container_1533735211869_0004_01_000002 on NM: [graphalytics-giraph-slave10:46663]
2018-08-08 13:38:46,746 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000008_0 : 13562
2018-08-08 13:38:46,750 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000009_0 : 13562
2018-08-08 13:38:46,750 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000011_0 : 13562
2018-08-08 13:38:46,751 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000007_0 : 13562
2018-08-08 13:38:46,758 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,758 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000013_0 : 13562
2018-08-08 13:38:46,759 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000006_0] using containerId: [container_1533735211869_0004_01_000009 on NM: [graphalytics-giraph-slave6:36387]
2018-08-08 13:38:46,759 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000005_0 : 13562
2018-08-08 13:38:46,759 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000006_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,760 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000002_0] using containerId: [container_1533735211869_0004_01_000005 on NM: [graphalytics-giraph-slave8:41519]
2018-08-08 13:38:46,760 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000002_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,760 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000004_0] using containerId: [container_1533735211869_0004_01_000007 on NM: [graphalytics-giraph-slave4:46069]
2018-08-08 13:38:46,761 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000004_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,761 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000010_0] using containerId: [container_1533735211869_0004_01_000013 on NM: [graphalytics-giraph-slave14:35219]
2018-08-08 13:38:46,761 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0004_m_000012_0 : 13562
2018-08-08 13:38:46,761 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000010_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,762 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000001_0] using containerId: [container_1533735211869_0004_01_000003 on NM: [graphalytics-giraph-slave15:37797]
2018-08-08 13:38:46,762 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000001_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,762 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000003_0] using containerId: [container_1533735211869_0004_01_000006 on NM: [graphalytics-giraph-slave9:37771]
2018-08-08 13:38:46,762 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000003_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,763 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000008_0] using containerId: [container_1533735211869_0004_01_000011 on NM: [graphalytics-giraph-slave5:46217]
2018-08-08 13:38:46,763 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000008_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,763 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000009_0] using containerId: [container_1533735211869_0004_01_000012 on NM: [graphalytics-giraph-slave7:43383]
2018-08-08 13:38:46,763 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000009_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,763 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000011_0] using containerId: [container_1533735211869_0004_01_000014 on NM: [graphalytics-giraph-slave2:43787]
2018-08-08 13:38:46,763 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000011_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,764 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000007_0] using containerId: [container_1533735211869_0004_01_000010 on NM: [graphalytics-giraph-slave11:46641]
2018-08-08 13:38:46,764 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000007_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,764 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000000 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,764 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000013_0] using containerId: [container_1533735211869_0004_01_000016 on NM: [graphalytics-giraph-slave13:40615]
2018-08-08 13:38:46,764 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000013_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,765 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000006 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,765 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000005_0] using containerId: [container_1533735211869_0004_01_000008 on NM: [graphalytics-giraph-slave12:33893]
2018-08-08 13:38:46,765 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000005_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,765 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000002 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,766 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000004 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,766 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000010 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,766 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0004_m_000012_0] using containerId: [container_1533735211869_0004_01_000015 on NM: [graphalytics-giraph-slave3:42077]
2018-08-08 13:38:46,766 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000012_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:38:46,767 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000001 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,767 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000003 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,767 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000008 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,767 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000009 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,767 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000011 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,767 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000007 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,767 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000013 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,767 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000005 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:46,768 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000012 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:38:47,496 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1533735211869_0004: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:55296, vCores:1> knownNMs=15
2018-08-08 13:38:48,280 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,297 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,297 INFO [IPC Server handler 0 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000013 asked for a task
2018-08-08 13:38:48,298 INFO [IPC Server handler 0 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000013 given task: attempt_1533735211869_0004_m_000010_0
2018-08-08 13:38:48,307 INFO [IPC Server handler 1 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000005 asked for a task
2018-08-08 13:38:48,308 INFO [IPC Server handler 1 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000005 given task: attempt_1533735211869_0004_m_000002_0
2018-08-08 13:38:48,326 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,338 INFO [IPC Server handler 2 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000003 asked for a task
2018-08-08 13:38:48,338 INFO [IPC Server handler 2 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000003 given task: attempt_1533735211869_0004_m_000001_0
2018-08-08 13:38:48,352 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,361 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,362 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,363 INFO [IPC Server handler 3 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000015 asked for a task
2018-08-08 13:38:48,364 INFO [IPC Server handler 3 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000015 given task: attempt_1533735211869_0004_m_000012_0
2018-08-08 13:38:48,372 INFO [IPC Server handler 4 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000016 asked for a task
2018-08-08 13:38:48,372 INFO [IPC Server handler 4 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000016 given task: attempt_1533735211869_0004_m_000013_0
2018-08-08 13:38:48,374 INFO [IPC Server handler 5 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000012 asked for a task
2018-08-08 13:38:48,375 INFO [IPC Server handler 5 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000012 given task: attempt_1533735211869_0004_m_000009_0
2018-08-08 13:38:48,378 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,387 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,390 INFO [IPC Server handler 6 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000002 asked for a task
2018-08-08 13:38:48,391 INFO [IPC Server handler 6 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000002 given task: attempt_1533735211869_0004_m_000000_0
2018-08-08 13:38:48,399 INFO [IPC Server handler 7 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000009 asked for a task
2018-08-08 13:38:48,399 INFO [IPC Server handler 7 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000009 given task: attempt_1533735211869_0004_m_000006_0
2018-08-08 13:38:48,401 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,413 INFO [IPC Server handler 8 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000006 asked for a task
2018-08-08 13:38:48,413 INFO [IPC Server handler 8 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000006 given task: attempt_1533735211869_0004_m_000003_0
2018-08-08 13:38:48,432 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,445 INFO [IPC Server handler 9 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000010 asked for a task
2018-08-08 13:38:48,446 INFO [IPC Server handler 9 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000010 given task: attempt_1533735211869_0004_m_000007_0
2018-08-08 13:38:48,448 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,449 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,461 INFO [IPC Server handler 10 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000011 asked for a task
2018-08-08 13:38:48,461 INFO [IPC Server handler 11 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000007 asked for a task
2018-08-08 13:38:48,461 INFO [IPC Server handler 10 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000011 given task: attempt_1533735211869_0004_m_000008_0
2018-08-08 13:38:48,461 INFO [IPC Server handler 11 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000007 given task: attempt_1533735211869_0004_m_000004_0
2018-08-08 13:38:48,466 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,468 INFO [Socket Reader #1 for port 36911] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0004 (auth:SIMPLE)
2018-08-08 13:38:48,479 INFO [IPC Server handler 12 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000008 asked for a task
2018-08-08 13:38:48,479 INFO [IPC Server handler 12 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000008 given task: attempt_1533735211869_0004_m_000005_0
2018-08-08 13:38:48,482 INFO [IPC Server handler 13 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0004_m_000014 asked for a task
2018-08-08 13:38:48,482 INFO [IPC Server handler 13 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0004_m_000014 given task: attempt_1533735211869_0004_m_000011_0
2018-08-08 13:38:54,949 INFO [IPC Server handler 15 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000010_0 is : 1.0
2018-08-08 13:38:54,982 INFO [IPC Server handler 17 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000002_0 is : 1.0
2018-08-08 13:38:55,013 INFO [IPC Server handler 18 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000001_0 is : 1.0
2018-08-08 13:38:55,053 INFO [IPC Server handler 19 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000012_0 is : 1.0
2018-08-08 13:38:55,084 INFO [IPC Server handler 21 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000013_0 is : 1.0
2018-08-08 13:38:55,094 INFO [IPC Server handler 22 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000009_0 is : 1.0
2018-08-08 13:38:55,111 INFO [IPC Server handler 23 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000006_0 is : 1.0
2018-08-08 13:38:55,116 INFO [IPC Server handler 24 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000003_0 is : 1.0
2018-08-08 13:38:55,161 INFO [IPC Server handler 25 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000007_0 is : 1.0
2018-08-08 13:38:55,168 INFO [IPC Server handler 26 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000000_0 is : 1.0
2018-08-08 13:38:55,172 INFO [IPC Server handler 27 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000008_0 is : 1.0
2018-08-08 13:38:55,196 INFO [IPC Server handler 28 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000004_0 is : 1.0
2018-08-08 13:38:55,216 INFO [IPC Server handler 29 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000005_0 is : 1.0
2018-08-08 13:38:55,221 INFO [IPC Server handler 0 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000011_0 is : 1.0
2018-08-08 13:38:57,009 INFO [IPC Server handler 18 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000013_0 is : 1.0
2018-08-08 13:38:57,032 INFO [IPC Server handler 19 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000013_0
2018-08-08 13:38:57,034 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000013_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,034 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000013_0 given a go for committing the task output.
2018-08-08 13:38:57,035 INFO [IPC Server handler 20 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000013_0
2018-08-08 13:38:57,035 INFO [IPC Server handler 20 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000013_0:true
2018-08-08 13:38:57,059 INFO [IPC Server handler 21 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000013_0 is : 1.0
2018-08-08 13:38:57,061 INFO [IPC Server handler 22 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000013_0
2018-08-08 13:38:57,063 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000013_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:57,064 INFO [ContainerLauncher #14] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000016 taskAttempt attempt_1533735211869_0004_m_000013_0
2018-08-08 13:38:57,064 INFO [ContainerLauncher #14] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000013_0
2018-08-08 13:38:57,064 INFO [ContainerLauncher #14] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave13:40615
2018-08-08 13:38:57,081 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000013_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:57,090 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000013_0
2018-08-08 13:38:57,090 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000013 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:57,093 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 1
2018-08-08 13:38:57,209 INFO [IPC Server handler 29 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000012_0 is : 1.0
2018-08-08 13:38:57,211 INFO [IPC Server handler 29 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000001_0 is : 1.0
2018-08-08 13:38:57,235 INFO [IPC Server handler 1 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000012_0
2018-08-08 13:38:57,237 INFO [IPC Server handler 2 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000012_0
2018-08-08 13:38:57,238 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000012_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,238 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000012_0 given a go for committing the task output.
2018-08-08 13:38:57,238 INFO [IPC Server handler 3 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000001_0
2018-08-08 13:38:57,239 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000001_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,239 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000001_0 given a go for committing the task output.
2018-08-08 13:38:57,240 INFO [IPC Server handler 4 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000001_0
2018-08-08 13:38:57,240 INFO [IPC Server handler 4 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000001_0:true
2018-08-08 13:38:57,261 INFO [IPC Server handler 5 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000010_0 is : 1.0
2018-08-08 13:38:57,265 INFO [IPC Server handler 6 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000005_0 is : 1.0
2018-08-08 13:38:57,267 INFO [IPC Server handler 7 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000001_0 is : 1.0
2018-08-08 13:38:57,270 INFO [IPC Server handler 8 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000001_0
2018-08-08 13:38:57,271 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000001_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:57,272 INFO [ContainerLauncher #15] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000003 taskAttempt attempt_1533735211869_0004_m_000001_0
2018-08-08 13:38:57,272 INFO [ContainerLauncher #15] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000001_0
2018-08-08 13:38:57,272 INFO [ContainerLauncher #15] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave15:37797
2018-08-08 13:38:57,285 INFO [IPC Server handler 9 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000010_0
2018-08-08 13:38:57,285 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000001_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:57,286 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000001_0
2018-08-08 13:38:57,286 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000001 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:57,287 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000010_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,287 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 2
2018-08-08 13:38:57,288 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000010_0 given a go for committing the task output.
2018-08-08 13:38:57,289 INFO [IPC Server handler 11 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000010_0
2018-08-08 13:38:57,289 INFO [IPC Server handler 11 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000010_0:true
2018-08-08 13:38:57,291 INFO [IPC Server handler 10 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000005_0
2018-08-08 13:38:57,292 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000005_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,292 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000005_0 given a go for committing the task output.
2018-08-08 13:38:57,292 INFO [IPC Server handler 12 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000005_0
2018-08-08 13:38:57,292 INFO [IPC Server handler 12 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000005_0:true
2018-08-08 13:38:57,316 INFO [IPC Server handler 13 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000010_0 is : 1.0
2018-08-08 13:38:57,318 INFO [IPC Server handler 14 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000010_0
2018-08-08 13:38:57,319 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000010_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:57,320 INFO [ContainerLauncher #16] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000013 taskAttempt attempt_1533735211869_0004_m_000010_0
2018-08-08 13:38:57,321 INFO [ContainerLauncher #16] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000010_0
2018-08-08 13:38:57,321 INFO [ContainerLauncher #16] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave14:35219
2018-08-08 13:38:57,322 INFO [IPC Server handler 15 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000005_0 is : 1.0
2018-08-08 13:38:57,324 INFO [IPC Server handler 16 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000005_0
2018-08-08 13:38:57,325 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000005_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:57,326 INFO [ContainerLauncher #17] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000008 taskAttempt attempt_1533735211869_0004_m_000005_0
2018-08-08 13:38:57,326 INFO [ContainerLauncher #17] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000005_0
2018-08-08 13:38:57,327 INFO [ContainerLauncher #17] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave12:33893
2018-08-08 13:38:57,332 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000010_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:57,333 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000010_0
2018-08-08 13:38:57,333 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000010 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:57,333 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 3
2018-08-08 13:38:57,341 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000005_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:57,342 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000005_0
2018-08-08 13:38:57,342 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000005 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:57,342 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 4
2018-08-08 13:38:57,355 INFO [IPC Server handler 17 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000007_0 is : 1.0
2018-08-08 13:38:57,358 INFO [IPC Server handler 18 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000003_0 is : 1.0
2018-08-08 13:38:57,362 INFO [IPC Server handler 19 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000008_0 is : 1.0
2018-08-08 13:38:57,368 INFO [IPC Server handler 20 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000009_0 is : 1.0
2018-08-08 13:38:57,371 INFO [IPC Server handler 21 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000002_0 is : 1.0
2018-08-08 13:38:57,374 INFO [IPC Server handler 23 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000011_0 is : 1.0
2018-08-08 13:38:57,374 INFO [IPC Server handler 22 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000004_0 is : 1.0
2018-08-08 13:38:57,377 INFO [IPC Server handler 24 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000007_0
2018-08-08 13:38:57,379 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000007_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,379 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000007_0 given a go for committing the task output.
2018-08-08 13:38:57,380 INFO [IPC Server handler 25 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000003_0
2018-08-08 13:38:57,380 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000003_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,380 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000003_0 given a go for committing the task output.
2018-08-08 13:38:57,381 INFO [IPC Server handler 26 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000007_0
2018-08-08 13:38:57,381 INFO [IPC Server handler 26 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000007_0:true
2018-08-08 13:38:57,382 INFO [IPC Server handler 27 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000003_0
2018-08-08 13:38:57,382 INFO [IPC Server handler 27 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000003_0:true
2018-08-08 13:38:57,385 INFO [IPC Server handler 28 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000008_0
2018-08-08 13:38:57,385 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000008_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,385 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000008_0 given a go for committing the task output.
2018-08-08 13:38:57,386 INFO [IPC Server handler 29 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000008_0
2018-08-08 13:38:57,387 INFO [IPC Server handler 29 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000008_0:true
2018-08-08 13:38:57,393 INFO [IPC Server handler 0 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000009_0
2018-08-08 13:38:57,394 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000009_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,394 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000009_0 given a go for committing the task output.
2018-08-08 13:38:57,394 INFO [IPC Server handler 1 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000002_0
2018-08-08 13:38:57,394 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000002_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,394 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000002_0 given a go for committing the task output.
2018-08-08 13:38:57,395 INFO [IPC Server handler 2 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000009_0
2018-08-08 13:38:57,395 INFO [IPC Server handler 2 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000009_0:true
2018-08-08 13:38:57,395 INFO [IPC Server handler 3 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000002_0
2018-08-08 13:38:57,396 INFO [IPC Server handler 3 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000002_0:true
2018-08-08 13:38:57,397 INFO [IPC Server handler 4 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000011_0
2018-08-08 13:38:57,397 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000011_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,397 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000011_0 given a go for committing the task output.
2018-08-08 13:38:57,397 INFO [IPC Server handler 5 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000004_0
2018-08-08 13:38:57,397 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000004_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,397 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000004_0 given a go for committing the task output.
2018-08-08 13:38:57,398 INFO [IPC Server handler 6 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000011_0
2018-08-08 13:38:57,398 INFO [IPC Server handler 6 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000011_0:true
2018-08-08 13:38:57,399 INFO [IPC Server handler 7 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000004_0
2018-08-08 13:38:57,399 INFO [IPC Server handler 7 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000004_0:true
2018-08-08 13:38:57,406 INFO [IPC Server handler 8 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000007_0 is : 1.0
2018-08-08 13:38:57,408 INFO [IPC Server handler 9 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000007_0
2018-08-08 13:38:57,409 INFO [IPC Server handler 11 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000003_0 is : 1.0
2018-08-08 13:38:57,409 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000007_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:57,410 INFO [ContainerLauncher #18] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000010 taskAttempt attempt_1533735211869_0004_m_000007_0
2018-08-08 13:38:57,411 INFO [ContainerLauncher #18] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000007_0
2018-08-08 13:38:57,411 INFO [ContainerLauncher #18] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave11:46641
2018-08-08 13:38:57,411 INFO [IPC Server handler 10 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000003_0
2018-08-08 13:38:57,412 INFO [IPC Server handler 12 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000008_0 is : 1.0
2018-08-08 13:38:57,412 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000003_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:57,413 INFO [ContainerLauncher #19] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000006 taskAttempt attempt_1533735211869_0004_m_000003_0
2018-08-08 13:38:57,413 INFO [ContainerLauncher #19] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000003_0
2018-08-08 13:38:57,415 INFO [ContainerLauncher #19] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave9:37771
2018-08-08 13:38:57,416 INFO [IPC Server handler 13 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000008_0
2018-08-08 13:38:57,416 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000008_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:57,421 INFO [ContainerLauncher #20] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000011 taskAttempt attempt_1533735211869_0004_m_000008_0
2018-08-08 13:38:57,423 INFO [ContainerLauncher #20] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000008_0
2018-08-08 13:38:57,423 INFO [ContainerLauncher #20] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave5:46217
2018-08-08 13:38:57,424 INFO [IPC Server handler 14 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000009_0 is : 1.0
2018-08-08 13:38:57,424 INFO [IPC Server handler 15 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000002_0 is : 1.0
2018-08-08 13:38:57,425 INFO [IPC Server handler 16 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000011_0 is : 1.0
2018-08-08 13:38:57,425 INFO [IPC Server handler 17 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000004_0 is : 1.0
2018-08-08 13:38:57,429 INFO [IPC Server handler 18 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000009_0
2018-08-08 13:38:57,429 INFO [IPC Server handler 19 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000002_0
2018-08-08 13:38:57,429 INFO [IPC Server handler 20 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000011_0
2018-08-08 13:38:57,429 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000009_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:57,429 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000011_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:57,430 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000012 taskAttempt attempt_1533735211869_0004_m_000009_0
2018-08-08 13:38:57,431 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000009_0
2018-08-08 13:38:57,431 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave7:43383
2018-08-08 13:38:57,432 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000002_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:57,432 INFO [IPC Server handler 21 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000004_0
2018-08-08 13:38:57,432 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000014 taskAttempt attempt_1533735211869_0004_m_000011_0
2018-08-08 13:38:57,433 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000005 taskAttempt attempt_1533735211869_0004_m_000002_0
2018-08-08 13:38:57,434 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000002_0
2018-08-08 13:38:57,434 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000011_0
2018-08-08 13:38:57,436 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000004_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:57,436 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000007 taskAttempt attempt_1533735211869_0004_m_000004_0
2018-08-08 13:38:57,437 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000004_0
2018-08-08 13:38:57,440 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave2:43787
2018-08-08 13:38:57,442 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave8:41519
2018-08-08 13:38:57,443 INFO [ContainerLauncher #10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave4:46069
2018-08-08 13:38:57,443 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000007_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:57,445 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000003_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:57,445 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000007_0
2018-08-08 13:38:57,445 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000007 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:57,450 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000003_0
2018-08-08 13:38:57,450 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000003 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:57,451 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 5
2018-08-08 13:38:57,451 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 6
2018-08-08 13:38:57,455 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000008_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:57,456 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000009_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:57,456 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000008_0
2018-08-08 13:38:57,456 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000008 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:57,457 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000009_0
2018-08-08 13:38:57,457 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000009 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:57,457 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 7
2018-08-08 13:38:57,457 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 8
2018-08-08 13:38:57,461 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000011_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:57,461 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000011_0
2018-08-08 13:38:57,461 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000011 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:57,462 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 9
2018-08-08 13:38:57,464 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000004_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:57,464 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000004_0
2018-08-08 13:38:57,464 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000004 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:57,464 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 10
2018-08-08 13:38:57,467 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000002_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:57,467 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000002_0
2018-08-08 13:38:57,467 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000002 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:57,467 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 11
2018-08-08 13:38:57,489 INFO [IPC Server handler 23 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000006_0 is : 1.0
2018-08-08 13:38:57,510 INFO [IPC Server handler 22 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0004_m_000006_0
2018-08-08 13:38:57,510 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000006_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:38:57,510 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0004_m_000006_0 given a go for committing the task output.
2018-08-08 13:38:57,511 INFO [IPC Server handler 24 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000006_0
2018-08-08 13:38:57,511 INFO [IPC Server handler 24 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000006_0:true
2018-08-08 13:38:57,525 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:14 AssignedReds:0 CompletedMaps:11 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:38:57,533 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000016
2018-08-08 13:38:57,533 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000013
2018-08-08 13:38:57,533 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000008
2018-08-08 13:38:57,533 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000010
2018-08-08 13:38:57,533 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000007
2018-08-08 13:38:57,534 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000005
2018-08-08 13:38:57,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000013_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:57,534 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000012
2018-08-08 13:38:57,534 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000011
2018-08-08 13:38:57,534 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000014
2018-08-08 13:38:57,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000010_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:57,534 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000003
2018-08-08 13:38:57,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000005_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:57,534 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000006
2018-08-08 13:38:57,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000007_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:57,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000004_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:57,534 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:3 AssignedReds:0 CompletedMaps:11 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:38:57,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000002_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:57,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000009_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:57,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000008_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:57,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000011_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:57,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000001_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:57,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000003_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:57,534 INFO [IPC Server handler 25 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000006_0 is : 1.0
2018-08-08 13:38:57,536 INFO [IPC Server handler 26 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000006_0
2018-08-08 13:38:57,536 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000006_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:57,537 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000009 taskAttempt attempt_1533735211869_0004_m_000006_0
2018-08-08 13:38:57,538 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000006_0
2018-08-08 13:38:57,538 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave6:36387
2018-08-08 13:38:57,548 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000006_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:57,549 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000006_0
2018-08-08 13:38:57,549 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000006 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:57,549 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 12
2018-08-08 13:38:58,075 INFO [IPC Server handler 27 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000012_0 is : 1.0
2018-08-08 13:38:58,185 INFO [IPC Server handler 28 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000000_0 is : 1.0
2018-08-08 13:38:58,239 INFO [IPC Server handler 29 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0004_m_000012_0
2018-08-08 13:38:58,239 INFO [IPC Server handler 29 on 36911] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0004_m_000012_0:true
2018-08-08 13:38:58,266 INFO [IPC Server handler 0 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000012_0 is : 1.0
2018-08-08 13:38:58,267 INFO [IPC Server handler 1 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000012_0
2018-08-08 13:38:58,268 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000012_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:58,268 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000015 taskAttempt attempt_1533735211869_0004_m_000012_0
2018-08-08 13:38:58,268 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000012_0
2018-08-08 13:38:58,268 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave3:42077
2018-08-08 13:38:58,278 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000012_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:58,278 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000012_0
2018-08-08 13:38:58,278 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000012 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:58,279 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 13
2018-08-08 13:38:58,534 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:3 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:38:58,537 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000009
2018-08-08 13:38:58,537 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0004_01_000015
2018-08-08 13:38:58,537 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:38:58,538 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000006_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:58,538 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0004_m_000012_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:38:59,835 INFO [IPC Server handler 27 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000000_0 is : 1.0
2018-08-08 13:38:59,864 INFO [IPC Server handler 28 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0004_m_000000_0 is : 1.0
2018-08-08 13:38:59,866 INFO [IPC Server handler 29 on 36911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0004_m_000000_0
2018-08-08 13:38:59,866 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000000_0 TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:38:59,866 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0004_01_000002 taskAttempt attempt_1533735211869_0004_m_000000_0
2018-08-08 13:38:59,867 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0004_m_000000_0
2018-08-08 13:38:59,867 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave10:46663
2018-08-08 13:38:59,878 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0004_m_000000_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:38:59,878 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0004_m_000000_0
2018-08-08 13:38:59,878 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0004_m_000000 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:38:59,878 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 14
2018-08-08 13:38:59,879 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0004Job Transitioned from RUNNING to COMMITTING
2018-08-08 13:38:59,880 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_COMMIT
2018-08-08 13:39:00,028 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Calling handler for JobFinishedEvent 
2018-08-08 13:39:00,028 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0004Job Transitioned from COMMITTING to SUCCEEDED
2018-08-08 13:39:00,030 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: We are finishing cleanly so this is the last retry
2018-08-08 13:39:00,030 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true
2018-08-08 13:39:00,030 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: RMCommunicator notified that shouldUnregistered is: true
2018-08-08 13:39:00,030 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true
2018-08-08 13:39:00,030 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true
2018-08-08 13:39:00,030 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
2018-08-08 13:39:00,030 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0
2018-08-08 13:39:00,171 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0004/job_1533735211869_0004_1.jhist to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0004-1533735519825-hduser-GraphalyticsBenchmark%3A+PageRankJob-1533735540025-14-0-SUCCEEDED-default-1533735524471.jhist_tmp
2018-08-08 13:39:00,277 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0004-1533735519825-hduser-GraphalyticsBenchmark%3A+PageRankJob-1533735540025-14-0-SUCCEEDED-default-1533735524471.jhist_tmp
2018-08-08 13:39:00,281 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0004/job_1533735211869_0004_1_conf.xml to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0004_conf.xml_tmp
2018-08-08 13:39:00,374 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0004_conf.xml_tmp
2018-08-08 13:39:00,379 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0004.summary_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0004.summary
2018-08-08 13:39:00,381 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0004_conf.xml_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0004_conf.xml
2018-08-08 13:39:00,384 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0004-1533735519825-hduser-GraphalyticsBenchmark%3A+PageRankJob-1533735540025-14-0-SUCCEEDED-default-1533735524471.jhist_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0004-1533735519825-hduser-GraphalyticsBenchmark%3A+PageRankJob-1533735540025-14-0-SUCCEEDED-default-1533735524471.jhist
2018-08-08 13:39:00,388 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()
2018-08-08 13:39:00,396 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Setting job diagnostics to 
2018-08-08 13:39:00,398 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: History url is http://graphalytics-giraph-slave1:19888/jobhistory/job/job_1533735211869_0004
2018-08-08 13:39:00,405 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Waiting for application to be successfully unregistered.
2018-08-08 13:39:01,407 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:39:01,408 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://graphalytics-giraph:9000 /tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0004
2018-08-08 13:39:01,412 INFO [Thread-94] org.apache.hadoop.ipc.Server: Stopping server on 36911
2018-08-08 13:39:01,413 INFO [IPC Server listener on 36911] org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 36911
2018-08-08 13:39:01,416 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-08-08 13:39:01,416 INFO [TaskHeartbeatHandler PingChecker] org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted
End of LogType:syslog



Container: container_1533735211869_0004_01_000014 on graphalytics-giraph-slave2_43787
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15687
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 539 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 571 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 10,317.00
               min = 16.00
               max = 6905.00
              mean = 124.30
            stddev = 754.23
            median = 25.00
              75% <= 81.00
              95% <= 89.00
              98% <= 2345.60
              99% <= 6905.00
            99.9% <= 6905.00
             count = 83

  remote-requests:
    count = 0

  requests-received:
             count = 83
         mean rate = 150.26 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 97
         mean rate = 175.97 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 7,588.00
               min = 16.00
               max = 1473.00
              mean = 78.23
            stddev = 177.79
            median = 16.00
              75% <= 53.00
              95% <= 341.00
              98% <= 386.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 97

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 539

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 571

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 86 ms
  compute all partitions: 17 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 535 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 17

  compute-per-partition-ms:
               sum = 49.00
               min = 0.00
               max = 4.00
              mean = 1.48
            stddev = 1.41
            median = 1.00
              75% <= 3.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 46.00
               min = 0.00
               max = 7.00
              mean = 4.18
            stddev = 2.99
            median = 5.00
              75% <= 7.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 9,453.00
               min = 16.00
               max = 6905.00
              mean = 178.36
            stddev = 947.19
            median = 46.00
              75% <= 85.00
              95% <= 89.00
              98% <= 6359.72
              99% <= 6905.00
            99.9% <= 6905.00
             count = 53

  remote-requests:
    count = 0

  requests-received:
             count = 53
         mean rate = 438.03 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 54
         mean rate = 444.65 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 6,702.00
               min = 16.00
               max = 1473.00
              mean = 124.11
            stddev = 229.04
            median = 16.00
              75% <= 125.00
              95% <= 341.00
              98% <= 1359.80
              99% <= 1473.00
            99.9% <= 1473.00
             count = 54

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 86

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.27
            stddev = 0.47
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 535

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 56 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 207 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 11.00
               min = 0.00
               max = 4.00
              mean = 0.33
            stddev = 0.89
            median = 0.00
              75% <= 0.00
              95% <= 3.30
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 11.00
               min = 0.00
               max = 4.00
              mean = 1.00
            stddev = 1.48
            median = 0.00
              75% <= 2.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 9,453.00
               min = 16.00
               max = 6905.00
              mean = 178.36
            stddev = 945.09
            median = 46.00
              75% <= 85.00
              95% <= 89.00
              98% <= 6359.72
              99% <= 6905.00
            99.9% <= 6905.00
             count = 53

  remote-requests:
    count = 0

  requests-received:
             count = 53
         mean rate = 582.60 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 54
         mean rate = 594.40 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 6,702.00
               min = 16.00
               max = 1473.00
              mean = 124.11
            stddev = 229.29
            median = 16.00
              75% <= 125.00
              95% <= 341.00
              98% <= 1359.80
              99% <= 1473.00
            99.9% <= 1473.00
             count = 54

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 56

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 207

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 133 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 168 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 9,361.00
               min = 16.00
               max = 6905.00
              mean = 183.55
            stddev = 963.50
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6632.36
              99% <= 6905.00
            99.9% <= 6905.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 308.85 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 314.91 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 6,670.00
               min = 16.00
               max = 1473.00
              mean = 128.27
            stddev = 232.22
            median = 34.50
              75% <= 269.00
              95% <= 341.00
              98% <= 1405.08
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 133

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 168

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.52249236988615

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:59728
Log Contents:
2018-08-08 13:38:48,087 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,154 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,154 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,156 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,156 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,325 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,566 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,765 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:49,235 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,246 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,393 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,409 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,438 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,439 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,447 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,454 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,454 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 11 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,460 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,460 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave2
INFO    2018-08-08 13:38:49,460 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,460 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,460 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,460 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000014:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000014/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,460 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000014:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,461 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000014/tmp
INFO    2018-08-08 13:38:49,461 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,461 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,461 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,461 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,461 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,461 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,461 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000014
INFO    2018-08-08 13:38:49,461 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,474 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,475 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,482 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30037, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,483 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,601 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,619 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,673 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave2/10.164.0.4:30011 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,678 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,679 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,700 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,710 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,713 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,716 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,722 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave2_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=11, port=30011)
INFO    2018-08-08 13:38:49,852 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,944 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0066, ave received req MBytes = 0.0066, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,955 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,956 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,958 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,960 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,961 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,961 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,962 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,962 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,970 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,972 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,973 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,974 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,976 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,977 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,978 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,980 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,986 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,988 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,043 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,100 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05604427 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,100 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04956828 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050055295 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.049800385 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048728805 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048023324 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04718929 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046232365 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045550354 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04463866 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04407969 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0029, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.119
MBytes/sec sent = 0.0347, MBytesSent = 0.0042, ave sent req MBytes = 0.0002, secs waited = 0.12
INFO    2018-08-08 13:38:50,107 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,111 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003837086 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,112 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003155609 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,113 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003092089 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,114 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002655884 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,115 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002938802 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,115 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002697209 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,116 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002777935 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,119 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003773035 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,120 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001007665 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,121 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002737155 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,121 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005136325 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,122 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0087, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0136, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 13:38:50,123 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:38:50,170 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,177 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:38:50,179 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50879.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,180 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.001, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.064
MBytes/sec sent = 0.0015, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.064
INFO    2018-08-08 13:38:50,180 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,194 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0168, MBytesSent = 0.0001, ave sent req MBytes = 0.0001, secs waited = 0.002
INFO    2018-08-08 13:38:50,194 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50879.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,206 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,241 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,247 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@64e92d61,outgoing=org.apache.giraph.conf.DefaultMessageClasses@111610e6)
WARN    2018-08-08 13:38:50,251 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:50,268 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,268 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,270 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave2_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=11, port=30011)
INFO    2018-08-08 13:38:50,306 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,306 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,306 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,308 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.113
MBytes/sec sent = 0.0123, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.114
INFO    2018-08-08 13:38:50,310 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,311 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,321 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,335 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008709286 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,335 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003979773 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,335 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012100455 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,335 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007624403 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,335 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009978312 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,335 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010500305 secs for 9 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,336 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005286203 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,335 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005783411 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,336 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00377199 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,336 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003124571 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,335 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008240929 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,339 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50738.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,339 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0065, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.027
MBytes/sec sent = 0.1394, MBytesSent = 0.0039, ave sent req MBytes = 0.0003, secs waited = 0.027
INFO    2018-08-08 13:38:50,340 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,345 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0253, MBytesSent = 0.0001, ave sent req MBytes = 0.0001, secs waited = 0.002
INFO    2018-08-08 13:38:50,346 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,351 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,372 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,374 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@383f3558,outgoing=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3)
INFO    2018-08-08 13:38:50,385 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,387 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave2_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=11, port=30011)
INFO    2018-08-08 13:38:50,414 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,414 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,414 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,415 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.069
MBytes/sec sent = 0.0201, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.069
INFO    2018-08-08 13:38:50,417 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,419 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,423 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,428 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003359275 secs for 18 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003069421 secs for 8 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005565678 secs for 5 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002200535 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00190808 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,430 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001802178 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,430 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004455875 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002786321 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,430 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003942056 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,432 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003058394 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,432 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002671049 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,432 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,433 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.2787, MBytesSent = 0.0039, ave sent req MBytes = 0.0003, secs waited = 0.013
INFO    2018-08-08 13:38:50,433 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,440 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0253, MBytesSent = 0.0001, ave sent req MBytes = 0.0001, secs waited = 0.001
INFO    2018-08-08 13:38:50,441 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,446 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,469 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,472 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@294bdeb4,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5300f14a)
INFO    2018-08-08 13:38:50,479 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,496 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave2_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=11, port=30011)
INFO    2018-08-08 13:38:50,507 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,554 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,581 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,582 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,582 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,583 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.141
MBytes/sec sent = 0.0098, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.142
INFO    2018-08-08 13:38:50,585 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,588 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,591 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,596 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0043105 secs for 15 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,596 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002670441 secs for 14 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,596 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002246581 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001826932 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001560458 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001837617 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001283502 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,599 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001545607 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,599 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001141954 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,600 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001340644 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,603 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003183977 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,603 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50444.47M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,604 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0122, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.015
MBytes/sec sent = 0.2439, MBytesSent = 0.0039, ave sent req MBytes = 0.0003, secs waited = 0.015
INFO    2018-08-08 13:38:50,604 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,611 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0253, MBytesSent = 0.0001, ave sent req MBytes = 0.0001, secs waited = 0.001
INFO    2018-08-08 13:38:50,612 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50444.47M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,618 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,636 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,640 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@45673f68,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27abb83e)
INFO    2018-08-08 13:38:50,645 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,645 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,645 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,646 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,667 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,712 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,717 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,720 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:52,950 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:52,951 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:38:52,954 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:53,155 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:53,155 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:53,158 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/11_worker
INFO    2018-08-08 13:38:53,160 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30037 closed
INFO    2018-08-08 13:38:53,160 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:53,162 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:53,165 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,375 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,379 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000011_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:57,403 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000011_0 is allowed to commit now
INFO    2018-08-08 13:38:57,412 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000011_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000011
INFO    2018-08-08 13:38:57,434 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000011_0' done.
INFO    2018-08-08 13:38:57,440 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000011_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129328
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=23
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=92
		CPU time spent (ms)=4650
		Physical memory (bytes) snapshot=1110274048
		Virtual memory (bytes) snapshot=58909093888
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000015 on graphalytics-giraph-slave3_42077
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15684
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 697 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 345 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  received-bytes:
               sum = 10,281.00
               min = 16.00
               max = 6653.00
              mean = 105.99
            stddev = 673.00
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 593.48
              99% <= 6653.00
            99.9% <= 6653.00
             count = 97

  remote-requests:
    count = 10

  requests-received:
             count = 97
         mean rate = 136.42 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 108
         mean rate = 152.13 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 10

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 5,129.00
               min = 16.00
               max = 1473.00
              mean = 47.49
            stddev = 140.61
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 89.00
              99% <= 1348.44
            99.9% <= 1473.00
             count = 108

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 697

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 10

  wait-requests-us:
    value = 345

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 86 ms
  compute all partitions: 17 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 215 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 17

  compute-per-partition-ms:
               sum = 38.00
               min = 0.00
               max = 4.00
              mean = 1.15
            stddev = 1.51
            median = 0.00
              75% <= 2.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 37.00
               min = 0.00
               max = 7.00
              mean = 3.36
            stddev = 2.87
            median = 3.00
              75% <= 7.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6653.00
              mean = 176.96
            stddev = 943.95
            median = 16.00
              75% <= 89.00
              95% <= 189.80
              98% <= 6400.52
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 416.05 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 424.04 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.71
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 86

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 215

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 57 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 302 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.09
            stddev = 0.38
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6653.00
              mean = 176.96
            stddev = 927.01
            median = 16.00
              75% <= 89.00
              95% <= 189.80
              98% <= 6400.52
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 551.47 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 562.15 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.68
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 57

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 302

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 130 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 174 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.03
            stddev = 0.17
            median = 0.00
              75% <= 0.00
              95% <= 0.30
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6653.00
              mean = 176.96
            stddev = 935.82
            median = 16.00
              75% <= 89.00
              95% <= 189.80
              98% <= 6400.52
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 316.22 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 322.47 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.68
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 130

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 174

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:52 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.56508157085038

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:52 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = 0.0

  vertices-loaded:
             count = 10
         mean rate = 2.69 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:60024
Log Contents:
2018-08-08 13:38:47,987 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,053 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,053 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,055 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,055 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,223 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,436 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,616 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:49,064 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,075 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,231 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,246 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,273 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,274 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,281 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,288 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,288 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 12 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,294 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,294 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave3
INFO    2018-08-08 13:38:49,294 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,294 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,294 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,294 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000015:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000015/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,295 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000015:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,295 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000015/tmp
INFO    2018-08-08 13:38:49,295 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,295 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,295 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,295 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,295 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,295 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,295 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000015
INFO    2018-08-08 13:38:49,295 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,308 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,309 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,316 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3002d, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,317 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,432 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,449 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,510 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave3/10.164.0.5:30012 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,514 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,515 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,537 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,546 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,550 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,553 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,560 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave3_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=12, port=30012)
INFO    2018-08-08 13:38:49,846 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,940 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,949 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,951 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,953 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,956 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,958 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,958 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,960 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,962 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,968 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,969 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,970 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,971 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,971 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,972 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,976 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,035 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,083 [load-0] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/example-directed.v:0+21'
INFO    2018-08-08 13:38:50,095 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.051173948 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,095 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0523566 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,095 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050360728 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,095 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04883911 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,098 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050478023 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,098 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050107967 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,099 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04988744 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050940108 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050290372 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.049599 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-0] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=10, e=0)
INFO    2018-08-08 13:38:50,106 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 0.07032312 secs, (v=10, e=0) 142.20074 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,115 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.017, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.008
MBytes/sec sent = 0.0572, MBytesSent = 0.0005, ave sent req MBytes = 0.0001, secs waited = 0.008
INFO    2018-08-08 13:38:50,116 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,119 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002613418 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,119 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 8.75929E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,120 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001001673 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,121 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004240541 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,122 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001130282 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,124 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003862339 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,124 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006076582 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,124 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002818349 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,125 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003193444 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,127 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004015631 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,128 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003853373 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,129 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:38:50,129 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=10, e=0)
INFO    2018-08-08 13:38:50,165 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,170 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:38:50,171 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50863.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,172 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0006, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.048
MBytes/sec sent = 0.001, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.048
INFO    2018-08-08 13:38:50,172 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,188 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,188 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50863.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,200 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,236 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,241 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4ad4936c,outgoing=org.apache.giraph.conf.DefaultMessageClasses@29d37757)
WARN    2018-08-08 13:38:50,246 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:50,262 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,262 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,264 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave3_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=12, port=30012)
INFO    2018-08-08 13:38:50,301 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,301 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,301 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,303 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.115
MBytes/sec sent = 0.0121, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.115
INFO    2018-08-08 13:38:50,306 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,307 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,316 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,329 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00535681 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007397447 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009976292 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011020311 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01053142 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004418456 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005110953 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00259702 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001881711 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,332 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00354034 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,329 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006544815 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,335 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,336 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0065, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.027
MBytes/sec sent = 0.0364, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.028
INFO    2018-08-08 13:38:50,336 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,339 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,340 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,346 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,367 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,370 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@352e612e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@65f00478)
INFO    2018-08-08 13:38:50,380 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,382 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave3_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=12, port=30012)
INFO    2018-08-08 13:38:50,409 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,409 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,409 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,410 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.07
MBytes/sec sent = 0.0198, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.07
INFO    2018-08-08 13:38:50,413 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,414 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,418 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,422 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002923954 secs for 21 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,422 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001722515 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002285013 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001911773 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003427864 secs for 8 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001773525 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002124529 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002032543 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002928892 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002164768 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002673058 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,429 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0122, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.014
MBytes/sec sent = 0.0679, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.014
INFO    2018-08-08 13:38:50,429 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,437 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,437 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,441 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,464 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,468 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@1f86099a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@77bb0ab5)
INFO    2018-08-08 13:38:50,477 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,495 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave3_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave3 hostOrIp=graphalytics-giraph-slave3, MRtaskID=12, port=30012)
INFO    2018-08-08 13:38:50,502 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,549 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,577 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,577 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,577 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,578 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.141
MBytes/sec sent = 0.0099, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.141
INFO    2018-08-08 13:38:50,580 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,583 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,587 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,590 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001683767 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,590 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002219967 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003463028 secs for 23 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,590 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001344759 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001153839 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,592 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001087057 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001001271 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,594 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001372009 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001396752 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001622003 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001985442 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,598 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:38:50,598 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,606 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,607 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,612 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,631 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,634 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@69e308c6,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1a1ed4e5)
INFO    2018-08-08 13:38:50,638 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,639 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,639 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,641 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,663 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,707 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,713 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,715 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:52,945 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:52,945 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 13:38:52,949 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:52,982 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:52,983 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:52,984 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/12_worker
INFO    2018-08-08 13:38:52,986 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3002d closed
INFO    2018-08-08 13:38:52,986 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:52,988 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:52,992 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,205 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,209 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000012_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:58,239 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000012_0 is allowed to commit now
INFO    2018-08-08 13:38:58,250 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000012_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000012
INFO    2018-08-08 13:38:58,267 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000012_0' done.
INFO    2018-08-08 13:38:58,272 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000012_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129328
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=65
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=85
		CPU time spent (ms)=4290
		Physical memory (bytes) snapshot=1098711040
		Virtual memory (bytes) snapshot=58875633664
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000007 on graphalytics-giraph-slave4_46069
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15687
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 566 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 333 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 10,074.00
               min = 16.00
               max = 6653.00
              mean = 138.00
            stddev = 774.78
            median = 32.00
              75% <= 59.00
              95% <= 140.10
              98% <= 3623.24
              99% <= 6653.00
            99.9% <= 6653.00
             count = 73

  remote-requests:
    count = 0

  requests-received:
             count = 73
         mean rate = 125.08 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 168.28 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,580.00
               min = 16.00
               max = 1473.00
              mean = 46.73
            stddev = 147.67
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 566

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 333

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 87 ms
  compute all partitions: 16 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 2553 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 16

  compute-per-partition-ms:
               sum = 54.00
               min = 0.00
               max = 8.00
              mean = 1.64
            stddev = 1.71
            median = 1.00
              75% <= 3.00
              95% <= 5.20
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 164

  messages-sent:
    count = 4

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 53.00
               min = 1.00
               max = 8.00
              mean = 4.82
            stddev = 2.36
            median = 5.00
              75% <= 7.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 9,227.00
               min = 16.00
               max = 6564.00
              mean = 156.39
            stddev = 849.97
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5319.40
              99% <= 6564.00
            99.9% <= 6564.00
             count = 59

  remote-requests:
    count = 4

  requests-received:
             count = 59
         mean rate = 484.41 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 59
         mean rate = 483.95 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 4

  sent-bytes:
               sum = 3,878.00
               min = 16.00
               max = 1473.00
              mean = 65.73
            stddev = 188.66
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1196.20
              99% <= 1473.00
            99.9% <= 1473.00
             count = 59

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 87

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 4

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 2553

  worker-context-post-superstep:
    value = 10

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 56 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 171 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 7.00
               min = 0.00
               max = 4.00
              mean = 0.21
            stddev = 0.74
            median = 0.00
              75% <= 0.00
              95% <= 1.90
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 164

  messages-sent:
    count = 4

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 7.00
               min = 0.00
               max = 4.00
              mean = 0.64
            stddev = 1.29
            median = 0.00
              75% <= 1.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 9,227.00
               min = 16.00
               max = 6653.00
              mean = 159.09
            stddev = 871.52
            median = 16.00
              75% <= 53.00
              95% <= 101.60
              98% <= 5516.84
              99% <= 6653.00
            99.9% <= 6653.00
             count = 58

  remote-requests:
    count = 4

  requests-received:
             count = 58
         mean rate = 628.78 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 59
         mean rate = 639.01 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 4

  sent-bytes:
               sum = 3,878.00
               min = 16.00
               max = 1473.00
              mean = 65.73
            stddev = 188.64
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1196.20
              99% <= 1473.00
            99.9% <= 1473.00
             count = 59

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 56

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 4

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 171

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 133 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 369 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6564.00
              mean = 173.56
            stddev = 909.84
            median = 34.50
              75% <= 89.00
              95% <= 177.20
              98% <= 6190.62
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 317.27 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 317.35 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.68
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 133

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 369

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.25485479628662

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:59859
Log Contents:
2018-08-08 13:38:48,044 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,116 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,116 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,118 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,118 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,300 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,537 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,726 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:49,203 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,215 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,365 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,380 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,409 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,409 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,417 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,424 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,424 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 4 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave4
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000007:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000007/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000007:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000007/tmp
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,431 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000007
INFO    2018-08-08 13:38:49,432 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,444 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,445 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,451 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30035, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,453 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,566 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,583 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,635 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave4/10.164.0.6:30004 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,640 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,640 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,661 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,675 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,678 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,682 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,689 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave4_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=4, port=30004)
INFO    2018-08-08 13:38:49,843 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,939 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,949 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,951 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,952 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,954 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,954 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,956 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,957 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,958 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,962 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,962 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,965 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,965 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,965 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,965 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,970 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,971 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,971 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,971 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,978 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,037 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,101 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.06339692 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.056983184 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.056209225 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.055419806 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05490884 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05397283 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05229297 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05132685 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05078334 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05004464 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04938417 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,107 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0027, MBytesReceived = 0.0002, ave received req MBytes = 0.0001, secs waited = 0.061
MBytes/sec sent = 0.0042, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.062
INFO    2018-08-08 13:38:50,108 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,112 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004235024 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,113 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003304612 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,114 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003572141 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,114 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001367171 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,115 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003266196 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,117 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005791482 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,118 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004470697 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,119 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004105081 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,120 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00417965 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,120 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00415615 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,120 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002931412 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,121 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0095, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:38:50,121 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:38:50,163 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,167 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,176 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,178 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,178 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0005, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.061
MBytes/sec sent = 0.0008, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.061
INFO    2018-08-08 13:38:50,178 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,186 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,186 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,198 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,234 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,239 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
WARN    2018-08-08 13:38:50,244 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:50,256 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,257 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,259 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave4_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=4, port=30004)
INFO    2018-08-08 13:38:50,297 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,297 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,297 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,299 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.112
MBytes/sec sent = 0.0124, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.113
INFO    2018-08-08 13:38:50,301 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,304 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,314 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,326 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008839872 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004433908 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006037581 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003076039 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005300187 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010868538 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005851221 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007186366 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007665991 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010927735 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008342918 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,334 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0102, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0292, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:38:50,334 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,338 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0496, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.1643, MBytesSent = 0.0007, ave sent req MBytes = 0.0001, secs waited = 0.003
INFO    2018-08-08 13:38:50,339 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 4 , message bytes = 164 , Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,344 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,365 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,369 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 13:38:50,376 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,379 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave4_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=4, port=30004)
INFO    2018-08-08 13:38:50,407 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,407 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,407 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,408 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.069
MBytes/sec sent = 0.0201, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.069
INFO    2018-08-08 13:38:50,411 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,412 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,416 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,421 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002476173 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,421 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003473279 secs for 25 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,421 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002340346 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,422 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001419575 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,422 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005117606 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,422 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002213316 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002967728 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001534268 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002365734 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,425 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001622292 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003460351 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50457.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0087, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0251, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,432 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0397, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.1314, MBytesSent = 0.0007, ave sent req MBytes = 0.0001, secs waited = 0.004
INFO    2018-08-08 13:38:50,433 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 4 , message bytes = 164 , Memory (free/total/max) = 50457.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,437 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,462 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,465 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 13:38:50,471 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,489 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave4_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=4, port=30004)
INFO    2018-08-08 13:38:50,500 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,547 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,574 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,574 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,575 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,575 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.142
MBytes/sec sent = 0.0098, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.142
INFO    2018-08-08 13:38:50,578 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,581 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,584 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,589 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002336004 secs for 11 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,589 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001884628 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,589 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004537405 secs for 16 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,589 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002180964 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,590 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00245442 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,590 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002034908 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001763752 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,592 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001911396 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,592 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001705699 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,592 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001264725 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002971465 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50303.67M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,596 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.014
MBytes/sec sent = 0.0679, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.014
INFO    2018-08-08 13:38:50,596 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,604 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.022, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.008
MBytes/sec sent = 0.073, MBytesSent = 0.0007, ave sent req MBytes = 0.0001, secs waited = 0.008
INFO    2018-08-08 13:38:50,604 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50303.67M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,610 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,629 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,631 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 13:38:50,635 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,635 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,635 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,637 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,660 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,705 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,710 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,713 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:52,941 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:52,942 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:38:52,945 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:53,145 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:53,145 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:53,147 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/4_worker
INFO    2018-08-08 13:38:53,149 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30035 closed
INFO    2018-08-08 13:38:53,149 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:53,151 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:53,155 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,368 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,372 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000004_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:57,396 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000004_0 is allowed to commit now
INFO    2018-08-08 13:38:57,406 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000004_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000004
INFO    2018-08-08 13:38:57,430 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000004_0' done.
INFO    2018-08-08 13:38:57,435 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000004_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129327
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=22
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=100
		CPU time spent (ms)=4700
		Physical memory (bytes) snapshot=1103863808
		Virtual memory (bytes) snapshot=58910842880
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000011 on graphalytics-giraph-slave5_46217
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15682
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 610 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 367 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 10,026.00
               min = 16.00
               max = 6653.00
              mean = 120.80
            stddev = 727.25
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2360.84
              99% <= 6653.00
            99.9% <= 6653.00
             count = 83

  remote-requests:
    count = 0

  requests-received:
             count = 83
         mean rate = 133.03 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 157.38 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,580.00
               min = 16.00
               max = 1473.00
              mean = 46.73
            stddev = 147.70
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 610

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 367

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 87 ms
  compute all partitions: 14 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1817 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 14

  compute-per-partition-ms:
               sum = 39.00
               min = 0.00
               max = 6.00
              mean = 1.18
            stddev = 1.44
            median = 1.00
              75% <= 2.00
              95% <= 4.60
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 39.00
               min = 0.00
               max = 8.00
              mean = 3.55
            stddev = 3.01
            median = 4.00
              75% <= 6.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 9,041.00
               min = 16.00
               max = 6653.00
              mean = 173.87
            stddev = 918.05
            median = 16.00
              75% <= 80.00
              95% <= 177.20
              98% <= 6274.28
              99% <= 6653.00
            99.9% <= 6653.00
             count = 52

  remote-requests:
    count = 1

  requests-received:
             count = 52
         mean rate = 426.64 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 434.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,692.00
               min = 16.00
               max = 1473.00
              mean = 69.66
            stddev = 198.77
            median = 25.00
              75% <= 85.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 87

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1817

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 57 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 163 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 7.00
               min = 0.00
               max = 2.00
              mean = 0.21
            stddev = 0.48
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 6.00
               min = 0.00
               max = 3.00
              mean = 0.55
            stddev = 1.04
            median = 0.00
              75% <= 1.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 9,041.00
               min = 16.00
               max = 6653.00
              mean = 173.87
            stddev = 965.14
            median = 16.00
              75% <= 80.00
              95% <= 177.20
              98% <= 6274.28
              99% <= 6653.00
            99.9% <= 6653.00
             count = 52

  remote-requests:
    count = 1

  requests-received:
             count = 52
         mean rate = 564.73 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 575.79 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,692.00
               min = 16.00
               max = 1473.00
              mean = 69.66
            stddev = 198.85
            median = 25.00
              75% <= 85.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 57

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 163

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 133 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 335 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6653.00
              mean = 176.96
            stddev = 926.38
            median = 16.00
              75% <= 89.00
              95% <= 189.80
              98% <= 6400.52
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 308.53 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 314.66 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.71
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 133

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 335

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.22427369788325

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:59802
Log Contents:
2018-08-08 13:38:48,069 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,132 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,132 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,134 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,134 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,311 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,538 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,723 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:49,178 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,190 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,337 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,351 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,379 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,380 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,388 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,394 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,394 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 8 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave5
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000011:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000011/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000011:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000011/tmp
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,400 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000011
INFO    2018-08-08 13:38:49,401 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,412 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,413 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,419 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30033, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,420 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,529 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,546 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,597 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave5/10.164.0.7:30008 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,603 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,604 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,624 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,634 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,637 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,640 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,646 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave5_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=8, port=30008)
INFO    2018-08-08 13:38:49,847 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,939 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,949 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,950 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,952 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,956 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,956 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,960 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,962 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,965 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,965 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,969 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,969 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,970 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,970 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,971 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,974 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,974 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,977 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,042 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,085 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042156477 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,085 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03357752 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,085 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.034728944 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,086 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03283219 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,088 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03480083 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,089 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.034054704 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,089 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03326892 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,089 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03276485 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.032036595 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031262208 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03061978 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,093 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0039, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.042
MBytes/sec sent = 0.0061, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.042
INFO    2018-08-08 13:38:50,095 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,099 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00374658 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.76057E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003896022 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00273588 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00397843 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00757916 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003535837 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001191189 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003071663 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003012754 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,107 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004835317 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,108 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0219, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.011
INFO    2018-08-08 13:38:50,108 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:38:50,166 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,170 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,180 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,182 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,182 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.002, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.085
MBytes/sec sent = 0.003, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.085
INFO    2018-08-08 13:38:50,182 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,189 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,189 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,201 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,237 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,242 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
WARN    2018-08-08 13:38:50,247 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:50,258 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,259 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,261 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave5_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=8, port=30008)
INFO    2018-08-08 13:38:50,300 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,300 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,301 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,302 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.113
MBytes/sec sent = 0.0123, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.113
INFO    2018-08-08 13:38:50,305 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,307 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,316 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,328 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006691421 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008453006 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002229107 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006107567 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011210581 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,329 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004011147 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,329 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005031691 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,329 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003697224 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,329 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009434151 secs for 7 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004642155 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011306822 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50581.99M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,333 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0088, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:38:50,333 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,340 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,341 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50581.99M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,347 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,368 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,370 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 13:38:50,379 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,382 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave5_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=8, port=30008)
INFO    2018-08-08 13:38:50,409 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,409 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,409 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,410 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.069
MBytes/sec sent = 0.0201, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.069
INFO    2018-08-08 13:38:50,413 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,414 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,419 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,423 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001905294 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002843245 secs for 16 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003035951 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001346104 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002175415 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004760026 secs for 6 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,425 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002034043 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,425 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001916581 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002921986 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003353706 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002775675 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50441.19M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0088, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:38:50,428 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,436 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,436 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50441.19M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,441 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,465 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,467 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 13:38:50,473 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,492 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave5_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=8, port=30008)
INFO    2018-08-08 13:38:50,502 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,550 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,577 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,578 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,578 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,579 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.143
MBytes/sec sent = 0.0098, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.143
INFO    2018-08-08 13:38:50,581 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,584 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,587 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,591 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001220044 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001735035 secs for 10 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003122836 secs for 20 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0010866 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,592 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001322583 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00199573 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002840146 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002464602 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003794395 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003691608 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005661249 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,599 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,599 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0122, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.014
MBytes/sec sent = 0.0679, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.014
INFO    2018-08-08 13:38:50,599 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,606 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,606 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,609 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,632 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,634 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 13:38:50,638 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,639 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,639 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,641 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,663 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,708 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,713 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,716 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:52,945 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:52,945 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:38:52,949 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:53,138 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:53,139 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:53,140 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/8_worker
INFO    2018-08-08 13:38:53,141 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30033 closed
INFO    2018-08-08 13:38:53,142 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:53,144 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:53,147 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,359 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,363 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000008_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:57,387 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000008_0 is allowed to commit now
INFO    2018-08-08 13:38:57,396 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000008_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000008
INFO    2018-08-08 13:38:57,417 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000008_0' done.
INFO    2018-08-08 13:38:57,422 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000008_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129327
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=22
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=88
		CPU time spent (ms)=4470
		Physical memory (bytes) snapshot=1098477568
		Virtual memory (bytes) snapshot=58905956352
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000009 on graphalytics-giraph-slave6_36387
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15684
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 640 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 372 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 10,058.00
               min = 16.00
               max = 6653.00
              mean = 121.18
            stddev = 726.96
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2360.84
              99% <= 6653.00
            99.9% <= 6653.00
             count = 83

  remote-requests:
    count = 0

  requests-received:
             count = 83
         mean rate = 126.85 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 150.01 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,580.00
               min = 16.00
               max = 1473.00
              mean = 46.73
            stddev = 147.68
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 640

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 372

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 86 ms
  compute all partitions: 15 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 2465 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 15

  compute-per-partition-ms:
               sum = 40.00
               min = 0.00
               max = 7.00
              mean = 1.21
            stddev = 1.69
            median = 0.00
              75% <= 2.00
              95% <= 4.90
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 123

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 40.00
               min = 0.00
               max = 7.00
              mean = 3.64
            stddev = 2.87
            median = 4.00
              75% <= 7.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 9,211.00
               min = 16.00
               max = 6653.00
              mean = 161.60
            stddev = 884.47
            median = 16.00
              75% <= 53.00
              95% <= 114.20
              98% <= 5643.08
              99% <= 6653.00
            99.9% <= 6653.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 461.23 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 468.31 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,832.00
               min = 16.00
               max = 1473.00
              mean = 66.07
            stddev = 190.26
            median = 20.50
              75% <= 60.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 86

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 2465

  worker-context-post-superstep:
    value = 10

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 54 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 158 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 12.00
               min = 0.00
               max = 3.00
              mean = 0.36
            stddev = 0.74
            median = 0.00
              75% <= 0.50
              95% <= 2.30
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 123

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 11.00
               min = 0.00
               max = 3.00
              mean = 1.00
            stddev = 1.10
            median = 1.00
              75% <= 2.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 9,211.00
               min = 16.00
               max = 6653.00
              mean = 161.60
            stddev = 876.53
            median = 16.00
              75% <= 53.00
              95% <= 114.20
              98% <= 5643.08
              99% <= 6653.00
            99.9% <= 6653.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 629.31 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 640.09 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,832.00
               min = 16.00
               max = 1473.00
              mean = 66.07
            stddev = 190.27
            median = 20.50
              75% <= 60.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 54

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 158

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 131 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 155 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6653.00
              mean = 176.96
            stddev = 926.41
            median = 16.00
              75% <= 89.00
              95% <= 189.80
              98% <= 6400.52
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 308.47 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 314.38 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.68
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 131

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 155

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.2244650128404

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:59816
Log Contents:
2018-08-08 13:38:48,027 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,092 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,092 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,094 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,094 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,262 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,475 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,664 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:49,126 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,138 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,296 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,312 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,343 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,344 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,351 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,358 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,359 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 6 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,364 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,364 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave6
INFO    2018-08-08 13:38:49,364 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,364 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,364 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,365 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000009:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000009/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,365 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000009:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,365 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000009/tmp
INFO    2018-08-08 13:38:49,365 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,365 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,365 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,365 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,365 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,365 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,365 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000009
INFO    2018-08-08 13:38:49,366 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,379 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,380 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,386 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30031, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,387 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,503 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,520 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,566 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave6/10.164.0.8:30006 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,572 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,572 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,596 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,607 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,610 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,613 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,619 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave6_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=6, port=30006)
INFO    2018-08-08 13:38:49,850 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,944 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,954 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,957 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,960 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,960 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,961 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,965 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,969 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,973 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,976 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,976 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,979 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,979 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,979 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,979 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,980 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,980 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,986 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,987 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,987 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,987 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,989 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,991 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,052 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,091 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03063813 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,091 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031449366 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,091 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038648464 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,091 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03233953 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,092 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.029875033 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,094 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031006305 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,094 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03036993 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,095 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030101182 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,095 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.029450277 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,095 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028870596 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,095 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028633976 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,096 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0044, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.037
MBytes/sec sent = 0.0069, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.037
INFO    2018-08-08 13:38:50,097 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,102 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003682935 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003518996 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004217503 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001065533 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00353657 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00330999 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,107 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006482477 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,107 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003306982 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,108 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002491741 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,108 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00299197 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,109 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002325928 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,110 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0219, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.011
INFO    2018-08-08 13:38:50,110 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:38:50,169 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,173 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,182 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,184 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.90M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,184 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.002, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.085
MBytes/sec sent = 0.003, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.085
INFO    2018-08-08 13:38:50,184 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,192 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,193 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.90M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,204 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,240 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,245 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
WARN    2018-08-08 13:38:50,250 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:50,261 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,262 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,265 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave6_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=6, port=30006)
INFO    2018-08-08 13:38:50,304 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,304 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,304 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,306 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.113
MBytes/sec sent = 0.0123, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.113
INFO    2018-08-08 13:38:50,309 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,310 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,318 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,330 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007142149 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005676022 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006461737 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010719554 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00214868 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003507952 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004803596 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004076344 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,331 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010142813 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,332 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009221147 secs for 7 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,332 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003479268 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,334 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,336 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0092, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0263, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:38:50,336 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,343 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,344 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 3 , message bytes = 123 , Memory (free/total/max) = 50582.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,350 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,371 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,375 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 13:38:50,385 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,388 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave6_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=6, port=30006)
INFO    2018-08-08 13:38:50,413 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,413 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,413 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,414 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.07
MBytes/sec sent = 0.0198, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.07
INFO    2018-08-08 13:38:50,416 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,418 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,421 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,426 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003680947 secs for 8 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002782544 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00182168 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004311178 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005301458 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003584816 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002285606 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001788563 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001699626 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,430 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003552053 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,431 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002580878 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,431 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50441.29M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,431 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0092, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0263, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:38:50,431 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,438 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,439 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 3 , message bytes = 123 , Memory (free/total/max) = 50441.29M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,443 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,468 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,471 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 13:38:50,477 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,495 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave6_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=6, port=30006)
INFO    2018-08-08 13:38:50,506 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,553 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,580 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,581 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,581 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,582 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.143
MBytes/sec sent = 0.0098, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.143
INFO    2018-08-08 13:38:50,584 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,587 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,591 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,595 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003981214 secs for 18 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00233789 secs for 13 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001860948 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001627416 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,596 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001721267 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,596 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001442315 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002089609 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001066563 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,598 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001330422 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,600 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003889551 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,600 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002200125 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,600 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,600 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:38:50,600 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,608 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,608 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,611 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,635 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,639 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 13:38:50,643 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,643 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,643 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,645 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,666 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,711 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,716 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,719 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:53,050 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:53,050 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:38:53,054 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:53,266 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:53,267 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:53,269 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/6_worker
INFO    2018-08-08 13:38:53,270 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30031 closed
INFO    2018-08-08 13:38:53,271 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:53,273 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:53,277 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,490 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,493 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000006_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:57,515 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000006_0 is allowed to commit now
INFO    2018-08-08 13:38:57,524 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000006_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000006
INFO    2018-08-08 13:38:57,540 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000006_0' done.
INFO    2018-08-08 13:38:57,544 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000006_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129327
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=22
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=96
		CPU time spent (ms)=4810
		Physical memory (bytes) snapshot=1124872192
		Virtual memory (bytes) snapshot=58912935936
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000012 on graphalytics-giraph-slave7_43383
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15683
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 666 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 303 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 10,026.00
               min = 16.00
               max = 6653.00
              mean = 126.91
            stddev = 745.10
            median = 25.00
              75% <= 53.00
              95% <= 100.00
              98% <= 2865.80
              99% <= 6653.00
            99.9% <= 6653.00
             count = 79

  remote-requests:
    count = 0

  requests-received:
             count = 79
         mean rate = 115.99 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 144.14 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,580.00
               min = 16.00
               max = 1473.00
              mean = 46.73
            stddev = 147.73
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 666

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 303

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 85 ms
  compute all partitions: 14 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 2295 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 14

  compute-per-partition-ms:
               sum = 36.00
               min = 0.00
               max = 8.00
              mean = 1.09
            stddev = 1.70
            median = 1.00
              75% <= 1.50
              95% <= 5.90
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 36.00
               min = 0.00
               max = 8.00
              mean = 3.27
            stddev = 2.69
            median = 4.00
              75% <= 5.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 9,133.00
               min = 16.00
               max = 6653.00
              mean = 169.13
            stddev = 900.38
            median = 31.00
              75% <= 62.00
              95% <= 152.00
              98% <= 6021.80
              99% <= 6653.00
            99.9% <= 6653.00
             count = 54

  remote-requests:
    count = 1

  requests-received:
             count = 54
         mean rate = 443.25 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 55
         mean rate = 449.76 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,724.00
               min = 16.00
               max = 1473.00
              mean = 67.71
            stddev = 195.33
            median = 16.00
              75% <= 81.00
              95% <= 89.00
              98% <= 1306.92
              99% <= 1473.00
            99.9% <= 1473.00
             count = 55

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 85

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 2295

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 57 ms
  compute all partitions: 13 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 168 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 13

  compute-per-partition-ms:
               sum = 6.00
               min = 0.00
               max = 2.00
              mean = 0.18
            stddev = 0.46
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 6.00
               min = 0.00
               max = 3.00
              mean = 0.55
            stddev = 1.21
            median = 0.00
              75% <= 0.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 9,133.00
               min = 16.00
               max = 6653.00
              mean = 169.13
            stddev = 900.38
            median = 31.00
              75% <= 62.00
              95% <= 152.00
              98% <= 6021.80
              99% <= 6653.00
            99.9% <= 6653.00
             count = 54

  remote-requests:
    count = 1

  requests-received:
             count = 54
         mean rate = 591.38 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 55
         mean rate = 602.23 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,724.00
               min = 16.00
               max = 1473.00
              mean = 67.71
            stddev = 195.38
            median = 16.00
              75% <= 81.00
              95% <= 89.00
              98% <= 1306.92
              99% <= 1473.00
            99.9% <= 1473.00
             count = 55

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 57

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 168

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 131 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 221 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6564.00
              mean = 173.56
            stddev = 905.01
            median = 34.50
              75% <= 89.00
              95% <= 177.20
              98% <= 6190.62
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 316.97 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 316.95 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.69
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 131

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 221

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.25459990304171

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:59809
Log Contents:
2018-08-08 13:38:47,973 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,041 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,041 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,044 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,044 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,221 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,447 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,643 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:49,103 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,115 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,265 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,279 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,308 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,309 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,316 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,323 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,323 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 9 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,329 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,329 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave7
INFO    2018-08-08 13:38:49,329 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,329 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,329 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,329 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000012:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000012/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,330 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000012:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,330 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000012/tmp
INFO    2018-08-08 13:38:49,330 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,330 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,330 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,330 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,330 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,330 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,330 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000012
INFO    2018-08-08 13:38:49,330 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,343 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,344 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,350 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3002f, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,351 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,464 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,481 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,540 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave7/10.164.0.9:30009 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,545 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,546 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,567 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,577 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,580 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,582 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,591 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave7_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=9, port=30009)
INFO    2018-08-08 13:38:49,848 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,940 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,949 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,951 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,953 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,956 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,957 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,958 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,960 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,960 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,961 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,961 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,965 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,965 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,972 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,972 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,973 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,973 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,974 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,977 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,978 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,041 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,087 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03864329 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,087 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0454144 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,087 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03802863 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,088 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03658103 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,087 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03737615 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037999295 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03751441 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037312295 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,091 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036954336 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,091 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036307745 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,091 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.035676327 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,092 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0039, MBytesReceived = 0.0002, ave received req MBytes = 0.0001, secs waited = 0.043
MBytes/sec sent = 0.006, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.043
INFO    2018-08-08 13:38:50,093 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,098 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004279598 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,099 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003761968 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,099 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003242793 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004286432 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004067535 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003884597 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004306538 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003478984 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.93604E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002908277 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005077871 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0092, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0143, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:38:50,106 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:38:50,165 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,169 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,178 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,180 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50738.75M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,180 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0006, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.078
MBytes/sec sent = 0.0009, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.078
INFO    2018-08-08 13:38:50,180 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,188 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,189 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.75M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,201 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,237 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,241 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
WARN    2018-08-08 13:38:50,247 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:50,259 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,260 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,263 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave7_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=9, port=30009)
INFO    2018-08-08 13:38:50,300 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,300 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,300 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,301 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.112
MBytes/sec sent = 0.0124, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.112
INFO    2018-08-08 13:38:50,304 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,307 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,315 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,326 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005685579 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003766392 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003618867 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002059839 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001833334 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005828883 secs for 8 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,327 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010126519 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007879267 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004027664 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006226951 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,329 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010091783 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,330 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50597.95M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,332 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.011, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:38:50,332 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,340 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,341 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50597.95M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,346 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,368 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,370 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 13:38:50,381 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,385 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave7_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=9, port=30009)
INFO    2018-08-08 13:38:50,409 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,409 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,409 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,411 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.07
MBytes/sec sent = 0.0198, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.07
INFO    2018-08-08 13:38:50,414 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,415 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,418 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,424 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003644164 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001970868 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004489514 secs for 9 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006189122 secs for 21 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002936616 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00208991 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001764019 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00250003 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001974265 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001404453 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,431 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002998521 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,431 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50457.14M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,432 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0019, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.008
MBytes/sec sent = 0.0049, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.008
INFO    2018-08-08 13:38:50,432 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,437 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0331, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.1095, MBytesSent = 0.0007, ave sent req MBytes = 0.0001, secs waited = 0.005
INFO    2018-08-08 13:38:50,438 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50457.14M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,441 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,464 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,467 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 13:38:50,475 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,494 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave7_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=9, port=30009)
INFO    2018-08-08 13:38:50,502 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,550 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,577 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,577 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,577 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,578 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.14
MBytes/sec sent = 0.01, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.14
INFO    2018-08-08 13:38:50,580 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,583 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,587 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,591 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00228064 secs for 13 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003230033 secs for 17 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001852837 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00182317 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,592 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001891547 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,592 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001841574 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001696578 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,594 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001764845 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002788348 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,596 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002387564 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002707224 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50303.54M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,597 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:38:50,597 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,606 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,607 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50303.54M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,609 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,631 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,634 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 13:38:50,639 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,640 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,640 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,641 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,663 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,708 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,713 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,716 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:52,947 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:52,947 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:38:52,951 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:53,142 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:53,142 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:53,144 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/9_worker
INFO    2018-08-08 13:38:53,145 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3002f closed
INFO    2018-08-08 13:38:53,145 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:53,147 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:53,151 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,365 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,369 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000009_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:57,396 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000009_0 is allowed to commit now
INFO    2018-08-08 13:38:57,407 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000009_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000009
INFO    2018-08-08 13:38:57,429 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000009_0' done.
INFO    2018-08-08 13:38:57,434 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000009_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129327
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=22
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=92
		CPU time spent (ms)=4570
		Physical memory (bytes) snapshot=1082068992
		Virtual memory (bytes) snapshot=58906316800
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000005 on graphalytics-giraph-slave8_41519
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15679
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 828 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 296 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 10,042.00
               min = 16.00
               max = 6653.00
              mean = 120.99
            stddev = 726.96
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2360.84
              99% <= 6653.00
            99.9% <= 6653.00
             count = 83

  remote-requests:
    count = 0

  requests-received:
             count = 83
         mean rate = 98.68 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 116.65 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,580.00
               min = 16.00
               max = 1473.00
              mean = 46.73
            stddev = 147.68
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 828

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 296

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 88 ms
  compute all partitions: 12 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 3980 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 12

  compute-per-partition-ms:
               sum = 34.00
               min = 0.00
               max = 5.00
              mean = 1.03
            stddev = 1.19
            median = 1.00
              75% <= 2.00
              95% <= 3.60
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 82

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 33.00
               min = 1.00
               max = 5.00
              mean = 3.00
            stddev = 1.49
            median = 3.00
              75% <= 4.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 9,149.00
               min = 16.00
               max = 6564.00
              mean = 163.38
            stddev = 891.53
            median = 31.00
              75% <= 80.00
              95% <= 126.80
              98% <= 5692.78
              99% <= 6564.00
            99.9% <= 6564.00
             count = 56

  remote-requests:
    count = 2

  requests-received:
             count = 56
         mean rate = 458.14 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 457.93 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,770.00
               min = 16.00
               max = 1473.00
              mean = 67.32
            stddev = 193.63
            median = 20.50
              75% <= 74.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 88

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 3980

  worker-context-post-superstep:
    value = 5

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 57 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 160 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.15
            stddev = 0.44
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 82

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 3.00
              mean = 0.45
            stddev = 1.04
            median = 0.00
              75% <= 0.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 9,149.00
               min = 16.00
               max = 6564.00
              mean = 163.38
            stddev = 872.36
            median = 31.00
              75% <= 80.00
              95% <= 126.80
              98% <= 5692.78
              99% <= 6564.00
            99.9% <= 6564.00
             count = 56

  remote-requests:
    count = 2

  requests-received:
             count = 56
         mean rate = 601.76 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 601.59 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,770.00
               min = 16.00
               max = 1473.00
              mean = 67.32
            stddev = 193.57
            median = 20.50
              75% <= 74.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 57

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 160

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 132 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 182 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6564.00
              mean = 173.56
            stddev = 908.67
            median = 34.50
              75% <= 89.00
              95% <= 177.20
              98% <= 6190.62
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 313.99 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 313.94 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.68
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 132

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 182

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.22427688839952

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:60014
Log Contents:
2018-08-08 13:38:47,952 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,012 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,012 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,014 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,014 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,174 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,376 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,554 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:48,992 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,003 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,144 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,158 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,184 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,184 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,191 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,197 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,197 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 2 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave8
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000005:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000005/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000005:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000005/tmp
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,203 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000005
INFO    2018-08-08 13:38:49,204 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,216 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,217 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,223 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3002b, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,224 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,324 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,339 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,383 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave8/10.164.0.10:30002 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,387 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,388 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,407 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,416 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,420 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,423 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
WARN    2018-08-08 13:38:49,427 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:49,429 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave8_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=2, port=30002)
INFO    2018-08-08 13:38:49,846 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,941 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,949 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,951 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,952 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,953 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,953 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,954 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,954 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,954 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,954 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,955 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,956 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,957 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,957 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,957 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,957 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,958 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,959 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,961 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,962 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,967 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,971 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,971 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,972 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,039 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,086 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040039174 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,086 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038899705 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,086 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046600837 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,086 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039393134 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,087 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03920081 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,087 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038936928 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,087 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03851828 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,088 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038185216 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04034808 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,091 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04068216 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,092 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040258337 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,093 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0036, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.046
MBytes/sec sent = 0.0056, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.047
INFO    2018-08-08 13:38:50,094 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,099 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005263072 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005651146 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005132602 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,101 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004828999 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004650737 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,102 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004435283 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006974145 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006597738 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006301834 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005775067 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005355712 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,107 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0129, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0202, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.012
INFO    2018-08-08 13:38:50,107 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:38:50,166 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,171 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,178 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,179 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,180 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.002, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.085
MBytes/sec sent = 0.003, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.085
INFO    2018-08-08 13:38:50,180 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,189 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,190 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,199 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,238 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,242 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
INFO    2018-08-08 13:38:50,258 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,258 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,260 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave8_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=2, port=30002)
INFO    2018-08-08 13:38:50,300 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,301 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,301 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,302 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.112
MBytes/sec sent = 0.0124, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.112
INFO    2018-08-08 13:38:50,304 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,307 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,307 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:38:50,316 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,325 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006331341 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,325 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003689637 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,325 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00577733 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00469699 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002315348 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001982653 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003535877 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005472644 secs for 7 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002791128 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007767617 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,326 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008993217 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,329 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50569.20M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,333 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0146, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:38:50,333 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,341 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,342 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 2 , message bytes = 82 , Memory (free/total/max) = 50569.20M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,345 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,369 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,370 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 13:38:50,379 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,381 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave8_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=2, port=30002)
INFO    2018-08-08 13:38:50,410 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,410 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,410 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,411 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.069
MBytes/sec sent = 0.0201, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.069
INFO    2018-08-08 13:38:50,413 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,415 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,419 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,423 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002822223 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,423 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003938647 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,424 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003673923 secs for 25 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,425 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003888559 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,425 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004350284 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004811776 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003984569 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004126015 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003409535 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003006885 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005594881 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50428.39M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,429 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0146, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:38:50,429 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,436 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,436 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 2 , message bytes = 82 , Memory (free/total/max) = 50428.39M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,438 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,466 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,468 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 13:38:50,473 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,490 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave8_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=2, port=30002)
WARN    2018-08-08 13:38:50,551 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,578 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,578 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,578 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,579 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.143
MBytes/sec sent = 0.0098, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.143
INFO    2018-08-08 13:38:50,581 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,582 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,585 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:38:50,588 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,591 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003423048 secs for 20 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001512713 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,591 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002397773 secs for 11 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,592 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002088087 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,592 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001483705 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,592 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001206088 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001195227 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,593 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001374091 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,594 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 8.83311E-4 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,594 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001641141 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001937333 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,596 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0166, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0849, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.011
INFO    2018-08-08 13:38:50,596 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,605 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,606 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,608 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,633 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,635 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 13:38:50,639 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,639 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,639 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,642 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,664 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,709 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,714 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,716 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:52,946 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:52,946 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:38:52,949 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:53,148 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:53,148 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:53,149 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/2_worker
INFO    2018-08-08 13:38:53,151 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3002b closed
INFO    2018-08-08 13:38:53,151 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:53,154 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:53,157 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,369 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,373 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000002_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:57,397 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000002_0 is allowed to commit now
INFO    2018-08-08 13:38:57,407 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000002_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000002
INFO    2018-08-08 13:38:57,431 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000002_0' done.
INFO    2018-08-08 13:38:57,438 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000002_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129327
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=22
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=90
		CPU time spent (ms)=4180
		Physical memory (bytes) snapshot=1099206656
		Virtual memory (bytes) snapshot=58912411648
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0004_01_000006 on graphalytics-giraph-slave9_37771
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:15689
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 672 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 350 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 12.5

  received-bytes:
               sum = 10,287.00
               min = 16.00
               max = 6653.00
              mean = 116.90
            stddev = 706.41
            median = 16.00
              75% <= 53.00
              95% <= 138.75
              98% <= 1729.64
              99% <= 6653.00
            99.9% <= 6653.00
             count = 88

  remote-requests:
    count = 7

  requests-received:
             count = 88
         mean rate = 128.32 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 106
         mean rate = 154.88 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 5,032.00
               min = 16.00
               max = 1473.00
              mean = 47.47
            stddev = 142.07
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 92.44
              99% <= 1376.40
            99.9% <= 1473.00
             count = 106

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 672

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 8

  wait-requests-us:
    value = 350

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 86 ms
  compute all partitions: 14 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 7184 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 14

  compute-per-partition-ms:
               sum = 42.00
               min = 0.00
               max = 6.00
              mean = 1.27
            stddev = 1.31
            median = 1.00
              75% <= 2.00
              95% <= 4.60
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 123

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 42.00
               min = 1.00
               max = 6.00
              mean = 3.82
            stddev = 2.08
            median = 4.00
              75% <= 6.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 9,073.00
               min = 16.00
               max = 6564.00
              mean = 164.96
            stddev = 880.29
            median = 16.00
              75% <= 89.00
              95% <= 139.40
              98% <= 5817.24
              99% <= 6564.00
            99.9% <= 6564.00
             count = 55

  remote-requests:
    count = 3

  requests-received:
             count = 55
         mean rate = 450.53 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 55
         mean rate = 450.48 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,784.00
               min = 16.00
               max = 1473.00
              mean = 68.80
            stddev = 195.10
            median = 46.00
              75% <= 81.00
              95% <= 89.00
              98% <= 1306.92
              99% <= 1473.00
            99.9% <= 1473.00
             count = 55

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 86

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 7184

  worker-context-post-superstep:
    value = 10

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 56 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 204 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 6.00
               min = 0.00
               max = 2.00
              mean = 0.18
            stddev = 0.46
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 123

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 6.00
               min = 0.00
               max = 2.00
              mean = 0.55
            stddev = 0.93
            median = 0.00
              75% <= 2.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 9,073.00
               min = 16.00
               max = 6653.00
              mean = 168.02
            stddev = 900.88
            median = 16.00
              75% <= 62.00
              95% <= 152.00
              98% <= 6021.80
              99% <= 6653.00
            99.9% <= 6653.00
             count = 54

  remote-requests:
    count = 3

  requests-received:
             count = 54
         mean rate = 579.88 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 55
         mean rate = 590.38 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,784.00
               min = 16.00
               max = 1473.00
              mean = 68.80
            stddev = 195.26
            median = 46.00
              75% <= 81.00
              95% <= 89.00
              98% <= 1306.92
              99% <= 1473.00
            99.9% <= 1473.00
             count = 55

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 56

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 204

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 130 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 163 us

8/8/18 1:38:50 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 9,025.00
               min = 16.00
               max = 6564.00
              mean = 173.56
            stddev = 905.02
            median = 34.50
              75% <= 89.00
              95% <= 177.20
              98% <= 6190.62
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 316.83 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 315.80 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,646.00
               min = 16.00
               max = 1473.00
              mean = 70.12
            stddev = 200.68
            median = 20.50
              75% <= 87.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 130

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 163

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.22444073591208

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:38:53 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = 0.0

  edges-loaded:
             count = 17
         mean rate = 4.44 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:39:07 +0000 2018
LogLength:60201
Log Contents:
2018-08-08 13:38:48,017 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:38:48,084 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:38:48,084 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:38:48,086 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:38:48,086 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:38:48,257 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:38:48,491 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004
2018-08-08 13:38:48,679 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:38:49,131 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:38:49,143 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:38:49,284 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:38:49,298 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:38:49,325 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:38:49,326 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:38:49,333 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:38:49,339 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0004/_haltComputation
INFO    2018-08-08 13:38:49,339 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0004, 3 on graphalytics-giraph:2181
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave9
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000006:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000006/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000006:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000006/tmp
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:38:49,345 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0004/container_1533735211869_0004_01_000006
INFO    2018-08-08 13:38:49,346 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@4eeea57d
INFO    2018-08-08 13:38:49,359 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:38:49,359 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:38:49,365 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30030, negotiated timeout = 40000
INFO    2018-08-08 13:38:49,367 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:38:49,474 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:38:49,491 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:38:49,539 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave9/10.164.0.11:30003 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:38:49,544 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:38:49,545 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:38:49,564 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:38:49,574 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:49,577 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,580 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:38:49,588 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave9_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=3, port=30003)
INFO    2018-08-08 13:38:49,848 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,941 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373542E9
INFO    2018-08-08 13:38:49,952 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:49,953 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:49,956 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,956 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,957 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,958 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,960 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,960 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,960 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,961 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,961 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,963 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:38:49,964 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,966 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:49,967 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,968 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,969 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,975 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,975 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,976 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,976 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:49,976 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:38:50,041 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,090 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047653385 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04055457 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041236714 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038554087 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037923854 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039861847 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,090 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037101146 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,091 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036797065 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,091 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036610916 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,091 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036159977 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,092 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03557688 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,094 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0036, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.045
MBytes/sec sent = 0.0057, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.045
INFO    2018-08-08 13:38:50,095 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:38:50,102 [load-0] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/example-directed.e:0+70'
INFO    2018-08-08 13:38:50,102 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005901764 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005350345 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,103 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00489414 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004942463 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004504241 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,104 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003974245 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004092004 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,105 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002920385 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,106 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005128014 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,108 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003307846 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:38:50,128 [load-0] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=0, e=17)
INFO    2018-08-08 13:38:50,132 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 0.03615445 secs, (v=0, e=17) 0.0 vertices/sec, 470.20493 edges/sec
INFO    2018-08-08 13:38:50,154 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0046, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.022
MBytes/sec sent = 0.0177, MBytesSent = 0.0004, ave sent req MBytes = 0.0001, secs waited = 0.022
INFO    2018-08-08 13:38:50,154 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=17)
INFO    2018-08-08 13:38:50,168 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:38:50,171 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,178 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:38:50,180 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,181 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0021, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.049
MBytes/sec sent = 0.0081, MBytesSent = 0.0004, ave sent req MBytes = 0.0001, secs waited = 0.049
INFO    2018-08-08 13:38:50,181 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,190 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,191 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,203 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:38:50,239 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,244 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
WARN    2018-08-08 13:38:50,249 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:38:50,261 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,262 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,264 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave9_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=3, port=30003)
INFO    2018-08-08 13:38:50,302 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,302 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,303 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,304 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.113
MBytes/sec sent = 0.0123, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.113
INFO    2018-08-08 13:38:50,307 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,309 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,317 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:38:50,328 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007211332 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00420765 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005217655 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004648139 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008610344 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005953512 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007907716 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,329 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003797441 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002665124 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,329 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006789191 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,328 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010040749 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,332 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,339 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0046, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.009
MBytes/sec sent = 0.0132, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.009
INFO    2018-08-08 13:38:50,339 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,343 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,343 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 3 , message bytes = 123 , Memory (free/total/max) = 50582.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,349 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:38:50,370 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,372 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 13:38:50,382 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,384 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave9_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=3, port=30003)
INFO    2018-08-08 13:38:50,411 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,412 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,412 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,413 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.07
MBytes/sec sent = 0.0198, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.07
INFO    2018-08-08 13:38:50,416 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,417 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,420 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:38:50,425 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003112207 secs for 16 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,425 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004009518 secs for 9 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,425 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002287992 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003416109 secs for 8 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,426 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001902277 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00344791 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,427 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001813238 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,428 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003153314 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,429 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002818495 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,430 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003184649 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,430 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003716614 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,431 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,431 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0065, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0188, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 13:38:50,431 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,438 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:38:50,438 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 3 , message bytes = 123 , Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,443 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:38:50,467 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,470 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 13:38:50,477 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.DoubleWritable and no combiner
INFO    2018-08-08 13:38:50,494 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave9_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=3, port=30003)
INFO    2018-08-08 13:38:50,505 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,552 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,579 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave10, MRtaskID=0, port=30000)
INFO    2018-08-08 13:38:50,580 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:38:50,580 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:38:50,581 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.143
MBytes/sec sent = 0.0098, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.143
INFO    2018-08-08 13:38:50,583 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:38:50,586 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:38:50,589 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:38:50,594 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001553465 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00145808 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,594 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002323619 secs for 10 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,594 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004149423 secs for 22 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,595 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001538496 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,596 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001326917 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001896923 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001515115 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,597 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001469363 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,599 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002508584 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,601 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002575649 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:38:50,601 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.67M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,602 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0114, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.015
MBytes/sec sent = 0.0637, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.015
INFO    2018-08-08 13:38:50,602 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:38:50,607 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:38:50,608 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.67M / 52608.00M / 52608.00M
INFO    2018-08-08 13:38:50,611 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:38:50,634 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:38:50,637 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=10,edges=17,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.pr.PageRankComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 13:38:50,641 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:38:50,641 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:38:50,641 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:38:50,644 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:38:50,665 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:38:50,710 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0004/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:38:50,715 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:38:50,718 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0004/_masterJobState)
INFO    2018-08-08 13:38:52,948 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:38:52,948 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:38:52,951 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:38:53,136 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:38:53,136 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:38:53,138 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0004/_cleanedUpDir/3_worker
INFO    2018-08-08 13:38:53,140 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30030 closed
INFO    2018-08-08 13:38:53,140 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:38:53,142 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:38:53,145 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:38:57,358 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:38:57,362 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0004_m_000003_0 is done. And is in the process of committing
INFO    2018-08-08 13:38:57,385 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0004_m_000003_0 is allowed to commit now
INFO    2018-08-08 13:38:57,394 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0004_m_000003_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r742250_PR-example-directed/_temporary/1/task_1533735211869_0004_m_000003
INFO    2018-08-08 13:38:57,415 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0004_m_000003_0' done.
INFO    2018-08-08 13:38:57,419 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0004_m_000003_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=129327
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=114
		HDFS: Number of bytes written=22
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=92
		CPU time spent (ms)=4440
		Physical memory (bytes) snapshot=1101160448
		Virtual memory (bytes) snapshot=58904743936
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0004=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0004/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog

