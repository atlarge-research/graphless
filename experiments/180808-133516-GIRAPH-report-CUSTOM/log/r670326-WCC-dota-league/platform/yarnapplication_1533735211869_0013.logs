

Container: container_1533735211869_0013_01_000015 on graphalytics-giraph-slave10_46663
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:19964
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10569 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 321 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 124,759,024.00
               min = 16.00
               max = 239744.00
              mean = 142418.98
            stddev = 66103.24
            median = 159261.00
              75% <= 182656.00
              95% <= 235776.00
              98% <= 238976.00
              99% <= 238976.00
            99.9% <= 239744.00
             count = 876

  remote-requests:
    count = 0

  requests-received:
             count = 876
         mean rate = 82.76 requests/s
     1-minute rate = 75.11 requests/s
     5-minute rate = 73.75 requests/s
    15-minute rate = 73.52 requests/s

  requests-sent:
             count = 338
         mean rate = 31.94 requests/s
     1-minute rate = 31.64 requests/s
     5-minute rate = 31.77 requests/s
    15-minute rate = 31.79 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 8,392.00
               min = 16.00
               max = 1473.00
              mean = 24.83
            stddev = 80.41
            median = 16.00
              75% <= 16.00
              95% <= 53.00
              98% <= 89.00
              99% <= 89.00
            99.9% <= 1473.00
             count = 338

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 10569

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 321

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1427 ms
  compute all partitions: 974 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 988 ms
  time to first message: 359292 us
  wait on requests time: 372582 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 988

  compute-all-ms:
    value = 974

  compute-per-partition-ms:
               sum = 5,876.00
               min = 16.00
               max = 544.00
              mean = 178.06
            stddev = 148.27
            median = 232.00
              75% <= 287.50
              95% <= 476.10
              98% <= 544.00
              99% <= 544.00
            99.9% <= 544.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 62977475

  messages-sent:
    count = 7783187

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6158940397351

  processing-per-thread-ms:
               sum = 5,875.00
               min = 322.00
               max = 864.00
              mean = 534.09
            stddev = 183.68
            median = 535.00
              75% <= 647.00
              95% <= 864.00
              98% <= 864.00
              99% <= 864.00
            99.9% <= 864.00
             count = 11

  received-bytes:
               sum = 58,168,632.00
               min = 16.00
               max = 394112.00
              mean = 85041.86
            stddev = 103456.23
            median = 26752.00
              75% <= 158368.00
              95% <= 296384.00
              98% <= 337446.40
              99% <= 365100.80
            99.9% <= 394112.00
             count = 684

  remote-requests:
    count = 279

  requests-received:
             count = 684
         mean rate = 468.37 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 602
         mean rate = 412.21 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 58,162,474.00
               min = 16.00
               max = 528765.00
              mean = 96615.41
            stddev = 183712.01
            median = 53.00
              75% <= 532.50
              95% <= 485443.00
              98% <= 524536.04
              99% <= 525487.08
            99.9% <= 528765.00
             count = 602

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 1427

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 1568

  time-to-first-message-ms:
    value = 359292

  total-requests:
    value = 302

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 372582

  worker-context-post-superstep:
    value = 10

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 651 ms
  compute all partitions: 291 ms
  time spent in gc: 84 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 299096 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 291

  compute-per-partition-ms:
               sum = 1,921.00
               min = 11.00
               max = 136.00
              mean = 58.21
            stddev = 49.63
            median = 36.00
              75% <= 122.50
              95% <= 134.60
              98% <= 136.00
              99% <= 136.00
            99.9% <= 136.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 61870875

  messages-sent:
    count = 7644827

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 1,921.00
               min = 148.00
               max = 191.00
              mean = 174.64
            stddev = 13.46
            median = 172.00
              75% <= 189.00
              95% <= 191.00
              98% <= 191.00
              99% <= 191.00
            99.9% <= 191.00
             count = 11

  received-bytes:
               sum = 56,690,725.00
               min = 16.00
               max = 389888.00
              mean = 85765.09
            stddev = 97111.66
            median = 53120.00
              75% <= 155424.00
              95% <= 259916.80
              98% <= 319969.28
              99% <= 334044.16
            99.9% <= 389888.00
             count = 661

  remote-requests:
    count = 264

  requests-received:
             count = 661
         mean rate = 969.80 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 589
         mean rate = 864.15 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 57,140,462.00
               min = 16.00
               max = 505693.00
              mean = 97012.67
            stddev = 180878.74
            median = 16.00
              75% <= 492.00
              95% <= 450973.00
              98% <= 473523.40
              99% <= 484919.00
            99.9% <= 505693.00
             count = 589

  superstep-gc-time-ms:
    count = 84

  superstep-time-ms:
    value = 651

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 404

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 286

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 299096

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 196 ms
  compute all partitions: 33 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 49327 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 33

  compute-per-partition-ms:
               sum = 160.00
               min = 1.00
               max = 20.00
              mean = 4.85
            stddev = 4.65
            median = 3.00
              75% <= 5.50
              95% <= 17.90
              98% <= 20.00
              99% <= 20.00
            99.9% <= 20.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 151710

  messages-sent:
    count = 11921

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 154.00
               min = 5.00
               max = 27.00
              mean = 14.00
            stddev = 6.54
            median = 14.00
              75% <= 19.00
              95% <= 27.00
              98% <= 27.00
              99% <= 27.00
            99.9% <= 27.00
             count = 11

  received-bytes:
               sum = 158,774.00
               min = 16.00
               max = 11414.00
              mean = 601.42
            stddev = 1538.48
            median = 32.00
              75% <= 108.00
              95% <= 4045.50
              98% <= 6390.50
              99% <= 7742.30
            99.9% <= 11414.00
             count = 264

  remote-requests:
    count = 264

  requests-received:
             count = 264
         mean rate = 1159.55 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 548
         mean rate = 2406.53 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 149,177.00
               min = 16.00
               max = 1761.00
              mean = 272.22
            stddev = 372.29
            median = 89.00
              75% <= 365.25
              95% <= 1113.40
              98% <= 1341.16
              99% <= 1505.40
            99.9% <= 1761.00
             count = 548

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 196

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 4

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 286

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 49327

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 106 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 226 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 37.00
               min = 0.00
               max = 3.00
              mean = 1.12
            stddev = 0.60
            median = 1.00
              75% <= 1.00
              95% <= 2.30
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 37.00
               min = 0.00
               max = 6.00
              mean = 3.36
            stddev = 1.80
            median = 4.00
              75% <= 5.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.16
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 382.84 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 390.19 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.70
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 106

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 226

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 97.17928696142786

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:68344
Log Contents:
2018-08-08 13:58:00,380 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,444 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,444 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,446 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,446 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,619 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:00,847 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:01,022 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,444 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,456 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,606 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,621 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,651 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,652 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,660 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,667 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,667 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 13 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,672 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave10
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000015:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000015/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000015:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000015/tmp
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,673 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000015
INFO    2018-08-08 13:58:01,674 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,687 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,687 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,693 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300ac, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,694 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:01,804 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:01,822 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:01,883 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave10/10.164.0.12:30013 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:01,888 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:01,889 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:01,911 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:01,920 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:01,924 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:01,927 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:01,933 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave10_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=13, port=30013)
INFO    2018-08-08 13:58:02,304 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,389 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,396 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,398 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,399 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,400 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,401 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,401 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,401 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,402 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,403 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,403 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,403 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,403 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,404 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,404 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,404 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,406 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,406 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,408 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,418 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,418 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,422 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,428 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,496 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,547 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050738852 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,547 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044712774 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,548 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044207893 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,548 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043136217 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,548 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042549282 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,550 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0441229 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,551 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044033974 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,551 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043530185 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043168567 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043712623 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042799063 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0025, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.14
MBytes/sec sent = 0.0091, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.141
INFO    2018-08-08 13:58:02,553 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,557 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002893562 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,557 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002072179 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,559 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003100179 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,560 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004066465 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,562 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004839635 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,562 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004487945 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,562 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004328427 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,562 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003953065 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,563 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004213838 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,563 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003892426 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,564 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00400959 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0238, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.01
INFO    2018-08-08 13:58:02,565 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:58:12,355 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,359 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,399 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,403 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50197.27M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,403 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 9.848
MBytes/sec sent = 0, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 9.848
INFO    2018-08-08 13:58:12,404 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,412 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 9 more tasks to send their aggregator data, task ids: [1, 2, 3, 5, 6, 7, 9, 10, 11]
INFO    2018-08-08 13:58:12,435 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:58:12,435 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50197.27M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,446 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,482 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,488 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@39ab59f8,outgoing=org.apache.giraph.conf.DefaultMessageClasses@64e92d61)
WARN    2018-08-08 13:58:12,492 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,508 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,509 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,512 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave10_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=13, port=30013)
INFO    2018-08-08 13:58:12,563 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,563 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,563 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,564 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.129
MBytes/sec sent = 0.0108, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.129
INFO    2018-08-08 13:58:12,567 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,568 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,574 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 2 more tasks to send their aggregator data, task ids: [10, 12]
INFO    2018-08-08 13:58:12,580 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,921 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.33734426 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.33 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,927 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.32668743 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.32 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,936 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.34508076 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.34 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,975 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.375956 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.37 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,104 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.50557 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.50 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,134 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.53768706 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.54 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,163 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.5643023 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.56 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,229 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.6443296 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.64 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,237 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.6547418 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.65 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,363 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.76866287 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.77 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,453 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.86884594 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.86 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,555 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 49472.61M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,928 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0042, MBytesReceived = 0.0043, ave received req MBytes = 0, secs waited = 1.004
MBytes/sec sent = 55.1846, MBytesSent = 55.4605, ave sent req MBytes = 0.1988, secs waited = 1.004
INFO    2018-08-08 13:58:13,928 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,930 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0661, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.2101, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:13,931 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 7783187 , message bytes = 62977475 , Memory (free/total/max) = 49472.61M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,934 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,957 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,959 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@127d7908,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6b9c69a9)
INFO    2018-08-08 13:58:13,968 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,970 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave10_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=13, port=30013)
INFO    2018-08-08 13:58:13,994 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,994 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,994 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,995 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.064
MBytes/sec sent = 0.0216, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.064
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:13,998 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,000 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,155 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.15122302 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.15 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,167 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16554022 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.16 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,171 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16889101 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.16 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,174 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17344694 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,177 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17381921 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,182 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17386541 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,190 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18185969 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,192 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18553023 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,195 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.19345057 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,197 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.19423656 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,198 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.19119297 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,292 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 48843.06M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,443 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 84ms
INFO    2018-08-08 13:58:14,591 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0093, MBytesReceived = 0.004, ave received req MBytes = 0, secs waited = 0.433
MBytes/sec sent = 125.5433, MBytesSent = 54.4858, ave sent req MBytes = 0.2064, secs waited = 0.433
INFO    2018-08-08 13:58:14,591 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,619 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,619 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7644827 , message bytes = 61870875 , Memory (free/total/max) = 51641.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,623 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,642 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,645 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4bd2f0dc,outgoing=org.apache.giraph.conf.DefaultMessageClasses@2e647e59)
INFO    2018-08-08 13:58:14,653 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,668 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave10_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=13, port=30013)
INFO    2018-08-08 13:58:14,672 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,706 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,728 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,728 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,728 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.11
MBytes/sec sent = 0.0127, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.11
INFO    2018-08-08 13:58:14,731 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,733 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,745 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008502699 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,746 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005833141 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,748 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013970158 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,750 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010128272 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,751 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012643835 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,754 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01659279 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,754 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017707536 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,758 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015418599 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,758 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.023179332 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,761 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.026186949 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,764 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.028050512 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.03 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,767 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 51550.16M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,816 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0567, MBytesReceived = 0.004, ave received req MBytes = 0, secs waited = 0.07
MBytes/sec sent = 1.9053, MBytesSent = 0.1353, ave sent req MBytes = 0.0005, secs waited = 0.07
INFO    2018-08-08 13:58:14,816 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,848 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,848 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 11921 , message bytes = 151710 , Memory (free/total/max) = 51550.16M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,854 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,873 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,876 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:58:14,882 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,896 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave10_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=13, port=30013)
INFO    2018-08-08 13:58:14,903 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,938 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,962 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,963 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,963 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.116
MBytes/sec sent = 0.012, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.116
INFO    2018-08-08 13:58:14,968 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,969 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,971 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,978 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00300329 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,978 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006412842 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004595515 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001872103 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005879933 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00444174 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005477216 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00651805 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008139853 secs for 7 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003396433 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004312899 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 51426.73M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,981 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0166, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0926, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.011
INFO    2018-08-08 13:58:14,981 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,988 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,988 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 51426.73M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,993 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,009 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,012 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:58:15,015 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,015 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,015 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,024 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,038 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,076 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,080 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,083 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,328 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,328 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4675 vertices using 1 threads
INFO    2018-08-08 13:58:17,332 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,583 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,583 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,586 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/13_worker
INFO    2018-08-08 13:58:17,592 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300ac closed
INFO    2018-08-08 13:58:17,592 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,594 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,598 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,809 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,812 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000013_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,843 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000013_0 is allowed to commit now
INFO    2018-08-08 13:58:21,852 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000013_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000013
INFO    2018-08-08 13:58:21,875 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000013_0' done.
INFO    2018-08-08 13:58:21,879 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000013_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128639
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=40879
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=172
		CPU time spent (ms)=23490
		Physical memory (bytes) snapshot=3498819584
		Virtual memory (bytes) snapshot=58883616768
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000013 on graphalytics-giraph-slave11_46641
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:19958
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10463 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 283 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 124,724,023.00
               min = 16.00
               max = 247424.00
              mean = 135275.51
            stddev = 65878.03
            median = 147613.00
              75% <= 182656.00
              95% <= 235776.00
              98% <= 238976.00
              99% <= 238976.00
            99.9% <= 247424.00
             count = 922

  remote-requests:
    count = 0

  requests-received:
             count = 922
         mean rate = 88.01 requests/s
     1-minute rate = 78.28 requests/s
     5-minute rate = 76.63 requests/s
    15-minute rate = 76.34 requests/s

  requests-sent:
             count = 338
         mean rate = 32.27 requests/s
     1-minute rate = 32.01 requests/s
     5-minute rate = 32.16 requests/s
    15-minute rate = 32.19 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 8,392.00
               min = 16.00
               max = 1473.00
              mean = 24.83
            stddev = 80.41
            median = 16.00
              75% <= 16.00
              95% <= 53.00
              98% <= 89.00
              99% <= 89.00
            99.9% <= 1473.00
             count = 338

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 10463

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 283

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1434 ms
  compute all partitions: 862 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 905 ms
  time to first message: 283660 us
  wait on requests time: 326634 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 905

  compute-all-ms:
    value = 862

  compute-per-partition-ms:
               sum = 3,833.00
               min = 14.00
               max = 545.00
              mean = 116.15
            stddev = 115.97
            median = 76.00
              75% <= 211.50
              95% <= 319.60
              98% <= 545.00
              99% <= 545.00
            99.9% <= 545.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 62950497

  messages-sent:
    count = 7780186

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 3,832.00
               min = 237.00
               max = 779.00
              mean = 348.36
            stddev = 150.23
            median = 307.00
              75% <= 363.00
              95% <= 779.00
              98% <= 779.00
              99% <= 779.00
            99.9% <= 779.00
             count = 11

  received-bytes:
               sum = 58,172,226.00
               min = 16.00
               max = 385920.00
              mean = 76341.50
            stddev = 94269.48
            median = 31852.50
              75% <= 131072.00
              95% <= 262144.00
              98% <= 324559.36
              99% <= 363802.88
            99.9% <= 385920.00
             count = 762

  remote-requests:
    count = 276

  requests-received:
             count = 762
         mean rate = 520.41 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 599
         mean rate = 409.08 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 58,157,646.00
               min = 16.00
               max = 525585.00
              mean = 97091.23
            stddev = 182833.00
            median = 53.00
              75% <= 558.00
              95% <= 465341.00
              98% <= 524453.00
              99% <= 525229.00
            99.9% <= 525585.00
             count = 599

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 1434

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 2868

  time-to-first-message-ms:
    value = 283660

  total-requests:
    value = 299

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 326634

  worker-context-post-superstep:
    value = 9

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 652 ms
  compute all partitions: 290 ms
  time spent in gc: 76 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 263233 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 290

  compute-per-partition-ms:
               sum = 1,895.00
               min = 13.00
               max = 136.00
              mean = 57.42
            stddev = 50.42
            median = 28.00
              75% <= 124.00
              95% <= 135.30
              98% <= 136.00
              99% <= 136.00
            99.9% <= 136.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 61287428

  messages-sent:
    count = 7572298

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 1,894.00
               min = 156.00
               max = 197.00
              mean = 172.18
            stddev = 12.39
            median = 170.00
              75% <= 184.00
              95% <= 197.00
              98% <= 197.00
              99% <= 197.00
            99.9% <= 197.00
             count = 11

  received-bytes:
               sum = 56,733,337.00
               min = 16.00
               max = 385664.00
              mean = 89203.36
            stddev = 102939.28
            median = 47168.00
              75% <= 181504.00
              95% <= 262144.00
              98% <= 323366.40
              99% <= 357608.96
            99.9% <= 385664.00
             count = 636

  remote-requests:
    count = 264

  requests-received:
             count = 636
         mean rate = 930.40 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 589
         mean rate = 861.63 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 56,622,807.00
               min = 16.00
               max = 521137.00
              mean = 96133.80
            stddev = 180565.79
            median = 16.00
              75% <= 509.00
              95% <= 465293.00
              98% <= 489055.40
              99% <= 497027.80
            99.9% <= 521137.00
             count = 589

  superstep-gc-time-ms:
    count = 76

  superstep-time-ms:
    value = 652

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 400

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 286

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 263233

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 196 ms
  compute all partitions: 30 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 50575 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 30

  compute-per-partition-ms:
               sum = 87.00
               min = 1.00
               max = 12.00
              mean = 2.64
            stddev = 2.38
            median = 2.00
              75% <= 2.00
              95% <= 9.20
              98% <= 12.00
              99% <= 12.00
            99.9% <= 12.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 20

  message-bytes-sent:
    count = 150974

  messages-sent:
    count = 11739

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 85.00
               min = 0.00
               max = 14.00
              mean = 7.73
            stddev = 4.29
            median = 7.00
              75% <= 12.00
              95% <= 14.00
              98% <= 14.00
              99% <= 14.00
            99.9% <= 14.00
             count = 11

  received-bytes:
               sum = 157,999.00
               min = 16.00
               max = 6653.00
              mean = 473.05
            stddev = 940.85
            median = 32.00
              75% <= 485.75
              95% <= 2399.00
              98% <= 3757.70
              99% <= 4557.05
            99.9% <= 6653.00
             count = 334

  remote-requests:
    count = 240

  requests-received:
             count = 334
         mean rate = 1472.92 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 526
         mean rate = 2319.54 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 120

  sent-bytes:
               sum = 147,874.00
               min = 16.00
               max = 1601.00
              mean = 281.13
            stddev = 394.63
            median = 53.00
              75% <= 377.25
              95% <= 1214.00
              98% <= 1425.56
              99% <= 1523.92
            99.9% <= 1601.00
             count = 526

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 196

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 73

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 260

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 50575

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 108 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 156 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 23.00
               min = 0.00
               max = 1.00
              mean = 0.70
            stddev = 0.47
            median = 1.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 23.00
               min = 0.00
               max = 5.00
              mean = 2.09
            stddev = 1.97
            median = 2.00
              75% <= 4.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.18
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 379.24 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 386.63 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.77
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 108

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 156

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 97.35388561466894

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:68341
Log Contents:
2018-08-08 13:58:00,410 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,475 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,475 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,477 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,477 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,658 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:00,875 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:01,069 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,545 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,556 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,709 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,726 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,757 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,758 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,766 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,773 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,773 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 11 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave11
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000013:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000013/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000013:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000013/tmp
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,779 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000013
INFO    2018-08-08 13:58:01,780 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,793 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,794 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,800 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300af, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,801 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:01,916 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:01,933 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:01,994 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave11/10.164.0.13:30011 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:01,999 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:02,000 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:02,021 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:02,031 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:02,035 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,037 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,043 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave11_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=11, port=30011)
INFO    2018-08-08 13:58:02,309 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,398 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,407 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,409 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,411 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,412 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,412 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,422 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,422 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,424 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,424 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,426 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,426 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,426 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,431 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,433 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,433 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,498 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,556 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.056697257 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.061247498 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.060396127 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.058628976 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.058544807 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05772333 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.056839325 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.056157704 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,569 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.054325745 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,569 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.054534145 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,569 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.055644255 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,571 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0025, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.138
MBytes/sec sent = 0.0092, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.138
INFO    2018-08-08 13:58:02,572 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,576 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003646142 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,577 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003147133 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,577 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002743009 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,577 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.23888E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,579 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003121063 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,579 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004512648 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,580 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002438938 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,580 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002376487 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,580 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002118966 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,583 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00354779 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,583 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002984216 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,584 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:58:02,584 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:58:12,359 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,362 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,403 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,407 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50213.70M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,407 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 9.826
MBytes/sec sent = 0, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 9.826
INFO    2018-08-08 13:58:12,407 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,413 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 9 more tasks to send their aggregator data, task ids: [1, 2, 3, 5, 6, 7, 9, 10, 13]
INFO    2018-08-08 13:58:12,437 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:58:12,437 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50213.70M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,449 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,487 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,492 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@39ab59f8,outgoing=org.apache.giraph.conf.DefaultMessageClasses@64e92d61)
WARN    2018-08-08 13:58:12,497 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,509 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,509 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,514 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave11_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=11, port=30011)
INFO    2018-08-08 13:58:12,559 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,559 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,559 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,560 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.123
MBytes/sec sent = 0.0113, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.123
INFO    2018-08-08 13:58:12,565 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,566 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,568 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:58:12,571 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 10 more tasks to send their aggregator data, task ids: [1, 3, 4, 5, 6, 8, 9, 10, 12, 13]
INFO    2018-08-08 13:58:12,584 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,843 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.24561939 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.24 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,857 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.25503927 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.25 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,871 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.28360212 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,879 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.29300222 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,882 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2865151 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,905 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.31197387 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.31 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,911 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.32462 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.32 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,927 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.327646 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.32 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,958 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3675568 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.36 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,993 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.4054085 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.40 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,383 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.7812939 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.78 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,447 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 49546.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,774 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0045, MBytesReceived = 0.0042, ave received req MBytes = 0, secs waited = 0.929
MBytes/sec sent = 59.63, MBytesSent = 55.4559, ave sent req MBytes = 0.2009, secs waited = 0.929
INFO    2018-08-08 13:58:13,774 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,937 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:58:13,939 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 7780186 , message bytes = 62950497 , Memory (free/total/max) = 49508.24M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,943 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,962 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,963 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@127d7908,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6b9c69a9)
INFO    2018-08-08 13:58:13,971 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,974 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave11_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=11, port=30011)
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,998 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0003, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.059
MBytes/sec sent = 0.0234, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.059
INFO    2018-08-08 13:58:14,001 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,002 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,004 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,163 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.1572373 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.16 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,172 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16582847 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.16 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,175 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16134532 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.16 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,177 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16633895 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.16 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,182 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16945823 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,182 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17107789 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,187 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17449361 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,190 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18525359 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,190 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.1761227 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,197 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18497767 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,207 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.20032668 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,296 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 48833.71M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,436 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 76ms
INFO    2018-08-08 13:58:14,559 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0103, MBytesReceived = 0.004, ave received req MBytes = 0, secs waited = 0.392
MBytes/sec sent = 137.0358, MBytesSent = 53.9921, ave sent req MBytes = 0.2045, secs waited = 0.393
INFO    2018-08-08 13:58:14,559 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,623 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,623 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7572298 , message bytes = 61287428 , Memory (free/total/max) = 51661.71M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,628 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,646 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,649 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4bd2f0dc,outgoing=org.apache.giraph.conf.DefaultMessageClasses@2e647e59)
INFO    2018-08-08 13:58:14,657 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,669 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave11_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=11, port=30011)
WARN    2018-08-08 13:58:14,710 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,733 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.11
MBytes/sec sent = 0.0127, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.11
INFO    2018-08-08 13:58:14,735 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,736 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,738 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,747 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007854321 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,748 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00642117 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,748 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005955474 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,748 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007245473 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,749 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006931398 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,753 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014368618 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,753 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012328063 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,755 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014680679 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,756 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00762129 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,758 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012478229 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,758 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015297163 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,769 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 51523.18M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,820 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0516, MBytesReceived = 0.0037, ave received req MBytes = 0, secs waited = 0.07
MBytes/sec sent = 1.8874, MBytesSent = 0.134, ave sent req MBytes = 0.0006, secs waited = 0.07
INFO    2018-08-08 13:58:14,820 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,852 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,853 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 11739 , message bytes = 150974 , Memory (free/total/max) = 51523.18M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,857 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,878 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,880 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:58:14,884 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,901 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave11_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=11, port=30011)
INFO    2018-08-08 13:58:14,907 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,942 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,967 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,967 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,967 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,968 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.115
MBytes/sec sent = 0.0121, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.115
INFO    2018-08-08 13:58:14,970 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,972 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,976 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,981 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002002205 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002452909 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003083323 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005060754 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004733341 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001734659 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004017396 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004434533 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006039403 secs for 7 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,984 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002956927 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,984 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002462888 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,984 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 51407.97M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,985 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:58:14,985 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,992 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,992 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 51407.97M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,995 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,014 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:58:15,019 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,020 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,020 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,025 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,043 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,080 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,085 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,087 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,229 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,230 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4658 vertices using 1 threads
INFO    2018-08-08 13:58:17,233 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,585 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,585 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,588 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/11_worker
INFO    2018-08-08 13:58:17,591 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300af closed
INFO    2018-08-08 13:58:17,591 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,593 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,597 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,807 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,811 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000011_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,833 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000011_0 is allowed to commit now
INFO    2018-08-08 13:58:21,843 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000011_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000011
INFO    2018-08-08 13:58:21,858 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000011_0' done.
INFO    2018-08-08 13:58:21,864 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000011_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128639
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=40725
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=175
		CPU time spent (ms)=24310
		Physical memory (bytes) snapshot=3452743680
		Virtual memory (bytes) snapshot=58935111680
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000007 on graphalytics-giraph-slave12_33893
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:19943
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10324 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 569 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 123,000,615.00
               min = 16.00
               max = 262144.00
              mean = 144706.61
            stddev = 68986.87
            median = 173390.50
              75% <= 188704.00
              95% <= 238976.00
              98% <= 238976.00
              99% <= 238976.00
            99.9% <= 262144.00
             count = 850

  remote-requests:
    count = 0

  requests-received:
             count = 850
         mean rate = 82.21 requests/s
     1-minute rate = 80.44 requests/s
     5-minute rate = 80.25 requests/s
    15-minute rate = 80.22 requests/s

  requests-sent:
             count = 334
         mean rate = 32.31 requests/s
     1-minute rate = 32.95 requests/s
     5-minute rate = 33.31 requests/s
    15-minute rate = 33.37 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 8,328.00
               min = 16.00
               max = 1473.00
              mean = 24.93
            stddev = 80.88
            median = 16.00
              75% <= 16.00
              95% <= 53.00
              98% <= 89.00
              99% <= 89.00
            99.9% <= 1473.00
             count = 334

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 10324

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 569

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1428 ms
  compute all partitions: 817 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 438668 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 817

  compute-per-partition-ms:
               sum = 4,012.00
               min = 19.00
               max = 275.00
              mean = 121.58
            stddev = 99.60
            median = 66.00
              75% <= 252.00
              95% <= 272.90
              98% <= 275.00
              99% <= 275.00
            99.9% <= 275.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 62064678

  messages-sent:
    count = 7670997

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 4,011.00
               min = 322.00
               max = 396.00
              mean = 364.64
            stddev = 25.73
            median = 372.00
              75% <= 387.00
              95% <= 396.00
              98% <= 396.00
              99% <= 396.00
            99.9% <= 396.00
             count = 11

  received-bytes:
               sum = 57,437,992.00
               min = 16.00
               max = 393088.00
              mean = 80671.34
            stddev = 96375.25
            median = 39424.00
              75% <= 141088.00
              95% <= 262144.00
              98% <= 328197.12
              99% <= 354177.28
            99.9% <= 393088.00
             count = 712

  remote-requests:
    count = 264

  requests-received:
             count = 712
         mean rate = 487.02 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 586
         mean rate = 400.83 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 57,397,527.00
               min = 16.00
               max = 505089.00
              mean = 97948.00
            stddev = 181976.22
            median = 16.00
              75% <= 501.00
              95% <= 456388.80
              98% <= 477031.16
              99% <= 484236.08
            99.9% <= 505089.00
             count = 586

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 1428

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 1389

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 286

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 438668

  worker-context-post-superstep:
    value = 10

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 650 ms
  compute all partitions: 299 ms
  time spent in gc: 94 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 246982 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 299

  compute-per-partition-ms:
               sum = 2,209.00
               min = 12.00
               max = 155.00
              mean = 66.94
            stddev = 55.76
            median = 33.00
              75% <= 140.00
              95% <= 150.10
              98% <= 155.00
              99% <= 155.00
            99.9% <= 155.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 60354240

  messages-sent:
    count = 7457545

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 2,209.00
               min = 170.00
               max = 220.00
              mean = 200.82
            stddev = 14.23
            median = 206.00
              75% <= 208.00
              95% <= 220.00
              98% <= 220.00
              99% <= 220.00
            99.9% <= 220.00
             count = 11

  received-bytes:
               sum = 56,026,922.00
               min = 16.00
               max = 388224.00
              mean = 94960.88
            stddev = 110286.71
            median = 42275.00
              75% <= 194400.00
              95% <= 300480.75
              98% <= 353559.04
              99% <= 376350.72
            99.9% <= 388224.00
             count = 590

  remote-requests:
    count = 264

  requests-received:
             count = 590
         mean rate = 866.14 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 589
         mean rate = 864.54 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 55,815,511.00
               min = 16.00
               max = 487361.00
              mean = 94763.18
            stddev = 176972.29
            median = 16.00
              75% <= 533.00
              95% <= 449785.00
              98% <= 463943.40
              99% <= 469207.00
            99.9% <= 487361.00
             count = 589

  superstep-gc-time-ms:
    count = 94

  superstep-time-ms:
    value = 650

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 224

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 286

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 246982

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 195 ms
  compute all partitions: 27 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 56878 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 27

  compute-per-partition-ms:
               sum = 101.00
               min = 1.00
               max = 11.00
              mean = 3.06
            stddev = 2.62
            median = 2.00
              75% <= 3.00
              95% <= 8.90
              98% <= 11.00
              99% <= 11.00
            99.9% <= 11.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 20

  message-bytes-sent:
    count = 153190

  messages-sent:
    count = 11669

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.722007722007722

  processing-per-thread-ms:
               sum = 94.00
               min = 0.00
               max = 13.00
              mean = 8.55
            stddev = 3.88
            median = 8.00
              75% <= 12.00
              95% <= 13.00
              98% <= 13.00
              99% <= 13.00
            99.9% <= 13.00
             count = 11

  received-bytes:
               sum = 157,925.00
               min = 16.00
               max = 6564.00
              mean = 411.26
            stddev = 809.89
            median = 16.00
              75% <= 452.50
              95% <= 2063.25
              98% <= 2548.90
              99% <= 4774.80
            99.9% <= 6564.00
             count = 384

  remote-requests:
    count = 239

  requests-received:
             count = 384
         mean rate = 1689.29 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 525
         mean rate = 2309.64 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 119

  sent-bytes:
               sum = 149,773.00
               min = 16.00
               max = 1801.00
              mean = 285.28
            stddev = 397.52
            median = 46.00
              75% <= 403.00
              95% <= 1181.00
              98% <= 1408.84
              99% <= 1541.08
            99.9% <= 1801.00
             count = 525

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 195

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 38

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 259

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 56878

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 107 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 183 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 26.00
               min = 0.00
               max = 2.00
              mean = 0.79
            stddev = 0.48
            median = 1.00
              75% <= 1.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 26.00
               min = 0.00
               max = 5.00
              mean = 2.36
            stddev = 1.69
            median = 3.00
              75% <= 4.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 904.77
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 389.13 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 389.10 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 107

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 183

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 97.15543812788896

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:68302
Log Contents:
2018-08-08 13:58:00,622 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,688 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,688 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,690 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,690 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,873 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:01,094 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:01,287 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,734 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,747 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,891 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,905 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,930 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,930 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,938 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,945 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,945 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 5 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave12
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000007:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000007/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000007:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000007/tmp
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,950 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000007
INFO    2018-08-08 13:58:01,951 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,963 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,963 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,969 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300b5, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,970 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:02,072 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:02,088 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:02,134 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave12/10.164.0.14:30005 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:02,139 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:02,139 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:02,158 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:02,167 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:02,171 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,174 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,180 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave12_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005)
INFO    2018-08-08 13:58:02,305 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,397 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,406 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,407 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,407 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,407 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,408 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,409 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,412 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,412 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,412 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,412 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,412 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,412 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,416 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,422 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,425 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,427 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,518 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,550 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.032174088 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039496265 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03874076 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03837908 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,566 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03764927 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,566 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037377615 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037134465 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036277335 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03614074 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03593556 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03534841 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,569 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.043
MBytes/sec sent = 0.006, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.043
INFO    2018-08-08 13:58:02,570 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,573 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002713643 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,574 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002066966 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,574 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.4159E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,575 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001995148 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,576 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003466053 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,576 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002783997 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,577 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002443919 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,577 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.55673E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,578 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003457146 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,579 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0049443 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,580 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003443597 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,581 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0186, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.009
MBytes/sec sent = 0.0262, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.009
INFO    2018-08-08 13:58:02,581 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:58:12,356 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,359 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,406 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,410 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50213.46M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,410 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 9.838
MBytes/sec sent = 0, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 9.838
INFO    2018-08-08 13:58:12,410 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,418 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 2 more tasks to send their aggregator data, task ids: [2, 10]
INFO    2018-08-08 13:58:12,433 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:58:12,433 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50213.46M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,446 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,484 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,489 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@39ab59f8,outgoing=org.apache.giraph.conf.DefaultMessageClasses@64e92d61)
WARN    2018-08-08 13:58:12,493 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,509 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,509 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,512 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave12_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005)
INFO    2018-08-08 13:58:12,560 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,561 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,561 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,562 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.128
MBytes/sec sent = 0.0109, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.128
INFO    2018-08-08 13:58:12,564 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,565 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,566 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:58:12,570 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 4 more tasks to send their aggregator data, task ids: [9, 10, 12, 13]
INFO    2018-08-08 13:58:12,579 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,911 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.32714012 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.32 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,925 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3333677 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.33 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,930 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.34095916 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.34 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,963 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.38073593 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.38 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,969 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.37452087 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.37 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,973 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.39235732 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.39 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,976 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.37132645 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.37 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,976 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3558391 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.35 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,983 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.38711578 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.38 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,989 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.40080908 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.40 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,986 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3887386 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.39 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,398 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 49695.41M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,837 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0044, MBytesReceived = 0.004, ave received req MBytes = 0, secs waited = 0.903
MBytes/sec sent = 60.5423, MBytesSent = 54.7302, ave sent req MBytes = 0.2097, secs waited = 0.904
INFO    2018-08-08 13:58:13,837 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,932 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:13,933 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 7670997 , message bytes = 62064678 , Memory (free/total/max) = 49413.11M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,936 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,959 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,960 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@127d7908,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6b9c69a9)
INFO    2018-08-08 13:58:13,971 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,972 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave12_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005)
INFO    2018-08-08 13:58:13,993 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,993 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,993 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,994 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.061
MBytes/sec sent = 0.0227, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.061
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:13,999 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,001 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,187 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17242429 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,190 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18863524 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,198 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.19484207 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,206 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.1959935 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,210 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.20657866 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,210 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.20743601 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,216 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.21010515 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,219 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2096758 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,222 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2186725 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.22 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,227 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2119474 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,231 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.22470246 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.22 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,302 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 48859.62M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,464 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 94ms
INFO    2018-08-08 13:58:14,549 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0112, MBytesReceived = 0.004, ave received req MBytes = 0, secs waited = 0.359
MBytes/sec sent = 147.8394, MBytesSent = 53.2222, ave sent req MBytes = 0.2016, secs waited = 0.36
INFO    2018-08-08 13:58:14,549 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,620 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,620 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7457545 , message bytes = 60354240 , Memory (free/total/max) = 51637.57M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,624 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,643 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,646 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4bd2f0dc,outgoing=org.apache.giraph.conf.DefaultMessageClasses@2e647e59)
INFO    2018-08-08 13:58:14,653 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,667 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave12_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005)
WARN    2018-08-08 13:58:14,707 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,728 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,728 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,728 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.108
MBytes/sec sent = 0.0129, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.108
INFO    2018-08-08 13:58:14,731 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,735 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,744 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00487878 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,744 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007325985 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,746 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003830874 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,746 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008136878 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,748 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01101954 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,750 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011543691 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,750 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015000661 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,751 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011196331 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,753 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014127437 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,754 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014521014 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,751 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013013466 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,763 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 51533.95M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,820 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.048, MBytesReceived = 0.0036, ave received req MBytes = 0, secs waited = 0.075
MBytes/sec sent = 1.787, MBytesSent = 0.1358, ave sent req MBytes = 0.0006, secs waited = 0.075
INFO    2018-08-08 13:58:14,820 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,849 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,849 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 11669 , message bytes = 153190 , Memory (free/total/max) = 51533.95M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,853 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,875 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,877 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:58:14,882 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,897 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave12_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005)
INFO    2018-08-08 13:58:14,904 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,939 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,963 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.115
MBytes/sec sent = 0.0121, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.115
INFO    2018-08-08 13:58:14,966 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,969 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,972 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,979 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005253394 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003966931 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001122759 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002746127 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003406041 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003695378 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005349413 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004900943 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006553722 secs for 7 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002482278 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001594302 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 51418.74M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,981 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0849, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.011
INFO    2018-08-08 13:58:14,981 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,989 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,989 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 51418.74M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,994 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,010 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,012 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,021 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,040 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,077 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,082 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,084 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,326 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,326 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4582 vertices using 1 threads
INFO    2018-08-08 13:58:17,330 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,583 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,583 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,586 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/5_worker
INFO    2018-08-08 13:58:17,591 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300b5 closed
INFO    2018-08-08 13:58:17,591 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,594 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,597 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,809 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,812 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000005_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,834 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000005_0 is allowed to commit now
INFO    2018-08-08 13:58:21,843 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000005_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000005
INFO    2018-08-08 13:58:21,863 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000005_0' done.
INFO    2018-08-08 13:58:21,867 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000005_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128638
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=39985
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=193
		CPU time spent (ms)=25480
		Physical memory (bytes) snapshot=3412733952
		Virtual memory (bytes) snapshot=58912452608
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000003 on graphalytics-giraph-slave13_40615
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:19946
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10626 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 325 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 123,888,197.00
               min = 16.00
               max = 247424.00
              mean = 146613.25
            stddev = 67383.29
            median = 164509.00
              75% <= 191104.00
              95% <= 238976.00
              98% <= 238976.00
              99% <= 238976.00
            99.9% <= 247424.00
             count = 845

  remote-requests:
    count = 0

  requests-received:
             count = 845
         mean rate = 79.41 requests/s
     1-minute rate = 73.53 requests/s
     5-minute rate = 72.47 requests/s
    15-minute rate = 72.29 requests/s

  requests-sent:
             count = 335
         mean rate = 31.48 requests/s
     1-minute rate = 31.59 requests/s
     5-minute rate = 31.76 requests/s
    15-minute rate = 31.79 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 8,344.00
               min = 16.00
               max = 1473.00
              mean = 24.91
            stddev = 80.77
            median = 16.00
              75% <= 16.00
              95% <= 53.00
              98% <= 89.00
              99% <= 89.00
            99.9% <= 1473.00
             count = 335

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 10626

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 325

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1431 ms
  compute all partitions: 785 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 334376 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 785

  compute-per-partition-ms:
               sum = 3,055.00
               min = 9.00
               max = 236.00
              mean = 92.58
            stddev = 92.27
            median = 46.00
              75% <= 215.00
              95% <= 229.00
              98% <= 236.00
              99% <= 236.00
            99.9% <= 236.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 62539199

  messages-sent:
    count = 7727782

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 3,049.00
               min = 242.00
               max = 294.00
              mean = 277.18
            stddev = 16.64
            median = 281.00
              75% <= 290.00
              95% <= 294.00
              98% <= 294.00
              99% <= 294.00
            99.9% <= 294.00
             count = 11

  received-bytes:
               sum = 57,815,943.00
               min = 16.00
               max = 358400.00
              mean = 69075.20
            stddev = 76780.40
            median = 45241.00
              75% <= 129536.00
              95% <= 228725.30
              98% <= 238976.00
              99% <= 239360.00
            99.9% <= 358400.00
             count = 837

  remote-requests:
    count = 264

  requests-received:
             count = 837
         mean rate = 572.21 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 588
         mean rate = 402.00 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 57,808,051.00
               min = 16.00
               max = 516777.00
              mean = 98313.01
            stddev = 184212.47
            median = 16.00
              75% <= 451.00
              95% <= 473799.00
              98% <= 489060.44
              99% <= 498276.48
            99.9% <= 516777.00
             count = 588

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 1431

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 3558

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 286

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 334376

  worker-context-post-superstep:
    value = 9

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 651 ms
  compute all partitions: 304 ms
  time spent in gc: 65 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 203683 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 304

  compute-per-partition-ms:
               sum = 2,000.00
               min = 11.00
               max = 141.00
              mean = 60.61
            stddev = 53.56
            median = 32.00
              75% <= 130.50
              95% <= 140.30
              98% <= 141.00
              99% <= 141.00
            99.9% <= 141.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 60943025

  messages-sent:
    count = 7528482

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 2,000.00
               min = 164.00
               max = 213.00
              mean = 181.82
            stddev = 14.56
            median = 182.00
              75% <= 193.00
              95% <= 213.00
              98% <= 213.00
              99% <= 213.00
            99.9% <= 213.00
             count = 11

  received-bytes:
               sum = 56,382,058.00
               min = 16.00
               max = 387456.00
              mean = 88373.13
            stddev = 104094.35
            median = 32597.00
              75% <= 184448.00
              95% <= 262144.00
              98% <= 325204.48
              99% <= 327680.00
            99.9% <= 387456.00
             count = 638

  remote-requests:
    count = 264

  requests-received:
             count = 638
         mean rate = 936.91 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 589
         mean rate = 864.99 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 56,333,569.00
               min = 16.00
               max = 477437.00
              mean = 95642.73
            stddev = 178283.07
            median = 16.00
              75% <= 504.50
              95% <= 444753.00
              98% <= 457977.00
              99% <= 460687.40
            99.9% <= 477437.00
             count = 589

  superstep-gc-time-ms:
    count = 65

  superstep-time-ms:
    value = 651

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 488

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 286

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 203683

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 197 ms
  compute all partitions: 31 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 52687 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 31

  compute-per-partition-ms:
               sum = 157.00
               min = 1.00
               max = 17.00
              mean = 4.76
            stddev = 4.53
            median = 3.00
              75% <= 5.50
              95% <= 17.00
              98% <= 17.00
              99% <= 17.00
            99.9% <= 17.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 167341

  messages-sent:
    count = 13119

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 157.00
               min = 6.00
               max = 24.00
              mean = 14.27
            stddev = 6.03
            median = 16.00
              75% <= 20.00
              95% <= 24.00
              98% <= 24.00
              99% <= 24.00
            99.9% <= 24.00
             count = 11

  received-bytes:
               sum = 158,587.00
               min = 16.00
               max = 9422.00
              mean = 607.61
            stddev = 1425.50
            median = 32.00
              75% <= 176.00
              95% <= 3636.80
              98% <= 5136.00
              99% <= 8521.08
            99.9% <= 9422.00
             count = 261

  remote-requests:
    count = 264

  requests-received:
             count = 261
         mean rate = 1142.24 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 548
         mean rate = 2398.13 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 163,038.00
               min = 16.00
               max = 1529.00
              mean = 297.51
            stddev = 395.03
            median = 89.00
              75% <= 394.00
              95% <= 1223.20
              98% <= 1393.00
              99% <= 1447.04
            99.9% <= 1529.00
             count = 548

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 197

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 17

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 286

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 52687

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 107 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 240 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 27.00
               min = 0.00
               max = 1.00
              mean = 0.82
            stddev = 0.39
            median = 1.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 27.00
               min = 0.00
               max = 6.00
              mean = 2.45
            stddev = 2.46
            median = 2.00
              75% <= 5.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 905.18
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 387.60 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 387.50 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 107

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 240

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 97.47102924797076

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:68330
Log Contents:
2018-08-08 13:58:00,398 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,456 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,456 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,458 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,458 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,629 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:00,834 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:01,008 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,426 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,437 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,572 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,585 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,610 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,611 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,619 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,625 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,625 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 1 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,631 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,631 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave13
INFO    2018-08-08 13:58:01,631 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,631 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,631 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,631 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000003:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000003/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,631 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000003:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,631 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000003/tmp
INFO    2018-08-08 13:58:01,631 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,631 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,631 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,632 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,632 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,632 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,632 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000003
INFO    2018-08-08 13:58:01,632 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,644 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,645 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,653 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300aa, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,654 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:01,756 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:01,772 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:01,831 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave13/10.164.0.15:30001 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:01,835 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:01,836 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:01,855 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:01,866 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:01,869 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:01,872 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:01,878 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave13_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=1, port=30001)
INFO    2018-08-08 13:58:02,304 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,391 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,398 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,400 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,401 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,402 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,403 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,404 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,405 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,405 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,405 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,405 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,405 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,405 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,406 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,406 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,406 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,406 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,408 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,408 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,422 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,427 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,496 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,555 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05196356 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,555 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05148637 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,555 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05880449 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,555 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0502742 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,555 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05268638 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,555 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04975799 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,555 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050880227 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,556 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.049228657 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,556 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048792463 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,556 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048434567 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,556 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047998946 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,559 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0025, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.142
MBytes/sec sent = 0.009, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.143
INFO    2018-08-08 13:58:02,560 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,564 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003772768 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002782677 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002407564 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,566 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00234017 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,566 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002475206 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002235917 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002028374 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001961648 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,570 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003824617 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,571 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003692332 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,572 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003428333 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,572 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0092, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0143, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:58:02,572 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:58:12,355 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,358 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,398 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,402 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50197.37M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,403 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 9.834
MBytes/sec sent = 0, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 9.835
INFO    2018-08-08 13:58:12,403 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,407 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 8 more tasks to send their aggregator data, task ids: [2, 3, 5, 6, 7, 9, 10, 13]
INFO    2018-08-08 13:58:12,432 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:58:12,432 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50197.37M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,443 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,483 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,489 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@39ab59f8,outgoing=org.apache.giraph.conf.DefaultMessageClasses@64e92d61)
WARN    2018-08-08 13:58:12,493 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,508 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,508 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,512 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave13_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=1, port=30001)
INFO    2018-08-08 13:58:12,554 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,555 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,555 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,556 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.124
MBytes/sec sent = 0.0112, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.124
INFO    2018-08-08 13:58:12,560 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,563 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,564 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:58:12,569 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 7 more tasks to send their aggregator data, task ids: [4, 8, 9, 10, 11, 12, 13]
INFO    2018-08-08 13:58:12,575 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,835 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.24363667 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.24 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,838 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2591909 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,859 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.27468008 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,865 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.28506187 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,871 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.29196388 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,874 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.29693416 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,871 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.28454363 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,871 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.28100553 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,882 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.29116464 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,876 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.29315615 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,885 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.29659656 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,361 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 49584.82M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,695 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0047, MBytesReceived = 0.004, ave received req MBytes = 0, secs waited = 0.854
MBytes/sec sent = 64.4707, MBytesSent = 55.1225, ave sent req MBytes = 0.2088, secs waited = 0.854
INFO    2018-08-08 13:58:13,695 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,934 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:58:13,935 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 7727782 , message bytes = 62539199 , Memory (free/total/max) = 49456.45M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,939 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,958 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,960 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@127d7908,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6b9c69a9)
INFO    2018-08-08 13:58:13,969 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,971 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave13_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=1, port=30001)
INFO    2018-08-08 13:58:13,991 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,992 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,992 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,993 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0003, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.058
MBytes/sec sent = 0.0238, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.058
INFO    2018-08-08 13:58:13,994 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:13,997 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:58:14,001 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,172 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17057572 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,176 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.166553 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.16 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,178 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17360516 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,179 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16625251 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,189 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.1857599 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,194 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18974246 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,196 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18195517 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,199 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18608204 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,204 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.19496574 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,207 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.19608141 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,222 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2185581 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,306 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 48874.37M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,456 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 65ms
INFO    2018-08-08 13:58:14,509 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.012, MBytesReceived = 0.004, ave received req MBytes = 0, secs waited = 0.334
MBytes/sec sent = 160.347, MBytesSent = 53.7163, ave sent req MBytes = 0.2035, secs waited = 0.334
INFO    2018-08-08 13:58:14,509 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,620 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,620 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7528482 , message bytes = 60943025 , Memory (free/total/max) = 51719.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,624 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,643 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,646 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4bd2f0dc,outgoing=org.apache.giraph.conf.DefaultMessageClasses@2e647e59)
INFO    2018-08-08 13:58:14,652 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,664 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave13_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=1, port=30001)
WARN    2018-08-08 13:58:14,706 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,728 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,728 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.109
MBytes/sec sent = 0.0128, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.109
INFO    2018-08-08 13:58:14,731 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,735 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,746 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009067741 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,746 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007191651 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,746 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008337014 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,751 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01139282 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,753 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.018189788 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,753 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01409815 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,757 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.020716395 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,758 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.020107705 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,758 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017341476 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,762 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.021875633 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,762 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.025150865 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,767 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 51623.17M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,819 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0552, MBytesReceived = 0.004, ave received req MBytes = 0, secs waited = 0.072
MBytes/sec sent = 2.0342, MBytesSent = 0.1485, ave sent req MBytes = 0.0006, secs waited = 0.072
INFO    2018-08-08 13:58:14,819 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,849 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,849 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 13119 , message bytes = 167341 , Memory (free/total/max) = 51616.77M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,855 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,874 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,876 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:58:14,881 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,897 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave13_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=1, port=30001)
WARN    2018-08-08 13:58:14,939 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,963 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,963 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,963 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.115
MBytes/sec sent = 0.0121, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.115
INFO    2018-08-08 13:58:14,966 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,969 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,972 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,979 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003465029 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006531145 secs for 7 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005074828 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005760959 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007615354 secs for 10 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004428106 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00632014 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005046554 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004655536 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00373404 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004330422 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 51501.57M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,989 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,989 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 51501.57M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,991 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,010 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,012 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,021 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,039 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,077 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,081 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,083 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,326 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,326 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4703 vertices using 1 threads
INFO    2018-08-08 13:58:17,330 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,581 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,581 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,583 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/1_worker
INFO    2018-08-08 13:58:17,586 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300aa closed
INFO    2018-08-08 13:58:17,586 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,588 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,592 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,804 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,807 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000001_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,829 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000001_0 is allowed to commit now
INFO    2018-08-08 13:58:21,839 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000001_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000001
INFO    2018-08-08 13:58:21,854 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000001_0' done.
INFO    2018-08-08 13:58:21,859 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000001_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128638
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=41048
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=154
		CPU time spent (ms)=20050
		Physical memory (bytes) snapshot=3410173952
		Virtual memory (bytes) snapshot=58950291456
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000002 on graphalytics-giraph-slave14_35219
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:31 +0000 2018
LogLength:6854
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
superstep time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave9_6
  largest: 0 ms from graphalytics-giraph-slave9_6
compute all partitions
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave9_6
  largest: 0 ms from graphalytics-giraph-slave9_6
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave9_6
  largest: 0 ms from graphalytics-giraph-slave9_6
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave9_6
  largest: 0 us from graphalytics-giraph-slave9_6
wait requests time
  mean: 342.3076923076923 us
  smallest: 569 us from graphalytics-giraph-slave12_5
  largest: 225 us from graphalytics-giraph-slave2_8
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_6
  largest: 0 bytes from graphalytics-giraph-slave9_6
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_6
  largest: 0 bytes from graphalytics-giraph-slave9_6
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave9_6
  largest: 100.0 % from graphalytics-giraph-slave9_6

--- METRICS: superstep 0 ---
superstep time
  mean: 1430.8461538461538 ms
  smallest: 1436 ms from graphalytics-giraph-slave2_8
  largest: 1427 ms from graphalytics-giraph-slave10_13
compute all partitions
  mean: 871.0769230769231 ms
  smallest: 1024 ms from graphalytics-giraph-slave5_4
  largest: 750 ms from graphalytics-giraph-slave6_7
network communication time
  mean: 746.5384615384615 ms
  smallest: 999 ms from graphalytics-giraph-slave2_8
  largest: 0 ms from graphalytics-giraph-slave12_5
time to first message
  mean: 300630.46153846156 us
  smallest: 525970 us from graphalytics-giraph-slave9_6
  largest: 0 us from graphalytics-giraph-slave12_5
wait requests time
  mean: 358503.6153846154 us
  smallest: 503831 us from graphalytics-giraph-slave6_7
  largest: 205657 us from graphalytics-giraph-slave1_10
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_6
  largest: 0 bytes from graphalytics-giraph-slave9_6
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_6
  largest: 0 bytes from graphalytics-giraph-slave9_6
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave9_6
  largest: 100.0 % from graphalytics-giraph-slave9_6

--- METRICS: superstep 1 ---
superstep time
  mean: 651.6923076923077 ms
  smallest: 655 ms from graphalytics-giraph-slave2_8
  largest: 650 ms from graphalytics-giraph-slave12_5
compute all partitions
  mean: 342.38461538461536 ms
  smallest: 511 ms from graphalytics-giraph-slave7_12
  largest: 290 ms from graphalytics-giraph-slave11_11
network communication time
  mean: 214.23076923076923 ms
  smallest: 346 ms from graphalytics-giraph-slave9_6
  largest: 0 ms from graphalytics-giraph-slave12_5
time to first message
  mean: 153694.76923076922 us
  smallest: 291284 us from graphalytics-giraph-slave15_2
  largest: 0 us from graphalytics-giraph-slave12_5
wait requests time
  mean: 194465.38461538462 us
  smallest: 299096 us from graphalytics-giraph-slave10_13
  largest: 48508 us from graphalytics-giraph-slave7_12
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_6
  largest: 0 bytes from graphalytics-giraph-slave9_6
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_6
  largest: 0 bytes from graphalytics-giraph-slave9_6
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave9_6
  largest: 100.0 % from graphalytics-giraph-slave9_6

--- METRICS: superstep 2 ---
superstep time
  mean: 196.46153846153845 ms
  smallest: 199 ms from graphalytics-giraph-slave2_8
  largest: 195 ms from graphalytics-giraph-slave12_5
compute all partitions
  mean: 36.30769230769231 ms
  smallest: 111 ms from graphalytics-giraph-slave15_2
  largest: 24 ms from graphalytics-giraph-slave1_10
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave9_6
  largest: 0 ms from graphalytics-giraph-slave9_6
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave9_6
  largest: 0 us from graphalytics-giraph-slave9_6
wait requests time
  mean: 47431.92307692308 us
  smallest: 57927 us from graphalytics-giraph-slave1_10
  largest: 221 us from graphalytics-giraph-slave15_2
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_6
  largest: 0 bytes from graphalytics-giraph-slave9_6
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_6
  largest: 0 bytes from graphalytics-giraph-slave9_6
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave9_6
  largest: 100.0 % from graphalytics-giraph-slave9_6

--- METRICS: superstep 3 ---
superstep time
  mean: 107.0 ms
  smallest: 108 ms from graphalytics-giraph-slave9_6
  largest: 106 ms from graphalytics-giraph-slave8_9
compute all partitions
  mean: 8.923076923076923 ms
  smallest: 14 ms from graphalytics-giraph-slave6_7
  largest: 6 ms from graphalytics-giraph-slave2_8
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave9_6
  largest: 0 ms from graphalytics-giraph-slave9_6
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave9_6
  largest: 0 us from graphalytics-giraph-slave9_6
wait requests time
  mean: 213.15384615384616 us
  smallest: 271 us from graphalytics-giraph-slave8_9
  largest: 156 us from graphalytics-giraph-slave11_11
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_6
  largest: 0 bytes from graphalytics-giraph-slave9_6
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_6
  largest: 0 bytes from graphalytics-giraph-slave9_6
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave9_6
  largest: 100.0 % from graphalytics-giraph-slave9_6
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:31 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:31 +0000 2018
LogLength:51584
Log Contents:
2018-08-08 13:58:00,421 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,485 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,486 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,487 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,487 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,657 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:00,870 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:01,049 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,504 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,516 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,663 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,676 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,703 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,704 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceMaster (master thread)...
INFO    2018-08-08 13:58:01,713 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,719 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,719 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 0 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave14
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000002:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000002/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000002:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000002/tmp
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,725 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000002
INFO    2018-08-08 13:58:01,726 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.master.BspServiceMaster@7a11c4c7
INFO    2018-08-08 13:58:01,737 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,738 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,745 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300ad, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,746 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:01,753 [main] org.apache.giraph.graph.GraphTaskManager  - map: No need to do anything when not a worker
INFO    2018-08-08 13:58:01,753 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for MASTER_ONLY
INFO    2018-08-08 13:58:01,778 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - becomeMaster: First child is '/_hadoopBsp/job_1533735211869_0013/_masterElectionDir/graphalytics-giraph-slave14_00000000000' and my bid is '/_hadoopBsp/job_1533735211869_0013/_masterElectionDir/graphalytics-giraph-slave14_00000000000'
INFO    2018-08-08 13:58:01,829 [main-EventThread] org.apache.giraph.bsp.BspService  - process: applicationAttemptChanged signaled
INFO    2018-08-08 13:58:01,887 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:01,904 [org.apache.giraph.master.MasterThread] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:01,962 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave14/10.164.0.16:30000 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:01,967 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:01,969 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:01,971 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - becomeMaster: I am now the master!
INFO    2018-08-08 13:58:01,973 [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,231 [org.apache.giraph.master.MasterThread] org.apache.giraph.io.formats.GiraphFileInputFormat  - Total input paths to process : 1
INFO    2018-08-08 13:58:02,244 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - generateVERTEXInputSplits: Got 1 input splits for 143 input threads
WARN    2018-08-08 13:58:02,244 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - createVERTEXInputSplits: Number of inputSplits=1 < 143=total number of input threads, some threads will be not used
INFO    2018-08-08 13:58:02,261 [org.apache.giraph.master.MasterThread] org.apache.giraph.io.formats.GiraphFileInputFormat  - Total input paths to process : 1
INFO    2018-08-08 13:58:02,268 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - generateEDGEInputSplits: Got 6 input splits for 143 input threads
WARN    2018-08-08 13:58:02,268 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - createEDGEInputSplits: Number of inputSplits=6 < 143=total number of input threads, some threads will be not used
INFO    2018-08-08 13:58:02,294 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,296 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,296 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,297 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,299 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,299 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,299 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,299 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,299 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,300 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,300 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,300 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,300 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,304 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,305 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - computePartitionCount: Creating 429 partitions.
INFO    2018-08-08 13:58:02,320 [org.apache.giraph.master.MasterThread] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.timeout is deprecated. Instead, use mapreduce.task.timeout
INFO    2018-08-08 13:58:02,321 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep -1 on path /_hadoopBsp/job_1533735211869_0013/_inputSplitsWorkerDoneDir
INFO    2018-08-08 13:58:02,408 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,409 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,418 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,422 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,426 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,427 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,427 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,427 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,430 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,520 [netty-server-worker-2] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0003, ave received req MBytes = 0.0003, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:12,358 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep -1 on path /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerFinishedDir
INFO    2018-08-08 13:58:12,480 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) on superstep = -1
INFO    2018-08-08 13:58:12,484 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep -1 took 10.215 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 0
WARN    2018-08-08 13:58:12,494 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,542 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,543 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:58:12,545 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010):(v=4791, e=8159298),Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007):(v=4745, e=7853493),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008):(v=4766, e=7716417),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=6, port=30006):(v=4794, e=8081345),Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=13, port=30013):(v=4675, e=7785219),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005):(v=4582, e=7675535),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=11, port=30011):(v=4658, e=7783058),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002):(v=4566, e=7402196),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=12, port=30012):(v=4645, e=7788721),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=9, port=30009):(v=4767, e=8008528),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=1, port=30001):(v=4703, e=7730802),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003):(v=4802, e=7821385),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=4, port=30004):(v=4676, e=7934629),]
INFO    2018-08-08 13:58:12,545 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 4705, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002) - 4566, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003) - 4802
INFO    2018-08-08 13:58:12,545 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 7826202, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002) - 7402196, Max: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010) - 8159298
INFO    2018-08-08 13:58:12,557 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 0 on path /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerFinishedDir
INFO    2018-08-08 13:58:13,956 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) on superstep = 0
INFO    2018-08-08 13:58:13,959 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 0 took 1.474 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 1
INFO    2018-08-08 13:58:13,989 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,989 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:58:13,989 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010):(v=4791, e=8159298),Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007):(v=4745, e=7853493),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008):(v=4766, e=7716417),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=6, port=30006):(v=4794, e=8081345),Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=13, port=30013):(v=4675, e=7785219),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005):(v=4582, e=7675535),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=11, port=30011):(v=4658, e=7783058),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002):(v=4566, e=7402196),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=12, port=30012):(v=4645, e=7788721),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=9, port=30009):(v=4767, e=8008528),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003):(v=4802, e=7821385),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=1, port=30001):(v=4703, e=7730802),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=4, port=30004):(v=4676, e=7934629),]
INFO    2018-08-08 13:58:13,989 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 4705, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002) - 4566, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003) - 4802
INFO    2018-08-08 13:58:13,989 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 7826202, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002) - 7402196, Max: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010) - 8159298
INFO    2018-08-08 13:58:13,995 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 1 on path /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerFinishedDir
INFO    2018-08-08 13:58:14,641 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) on superstep = 1
INFO    2018-08-08 13:58:14,644 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0
INFO    2018-08-08 13:58:14,708 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 1 took 0.749 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 2
INFO    2018-08-08 13:58:14,725 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,725 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:58:14,725 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010):(v=4791, e=8159298),Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007):(v=4745, e=7853493),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008):(v=4766, e=7716417),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=6, port=30006):(v=4794, e=8081345),Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=13, port=30013):(v=4675, e=7785219),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005):(v=4582, e=7675535),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=11, port=30011):(v=4658, e=7783058),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002):(v=4566, e=7402196),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=12, port=30012):(v=4645, e=7788721),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=9, port=30009):(v=4767, e=8008528),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=1, port=30001):(v=4703, e=7730802),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003):(v=4802, e=7821385),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=4, port=30004):(v=4676, e=7934629),]
INFO    2018-08-08 13:58:14,726 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 4705, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002) - 4566, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003) - 4802
INFO    2018-08-08 13:58:14,726 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 7826202, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002) - 7402196, Max: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010) - 8159298
INFO    2018-08-08 13:58:14,731 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 2 on path /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerFinishedDir
INFO    2018-08-08 13:58:14,871 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) on superstep = 2
INFO    2018-08-08 13:58:14,875 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1
INFO    2018-08-08 13:58:14,941 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 2 took 0.232 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 3
INFO    2018-08-08 13:58:14,960 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,960 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:58:14,960 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010):(v=4791, e=8159298),Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007):(v=4745, e=7853493),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008):(v=4766, e=7716417),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=6, port=30006):(v=4794, e=8081345),Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=13, port=30013):(v=4675, e=7785219),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=5, port=30005):(v=4582, e=7675535),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=11, port=30011):(v=4658, e=7783058),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002):(v=4566, e=7402196),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=12, port=30012):(v=4645, e=7788721),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=9, port=30009):(v=4767, e=8008528),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=1, port=30001):(v=4703, e=7730802),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003):(v=4802, e=7821385),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=4, port=30004):(v=4676, e=7934629),]
INFO    2018-08-08 13:58:14,960 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 4705, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002) - 4566, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003) - 4802
INFO    2018-08-08 13:58:14,960 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 7826202, Min: Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002) - 7402196, Max: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010) - 8159298
INFO    2018-08-08 13:58:14,966 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 3 on path /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerFinishedDir
INFO    2018-08-08 13:58:15,009 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) on superstep = 3
INFO    2018-08-08 13:58:15,011 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2
INFO    2018-08-08 13:58:15,079 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 3 took 0.138 seconds ended with state ALL_SUPERSTEPS_DONE and is now on superstep 4
INFO    2018-08-08 13:58:15,081 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - setJobState: {"_applicationAttemptKey":-1,"_stateKey":"FINISHED","_superstepKey":-1} on superstep 4
INFO    2018-08-08 13:58:15,083 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - setJobState: {"_applicationAttemptKey":-1,"_stateKey":"FINISHED","_superstepKey":-1}
INFO    2018-08-08 13:58:15,089 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/0_master
INFO    2018-08-08 13:58:15,090 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Node /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir already exists, no need to create.
INFO    2018-08-08 13:58:15,091 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 1 of 14 desired children from /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir
INFO    2018-08-08 13:58:15,091 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir to change since only got 1 nodes.
INFO    2018-08-08 13:58:17,584 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:58:17,587 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 7 of 14 desired children from /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir
INFO    2018-08-08 13:58:17,587 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir to change since only got 7 nodes.
INFO    2018-08-08 13:58:17,588 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:58:17,593 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 14 of 14 desired children from /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir
INFO    2018-08-08 13:58:17,593 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanupZooKeeper: Removing the following path and all children - /_hadoopBsp/job_1533735211869_0013 from ZooKeeper list graphalytics-giraph:2181
INFO    2018-08-08 13:58:17,705 [main-EventThread] org.apache.giraph.bsp.BspService  - process: masterElectionChildrenChanged signaled
INFO    2018-08-08 13:58:17,714 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:58:17,776 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanup: Removed HDFS checkpoint directory (_bsp/_checkpoints//job_1533735211869_0013) with return = false since the job GraphalyticsBenchmark: WeaklyConnectedComponentsJob succeeded 
INFO    2018-08-08 13:58:17,776 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:17,777 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:19,981 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:19,981 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:19,984 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:24,196 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:24,199 [org.apache.giraph.master.MasterThread] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300ad closed
INFO    2018-08-08 13:58:24,199 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:24,199 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - setup: Took 0.064 seconds.
INFO    2018-08-08 13:58:24,199 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - input superstep: Took 10.215 seconds.
INFO    2018-08-08 13:58:24,199 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 0: Took 1.474 seconds.
INFO    2018-08-08 13:58:24,199 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 1: Took 0.749 seconds.
INFO    2018-08-08 13:58:24,199 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 2: Took 0.232 seconds.
INFO    2018-08-08 13:58:24,199 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 3: Took 0.138 seconds.
INFO    2018-08-08 13:58:24,199 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - shutdown: Took 9.12 seconds.
INFO    2018-08-08 13:58:24,199 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - total: Took 21.994 seconds.
INFO    2018-08-08 13:58:24,199 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Joined with master thread
INFO    2018-08-08 13:58:24,203 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000000_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:24,233 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000000_0' done.
INFO    2018-08-08 13:58:24,238 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000000_0: Counters: 49
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128638
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=98
		CPU time spent (ms)=4970
		Physical memory (bytes) snapshot=1088458752
		Virtual memory (bytes) snapshot=58910306304
		Total committed heap usage (bytes)=55163486208
	Giraph Stats
		Aggregate bytes loaded from local disks (out-of-core)=0
		Aggregate bytes stored to local disks (out-of-core)=0
		Aggregate edges=101740626
		Aggregate finished vertices=61170
		Aggregate sent message bytes=1627497029
		Aggregate sent messages=201014595
		Aggregate vertices=61170
		Current master task partition=0
		Current workers=13
		Last checkpointed superstep=0
		Lowest percentage of graph in memory so far (out-of-core)=100
		Sent message bytes=0
		Sent messages=0
		Superstep=4
	Giraph Timers
		Initialize (ms)=453
		Input superstep (ms)=10215
		Setup (ms)=64
		Shutdown (ms)=9120
		Superstep 0 UndirectedWeaklyConnectedComponentsComputation (ms)=1474
		Superstep 1 UndirectedWeaklyConnectedComponentsComputation (ms)=749
		Superstep 2 UndirectedWeaklyConnectedComponentsComputation (ms)=232
		Superstep 3 UndirectedWeaklyConnectedComponentsComputation (ms)=138
		Total (ms)=21994
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000004 on graphalytics-giraph-slave15_37797
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:19981
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10500 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 339 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 118,624,796.00
               min = 16.00
               max = 303744.00
              mean = 144312.40
            stddev = 68305.62
            median = 164317.00
              75% <= 182656.00
              95% <= 238976.00
              98% <= 238976.00
              99% <= 238976.00
            99.9% <= 303744.00
             count = 822

  remote-requests:
    count = 0

  requests-received:
             count = 822
         mean rate = 78.17 requests/s
     1-minute rate = 71.93 requests/s
     5-minute rate = 70.87 requests/s
    15-minute rate = 70.69 requests/s

  requests-sent:
             count = 327
         mean rate = 31.10 requests/s
     1-minute rate = 31.16 requests/s
     5-minute rate = 31.35 requests/s
    15-minute rate = 31.38 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 8,216.00
               min = 16.00
               max = 1473.00
              mean = 25.13
            stddev = 81.73
            median = 16.00
              75% <= 16.00
              95% <= 53.00
              98% <= 89.00
              99% <= 89.00
            99.9% <= 1473.00
             count = 327

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 10500

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 339

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1430 ms
  compute all partitions: 912 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 908 ms
  time to first message: 409098 us
  wait on requests time: 404477 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 908

  compute-all-ms:
    value = 912

  compute-per-partition-ms:
               sum = 4,579.00
               min = 11.00
               max = 446.00
              mean = 138.76
            stddev = 141.77
            median = 55.00
              75% <= 305.00
              95% <= 357.10
              98% <= 446.00
              99% <= 446.00
            99.9% <= 446.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 59898421

  messages-sent:
    count = 7400349

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.560137457044673

  processing-per-thread-ms:
               sum = 4,579.00
               min = 333.00
               max = 777.00
              mean = 416.27
            stddev = 121.30
            median = 383.00
              75% <= 398.00
              95% <= 777.00
              98% <= 777.00
              99% <= 777.00
            99.9% <= 777.00
             count = 11

  received-bytes:
               sum = 55,568,236.00
               min = 16.00
               max = 386432.00
              mean = 74588.24
            stddev = 90232.42
            median = 37701.00
              75% <= 131072.00
              95% <= 239360.00
              98% <= 319953.92
              99% <= 349670.40
            99.9% <= 386432.00
             count = 745

  remote-requests:
    count = 269

  requests-received:
             count = 745
         mean rate = 510.16 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 590
         mean rate = 404.04 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 55,548,340.00
               min = 16.00
               max = 525489.00
              mean = 94149.73
            stddev = 176222.65
            median = 20.50
              75% <= 487.25
              95% <= 436581.40
              98% <= 513821.32
              99% <= 523814.68
            99.9% <= 525489.00
             count = 590

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 1430

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 3827

  time-to-first-message-ms:
    value = 409098

  total-requests:
    value = 291

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 404477

  worker-context-post-superstep:
    value = 10

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 651 ms
  compute all partitions: 465 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 324 ms
  time to first message: 291284 us
  wait on requests time: 150849 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 324

  compute-all-ms:
    value = 465

  compute-per-partition-ms:
               sum = 3,052.00
               min = 11.00
               max = 228.00
              mean = 92.48
            stddev = 89.99
            median = 39.00
              75% <= 210.00
              95% <= 222.40
              98% <= 228.00
              99% <= 228.00
            99.9% <= 228.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 57772599

  messages-sent:
    count = 7134955

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 3,052.00
               min = 241.00
               max = 354.00
              mean = 277.45
            stddev = 30.72
            median = 273.00
              75% <= 289.00
              95% <= 354.00
              98% <= 354.00
              99% <= 354.00
            99.9% <= 354.00
             count = 11

  received-bytes:
               sum = 54,227,677.00
               min = 16.00
               max = 375552.00
              mean = 91911.32
            stddev = 106681.37
            median = 46053.00
              75% <= 191104.00
              95% <= 300045.60
              98% <= 324326.40
              99% <= 368972.80
            99.9% <= 375552.00
             count = 590

  remote-requests:
    count = 276

  requests-received:
             count = 590
         mean rate = 864.14 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 598
         mean rate = 875.92 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 53,579,548.00
               min = 16.00
               max = 525961.00
              mean = 89597.91
            stddev = 170989.20
            median = 53.00
              75% <= 568.75
              95% <= 461066.80
              98% <= 524346.68
              99% <= 525325.68
            99.9% <= 525961.00
             count = 598

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 651

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 748

  time-to-first-message-ms:
    value = 291284

  total-requests:
    value = 299

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 150849

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 195 ms
  compute all partitions: 111 ms
  time spent in gc: 67 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 221 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 111

  compute-per-partition-ms:
               sum = 170.00
               min = 1.00
               max = 15.00
              mean = 5.15
            stddev = 3.71
            median = 4.00
              75% <= 8.50
              95% <= 12.90
              98% <= 15.00
              99% <= 15.00
            99.9% <= 15.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 151366

  messages-sent:
    count = 11789

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 148.00
               min = 7.00
               max = 19.00
              mean = 13.45
            stddev = 4.08
            median = 14.00
              75% <= 17.00
              95% <= 19.00
              98% <= 19.00
              99% <= 19.00
            99.9% <= 19.00
             count = 11

  received-bytes:
               sum = 153,548.00
               min = 16.00
               max = 13642.00
              mean = 783.41
            stddev = 2843.79
            median = 32.00
              75% <= 53.00
              95% <= 11323.00
              98% <= 11956.32
              99% <= 12211.25
            99.9% <= 13642.00
             count = 196

  remote-requests:
    count = 264

  requests-received:
             count = 196
         mean rate = 864.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 548
         mean rate = 2417.94 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 147,710.00
               min = 16.00
               max = 1493.00
              mean = 269.54
            stddev = 360.51
            median = 88.00
              75% <= 380.00
              95% <= 1047.60
              98% <= 1305.00
              99% <= 1467.12
            99.9% <= 1493.00
             count = 548

  superstep-gc-time-ms:
    count = 67

  superstep-time-ms:
    value = 195

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 13

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 286

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 221

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 107 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 219 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 34.00
               min = 0.00
               max = 2.00
              mean = 1.03
            stddev = 0.53
            median = 1.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 33.00
               min = 0.00
               max = 6.00
              mean = 3.00
            stddev = 1.79
            median = 3.00
              75% <= 4.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 904.77
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 387.65 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 387.64 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 107

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 219

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 97.71236265372765

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:68277
Log Contents:
2018-08-08 13:58:00,368 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,428 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,428 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,430 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,430 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,597 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:00,829 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:01,038 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,511 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,523 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,677 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,693 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,722 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,722 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,730 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,737 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,737 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 2 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,743 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,743 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave15
INFO    2018-08-08 13:58:01,743 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,744 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,744 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,744 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000004:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000004/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,744 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000004:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,744 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000004/tmp
INFO    2018-08-08 13:58:01,744 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,744 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,744 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,744 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,744 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,744 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,744 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000004
INFO    2018-08-08 13:58:01,745 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,758 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,759 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,765 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300ae, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,767 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:01,877 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:01,894 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:01,952 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave15/10.164.0.17:30002 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:01,958 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:01,958 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:01,980 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:01,990 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:01,993 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:01,996 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,002 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave15_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002)
INFO    2018-08-08 13:58:02,301 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,395 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,404 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,405 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,406 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,407 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,408 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,410 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,418 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,422 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,422 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,425 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,427 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,428 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,430 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,430 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,430 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,430 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,494 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,549 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0446894 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,549 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047793247 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,549 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05451336 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,551 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045951594 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04566294 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045131925 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04453113 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043216847 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042041905 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,554 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0422451 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,554 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04140265 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,555 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0028, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.125
MBytes/sec sent = 0.0102, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.126
INFO    2018-08-08 13:58:02,556 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,560 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003314357 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,562 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003850369 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,562 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003234875 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,562 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002908055 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,564 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.50771E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003869212 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003272472 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0044804 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.007555997 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,570 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00571463 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,570 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004150979 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,571 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:58:02,571 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:58:12,354 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,358 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,405 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,410 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50226.27M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,410 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 9.844
MBytes/sec sent = 0, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 9.844
INFO    2018-08-08 13:58:12,410 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,425 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 0 more aggregator requests
INFO    2018-08-08 13:58:12,431 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:58:12,432 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50226.27M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,445 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,482 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,487 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@39ab59f8,outgoing=org.apache.giraph.conf.DefaultMessageClasses@64e92d61)
WARN    2018-08-08 13:58:12,492 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,508 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,508 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,511 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave15_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002)
INFO    2018-08-08 13:58:12,550 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,551 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,551 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,552 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.12
MBytes/sec sent = 0.0116, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.12
INFO    2018-08-08 13:58:12,556 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,560 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,562 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:58:12,565 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 10 more tasks to send their aggregator data, task ids: [3, 4, 5, 6, 7, 8, 9, 10, 12, 13]
INFO    2018-08-08 13:58:12,576 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,925 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.33850685 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.33 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,952 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3595202 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.36 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,961 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3829935 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.38 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,966 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.38734472 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.38 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,966 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.38108742 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.38 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,970 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.38669097 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.38 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,982 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3987053 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.40 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,986 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.40521756 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.40 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,991 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.39774826 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.40 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,992 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.4014188 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.40 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,370 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.7779555 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.78 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,489 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 49597.16M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,894 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0042, MBytesReceived = 0.0041, ave received req MBytes = 0, secs waited = 0.966
MBytes/sec sent = 54.775, MBytesSent = 52.9675, ave sent req MBytes = 0.1969, secs waited = 0.966
INFO    2018-08-08 13:58:13,894 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,933 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:58:13,934 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 7400349 , message bytes = 59898421 , Memory (free/total/max) = 49584.26M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,939 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,957 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,958 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@127d7908,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6b9c69a9)
INFO    2018-08-08 13:58:13,967 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,969 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave15_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002)
INFO    2018-08-08 13:58:13,992 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,993 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,993 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,994 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0003, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.06
MBytes/sec sent = 0.023, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.06
INFO    2018-08-08 13:58:13,996 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:13,999 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,253 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2422016 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.24 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,259 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2593946 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,263 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2612233 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,269 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.26826265 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.27 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,277 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2590537 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.25 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,283 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2737598 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.27 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,286 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.27533287 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.27 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,291 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.28291172 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,301 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.29104385 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,312 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3045538 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.30 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,361 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.35907876 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.35 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,465 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 48780.38M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,616 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0117, MBytesReceived = 0.0042, ave received req MBytes = 0, secs waited = 0.358
MBytes/sec sent = 142.3116, MBytesSent = 51.0899, ave sent req MBytes = 0.1851, secs waited = 0.358
INFO    2018-08-08 13:58:14,616 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,618 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0661, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.2101, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,618 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7134955 , message bytes = 57772599 , Memory (free/total/max) = 48751.77M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,620 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,642 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,644 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4bd2f0dc,outgoing=org.apache.giraph.conf.DefaultMessageClasses@2e647e59)
INFO    2018-08-08 13:58:14,652 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,666 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave15_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002)
WARN    2018-08-08 13:58:14,705 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,727 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,727 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,727 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,728 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.11
MBytes/sec sent = 0.0127, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.11
INFO    2018-08-08 13:58:14,730 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,731 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,733 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,823 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0896267 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,825 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.018585498 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,827 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012034882 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,827 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017045548 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,832 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017535709 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,832 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.09598944 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,834 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017355382 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,835 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.016982688 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,835 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.020602956 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,835 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.027675312 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,837 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.021006469 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,845 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 51724.56M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,845 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.1918, MBytesReceived = 0.004, ave received req MBytes = 0, secs waited = 0.02
MBytes/sec sent = 6.3751, MBytesSent = 0.1339, ave sent req MBytes = 0.0005, secs waited = 0.02
INFO    2018-08-08 13:58:14,845 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,847 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0661, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.2101, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,848 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 11789 , message bytes = 151366 , Memory (free/total/max) = 51724.56M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,853 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 67ms
INFO    2018-08-08 13:58:14,853 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,873 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,876 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:58:14,881 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,896 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave15_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=2, port=30002)
INFO    2018-08-08 13:58:14,902 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,938 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,962 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,962 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,962 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,963 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.115
MBytes/sec sent = 0.0121, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.115
INFO    2018-08-08 13:58:14,965 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,968 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,971 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,979 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004453875 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003777194 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002729236 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0023613 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006717063 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00350939 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005751554 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002260089 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004629575 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005495705 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007691071 secs for 7 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 51590.16M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,988 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,988 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 51590.16M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,993 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,009 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,011 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:58:15,015 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,015 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,015 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,022 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,038 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,075 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,080 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,082 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,326 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,327 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4566 vertices using 1 threads
INFO    2018-08-08 13:58:17,330 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,582 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,583 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,586 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/2_worker
INFO    2018-08-08 13:58:17,592 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300ae closed
INFO    2018-08-08 13:58:17,592 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,594 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,597 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,807 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,811 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000002_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,834 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000002_0 is allowed to commit now
INFO    2018-08-08 13:58:21,843 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000002_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000002
INFO    2018-08-08 13:58:21,871 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000002_0' done.
INFO    2018-08-08 13:58:21,876 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000002_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128638
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=39878
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=163
		CPU time spent (ms)=24250
		Physical memory (bytes) snapshot=3275366400
		Virtual memory (bytes) snapshot=58921521152
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000012 on graphalytics-giraph-slave1_33157
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:19966
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10319 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 418 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 130,750,488.00
               min = 16.00
               max = 247424.00
              mean = 148075.30
            stddev = 66350.37
            median = 164509.00
              75% <= 191104.00
              95% <= 238976.00
              98% <= 238976.00
              99% <= 238976.00
            99.9% <= 247424.00
             count = 883

  remote-requests:
    count = 0

  requests-received:
             count = 883
         mean rate = 85.42 requests/s
     1-minute rate = 80.16 requests/s
     5-minute rate = 79.40 requests/s
    15-minute rate = 79.27 requests/s

  requests-sent:
             count = 350
         mean rate = 33.86 requests/s
     1-minute rate = 33.88 requests/s
     5-minute rate = 34.13 requests/s
    15-minute rate = 34.18 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 8,584.00
               min = 16.00
               max = 1473.00
              mean = 24.53
            stddev = 79.02
            median = 16.00
              75% <= 16.00
              95% <= 53.00
              98% <= 89.00
              99% <= 89.00
            99.9% <= 1473.00
             count = 350

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 10319

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 418

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1430 ms
  compute all partitions: 858 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 621 ms
  time to first message: 442864 us
  wait on requests time: 205657 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 621

  compute-all-ms:
    value = 858

  compute-per-partition-ms:
               sum = 4,881.00
               min = 18.00
               max = 488.00
              mean = 147.91
            stddev = 129.66
            median = 66.00
              75% <= 230.50
              95% <= 486.60
              98% <= 488.00
              99% <= 488.00
            99.9% <= 488.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 25

  message-bytes-sent:
    count = 65990129

  messages-sent:
    count = 8157591

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 8.47457627118644

  processing-per-thread-ms:
               sum = 4,880.00
               min = 299.00
               max = 785.00
              mean = 443.64
            stddev = 197.72
            median = 347.00
              75% <= 679.00
              95% <= 785.00
              98% <= 785.00
              99% <= 785.00
            99.9% <= 785.00
             count = 11

  received-bytes:
               sum = 60,698,546.00
               min = 16.00
               max = 394240.00
              mean = 87210.55
            stddev = 105003.88
            median = 35136.00
              75% <= 149920.00
              95% <= 305235.20
              98% <= 376599.04
              99% <= 380725.76
            99.9% <= 394240.00
             count = 696

  remote-requests:
    count = 270

  requests-received:
             count = 696
         mean rate = 476.76 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 602
         mean rate = 412.39 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 60,712,367.00
               min = 16.00
               max = 528077.00
              mean = 100851.11
            stddev = 191298.67
            median = 16.00
              75% <= 510.00
              95% <= 507734.60
              98% <= 521028.84
              99% <= 524527.48
            99.9% <= 528077.00
             count = 602

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 1430

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 442864

  total-requests:
    value = 295

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 205657

  worker-context-post-superstep:
    value = 15

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 653 ms
  compute all partitions: 290 ms
  time spent in gc: 67 ms
  bytes transferred in out-of-core: 0
  network communication time: 328 ms
  time to first message: 146927 us
  wait on requests time: 183875 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 328

  compute-all-ms:
    value = 290

  compute-per-partition-ms:
               sum = 1,690.00
               min = 13.00
               max = 108.00
              mean = 51.21
            stddev = 39.09
            median = 31.00
              75% <= 97.50
              95% <= 104.50
              98% <= 108.00
              99% <= 108.00
            99.9% <= 108.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 24

  message-bytes-sent:
    count = 64780589

  messages-sent:
    count = 8006352

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.717041800643088

  processing-per-thread-ms:
               sum = 1,690.00
               min = 124.00
               max = 229.00
              mean = 153.64
            stddev = 32.43
            median = 142.00
              75% <= 161.00
              95% <= 229.00
              98% <= 229.00
              99% <= 229.00
            99.9% <= 229.00
             count = 11

  received-bytes:
               sum = 59,158,223.00
               min = 16.00
               max = 384896.00
              mean = 84391.19
            stddev = 97105.24
            median = 56320.00
              75% <= 141120.00
              95% <= 262144.00
              98% <= 324019.20
              99% <= 327680.00
            99.9% <= 384896.00
             count = 701

  remote-requests:
    count = 287

  requests-received:
             count = 701
         mean rate = 1025.70 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 612
         mean rate = 895.41 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 59,600,350.00
               min = 16.00
               max = 529801.00
              mean = 97386.19
            stddev = 184231.66
            median = 53.00
              75% <= 13083.00
              95% <= 502110.80
              98% <= 525674.92
              99% <= 526619.96
            99.9% <= 529801.00
             count = 612

  superstep-gc-time-ms:
    count = 67

  superstep-time-ms:
    value = 653

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 500

  time-to-first-message-ms:
    value = 146927

  total-requests:
    value = 311

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 183875

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 196 ms
  compute all partitions: 24 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 57927 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 24

  compute-per-partition-ms:
               sum = 66.00
               min = 1.00
               max = 8.00
              mean = 2.00
            stddev = 1.46
            median = 2.00
              75% <= 2.00
              95% <= 5.90
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 14

  message-bytes-sent:
    count = 158817

  messages-sent:
    count = 12698

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 66.00
               min = 0.00
               max = 15.00
              mean = 6.00
            stddev = 5.37
            median = 7.00
              75% <= 10.00
              95% <= 15.00
              98% <= 15.00
              99% <= 15.00
            99.9% <= 15.00
             count = 11

  received-bytes:
               sum = 165,991.00
               min = 16.00
               max = 7369.00
              mean = 592.83
            stddev = 1141.18
            median = 32.00
              75% <= 687.00
              95% <= 3024.25
              98% <= 4124.74
              99% <= 6623.09
            99.9% <= 7369.00
             count = 280

  remote-requests:
    count = 168

  requests-received:
             count = 280
         mean rate = 1232.27 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 460
         mean rate = 2024.66 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 84

  sent-bytes:
               sum = 154,042.00
               min = 16.00
               max = 1985.00
              mean = 334.87
            stddev = 521.89
            median = 16.00
              75% <= 451.00
              95% <= 1577.00
              98% <= 1755.24
              99% <= 1853.00
            99.9% <= 1985.00
             count = 460

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 196

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 13

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 182

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 57927

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 107 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 236 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 24.00
               min = 0.00
               max = 1.00
              mean = 0.73
            stddev = 0.45
            median = 1.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 24.00
               min = 0.00
               max = 4.00
              mean = 2.18
            stddev = 1.60
            median = 2.00
              75% <= 4.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.25
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 382.51 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 390.04 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.77
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 107

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 236

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 97.29506044202188

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:68291
Log Contents:
2018-08-08 13:58:00,523 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,594 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,594 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,596 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,596 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,779 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:01,011 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:01,215 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,687 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,699 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,857 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,872 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,902 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,903 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,912 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,919 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,919 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 10 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,925 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,925 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave1
INFO    2018-08-08 13:58:01,925 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,925 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,925 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,925 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000012:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000012/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,925 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000012:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,925 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000012/tmp
INFO    2018-08-08 13:58:01,925 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,925 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,926 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,926 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,926 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,926 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,926 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000012
INFO    2018-08-08 13:58:01,926 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,940 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,941 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,947 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300b4, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,948 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:02,061 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:02,078 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:02,133 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave1/10.164.0.3:30010 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:02,139 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:02,140 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:02,162 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:02,173 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:02,176 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,179 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,187 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave1_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010)
INFO    2018-08-08 13:58:02,308 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,397 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,407 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,409 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,410 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,410 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,411 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,412 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,418 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,418 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,424 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,428 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,429 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,430 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,431 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,497 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,550 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.052512184 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,550 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043419003 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,551 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042651415 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,550 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04494532 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,551 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042005725 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,551 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039966542 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,551 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041118983 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039949633 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039772686 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03961226 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,554 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039256588 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,557 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0034, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.049
MBytes/sec sent = 0.0052, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.051
INFO    2018-08-08 13:58:02,558 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,562 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00408544 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,563 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003643255 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,564 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00303268 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,564 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002642679 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004342405 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004383812 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001342168 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003360923 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002933293 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,569 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005249642 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,571 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003453611 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,571 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.014, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0219, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.011
INFO    2018-08-08 13:58:02,571 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:58:12,357 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,360 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,419 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,424 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50200.63M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,424 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 9.864
MBytes/sec sent = 0, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 9.864
INFO    2018-08-08 13:58:12,424 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,438 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:58:12,438 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50200.63M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,449 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,484 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,490 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@39ab59f8,outgoing=org.apache.giraph.conf.DefaultMessageClasses@64e92d61)
WARN    2018-08-08 13:58:12,494 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,511 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,511 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,514 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave1_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010)
INFO    2018-08-08 13:58:12,564 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,564 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,564 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,566 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.127
MBytes/sec sent = 0.011, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.127
INFO    2018-08-08 13:58:12,568 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,569 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,576 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 5 more tasks to send their aggregator data, task ids: [8, 9, 11, 12, 13]
INFO    2018-08-08 13:58:12,582 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,897 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3114159 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.31 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,908 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3104844 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.31 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,903 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.30090946 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.30 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,924 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.33909553 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.33 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,946 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3504152 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.35 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,959 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.35602382 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.35 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,951 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.35216007 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.35 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,947 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.34769723 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.34 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,272 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.68533266 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.68 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,376 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.7863481 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.78 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,378 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.79434705 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.79 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,441 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 49782.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,646 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0056, MBytesReceived = 0.0041, ave received req MBytes = 0, secs waited = 0.734
MBytes/sec sent = 78.7648, MBytesSent = 57.8921, ave sent req MBytes = 0.2144, secs waited = 0.734
INFO    2018-08-08 13:58:13,647 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,697 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 11 more tasks to send their aggregator data
INFO    2018-08-08 13:58:13,935 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:58:13,936 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 8157591 , message bytes = 65990129 , Memory (free/total/max) = 49382.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,941 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,959 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,961 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@127d7908,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6b9c69a9)
INFO    2018-08-08 13:58:13,968 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,970 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave1_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010)
INFO    2018-08-08 13:58:13,996 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,996 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,996 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.061
MBytes/sec sent = 0.0227, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.061
INFO    2018-08-08 13:58:13,999 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,000 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,002 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,132 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.12574635 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.12 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,137 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.1352206 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.13 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,139 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.12792718 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.13 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,144 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.1401632 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.14 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,146 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.13775635 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.14 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,152 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.14275505 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.14 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,156 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.15157641 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.15 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,160 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.15211874 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.15 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,165 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16242279 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.16 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,207 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2025743 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,240 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.23050903 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.23 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,293 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 48758.03M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,387 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 67ms
INFO    2018-08-08 13:58:14,477 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0125, MBytesReceived = 0.0042, ave received req MBytes = 0, secs waited = 0.336
MBytes/sec sent = 168.6252, MBytesSent = 56.8267, ave sent req MBytes = 0.2066, secs waited = 0.336
INFO    2018-08-08 13:58:14,477 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,620 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,621 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 8006352 , message bytes = 64780589 , Memory (free/total/max) = 51606.15M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,625 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,644 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,646 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4bd2f0dc,outgoing=org.apache.giraph.conf.DefaultMessageClasses@2e647e59)
INFO    2018-08-08 13:58:14,654 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,667 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave1_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010)
INFO    2018-08-08 13:58:14,674 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,707 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,730 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,730 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,730 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.109
MBytes/sec sent = 0.0128, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.109
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,733 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,736 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,746 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007429371 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,747 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009339586 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,746 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007159458 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,746 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008123083 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,750 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011410866 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,750 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013771562 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,751 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010727767 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,754 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015810218 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,754 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006466026 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,758 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002206995 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,760 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005147114 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,761 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 51499.01M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,819 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0361, MBytesReceived = 0.0026, ave received req MBytes = 0, secs waited = 0.071
MBytes/sec sent = 1.9416, MBytesSent = 0.1398, ave sent req MBytes = 0.0008, secs waited = 0.071
INFO    2018-08-08 13:58:14,819 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,850 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.0
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,850 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 12698 , message bytes = 158817 , Memory (free/total/max) = 51492.23M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,854 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,875 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,877 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:58:14,882 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,897 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave1_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=10, port=30010)
INFO    2018-08-08 13:58:14,905 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,940 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,965 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,965 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,965 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.115
MBytes/sec sent = 0.0121, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.115
INFO    2018-08-08 13:58:14,967 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,969 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,973 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,979 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001898844 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003186438 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004628383 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002544376 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004225887 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003878729 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003384855 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00605531 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004569023 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00126885 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002058751 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,983 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 51453.83M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,983 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:58:14,983 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,990 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,990 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 51453.83M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,992 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,011 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,013 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,019 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,040 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,078 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,082 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,085 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,323 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,323 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4791 vertices using 1 threads
INFO    2018-08-08 13:58:17,327 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,586 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,586 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,592 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/10_worker
INFO    2018-08-08 13:58:17,597 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300b4 closed
INFO    2018-08-08 13:58:17,597 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,599 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,603 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,815 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,817 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000010_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,840 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000010_0 is allowed to commit now
INFO    2018-08-08 13:58:21,851 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000010_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000010
INFO    2018-08-08 13:58:21,868 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000010_0' done.
INFO    2018-08-08 13:58:21,874 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000010_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128639
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=41858
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=160
		CPU time spent (ms)=28860
		Physical memory (bytes) snapshot=3568795648
		Virtual memory (bytes) snapshot=58929102848
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000010 on graphalytics-giraph-slave2_43787
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:20050
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10321 ms
  compute all partitions: 0 ms
  time spent in gc: 404 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 225 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 232

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.539811504712382

  received-bytes:
               sum = 2,814,309.00
               min = 16.00
               max = 122496.00
              mean = 942.50
            stddev = 8075.34
            median = 16.00
              75% <= 16.00
              95% <= 16.00
              98% <= 89.00
              99% <= 52687.36
            99.9% <= 89785.34
             count = 2986

  remote-requests:
    count = 2845

  requests-received:
             count = 2986
         mean rate = 288.94 requests/s
     1-minute rate = 247.72 requests/s
     5-minute rate = 240.80 requests/s
    15-minute rate = 239.60 requests/s

  requests-sent:
             count = 2958
         mean rate = 286.27 requests/s
     1-minute rate = 243.42 requests/s
     5-minute rate = 236.26 requests/s
    15-minute rate = 235.02 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 1,473,991,550.00
               min = 16.00
               max = 524573.00
              mean = 498306.81
            stddev = 110290.49
            median = 524573.00
              75% <= 524573.00
              95% <= 524573.00
              98% <= 524573.00
              99% <= 524573.00
            99.9% <= 524573.00
             count = 2958

  superstep-gc-time-ms:
    count = 404

  superstep-time-ms:
    value = 10321

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3077

  wait-requests-us:
    value = 225

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1436 ms
  compute all partitions: 813 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 999 ms
  time to first message: 267831 us
  wait on requests time: 453666 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 999

  compute-all-ms:
    value = 813

  compute-per-partition-ms:
               sum = 3,424.00
               min = 8.00
               max = 343.00
              mean = 103.76
            stddev = 107.21
            median = 26.00
              75% <= 225.50
              95% <= 265.30
              98% <= 343.00
              99% <= 343.00
            99.9% <= 343.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 62424296

  messages-sent:
    count = 7712501

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.718120805369128

  processing-per-thread-ms:
               sum = 3,423.00
               min = 251.00
               max = 585.00
              mean = 311.18
            stddev = 100.76
            median = 259.00
              75% <= 345.00
              95% <= 585.00
              98% <= 585.00
              99% <= 585.00
            99.9% <= 585.00
             count = 11

  received-bytes:
               sum = 57,715,155.00
               min = 16.00
               max = 389760.00
              mean = 69452.65
            stddev = 87651.07
            median = 28160.00
              75% <= 127360.00
              95% <= 241126.40
              98% <= 295792.64
              99% <= 350295.04
            99.9% <= 389760.00
             count = 831

  remote-requests:
    count = 275

  requests-received:
             count = 831
         mean rate = 567.00 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 598
         mean rate = 408.03 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 57,708,121.00
               min = 16.00
               max = 529977.00
              mean = 96501.87
            stddev = 182667.26
            median = 53.00
              75% <= 567.00
              95% <= 474646.40
              98% <= 524517.00
              99% <= 526343.76
            99.9% <= 529977.00
             count = 598

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 1436

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 870

  time-to-first-message-ms:
    value = 267831

  total-requests:
    value = 298

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 453666

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 655 ms
  compute all partitions: 317 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 249 ms
  time to first message: 188432 us
  wait on requests time: 120829 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 249

  compute-all-ms:
    value = 317

  compute-per-partition-ms:
               sum = 2,083.00
               min = 8.00
               max = 151.00
              mean = 63.12
            stddev = 61.04
            median = 25.00
              75% <= 142.50
              95% <= 149.60
              98% <= 151.00
              99% <= 151.00
            99.9% <= 151.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 60851942

  messages-sent:
    count = 7516010

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 2,080.00
               min = 165.00
               max = 265.00
              mean = 189.09
            stddev = 29.44
            median = 174.00
              75% <= 202.00
              95% <= 265.00
              98% <= 265.00
              99% <= 265.00
            99.9% <= 265.00
             count = 11

  received-bytes:
               sum = 56,272,805.00
               min = 16.00
               max = 370816.00
              mean = 81319.08
            stddev = 94057.72
            median = 41472.00
              75% <= 151741.75
              95% <= 239360.00
              98% <= 262144.00
              99% <= 324789.76
            99.9% <= 370816.00
             count = 692

  remote-requests:
    count = 276

  requests-received:
             count = 692
         mean rate = 1012.52 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 600
         mean rate = 877.93 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 56,254,876.00
               min = 16.00
               max = 527833.00
              mean = 93758.13
            stddev = 176731.86
            median = 53.00
              75% <= 624.00
              95% <= 452053.60
              98% <= 523389.16
              99% <= 525800.44
            99.9% <= 527833.00
             count = 600

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 655

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 358

  time-to-first-message-ms:
    value = 188432

  total-requests:
    value = 299

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 120829

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 199 ms
  compute all partitions: 28 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 53064 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 28

  compute-per-partition-ms:
               sum = 75.00
               min = 1.00
               max = 10.00
              mean = 2.27
            stddev = 1.94
            median = 2.00
              75% <= 2.00
              95% <= 8.60
              98% <= 10.00
              99% <= 10.00
            99.9% <= 10.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 20

  message-bytes-sent:
    count = 162070

  messages-sent:
    count = 12494

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 75.00
               min = 0.00
               max = 15.00
              mean = 6.82
            stddev = 4.29
            median = 6.00
              75% <= 9.00
              95% <= 15.00
              98% <= 15.00
              99% <= 15.00
            99.9% <= 15.00
             count = 11

  received-bytes:
               sum = 155,345.00
               min = 16.00
               max = 6653.00
              mean = 442.58
            stddev = 909.66
            median = 16.00
              75% <= 426.00
              95% <= 2348.80
              98% <= 3647.88
              99% <= 4355.08
            99.9% <= 6653.00
             count = 351

  remote-requests:
    count = 240

  requests-received:
             count = 351
         mean rate = 1526.60 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 526
         mean rate = 2287.89 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 120

  sent-bytes:
               sum = 157,978.00
               min = 16.00
               max = 1669.00
              mean = 300.34
            stddev = 409.48
            median = 53.00
              75% <= 469.00
              95% <= 1255.60
              98% <= 1506.76
              99% <= 1632.36
            99.9% <= 1669.00
             count = 526

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 199

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 50

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 260

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 53064

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 107 ms
  compute all partitions: 6 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 184 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 6

  compute-per-partition-ms:
               sum = 21.00
               min = 0.00
               max = 1.00
              mean = 0.64
            stddev = 0.49
            median = 1.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 21.00
               min = 0.00
               max = 4.00
              mean = 1.91
            stddev = 1.51
            median = 2.00
              75% <= 3.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.16
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 382.47 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 389.85 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.68
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 107

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 184

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 93.87456545494247

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = 0.0

  edges-loaded:
             count = 99625100
         mean rate = 6333273.50 edges/s
     1-minute rate = 6878860.44 edges/s
     5-minute rate = 6980728.39 edges/s
    15-minute rate = 6993875.50 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:95020
Log Contents:
2018-08-08 13:58:00,505 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,571 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,571 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,573 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,573 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,757 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:00,997 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:01,189 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,661 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,673 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,828 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,845 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,875 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,876 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,885 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,892 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,892 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 8 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,898 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,898 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave2
INFO    2018-08-08 13:58:01,898 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,898 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,898 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,898 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000010:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000010/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,898 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000010:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,898 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000010/tmp
INFO    2018-08-08 13:58:01,898 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,898 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,899 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,899 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,899 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,899 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,899 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000010
INFO    2018-08-08 13:58:01,899 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,913 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,914 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,920 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300b3, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,921 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:02,046 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:02,064 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:02,133 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave2/10.164.0.4:30008 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:02,138 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:02,139 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:02,161 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:02,172 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:02,176 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,179 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,185 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave2_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008)
INFO    2018-08-08 13:58:02,309 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,398 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,408 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,410 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,411 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,412 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,418 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,418 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,421 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,422 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,425 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,426 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,428 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,432 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,500 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,539 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038909063 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,539 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0325542 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,539 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03191854 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,539 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031225223 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,540 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030460607 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,540 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028192747 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,541 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028751908 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,542 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.027768197 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,542 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.027104516 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,544 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.027303113 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,545 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.026831456 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,545 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.003, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.117
MBytes/sec sent = 0.0109, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.117
INFO    2018-08-08 13:58:02,546 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,552 [load-0] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/dota-league.e:0+134217728'
INFO    2018-08-08 13:58:02,554 [load-1] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/dota-league.e:134217728+134217728'
INFO    2018-08-08 13:58:02,554 [load-2] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/dota-league.e:268435456+134217728'
INFO    2018-08-08 13:58:02,556 [load-3] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/dota-league.e:402653184+134217728'
INFO    2018-08-08 13:58:02,557 [load-4] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/dota-league.e:536870912+134217728'
INFO    2018-08-08 13:58:02,557 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005112866 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,561 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006585323 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,566 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.007999486 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003945275 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,569 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003993467 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,570 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004109282 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:03,502 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 54ms
INFO    2018-08-08 13:58:03,624 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 1000000 edges at 569036.1237537849 edges/sec Memory (free/total/max) = 51454.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:03,625 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 2000000 edges at 1136730.7267592303 edges/sec Memory (free/total/max) = 51433.49M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:03,634 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 3000000 edges at 1696280.8935673693 edges/sec Memory (free/total/max) = 51401.74M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:03,636 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 4000000 edges at 2258530.9275365532 edges/sec Memory (free/total/max) = 51391.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:03,696 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 5000000 edges at 2730881.5102272863 edges/sec Memory (free/total/max) = 51285.35M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:04,365 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 6000000 edges at 2400650.2900710944 edges/sec Memory (free/total/max) = 48690.46M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:04,366 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 7000000 edges at 2799118.144546444 edges/sec Memory (free/total/max) = 48679.70M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:04,369 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 8000000 edges at 3194849.595746096 edges/sec Memory (free/total/max) = 48669.34M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:04,387 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 9000000 edges at 3569165.499553514 edges/sec Memory (free/total/max) = 48552.21M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:04,564 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 150ms
INFO    2018-08-08 13:58:04,667 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 10000000 edges at 3569232.8584070927 edges/sec Memory (free/total/max) = 51546.07M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,054 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 11000000 edges at 3449765.9111319394 edges/sec Memory (free/total/max) = 49434.45M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,064 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 12000000 edges at 3752083.204668798 edges/sec Memory (free/total/max) = 49376.44M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,065 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 13000000 edges at 4063264.468926035 edges/sec Memory (free/total/max) = 49376.44M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,100 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 14000000 edges at 4328233.989008885 edges/sec Memory (free/total/max) = 49144.41M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,121 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 15000000 edges at 4607047.442919698 edges/sec Memory (free/total/max) = 48993.61M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,227 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 20ms
INFO    2018-08-08 13:58:05,493 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 16000000 edges at 4410192.850726668 edges/sec Memory (free/total/max) = 50713.74M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,515 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 17000000 edges at 4657991.661356488 edges/sec Memory (free/total/max) = 50541.67M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,548 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 18000000 edges at 4887861.404663802 edges/sec Memory (free/total/max) = 50320.50M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,588 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 19000000 edges at 5103658.220984052 edges/sec Memory (free/total/max) = 49944.74M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,592 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 20000000 edges at 5366411.36061214 edges/sec Memory (free/total/max) = 49920.43M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,823 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 25ms
INFO    2018-08-08 13:58:05,888 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 21000000 edges at 5220444.72885118 edges/sec Memory (free/total/max) = 51719.40M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,902 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 22000000 edges at 5449722.973067851 edges/sec Memory (free/total/max) = 51601.70M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,933 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 23000000 edges at 5654415.205332574 edges/sec Memory (free/total/max) = 51375.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:05,988 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 24000000 edges at 5822270.320849119 edges/sec Memory (free/total/max) = 50981.42M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:06,011 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 25000000 edges at 6030875.884949891 edges/sec Memory (free/total/max) = 50837.35M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:06,271 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 26000000 edges at 5901446.72223199 edges/sec Memory (free/total/max) = 48885.78M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:06,302 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 27000000 edges at 6086344.786458933 edges/sec Memory (free/total/max) = 48689.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:06,326 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 28000000 edges at 6277642.657797212 edges/sec Memory (free/total/max) = 48486.49M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:06,378 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 35ms
INFO    2018-08-08 13:58:06,424 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 29000000 edges at 6362268.8162920475 edges/sec Memory (free/total/max) = 52016.83M / 52732.50M / 52732.50M
INFO    2018-08-08 13:58:06,445 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 30000000 edges at 6550860.998669471 edges/sec Memory (free/total/max) = 51871.27M / 52732.50M / 52732.50M
INFO    2018-08-08 13:58:06,694 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 31000000 edges at 6419739.0112634115 edges/sec Memory (free/total/max) = 50078.92M / 52732.50M / 52732.50M
INFO    2018-08-08 13:58:06,729 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 32000000 edges at 6579852.938267637 edges/sec Memory (free/total/max) = 49848.46M / 52732.50M / 52732.50M
INFO    2018-08-08 13:58:06,732 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 33000000 edges at 6780894.964302555 edges/sec Memory (free/total/max) = 49819.78M / 52732.50M / 52732.50M
INFO    2018-08-08 13:58:06,816 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 34000000 edges at 6867971.869803681 edges/sec Memory (free/total/max) = 49215.38M / 52732.50M / 52732.50M
INFO    2018-08-08 13:58:06,829 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 35000000 edges at 7050971.6986302985 edges/sec Memory (free/total/max) = 49128.87M / 52732.50M / 52732.50M
INFO    2018-08-08 13:58:06,994 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 48ms
INFO    2018-08-08 13:58:07,109 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 36000000 edges at 6865964.794064046 edges/sec Memory (free/total/max) = 51088.15M / 52303.00M / 52303.00M
INFO    2018-08-08 13:58:07,150 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 37000000 edges at 7001894.31046459 edges/sec Memory (free/total/max) = 50803.52M / 52303.00M / 52303.00M
INFO    2018-08-08 13:58:07,164 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 38000000 edges at 7172028.522248472 edges/sec Memory (free/total/max) = 50672.10M / 52303.00M / 52303.00M
INFO    2018-08-08 13:58:07,265 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 39000000 edges at 7222956.887893474 edges/sec Memory (free/total/max) = 49928.26M / 52303.00M / 52303.00M
INFO    2018-08-08 13:58:07,273 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 40000000 edges at 7397145.863381507 edges/sec Memory (free/total/max) = 49899.01M / 52303.00M / 52303.00M
INFO    2018-08-08 13:58:07,463 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 41000000 edges at 7325121.715977781 edges/sec Memory (free/total/max) = 48497.04M / 52303.00M / 52303.00M
INFO    2018-08-08 13:58:07,500 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 42000000 edges at 7453918.903001132 edges/sec Memory (free/total/max) = 48214.79M / 52303.00M / 52303.00M
INFO    2018-08-08 13:58:07,545 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 43000000 edges at 7570816.073694964 edges/sec Memory (free/total/max) = 47846.14M / 52303.00M / 52303.00M
INFO    2018-08-08 13:58:07,559 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 7ms
INFO    2018-08-08 13:58:07,638 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 44000000 edges at 7622280.57470665 edges/sec Memory (free/total/max) = 51687.76M / 52723.00M / 52723.00M
INFO    2018-08-08 13:58:07,646 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 45000000 edges at 7785031.622852948 edges/sec Memory (free/total/max) = 51661.73M / 52723.00M / 52723.00M
INFO    2018-08-08 13:58:07,834 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 46000000 edges at 7707660.262424535 edges/sec Memory (free/total/max) = 50236.17M / 52723.00M / 52723.00M
INFO    2018-08-08 13:58:07,875 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 47000000 edges at 7820646.177975183 edges/sec Memory (free/total/max) = 49932.63M / 52723.00M / 52723.00M
INFO    2018-08-08 13:58:07,944 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 48000000 edges at 7896160.004165934 edges/sec Memory (free/total/max) = 49447.04M / 52723.00M / 52723.00M
INFO    2018-08-08 13:58:08,010 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 49000000 edges at 7975162.104361552 edges/sec Memory (free/total/max) = 48946.00M / 52723.00M / 52723.00M
INFO    2018-08-08 13:58:08,034 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 50000000 edges at 8105140.770507991 edges/sec Memory (free/total/max) = 48778.93M / 52723.00M / 52723.00M
INFO    2018-08-08 13:58:08,112 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 7ms
INFO    2018-08-08 13:58:08,223 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 51000000 edges at 8022530.4569171 edges/sec Memory (free/total/max) = 51629.54M / 52723.50M / 52723.50M
INFO    2018-08-08 13:58:08,276 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 52000000 edges at 8112180.226523413 edges/sec Memory (free/total/max) = 51245.98M / 52723.50M / 52723.50M
INFO    2018-08-08 13:58:08,342 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 53000000 edges at 8182804.941915065 edges/sec Memory (free/total/max) = 50752.97M / 52723.50M / 52723.50M
INFO    2018-08-08 13:58:08,412 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 54000000 edges at 8248718.221135589 edges/sec Memory (free/total/max) = 50277.26M / 52723.50M / 52723.50M
INFO    2018-08-08 13:58:08,418 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 55000000 edges at 8394595.306665832 edges/sec Memory (free/total/max) = 50215.56M / 52723.50M / 52723.50M
INFO    2018-08-08 13:58:08,574 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 56000000 edges at 8347822.543331777 edges/sec Memory (free/total/max) = 49044.87M / 52723.50M / 52723.50M
INFO    2018-08-08 13:58:08,619 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 57000000 edges at 8440430.403323635 edges/sec Memory (free/total/max) = 48691.61M / 52723.50M / 52723.50M
INFO    2018-08-08 13:58:08,687 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 7ms
INFO    2018-08-08 13:58:08,760 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 58000000 edges at 8411925.153569182 edges/sec Memory (free/total/max) = 51781.43M / 52736.00M / 52736.00M
INFO    2018-08-08 13:58:08,774 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 59000000 edges at 8540528.41272416 edges/sec Memory (free/total/max) = 51671.55M / 52736.00M / 52736.00M
INFO    2018-08-08 13:58:08,785 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 60000000 edges at 8671088.380472101 edges/sec Memory (free/total/max) = 51593.51M / 52736.00M / 52736.00M
INFO    2018-08-08 13:58:08,930 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 61000000 edges at 8635011.809500493 edges/sec Memory (free/total/max) = 50544.33M / 52736.00M / 52736.00M
INFO    2018-08-08 13:58:08,995 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 62000000 edges at 8696109.699051779 edges/sec Memory (free/total/max) = 50059.43M / 52736.00M / 52736.00M
INFO    2018-08-08 13:58:09,133 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 63000000 edges at 8669288.009923892 edges/sec Memory (free/total/max) = 49041.91M / 52736.00M / 52736.00M
INFO    2018-08-08 13:58:09,147 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 64000000 edges at 8789979.10452485 edges/sec Memory (free/total/max) = 48900.08M / 52736.00M / 52736.00M
INFO    2018-08-08 13:58:09,149 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 65000000 edges at 8924417.911308505 edges/sec Memory (free/total/max) = 48900.08M / 52736.00M / 52736.00M
INFO    2018-08-08 13:58:09,246 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 7ms
INFO    2018-08-08 13:58:09,285 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 66000000 edges at 8895323.335699553 edges/sec Memory (free/total/max) = 52011.24M / 52728.00M / 52728.00M
INFO    2018-08-08 13:58:09,355 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 67000000 edges at 8945694.663591303 edges/sec Memory (free/total/max) = 51454.80M / 52728.00M / 52728.00M
INFO    2018-08-08 13:58:09,498 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 68000000 edges at 8909239.685127592 edges/sec Memory (free/total/max) = 50376.97M / 52728.00M / 52728.00M
INFO    2018-08-08 13:58:09,520 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 69000000 edges at 9013811.304990146 edges/sec Memory (free/total/max) = 50202.60M / 52728.00M / 52728.00M
INFO    2018-08-08 13:58:09,527 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 70000000 edges at 9135915.796642574 edges/sec Memory (free/total/max) = 50155.02M / 52728.00M / 52728.00M
INFO    2018-08-08 13:58:09,621 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 71000000 edges at 9154261.772524916 edges/sec Memory (free/total/max) = 49428.94M / 52728.00M / 52728.00M
INFO    2018-08-08 13:58:09,693 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 72000000 edges at 9198255.39679322 edges/sec Memory (free/total/max) = 48906.47M / 52728.00M / 52728.00M
INFO    2018-08-08 13:58:09,779 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 6ms
INFO    2018-08-08 13:58:09,847 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 73000000 edges at 9146452.178116463 edges/sec Memory (free/total/max) = 51742.70M / 52764.00M / 52764.00M
INFO    2018-08-08 13:58:09,864 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 74000000 edges at 9251500.928817563 edges/sec Memory (free/total/max) = 51613.02M / 52764.00M / 52764.00M
INFO    2018-08-08 13:58:09,877 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 75000000 edges at 9361166.189130716 edges/sec Memory (free/total/max) = 51483.81M / 52764.00M / 52764.00M
INFO    2018-08-08 13:58:09,960 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 76000000 edges at 9389170.604576753 edges/sec Memory (free/total/max) = 50821.27M / 52764.00M / 52764.00M
INFO    2018-08-08 13:58:10,019 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 77000000 edges at 9444199.984053455 edges/sec Memory (free/total/max) = 50352.10M / 52764.00M / 52764.00M
INFO    2018-08-08 13:58:10,172 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 78000000 edges at 9389715.879855536 edges/sec Memory (free/total/max) = 49091.05M / 52764.00M / 52764.00M
INFO    2018-08-08 13:58:10,198 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 79000000 edges at 9480701.914005361 edges/sec Memory (free/total/max) = 48881.01M / 52764.00M / 52764.00M
INFO    2018-08-08 13:58:10,205 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 80000000 edges at 9592461.812614262 edges/sec Memory (free/total/max) = 48816.11M / 52764.00M / 52764.00M
INFO    2018-08-08 13:58:10,297 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 17ms
INFO    2018-08-08 13:58:10,309 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 81000000 edges at 9593538.231533846 edges/sec Memory (free/total/max) = 52155.22M / 52748.50M / 52748.50M
INFO    2018-08-08 13:58:10,356 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 82000000 edges at 9657703.473853868 edges/sec Memory (free/total/max) = 51764.08M / 52748.50M / 52748.50M
INFO    2018-08-08 13:58:10,522 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 83000000 edges at 9588193.362080451 edges/sec Memory (free/total/max) = 50447.45M / 52748.50M / 52748.50M
INFO    2018-08-08 13:58:10,547 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 84000000 edges at 9675810.985354597 edges/sec Memory (free/total/max) = 50252.67M / 52748.50M / 52748.50M
INFO    2018-08-08 13:58:10,561 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 85000000 edges at 9775556.5499037 edges/sec Memory (free/total/max) = 50122.42M / 52748.50M / 52748.50M
INFO    2018-08-08 13:58:10,631 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 86000000 edges at 9811001.19917198 edges/sec Memory (free/total/max) = 49528.81M / 52748.50M / 52748.50M
INFO    2018-08-08 13:58:10,688 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 87000000 edges at 9861636.552063385 edges/sec Memory (free/total/max) = 48996.97M / 52748.50M / 52748.50M
INFO    2018-08-08 13:58:10,800 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 7ms
INFO    2018-08-08 13:58:10,858 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 88000000 edges at 9785338.016910426 edges/sec Memory (free/total/max) = 51854.41M / 52801.00M / 52801.00M
INFO    2018-08-08 13:58:10,883 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 89000000 edges at 9869220.652832627 edges/sec Memory (free/total/max) = 51640.96M / 52801.00M / 52801.00M
INFO    2018-08-08 13:58:10,897 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 90000000 edges at 9965061.05543471 edges/sec Memory (free/total/max) = 51542.46M / 52801.00M / 52801.00M
INFO    2018-08-08 13:58:10,967 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 91000000 edges at 9997900.33435876 edges/sec Memory (free/total/max) = 50967.98M / 52801.00M / 52801.00M
INFO    2018-08-08 13:58:11,018 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 92000000 edges at 1.0052121255011985E7 edges/sec Memory (free/total/max) = 50557.61M / 52801.00M / 52801.00M
INFO    2018-08-08 13:58:11,202 [load-3] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 93000000 edges at 9960987.485116327 edges/sec Memory (free/total/max) = 49038.17M / 52801.00M / 52801.00M
INFO    2018-08-08 13:58:11,220 [load-2] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 94000000 edges at 1.0048909574824866E7 edges/sec Memory (free/total/max) = 48878.74M / 52801.00M / 52801.00M
INFO    2018-08-08 13:58:11,224 [load-4] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 95000000 edges at 1.015144425377991E7 edges/sec Memory (free/total/max) = 48845.65M / 52801.00M / 52801.00M
INFO    2018-08-08 13:58:11,281 [load-4] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=0, e=19173962)
INFO    2018-08-08 13:58:11,282 [load-2] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=0, e=19173962)
INFO    2018-08-08 13:58:11,284 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 8.733076 secs, (v=0, e=19173962) 0.0 vertices/sec, 2195556.5 edges/sec
INFO    2018-08-08 13:58:11,284 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 8.734917 secs, (v=0, e=19173962) 0.0 vertices/sec, 2195093.8 edges/sec
INFO    2018-08-08 13:58:11,311 [load-3] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=0, e=19173960)
INFO    2018-08-08 13:58:11,313 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 8.762695 secs, (v=0, e=19173960) 0.0 vertices/sec, 2188135.0 edges/sec
INFO    2018-08-08 13:58:11,315 [load-1] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 96521884 edges at 1.021452471600585E7 edges/sec Memory (free/total/max) = 48385.03M / 52801.00M / 52801.00M
INFO    2018-08-08 13:58:11,452 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 97521884 edges at 1.0173149977749309E7 edges/sec Memory (free/total/max) = 48219.60M / 52801.00M / 52801.00M
INFO    2018-08-08 13:58:11,502 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 14ms
INFO    2018-08-08 13:58:11,919 [load-1] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=0, e=20740348)
INFO    2018-08-08 13:58:11,920 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 9.371967 secs, (v=0, e=20740348) 0.0 vertices/sec, 2213019.8 edges/sec
INFO    2018-08-08 13:58:12,142 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 99262232 edges at 9659241.148730269 edges/sec Memory (free/total/max) = 51554.03M / 52782.00M / 52782.00M
INFO    2018-08-08 13:58:12,331 [load-0] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=0, e=21362868)
INFO    2018-08-08 13:58:12,333 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 9.78593 secs, (v=0, e=21362868) 0.0 vertices/sec, 2183018.8 edges/sec
INFO    2018-08-08 13:58:12,343 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0166, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 225.4913, MBytesSent = 2.4804, ave sent req MBytes = 0.2067, secs waited = 0.01
INFO    2018-08-08 13:58:12,343 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=99625100)
INFO    2018-08-08 13:58:12,358 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,361 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,382 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,384 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 51263.47M / 52782.00M / 52782.00M
INFO    2018-08-08 13:58:12,384 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0035, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.051
MBytes/sec sent = 47.7001, MBytesSent = 2.4804, ave sent req MBytes = 0.2067, secs waited = 0.051
INFO    2018-08-08 13:58:12,384 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,404 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 11 more tasks to send their aggregator data
INFO    2018-08-08 13:58:12,435 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:12,435 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 51263.14M / 52782.00M / 52782.00M
INFO    2018-08-08 13:58:12,443 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,486 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,491 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@6813a331,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1bd81830)
WARN    2018-08-08 13:58:12,496 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,505 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,505 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,507 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave2_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008)
INFO    2018-08-08 13:58:12,566 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,566 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,566 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,568 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.132
MBytes/sec sent = 0.0106, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.133
INFO    2018-08-08 13:58:12,570 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,572 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,574 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 3 more tasks to send their aggregator data, task ids: [10, 12, 13]
INFO    2018-08-08 13:58:12,582 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,839 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.25572538 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.25 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,844 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.25573292 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,847 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.26260194 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,844 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.25796804 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,850 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.25958186 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,850 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2623839 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,850 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.25981593 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,905 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3149299 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.31 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,936 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3469536 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.35 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,969 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3834327 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.38 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,175 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.5865142 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.59 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,396 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50665.73M / 52782.00M / 52782.00M
INFO    2018-08-08 13:58:13,849 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0042, MBytesReceived = 0.0042, ave received req MBytes = 0, secs waited = 1.009
MBytes/sec sent = 54.4823, MBytesSent = 55.0272, ave sent req MBytes = 0.2001, secs waited = 1.009
INFO    2018-08-08 13:58:13,850 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,937 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:58:13,937 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 7712501 , message bytes = 62424296 , Memory (free/total/max) = 50494.45M / 52782.00M / 52782.00M
INFO    2018-08-08 13:58:13,940 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,961 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,963 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@58faa93b,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5f212d84)
INFO    2018-08-08 13:58:13,968 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,970 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave2_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008)
INFO    2018-08-08 13:58:13,996 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,998 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0003, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.061
MBytes/sec sent = 0.0227, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.061
INFO    2018-08-08 13:58:14,000 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,002 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,004 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,174 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16698554 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,177 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17243141 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,178 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.1684264 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,179 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17205149 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,182 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17257367 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,183 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17590825 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,194 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18912518 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,205 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.19830684 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,209 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.20276141 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,218 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2103457 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,274 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.26536515 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.27 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,322 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 49873.41M / 52782.00M / 52782.00M
INFO    2018-08-08 13:58:14,442 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0158, MBytesReceived = 0.0042, ave received req MBytes = 0, secs waited = 0.265
MBytes/sec sent = 201.6588, MBytesSent = 53.6412, ave sent req MBytes = 0.1944, secs waited = 0.265
INFO    2018-08-08 13:58:14,443 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,623 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,623 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7516010 , message bytes = 60851942 , Memory (free/total/max) = 49792.13M / 52782.00M / 52782.00M
INFO    2018-08-08 13:58:14,627 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,646 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,648 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@72be135f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@155d1021)
INFO    2018-08-08 13:58:14,654 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,667 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave2_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008)
INFO    2018-08-08 13:58:14,677 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,710 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,731 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.109
MBytes/sec sent = 0.0128, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.109
INFO    2018-08-08 13:58:14,734 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,735 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,738 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,747 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004278629 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,747 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004276618 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,747 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007687797 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,747 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006038282 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,747 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006430991 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,747 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006697534 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,751 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007402355 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,750 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00994205 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,755 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017142076 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,756 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015109459 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,756 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012819271 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,767 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 49652.18M / 52782.00M / 52782.00M
INFO    2018-08-08 13:58:14,820 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0516, MBytesReceived = 0.0037, ave received req MBytes = 0, secs waited = 0.071
MBytes/sec sent = 1.995, MBytesSent = 0.1436, ave sent req MBytes = 0.0006, secs waited = 0.071
INFO    2018-08-08 13:58:14,820 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,852 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,852 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 12494 , message bytes = 162070 , Memory (free/total/max) = 49651.12M / 52782.00M / 52782.00M
INFO    2018-08-08 13:58:14,858 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,877 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,880 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@40620d8e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@383f3558)
INFO    2018-08-08 13:58:14,885 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,900 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave2_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008)
INFO    2018-08-08 13:58:14,907 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,942 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,966 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,967 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,967 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,967 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.115
MBytes/sec sent = 0.0121, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.115
INFO    2018-08-08 13:58:14,970 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,972 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,975 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,980 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003166776 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002889971 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002224552 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001904691 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00392382 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005114668 secs for 7 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003101044 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004497639 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002773166 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001569446 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 7.41584E-4 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 49617.86M / 52782.00M / 52782.00M
INFO    2018-08-08 13:58:14,983 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0183, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0926, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.01
INFO    2018-08-08 13:58:14,983 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,992 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,992 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 49617.86M / 52782.00M / 52782.00M
INFO    2018-08-08 13:58:14,994 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,013 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,015 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7d151a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@294bdeb4)
INFO    2018-08-08 13:58:15,019 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,019 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,019 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,021 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,043 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,080 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,085 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,087 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,325 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,325 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4766 vertices using 1 threads
INFO    2018-08-08 13:58:17,328 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,585 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,585 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,588 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/8_worker
INFO    2018-08-08 13:58:17,594 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300b3 closed
INFO    2018-08-08 13:58:17,594 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,596 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,599 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,809 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,815 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000008_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,834 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000008_0 is allowed to commit now
INFO    2018-08-08 13:58:21,843 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000008_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000008
INFO    2018-08-08 13:58:21,857 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000008_0' done.
INFO    2018-08-08 13:58:21,862 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000008_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128638
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=671109164
		HDFS: Number of bytes written=41618
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=496
		CPU time spent (ms)=74840
		Physical memory (bytes) snapshot=5985964032
		Virtual memory (bytes) snapshot=58915659776
		Total committed heap usage (bytes)=55345938432
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000001 on graphalytics-giraph-slave3_42077
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:2248
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/11/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Aug 08, 2018 1:57:55 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver as a provider class
Aug 08, 2018 1:57:55 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
Aug 08, 2018 1:57:55 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices as a root resource class
Aug 08, 2018 1:57:55 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.9 09/02/2011 11:17 AM'
Aug 08, 2018 1:57:56 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
Aug 08, 2018 1:57:56 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
Aug 08, 2018 1:57:56 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices to GuiceManagedComponentProvider with the scope "PerRequest"
log4j:WARN No appenders could be found for logger (org.apache.hadoop.ipc.Server).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:121653
Log Contents:
2018-08-08 13:57:53,584 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1533735211869_0013_000001
2018-08-08 13:57:53,782 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens:
2018-08-08 13:57:53,782 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 13 cluster_timestamp: 1533735211869 } attemptId: 1 } keyId: -63235253)
2018-08-08 13:57:54,020 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Using mapred newApiCommitter.
2018-08-08 13:57:54,022 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config null
2018-08-08 13:57:54,107 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:57:54,598 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is org.apache.giraph.io.internal.WrappedVertexOutputFormat$2
2018-08-08 13:57:54,786 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler
2018-08-08 13:57:54,787 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher
2018-08-08 13:57:54,787 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher
2018-08-08 13:57:54,788 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher
2018-08-08 13:57:54,788 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler
2018-08-08 13:57:54,794 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher
2018-08-08 13:57:54,795 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter
2018-08-08 13:57:54,796 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter
2018-08-08 13:57:54,830 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 13:57:54,848 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 13:57:54,863 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 13:57:54,871 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled
2018-08-08 13:57:54,920 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler
2018-08-08 13:57:55,016 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:57:55,077 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:57:55,077 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MRAppMaster metrics system started
2018-08-08 13:57:55,085 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for job_1533735211869_0013 to jobTokenSecretManager
2018-08-08 13:57:55,186 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing job_1533735211869_0013 because: not enabled; too many maps; too much RAM;
2018-08-08 13:57:55,202 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job job_1533735211869_0013 = 0. Number of splits = 14
2018-08-08 13:57:55,203 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job job_1533735211869_0013 = 0
2018-08-08 13:57:55,203 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0013Job Transitioned from NEW to INITED
2018-08-08 13:57:55,204 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job job_1533735211869_0013.
2018-08-08 13:57:55,232 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2018-08-08 13:57:55,241 INFO [Socket Reader #1 for port 37559] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 37559
2018-08-08 13:57:55,283 INFO [main] org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server
2018-08-08 13:57:55,284 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-08-08 13:57:55,284 INFO [IPC Server listener on 37559] org.apache.hadoop.ipc.Server: IPC Server listener on 37559: starting
2018-08-08 13:57:55,285 INFO [main] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at graphalytics-giraph-slave3/10.164.0.5:37559
2018-08-08 13:57:55,349 INFO [main] org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-08-08 13:57:55,356 INFO [main] org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-08-08 13:57:55,361 INFO [main] org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined
2018-08-08 13:57:55,366 INFO [main] org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-08-08 13:57:55,395 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce
2018-08-08 13:57:55,395 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static
2018-08-08 13:57:55,397 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /mapreduce/*
2018-08-08 13:57:55,397 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-08-08 13:57:55,627 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-08-08 13:57:55,629 INFO [main] org.apache.hadoop.http.HttpServer2: Jetty bound to port 44933
2018-08-08 13:57:55,629 INFO [main] org.mortbay.log: jetty-6.1.26
2018-08-08 13:57:55,654 INFO [main] org.mortbay.log: Extract jar:file:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar!/webapps/mapreduce to /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000001/tmp/Jetty_0_0_0_0_44933_mapreduce____.vcwl1c/webapp
2018-08-08 13:57:56,575 INFO [main] org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:44933
2018-08-08 13:57:56,575 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Web app mapreduce started at 44933
2018-08-08 13:57:56,578 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: JOB_CREATE job_1533735211869_0013
2018-08-08 13:57:56,579 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 3000
2018-08-08 13:57:56,580 INFO [Socket Reader #1 for port 45173] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 45173
2018-08-08 13:57:56,586 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-08-08 13:57:56,586 INFO [IPC Server listener on 45173] org.apache.hadoop.ipc.Server: IPC Server listener on 45173: starting
2018-08-08 13:57:56,646 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true
2018-08-08 13:57:56,646 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: maxTaskFailuresPerNode is 3
2018-08-08 13:57:56,646 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: blacklistDisablePercent is 33
2018-08-08 13:57:56,679 INFO [main] org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at graphalytics-giraph/10.164.0.2:8030
2018-08-08 13:57:56,829 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: maxContainerCapability: <memory:57344, vCores:32>
2018-08-08 13:57:56,829 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: queue: default
2018-08-08 13:57:56,833 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500
2018-08-08 13:57:56,833 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: The thread pool initial size is 10
2018-08-08 13:57:56,847 INFO [main] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2018-08-08 13:57:56,856 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0013Job Transitioned from INITED to SETUP
2018-08-08 13:57:56,858 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_SETUP
2018-08-08 13:57:56,888 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0013Job Transitioned from SETUP to RUNNING
2018-08-08 13:57:56,896 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000000 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,896 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000001 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,896 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000002 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,897 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000003 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,897 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000004 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,898 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000005 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,898 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000006 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,898 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000007 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,898 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000008 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,898 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000009 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,899 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000010 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,899 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000011 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,899 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000012 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,899 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000013 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:57:56,901 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,902 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000001_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,905 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000002_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,907 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000003_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,908 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000004_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,909 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000005_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,909 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000006_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,910 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000007_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,911 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000008_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,911 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000009_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,912 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000010_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,913 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000011_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,914 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000012_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,914 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000013_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:57:56,917 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: mapResourceRequest:<memory:57344, vCores:1>
2018-08-08 13:57:56,937 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1533735211869_0013, File: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0013/job_1533735211869_0013_1.jhist
2018-08-08 13:57:57,832 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:14 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:57:57,872 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1533735211869_0013: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:858112, vCores:1> knownNMs=15
2018-08-08 13:57:58,895 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 14
2018-08-08 13:57:58,897 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave14 to /default-rack
2018-08-08 13:57:58,897 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave13 to /default-rack
2018-08-08 13:57:58,898 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave15 to /default-rack
2018-08-08 13:57:58,898 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave4 to /default-rack
2018-08-08 13:57:58,898 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave5 to /default-rack
2018-08-08 13:57:58,898 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave12 to /default-rack
2018-08-08 13:57:58,898 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave9 to /default-rack
2018-08-08 13:57:58,898 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave6 to /default-rack
2018-08-08 13:57:58,898 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave2 to /default-rack
2018-08-08 13:57:58,898 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave8 to /default-rack
2018-08-08 13:57:58,898 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave1 to /default-rack
2018-08-08 13:57:58,898 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave11 to /default-rack
2018-08-08 13:57:58,898 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave7 to /default-rack
2018-08-08 13:57:58,898 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave10 to /default-rack
2018-08-08 13:57:58,900 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000002 to attempt_1533735211869_0013_m_000000_0
2018-08-08 13:57:58,902 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000003 to attempt_1533735211869_0013_m_000001_0
2018-08-08 13:57:58,902 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000004 to attempt_1533735211869_0013_m_000002_0
2018-08-08 13:57:58,902 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000005 to attempt_1533735211869_0013_m_000003_0
2018-08-08 13:57:58,902 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000006 to attempt_1533735211869_0013_m_000004_0
2018-08-08 13:57:58,902 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000007 to attempt_1533735211869_0013_m_000005_0
2018-08-08 13:57:58,902 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000008 to attempt_1533735211869_0013_m_000006_0
2018-08-08 13:57:58,902 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000009 to attempt_1533735211869_0013_m_000007_0
2018-08-08 13:57:58,902 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000010 to attempt_1533735211869_0013_m_000008_0
2018-08-08 13:57:58,902 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000011 to attempt_1533735211869_0013_m_000009_0
2018-08-08 13:57:58,902 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000012 to attempt_1533735211869_0013_m_000010_0
2018-08-08 13:57:58,903 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000013 to attempt_1533735211869_0013_m_000011_0
2018-08-08 13:57:58,903 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000014 to attempt_1533735211869_0013_m_000012_0
2018-08-08 13:57:58,904 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0013_01_000015 to attempt_1533735211869_0013_m_000013_0
2018-08-08 13:57:58,904 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:14 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:57:58,939 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave14 to /default-rack
2018-08-08 13:57:58,953 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-jar file on the remote FS is hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0013/job.jar
2018-08-08 13:57:58,956 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0013/job.xml
2018-08-08 13:57:58,957 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Adding #0 tokens and #1 secret keys for NM use for launching container
2018-08-08 13:57:58,957 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Size of containertokens_dob is 1
2018-08-08 13:57:58,957 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Putting shuffle token in serviceData
2018-08-08 13:57:58,999 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave13 to /default-rack
2018-08-08 13:57:59,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,003 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave15 to /default-rack
2018-08-08 13:57:59,003 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,004 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave4 to /default-rack
2018-08-08 13:57:59,004 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000003_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,004 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave5 to /default-rack
2018-08-08 13:57:59,005 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000004_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,005 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave12 to /default-rack
2018-08-08 13:57:59,005 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000005_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,005 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave9 to /default-rack
2018-08-08 13:57:59,006 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000006_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,006 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave6 to /default-rack
2018-08-08 13:57:59,006 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000007_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,006 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave2 to /default-rack
2018-08-08 13:57:59,007 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000008_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,008 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave8 to /default-rack
2018-08-08 13:57:59,008 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000009_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,008 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave1 to /default-rack
2018-08-08 13:57:59,009 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000010_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,009 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave11 to /default-rack
2018-08-08 13:57:59,010 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000011_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,010 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave7 to /default-rack
2018-08-08 13:57:59,011 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000012_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,011 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave10 to /default-rack
2018-08-08 13:57:59,011 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000013_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:57:59,013 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000002 taskAttempt attempt_1533735211869_0013_m_000000_0
2018-08-08 13:57:59,014 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000003 taskAttempt attempt_1533735211869_0013_m_000001_0
2018-08-08 13:57:59,014 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000004 taskAttempt attempt_1533735211869_0013_m_000002_0
2018-08-08 13:57:59,014 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000005 taskAttempt attempt_1533735211869_0013_m_000003_0
2018-08-08 13:57:59,016 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000006 taskAttempt attempt_1533735211869_0013_m_000004_0
2018-08-08 13:57:59,017 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000007 taskAttempt attempt_1533735211869_0013_m_000005_0
2018-08-08 13:57:59,017 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000008 taskAttempt attempt_1533735211869_0013_m_000006_0
2018-08-08 13:57:59,018 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000009 taskAttempt attempt_1533735211869_0013_m_000007_0
2018-08-08 13:57:59,018 INFO [ContainerLauncher Event Handler] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Setting ContainerLauncher pool size to 21 as number-of-nodes to talk to is 11
2018-08-08 13:57:59,018 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000006_0
2018-08-08 13:57:59,018 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000010 taskAttempt attempt_1533735211869_0013_m_000008_0
2018-08-08 13:57:59,018 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000002_0
2018-08-08 13:57:59,018 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000005_0
2018-08-08 13:57:59,018 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000007_0
2018-08-08 13:57:59,019 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000004_0
2018-08-08 13:57:59,019 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000003_0
2018-08-08 13:57:59,018 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000001_0
2018-08-08 13:57:59,020 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000012 taskAttempt attempt_1533735211869_0013_m_000010_0
2018-08-08 13:57:59,020 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000010_0
2018-08-08 13:57:59,019 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000000_0
2018-08-08 13:57:59,019 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000011 taskAttempt attempt_1533735211869_0013_m_000009_0
2018-08-08 13:57:59,020 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000009_0
2018-08-08 13:57:59,019 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000008_0
2018-08-08 13:57:59,021 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000013 taskAttempt attempt_1533735211869_0013_m_000011_0
2018-08-08 13:57:59,021 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000011_0
2018-08-08 13:57:59,022 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000015 taskAttempt attempt_1533735211869_0013_m_000013_0
2018-08-08 13:57:59,022 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000013_0
2018-08-08 13:57:59,023 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0013_01_000014 taskAttempt attempt_1533735211869_0013_m_000012_0
2018-08-08 13:57:59,023 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0013_m_000012_0
2018-08-08 13:57:59,023 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave9:37771
2018-08-08 13:57:59,044 INFO [ContainerLauncher #12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave7:43383
2018-08-08 13:57:59,046 INFO [ContainerLauncher #13] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave10:46663
2018-08-08 13:57:59,049 INFO [ContainerLauncher #11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave11:46641
2018-08-08 13:57:59,050 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave2:43787
2018-08-08 13:57:59,054 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave8:41519
2018-08-08 13:57:59,055 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave14:35219
2018-08-08 13:57:59,057 INFO [ContainerLauncher #10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave1:33157
2018-08-08 13:57:59,058 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave13:40615
2018-08-08 13:57:59,060 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave4:46069
2018-08-08 13:57:59,061 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave6:36387
2018-08-08 13:57:59,061 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave12:33893
2018-08-08 13:57:59,064 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave5:46217
2018-08-08 13:57:59,067 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave15:37797
2018-08-08 13:57:59,133 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000004_0 : 13562
2018-08-08 13:57:59,133 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000001_0 : 13562
2018-08-08 13:57:59,138 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000000_0 : 13562
2018-08-08 13:57:59,138 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000012_0 : 13562
2018-08-08 13:57:59,138 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000011_0 : 13562
2018-08-08 13:57:59,138 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000008_0 : 13562
2018-08-08 13:57:59,138 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000007_0 : 13562
2018-08-08 13:57:59,138 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000013_0 : 13562
2018-08-08 13:57:59,139 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000002_0 : 13562
2018-08-08 13:57:59,139 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000009_0 : 13562
2018-08-08 13:57:59,140 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000010_0 : 13562
2018-08-08 13:57:59,140 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000003_0 : 13562
2018-08-08 13:57:59,141 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000009_0] using containerId: [container_1533735211869_0013_01_000011 on NM: [graphalytics-giraph-slave8:41519]
2018-08-08 13:57:59,141 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000006_0 : 13562
2018-08-08 13:57:59,142 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0013_m_000005_0 : 13562
2018-08-08 13:57:59,146 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000009_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,146 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000004_0] using containerId: [container_1533735211869_0013_01_000006 on NM: [graphalytics-giraph-slave5:46217]
2018-08-08 13:57:59,146 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000004_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,146 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000002_0] using containerId: [container_1533735211869_0013_01_000004 on NM: [graphalytics-giraph-slave15:37797]
2018-08-08 13:57:59,146 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000002_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,146 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000013_0] using containerId: [container_1533735211869_0013_01_000015 on NM: [graphalytics-giraph-slave10:46663]
2018-08-08 13:57:59,147 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000013_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,147 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000007_0] using containerId: [container_1533735211869_0013_01_000009 on NM: [graphalytics-giraph-slave6:36387]
2018-08-08 13:57:59,147 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000007_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,147 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000008_0] using containerId: [container_1533735211869_0013_01_000010 on NM: [graphalytics-giraph-slave2:43787]
2018-08-08 13:57:59,147 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000008_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,148 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000011_0] using containerId: [container_1533735211869_0013_01_000013 on NM: [graphalytics-giraph-slave11:46641]
2018-08-08 13:57:59,148 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000011_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,148 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000012_0] using containerId: [container_1533735211869_0013_01_000014 on NM: [graphalytics-giraph-slave7:43383]
2018-08-08 13:57:59,148 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000012_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,148 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000000_0] using containerId: [container_1533735211869_0013_01_000002 on NM: [graphalytics-giraph-slave14:35219]
2018-08-08 13:57:59,148 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,148 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000001_0] using containerId: [container_1533735211869_0013_01_000003 on NM: [graphalytics-giraph-slave13:40615]
2018-08-08 13:57:59,148 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000001_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,148 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000010_0] using containerId: [container_1533735211869_0013_01_000012 on NM: [graphalytics-giraph-slave1:33157]
2018-08-08 13:57:59,149 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000010_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,149 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000003_0] using containerId: [container_1533735211869_0013_01_000005 on NM: [graphalytics-giraph-slave4:46069]
2018-08-08 13:57:59,149 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000003_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,150 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000006_0] using containerId: [container_1533735211869_0013_01_000008 on NM: [graphalytics-giraph-slave9:37771]
2018-08-08 13:57:59,150 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000006_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,150 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0013_m_000005_0] using containerId: [container_1533735211869_0013_01_000007 on NM: [graphalytics-giraph-slave12:33893]
2018-08-08 13:57:59,150 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000005_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:57:59,150 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000009 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,150 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000004 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,150 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000002 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,153 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000013 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,153 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000007 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,153 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000008 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,153 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000011 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,153 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000012 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,154 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000000 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,154 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000001 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,154 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000010 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,154 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000003 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,154 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000006 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,154 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000005 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:57:59,908 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1533735211869_0013: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:55296, vCores:1> knownNMs=15
2018-08-08 13:58:00,685 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,703 INFO [IPC Server handler 0 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000005 asked for a task
2018-08-08 13:58:00,705 INFO [IPC Server handler 0 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000005 given task: attempt_1533735211869_0013_m_000003_0
2018-08-08 13:58:00,705 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,717 INFO [IPC Server handler 1 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000009 asked for a task
2018-08-08 13:58:00,717 INFO [IPC Server handler 1 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000009 given task: attempt_1533735211869_0013_m_000007_0
2018-08-08 13:58:00,733 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,746 INFO [IPC Server handler 2 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000004 asked for a task
2018-08-08 13:58:00,747 INFO [IPC Server handler 2 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000004 given task: attempt_1533735211869_0013_m_000002_0
2018-08-08 13:58:00,755 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,759 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,765 INFO [IPC Server handler 3 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000003 asked for a task
2018-08-08 13:58:00,766 INFO [IPC Server handler 3 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000003 given task: attempt_1533735211869_0013_m_000001_0
2018-08-08 13:58:00,770 INFO [IPC Server handler 4 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000015 asked for a task
2018-08-08 13:58:00,770 INFO [IPC Server handler 4 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000015 given task: attempt_1533735211869_0013_m_000013_0
2018-08-08 13:58:00,777 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,785 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,788 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,788 INFO [IPC Server handler 5 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000008 asked for a task
2018-08-08 13:58:00,788 INFO [IPC Server handler 5 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000008 given task: attempt_1533735211869_0013_m_000006_0
2018-08-08 13:58:00,796 INFO [IPC Server handler 6 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000002 asked for a task
2018-08-08 13:58:00,796 INFO [IPC Server handler 6 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000002 given task: attempt_1533735211869_0013_m_000000_0
2018-08-08 13:58:00,798 INFO [IPC Server handler 7 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000013 asked for a task
2018-08-08 13:58:00,798 INFO [IPC Server handler 7 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000013 given task: attempt_1533735211869_0013_m_000011_0
2018-08-08 13:58:00,834 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,836 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,845 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,846 INFO [IPC Server handler 8 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000011 asked for a task
2018-08-08 13:58:00,846 INFO [IPC Server handler 8 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000011 given task: attempt_1533735211869_0013_m_000009_0
2018-08-08 13:58:00,848 INFO [IPC Server handler 8 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000006 asked for a task
2018-08-08 13:58:00,848 INFO [IPC Server handler 8 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000006 given task: attempt_1533735211869_0013_m_000004_0
2018-08-08 13:58:00,857 INFO [IPC Server handler 9 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000014 asked for a task
2018-08-08 13:58:00,857 INFO [IPC Server handler 9 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000014 given task: attempt_1533735211869_0013_m_000012_0
2018-08-08 13:58:00,899 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,912 INFO [IPC Server handler 11 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000010 asked for a task
2018-08-08 13:58:00,912 INFO [IPC Server handler 11 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000010 given task: attempt_1533735211869_0013_m_000008_0
2018-08-08 13:58:00,916 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:00,929 INFO [IPC Server handler 12 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000012 asked for a task
2018-08-08 13:58:00,929 INFO [IPC Server handler 12 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000012 given task: attempt_1533735211869_0013_m_000010_0
2018-08-08 13:58:01,010 INFO [Socket Reader #1 for port 45173] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0013 (auth:SIMPLE)
2018-08-08 13:58:01,020 INFO [IPC Server handler 13 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0013_m_000007 asked for a task
2018-08-08 13:58:01,020 INFO [IPC Server handler 13 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0013_m_000007 given task: attempt_1533735211869_0013_m_000005_0
2018-08-08 13:58:07,376 INFO [IPC Server handler 16 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000007_0 is : 1.0
2018-08-08 13:58:07,377 INFO [IPC Server handler 15 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000003_0 is : 1.0
2018-08-08 13:58:07,428 INFO [IPC Server handler 17 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000001_0 is : 1.0
2018-08-08 13:58:07,438 INFO [IPC Server handler 19 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000013_0 is : 1.0
2018-08-08 13:58:07,446 INFO [IPC Server handler 20 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000006_0 is : 1.0
2018-08-08 13:58:07,498 INFO [IPC Server handler 21 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000000_0 is : 1.0
2018-08-08 13:58:07,506 INFO [IPC Server handler 22 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000002_0 is : 1.0
2018-08-08 13:58:07,529 INFO [IPC Server handler 23 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000011_0 is : 1.0
2018-08-08 13:58:07,566 INFO [IPC Server handler 24 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000009_0 is : 1.0
2018-08-08 13:58:07,567 INFO [IPC Server handler 25 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000004_0 is : 1.0
2018-08-08 13:58:07,588 INFO [IPC Server handler 26 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000012_0 is : 1.0
2018-08-08 13:58:07,650 INFO [IPC Server handler 2 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000008_0 is : 1.0
2018-08-08 13:58:07,681 INFO [IPC Server handler 3 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000010_0 is : 1.0
2018-08-08 13:58:07,733 INFO [IPC Server handler 4 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000005_0 is : 1.0
2018-08-08 13:58:10,663 INFO [IPC Server handler 3 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000008_0 is : 1.0
2018-08-08 13:58:13,675 INFO [IPC Server handler 4 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000008_0 is : 1.0
2018-08-08 13:58:16,407 INFO [IPC Server handler 20 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000007_0 is : 1.0
2018-08-08 13:58:16,410 INFO [IPC Server handler 21 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000003_0 is : 1.0
2018-08-08 13:58:16,450 INFO [IPC Server handler 22 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000001_0 is : 1.0
2018-08-08 13:58:16,460 INFO [IPC Server handler 23 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000013_0 is : 1.0
2018-08-08 13:58:16,469 INFO [IPC Server handler 25 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000006_0 is : 1.0
2018-08-08 13:58:16,522 INFO [IPC Server handler 24 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000000_0 is : 1.0
2018-08-08 13:58:16,526 INFO [IPC Server handler 26 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000002_0 is : 1.0
2018-08-08 13:58:16,551 INFO [IPC Server handler 27 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000011_0 is : 1.0
2018-08-08 13:58:16,584 INFO [IPC Server handler 0 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000009_0 is : 1.0
2018-08-08 13:58:16,584 INFO [IPC Server handler 1 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000004_0 is : 1.0
2018-08-08 13:58:16,607 INFO [IPC Server handler 2 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000012_0 is : 1.0
2018-08-08 13:58:16,688 INFO [IPC Server handler 6 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000008_0 is : 1.0
2018-08-08 13:58:16,701 INFO [IPC Server handler 7 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000010_0 is : 1.0
2018-08-08 13:58:16,751 INFO [IPC Server handler 8 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000005_0 is : 1.0
2018-08-08 13:58:19,420 INFO [IPC Server handler 22 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000007_0 is : 1.0
2018-08-08 13:58:19,425 INFO [IPC Server handler 23 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000003_0 is : 1.0
2018-08-08 13:58:19,467 INFO [IPC Server handler 25 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000001_0 is : 1.0
2018-08-08 13:58:19,473 INFO [IPC Server handler 24 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000013_0 is : 1.0
2018-08-08 13:58:19,483 INFO [IPC Server handler 26 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000006_0 is : 1.0
2018-08-08 13:58:19,540 INFO [IPC Server handler 27 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000000_0 is : 1.0
2018-08-08 13:58:19,543 INFO [IPC Server handler 28 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000002_0 is : 1.0
2018-08-08 13:58:19,566 INFO [IPC Server handler 29 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000011_0 is : 1.0
2018-08-08 13:58:19,597 INFO [IPC Server handler 2 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000009_0 is : 1.0
2018-08-08 13:58:19,600 INFO [IPC Server handler 3 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000004_0 is : 1.0
2018-08-08 13:58:19,623 INFO [IPC Server handler 4 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000012_0 is : 1.0
2018-08-08 13:58:19,701 INFO [IPC Server handler 7 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000008_0 is : 1.0
2018-08-08 13:58:19,716 INFO [IPC Server handler 8 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000010_0 is : 1.0
2018-08-08 13:58:19,765 INFO [IPC Server handler 9 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000005_0 is : 1.0
2018-08-08 13:58:21,807 INFO [IPC Server handler 11 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000001_0 is : 1.0
2018-08-08 13:58:21,807 INFO [IPC Server handler 12 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000011_0 is : 1.0
2018-08-08 13:58:21,809 INFO [IPC Server handler 13 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000008_0 is : 1.0
2018-08-08 13:58:21,810 INFO [IPC Server handler 10 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000009_0 is : 1.0
2018-08-08 13:58:21,811 INFO [IPC Server handler 14 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000003_0 is : 1.0
2018-08-08 13:58:21,812 INFO [IPC Server handler 14 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000005_0 is : 1.0
2018-08-08 13:58:21,812 INFO [IPC Server handler 15 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000002_0 is : 1.0
2018-08-08 13:58:21,813 INFO [IPC Server handler 18 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000007_0 is : 1.0
2018-08-08 13:58:21,813 INFO [IPC Server handler 17 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000013_0 is : 1.0
2018-08-08 13:58:21,814 INFO [IPC Server handler 19 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000006_0 is : 1.0
2018-08-08 13:58:21,814 INFO [IPC Server handler 19 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000012_0 is : 1.0
2018-08-08 13:58:21,816 INFO [IPC Server handler 21 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000004_0 is : 1.0
2018-08-08 13:58:21,816 INFO [IPC Server handler 22 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000010_0 is : 1.0
2018-08-08 13:58:21,827 INFO [IPC Server handler 23 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000001_0
2018-08-08 13:58:21,828 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000001_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,828 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000001_0 given a go for committing the task output.
2018-08-08 13:58:21,829 INFO [IPC Server handler 25 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000011_0
2018-08-08 13:58:21,829 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000011_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,829 INFO [IPC Server handler 24 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000001_0
2018-08-08 13:58:21,829 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000011_0 given a go for committing the task output.
2018-08-08 13:58:21,830 INFO [IPC Server handler 26 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000008_0
2018-08-08 13:58:21,830 INFO [IPC Server handler 24 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000001_0:true
2018-08-08 13:58:21,830 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000008_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,830 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000008_0 given a go for committing the task output.
2018-08-08 13:58:21,830 INFO [IPC Server handler 27 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000011_0
2018-08-08 13:58:21,830 INFO [IPC Server handler 27 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000011_0:true
2018-08-08 13:58:21,831 INFO [IPC Server handler 28 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000008_0
2018-08-08 13:58:21,831 INFO [IPC Server handler 28 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000008_0:true
2018-08-08 13:58:21,832 INFO [IPC Server handler 29 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000003_0
2018-08-08 13:58:21,832 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000003_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,832 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000003_0 given a go for committing the task output.
2018-08-08 13:58:21,832 INFO [IPC Server handler 0 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000007_0
2018-08-08 13:58:21,832 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000007_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,832 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000007_0 given a go for committing the task output.
2018-08-08 13:58:21,833 INFO [IPC Server handler 1 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000005_0
2018-08-08 13:58:21,833 INFO [IPC Server handler 2 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000003_0
2018-08-08 13:58:21,833 INFO [IPC Server handler 3 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000007_0
2018-08-08 13:58:21,833 INFO [IPC Server handler 2 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000003_0:true
2018-08-08 13:58:21,833 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000005_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,833 INFO [IPC Server handler 2 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000009_0
2018-08-08 13:58:21,833 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000005_0 given a go for committing the task output.
2018-08-08 13:58:21,833 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000009_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,833 INFO [IPC Server handler 3 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000007_0:true
2018-08-08 13:58:21,834 INFO [IPC Server handler 2 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000006_0
2018-08-08 13:58:21,834 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000009_0 given a go for committing the task output.
2018-08-08 13:58:21,834 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000006_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,834 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000006_0 given a go for committing the task output.
2018-08-08 13:58:21,834 INFO [IPC Server handler 6 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000005_0
2018-08-08 13:58:21,834 INFO [IPC Server handler 6 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000005_0:true
2018-08-08 13:58:21,834 INFO [IPC Server handler 7 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000002_0
2018-08-08 13:58:21,834 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000002_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,834 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000002_0 given a go for committing the task output.
2018-08-08 13:58:21,835 INFO [IPC Server handler 8 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000009_0
2018-08-08 13:58:21,835 INFO [IPC Server handler 8 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000009_0:true
2018-08-08 13:58:21,835 INFO [IPC Server handler 9 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000006_0
2018-08-08 13:58:21,835 INFO [IPC Server handler 9 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000006_0:true
2018-08-08 13:58:21,836 INFO [IPC Server handler 11 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000002_0
2018-08-08 13:58:21,836 INFO [IPC Server handler 11 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000002_0:true
2018-08-08 13:58:21,836 INFO [IPC Server handler 11 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000004_0
2018-08-08 13:58:21,836 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000004_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,836 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000004_0 given a go for committing the task output.
2018-08-08 13:58:21,837 INFO [IPC Server handler 13 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000004_0
2018-08-08 13:58:21,837 INFO [IPC Server handler 13 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000004_0:true
2018-08-08 13:58:21,837 INFO [IPC Server handler 13 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000010_0
2018-08-08 13:58:21,838 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000010_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,838 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000010_0 given a go for committing the task output.
2018-08-08 13:58:21,838 INFO [IPC Server handler 16 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000012_0
2018-08-08 13:58:21,838 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000012_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,838 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000012_0 given a go for committing the task output.
2018-08-08 13:58:21,839 INFO [IPC Server handler 14 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000010_0
2018-08-08 13:58:21,839 INFO [IPC Server handler 14 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000010_0:true
2018-08-08 13:58:21,839 INFO [IPC Server handler 15 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000012_0
2018-08-08 13:58:21,840 INFO [IPC Server handler 15 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000012_0:true
2018-08-08 13:58:21,843 INFO [IPC Server handler 18 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0013_m_000013_0
2018-08-08 13:58:21,843 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000013_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:58:21,843 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0013_m_000013_0 given a go for committing the task output.
2018-08-08 13:58:21,844 INFO [IPC Server handler 17 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0013_m_000013_0
2018-08-08 13:58:21,845 INFO [IPC Server handler 17 on 45173] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0013_m_000013_0:true
2018-08-08 13:58:21,852 INFO [IPC Server handler 20 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000008_0 is : 1.0
2018-08-08 13:58:21,853 INFO [IPC Server handler 19 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000001_0 is : 1.0
2018-08-08 13:58:21,854 INFO [IPC Server handler 21 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000011_0 is : 1.0
2018-08-08 13:58:21,854 INFO [IPC Server handler 22 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000008_0
2018-08-08 13:58:21,855 INFO [IPC Server handler 23 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000001_0
2018-08-08 13:58:21,855 INFO [IPC Server handler 25 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000011_0
2018-08-08 13:58:21,855 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000008_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,855 INFO [IPC Server handler 24 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000007_0 is : 1.0
2018-08-08 13:58:21,856 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000001_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,856 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000011_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,856 INFO [IPC Server handler 26 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000005_0 is : 1.0
2018-08-08 13:58:21,857 INFO [ContainerLauncher #14] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000010 taskAttempt attempt_1533735211869_0013_m_000008_0
2018-08-08 13:58:21,857 INFO [IPC Server handler 27 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000007_0
2018-08-08 13:58:21,857 INFO [ContainerLauncher #15] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000003 taskAttempt attempt_1533735211869_0013_m_000001_0
2018-08-08 13:58:21,859 INFO [ContainerLauncher #14] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000008_0
2018-08-08 13:58:21,859 INFO [ContainerLauncher #16] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000013 taskAttempt attempt_1533735211869_0013_m_000011_0
2018-08-08 13:58:21,859 INFO [ContainerLauncher #15] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000001_0
2018-08-08 13:58:21,859 INFO [IPC Server handler 28 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000003_0 is : 1.0
2018-08-08 13:58:21,859 INFO [ContainerLauncher #14] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave2:43787
2018-08-08 13:58:21,860 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000007_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,860 INFO [ContainerLauncher #16] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000011_0
2018-08-08 13:58:21,862 INFO [IPC Server handler 29 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000006_0 is : 1.0
2018-08-08 13:58:21,862 INFO [IPC Server handler 0 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000005_0
2018-08-08 13:58:21,863 INFO [IPC Server handler 1 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000003_0
2018-08-08 13:58:21,863 INFO [ContainerLauncher #16] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave11:46641
2018-08-08 13:58:21,863 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000005_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,863 INFO [ContainerLauncher #17] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000009 taskAttempt attempt_1533735211869_0013_m_000007_0
2018-08-08 13:58:21,864 INFO [ContainerLauncher #17] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000007_0
2018-08-08 13:58:21,864 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000003_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,864 INFO [IPC Server handler 4 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000002_0 is : 1.0
2018-08-08 13:58:21,865 INFO [IPC Server handler 5 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000009_0 is : 1.0
2018-08-08 13:58:21,865 INFO [IPC Server handler 3 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000004_0 is : 1.0
2018-08-08 13:58:21,865 INFO [ContainerLauncher #18] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000007 taskAttempt attempt_1533735211869_0013_m_000005_0
2018-08-08 13:58:21,866 INFO [ContainerLauncher #18] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000005_0
2018-08-08 13:58:21,866 INFO [IPC Server handler 2 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000010_0 is : 1.0
2018-08-08 13:58:21,866 INFO [IPC Server handler 6 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000006_0
2018-08-08 13:58:21,866 INFO [ContainerLauncher #19] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000005 taskAttempt attempt_1533735211869_0013_m_000003_0
2018-08-08 13:58:21,867 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000006_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,868 INFO [IPC Server handler 7 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000010_0
2018-08-08 13:58:21,867 INFO [ContainerLauncher #19] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000003_0
2018-08-08 13:58:21,868 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000010_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,868 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000012 taskAttempt attempt_1533735211869_0013_m_000010_0
2018-08-08 13:58:21,870 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000010_0
2018-08-08 13:58:21,870 INFO [ContainerLauncher #20] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000008 taskAttempt attempt_1533735211869_0013_m_000006_0
2018-08-08 13:58:21,871 INFO [ContainerLauncher #20] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000006_0
2018-08-08 13:58:21,872 INFO [IPC Server handler 12 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000002_0
2018-08-08 13:58:21,872 INFO [ContainerLauncher #15] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave13:40615
2018-08-08 13:58:21,872 INFO [IPC Server handler 8 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000013_0 is : 1.0
2018-08-08 13:58:21,872 INFO [IPC Server handler 9 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000012_0 is : 1.0
2018-08-08 13:58:21,872 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000002_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,873 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000004 taskAttempt attempt_1533735211869_0013_m_000002_0
2018-08-08 13:58:21,874 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000002_0
2018-08-08 13:58:21,874 INFO [IPC Server handler 11 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000009_0
2018-08-08 13:58:21,874 INFO [IPC Server handler 10 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000012_0
2018-08-08 13:58:21,875 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000009_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,875 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000012_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,875 INFO [IPC Server handler 13 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000004_0
2018-08-08 13:58:21,875 INFO [IPC Server handler 16 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000013_0
2018-08-08 13:58:21,877 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000014 taskAttempt attempt_1533735211869_0013_m_000012_0
2018-08-08 13:58:21,877 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000004_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,878 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000011 taskAttempt attempt_1533735211869_0013_m_000009_0
2018-08-08 13:58:21,878 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000013_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:21,877 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000012_0
2018-08-08 13:58:21,880 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000006 taskAttempt attempt_1533735211869_0013_m_000004_0
2018-08-08 13:58:21,880 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000015 taskAttempt attempt_1533735211869_0013_m_000013_0
2018-08-08 13:58:21,879 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000009_0
2018-08-08 13:58:21,882 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000013_0
2018-08-08 13:58:21,882 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000004_0
2018-08-08 13:58:21,880 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave7:43383
2018-08-08 13:58:21,886 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave15:37797
2018-08-08 13:58:21,890 INFO [ContainerLauncher #20] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave9:37771
2018-08-08 13:58:21,894 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave1:33157
2018-08-08 13:58:21,902 INFO [ContainerLauncher #19] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave4:46069
2018-08-08 13:58:21,912 INFO [ContainerLauncher #18] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave12:33893
2018-08-08 13:58:21,919 INFO [ContainerLauncher #17] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave6:36387
2018-08-08 13:58:21,923 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave5:46217
2018-08-08 13:58:21,925 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave10:46663
2018-08-08 13:58:21,929 INFO [ContainerLauncher #13] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave8:41519
2018-08-08 13:58:21,929 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000002_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,929 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000006_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,929 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000012_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,929 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000008_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,930 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000010_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,930 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000001_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,930 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000011_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,993 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000002_0
2018-08-08 13:58:21,994 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000002 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:21,995 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000006_0
2018-08-08 13:58:21,995 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000006 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:21,995 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000012_0
2018-08-08 13:58:21,995 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000012 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:21,995 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000008_0
2018-08-08 13:58:21,995 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000008 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:21,995 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000010_0
2018-08-08 13:58:21,995 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000010 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:21,996 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000001_0
2018-08-08 13:58:21,996 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000001 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:21,996 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000011_0
2018-08-08 13:58:21,997 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000011 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:21,997 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000003_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,997 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000005_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,997 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000007_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,997 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000004_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,997 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000013_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,997 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000009_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:21,999 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 1
2018-08-08 13:58:21,999 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 2
2018-08-08 13:58:21,999 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 3
2018-08-08 13:58:21,999 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 4
2018-08-08 13:58:21,999 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 5
2018-08-08 13:58:21,999 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 6
2018-08-08 13:58:21,999 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 7
2018-08-08 13:58:21,999 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000003_0
2018-08-08 13:58:22,000 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000003 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:22,000 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000005_0
2018-08-08 13:58:22,000 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000005 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:22,000 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000007_0
2018-08-08 13:58:22,000 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000007 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:22,000 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000004_0
2018-08-08 13:58:22,000 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000004 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:22,000 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000013_0
2018-08-08 13:58:22,000 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000013 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:22,000 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000009_0
2018-08-08 13:58:22,000 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000009 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:22,001 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 8
2018-08-08 13:58:22,001 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 9
2018-08-08 13:58:22,002 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000003
2018-08-08 13:58:22,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 10
2018-08-08 13:58:22,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 11
2018-08-08 13:58:22,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 12
2018-08-08 13:58:22,002 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 13
2018-08-08 13:58:22,003 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000007
2018-08-08 13:58:22,003 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000013
2018-08-08 13:58:22,003 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000001_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,003 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000012
2018-08-08 13:58:22,003 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000005_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,003 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000011_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,003 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000015
2018-08-08 13:58:22,003 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000010_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,003 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000013_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,003 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000005
2018-08-08 13:58:22,003 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000011
2018-08-08 13:58:22,003 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000003_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,003 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000009
2018-08-08 13:58:22,003 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000009_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,003 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000007_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,003 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000014
2018-08-08 13:58:22,004 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000010
2018-08-08 13:58:22,004 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000006
2018-08-08 13:58:22,004 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000012_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,004 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000008_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,004 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000004_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,004 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000004
2018-08-08 13:58:22,004 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0013_01_000008
2018-08-08 13:58:22,004 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:58:22,004 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000002_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,004 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0013_m_000006_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:58:22,555 INFO [IPC Server handler 14 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000000_0 is : 1.0
2018-08-08 13:58:24,201 INFO [IPC Server handler 14 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000000_0 is : 1.0
2018-08-08 13:58:24,230 INFO [IPC Server handler 15 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0013_m_000000_0 is : 1.0
2018-08-08 13:58:24,231 INFO [IPC Server handler 18 on 45173] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0013_m_000000_0
2018-08-08 13:58:24,232 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000000_0 TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:58:24,232 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0013_01_000002 taskAttempt attempt_1533735211869_0013_m_000000_0
2018-08-08 13:58:24,233 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0013_m_000000_0
2018-08-08 13:58:24,233 INFO [ContainerLauncher #11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave14:35219
2018-08-08 13:58:24,242 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0013_m_000000_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:58:24,242 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0013_m_000000_0
2018-08-08 13:58:24,242 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0013_m_000000 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:58:24,242 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 14
2018-08-08 13:58:24,244 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0013Job Transitioned from RUNNING to COMMITTING
2018-08-08 13:58:24,246 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_COMMIT
2018-08-08 13:58:24,368 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Calling handler for JobFinishedEvent 
2018-08-08 13:58:24,369 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0013Job Transitioned from COMMITTING to SUCCEEDED
2018-08-08 13:58:24,370 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: We are finishing cleanly so this is the last retry
2018-08-08 13:58:24,370 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true
2018-08-08 13:58:24,370 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: RMCommunicator notified that shouldUnregistered is: true
2018-08-08 13:58:24,370 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true
2018-08-08 13:58:24,370 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true
2018-08-08 13:58:24,370 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
2018-08-08 13:58:24,370 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0
2018-08-08 13:58:24,481 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0013/job_1533735211869_0013_1.jhist to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0013-1533736671716-hduser-GraphalyticsBenchmark%3A+WeaklyConnectedComponentsJo-1533736704366-14-0-SUCCEEDED-default-1533736676851.jhist_tmp
2018-08-08 13:58:24,556 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0013-1533736671716-hduser-GraphalyticsBenchmark%3A+WeaklyConnectedComponentsJo-1533736704366-14-0-SUCCEEDED-default-1533736676851.jhist_tmp
2018-08-08 13:58:24,560 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0013/job_1533735211869_0013_1_conf.xml to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0013_conf.xml_tmp
2018-08-08 13:58:24,639 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0013_conf.xml_tmp
2018-08-08 13:58:24,643 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0013.summary_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0013.summary
2018-08-08 13:58:24,645 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0013_conf.xml_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0013_conf.xml
2018-08-08 13:58:24,648 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0013-1533736671716-hduser-GraphalyticsBenchmark%3A+WeaklyConnectedComponentsJo-1533736704366-14-0-SUCCEEDED-default-1533736676851.jhist_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0013-1533736671716-hduser-GraphalyticsBenchmark%3A+WeaklyConnectedComponentsJo-1533736704366-14-0-SUCCEEDED-default-1533736676851.jhist
2018-08-08 13:58:24,687 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()
2018-08-08 13:58:24,697 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Setting job diagnostics to 
2018-08-08 13:58:24,698 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: History url is http://graphalytics-giraph-slave3:19888/jobhistory/job/job_1533735211869_0013
2018-08-08 13:58:24,704 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Waiting for application to be successfully unregistered.
2018-08-08 13:58:25,705 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:58:25,706 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://graphalytics-giraph:9000 /tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0013
2018-08-08 13:58:25,710 INFO [Thread-94] org.apache.hadoop.ipc.Server: Stopping server on 45173
2018-08-08 13:58:25,711 INFO [IPC Server listener on 45173] org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 45173
2018-08-08 13:58:25,711 INFO [TaskHeartbeatHandler PingChecker] org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted
2018-08-08 13:58:25,714 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
End of LogType:syslog



Container: container_1533735211869_0013_01_000005 on graphalytics-giraph-slave4_46069
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:19969
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10635 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 296 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 125,341,140.00
               min = 16.00
               max = 262144.00
              mean = 141149.93
            stddev = 65431.93
            median = 164509.00
              75% <= 182656.00
              95% <= 230528.00
              98% <= 238976.00
              99% <= 238976.00
            99.9% <= 262144.00
             count = 888

  remote-requests:
    count = 0

  requests-received:
             count = 888
         mean rate = 83.36 requests/s
     1-minute rate = 76.40 requests/s
     5-minute rate = 75.13 requests/s
    15-minute rate = 74.91 requests/s

  requests-sent:
             count = 339
         mean rate = 31.83 requests/s
     1-minute rate = 32.14 requests/s
     5-minute rate = 32.35 requests/s
    15-minute rate = 32.38 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 8,408.00
               min = 16.00
               max = 1473.00
              mean = 24.80
            stddev = 80.28
            median = 16.00
              75% <= 16.00
              95% <= 53.00
              98% <= 89.00
              99% <= 89.00
            99.9% <= 1473.00
             count = 339

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 10635

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 296

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1429 ms
  compute all partitions: 873 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 933 ms
  time to first message: 301612 us
  wait on requests time: 361943 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 933

  compute-all-ms:
    value = 873

  compute-per-partition-ms:
               sum = 3,937.00
               min = 13.00
               max = 597.00
              mean = 119.30
            stddev = 130.62
            median = 69.00
              75% <= 201.00
              95% <= 475.20
              98% <= 597.00
              99% <= 597.00
            99.9% <= 597.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 63287846

  messages-sent:
    count = 7819801

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.666666666666666

  processing-per-thread-ms:
               sum = 3,936.00
               min = 223.00
               max = 831.00
              mean = 357.82
            stddev = 196.26
            median = 289.00
              75% <= 299.00
              95% <= 831.00
              98% <= 831.00
              99% <= 831.00
            99.9% <= 831.00
             count = 11

  received-bytes:
               sum = 58,415,724.00
               min = 16.00
               max = 313856.00
              mean = 68886.47
            stddev = 77870.43
            median = 40041.00
              75% <= 129536.00
              95% <= 227539.20
              98% <= 238976.00
              99% <= 239360.00
            99.9% <= 313856.00
             count = 848

  remote-requests:
    count = 277

  requests-received:
             count = 848
         mean rate = 580.32 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 601
         mean rate = 411.29 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 58,432,181.00
               min = 16.00
               max = 526901.00
              mean = 97224.93
            stddev = 182868.05
            median = 53.00
              75% <= 588.50
              95% <= 455032.60
              98% <= 524720.20
              99% <= 525244.52
            99.9% <= 526901.00
             count = 601

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 1429

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 4132

  time-to-first-message-ms:
    value = 301612

  total-requests:
    value = 300

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 361943

  worker-context-post-superstep:
    value = 11

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 651 ms
  compute all partitions: 335 ms
  time spent in gc: 80 ms
  bytes transferred in out-of-core: 0
  network communication time: 316 ms
  time to first message: 205096 us
  wait on requests time: 185383 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 316

  compute-all-ms:
    value = 335

  compute-per-partition-ms:
               sum = 2,233.00
               min = 9.00
               max = 162.00
              mean = 67.67
            stddev = 64.49
            median = 30.00
              75% <= 153.50
              95% <= 160.60
              98% <= 162.00
              99% <= 162.00
            99.9% <= 162.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 61584751

  messages-sent:
    count = 7607161

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 2,233.00
               min = 178.00
               max = 231.00
              mean = 203.00
            stddev = 20.05
            median = 209.00
              75% <= 219.00
              95% <= 231.00
              98% <= 231.00
              99% <= 231.00
            99.9% <= 231.00
             count = 11

  received-bytes:
               sum = 56,970,641.00
               min = 16.00
               max = 378624.00
              mean = 87111.07
            stddev = 103404.73
            median = 40704.00
              75% <= 173705.50
              95% <= 283328.00
              98% <= 322790.40
              99% <= 349561.60
            99.9% <= 378624.00
             count = 654

  remote-requests:
    count = 276

  requests-received:
             count = 654
         mean rate = 959.31 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 601
         mean rate = 881.61 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 56,860,928.00
               min = 16.00
               max = 528885.00
              mean = 94610.53
            stddev = 177690.67
            median = 53.00
              75% <= 617.50
              95% <= 443332.60
              98% <= 522632.04
              99% <= 524906.44
            99.9% <= 528885.00
             count = 601

  superstep-gc-time-ms:
    count = 80

  superstep-time-ms:
    value = 651

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 496

  time-to-first-message-ms:
    value = 205096

  total-requests:
    value = 299

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 185383

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 195 ms
  compute all partitions: 33 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 42622 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 33

  compute-per-partition-ms:
               sum = 79.00
               min = 1.00
               max = 10.00
              mean = 2.39
            stddev = 2.00
            median = 2.00
              75% <= 2.00
              95% <= 7.90
              98% <= 10.00
              99% <= 10.00
            99.9% <= 10.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 14

  message-bytes-sent:
    count = 163149

  messages-sent:
    count = 12844

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 79.00
               min = 0.00
               max = 17.00
              mean = 7.18
            stddev = 6.32
            median = 9.00
              75% <= 12.00
              95% <= 17.00
              98% <= 17.00
              99% <= 17.00
            99.9% <= 17.00
             count = 11

  received-bytes:
               sum = 157,016.00
               min = 16.00
               max = 7001.00
              mean = 754.88
            stddev = 1521.21
            median = 32.00
              75% <= 684.75
              95% <= 4765.40
              98% <= 6539.70
              99% <= 6898.05
            99.9% <= 7001.00
             count = 208

  remote-requests:
    count = 168

  requests-received:
             count = 208
         mean rate = 919.79 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 460
         mean rate = 2034.19 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 84

  sent-bytes:
               sum = 159,017.00
               min = 16.00
               max = 2253.00
              mean = 345.69
            stddev = 541.99
            median = 16.00
              75% <= 474.25
              95% <= 1600.60
              98% <= 1917.48
              99% <= 2014.36
            99.9% <= 2253.00
             count = 460

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 195

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 3

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 182

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 42622

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 107 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 210 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 36.00
               min = 0.00
               max = 2.00
              mean = 1.09
            stddev = 0.46
            median = 1.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 35.00
               min = 0.00
               max = 7.00
              mean = 3.18
            stddev = 2.32
            median = 4.00
              75% <= 5.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.18
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 381.16 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 388.59 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.67
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 107

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 210

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 97.45787215348868

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:68276
Log Contents:
2018-08-08 13:58:00,318 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,378 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,378 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,380 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,380 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,552 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:00,777 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:00,945 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,378 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,389 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,538 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,553 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,582 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,583 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,592 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,598 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,599 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 3 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave4
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000005:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000005/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000005:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000005/tmp
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000005
INFO    2018-08-08 13:58:01,606 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,620 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,620 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,626 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300a9, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,628 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:01,742 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:01,760 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:01,815 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave4/10.164.0.6:30003 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:01,821 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:01,822 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:01,844 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:01,855 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:01,859 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:01,862 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:01,871 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave4_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003)
INFO    2018-08-08 13:58:02,303 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,395 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,403 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,405 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,405 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,406 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,407 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,407 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,410 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,420 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,427 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,427 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,507 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,548 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0316052 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,548 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03254461 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,548 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.033700466 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,548 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040645093 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,549 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031377673 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,549 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030913398 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,549 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030385694 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,550 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.02981882 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,550 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.029155444 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,550 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028622221 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,550 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028486328 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0028, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.126
MBytes/sec sent = 0.0101, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.126
INFO    2018-08-08 13:58:02,554 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,558 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003786092 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,558 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002873206 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,559 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002624538 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,561 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003769165 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,562 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004083727 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,564 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005214809 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,564 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004771089 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004112078 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,566 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004254745 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00529354 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005094136 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,569 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0102, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.008
MBytes/sec sent = 0.0159, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.009
INFO    2018-08-08 13:58:02,569 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:58:12,355 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,358 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,401 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,405 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50213.37M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,405 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 9.845
MBytes/sec sent = 0, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 9.845
INFO    2018-08-08 13:58:12,405 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,414 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 4 more tasks to send their aggregator data, task ids: [2, 5, 9, 10]
INFO    2018-08-08 13:58:12,432 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:58:12,433 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50213.37M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,445 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,483 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,487 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@39ab59f8,outgoing=org.apache.giraph.conf.DefaultMessageClasses@64e92d61)
WARN    2018-08-08 13:58:12,492 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,508 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,509 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,511 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave4_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003)
INFO    2018-08-08 13:58:12,549 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,549 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,549 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,551 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.118
MBytes/sec sent = 0.0118, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.118
INFO    2018-08-08 13:58:12,555 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,560 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,560 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:58:12,566 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 11 more tasks to send their aggregator data
INFO    2018-08-08 13:58:12,576 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,824 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.23309991 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.23 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,824 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2245781 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.22 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,861 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.28235912 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,865 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2671451 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.27 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,875 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.29195052 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,881 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.28230584 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,888 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.29860228 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,892 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2984297 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,890 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.30464983 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.30 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,241 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.6596852 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.66 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,416 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.83581305 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.83 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,450 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 49554.78M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,812 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0043, MBytesReceived = 0.0042, ave received req MBytes = 0, secs waited = 0.983
MBytes/sec sent = 56.6236, MBytesSent = 55.7177, ave sent req MBytes = 0.2011, secs waited = 0.983
INFO    2018-08-08 13:58:13,812 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,931 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:13,932 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 7819801 , message bytes = 63287846 , Memory (free/total/max) = 49516.17M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,935 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,957 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,959 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@127d7908,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6b9c69a9)
INFO    2018-08-08 13:58:13,968 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,970 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave4_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003)
INFO    2018-08-08 13:58:13,991 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,991 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,991 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,992 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0003, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.06
MBytes/sec sent = 0.023, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.06
INFO    2018-08-08 13:58:13,996 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:13,998 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:58:14,000 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,189 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18080766 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,189 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18352717 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,189 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18498959 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,189 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18133263 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,206 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2033044 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,217 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.21028763 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,221 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.21732788 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,221 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2155169 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,228 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.22690393 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.23 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,228 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.21991675 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.22 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,239 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.23574959 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.23 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,336 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 48815.72M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,480 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 80ms
INFO    2018-08-08 13:58:14,522 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0128, MBytesReceived = 0.0042, ave received req MBytes = 0, secs waited = 0.328
MBytes/sec sent = 164.8, MBytesSent = 54.2192, ave sent req MBytes = 0.1964, secs waited = 0.328
INFO    2018-08-08 13:58:14,522 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,619 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,619 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7607161 , message bytes = 61584751 , Memory (free/total/max) = 51685.03M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,624 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,642 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,645 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4bd2f0dc,outgoing=org.apache.giraph.conf.DefaultMessageClasses@2e647e59)
INFO    2018-08-08 13:58:14,653 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,666 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave4_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003)
WARN    2018-08-08 13:58:14,706 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,727 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,728 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,728 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.109
MBytes/sec sent = 0.0128, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.109
INFO    2018-08-08 13:58:14,731 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,734 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,744 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006845443 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,746 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010235022 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,746 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010857388 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,750 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015439091 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,754 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010254977 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,756 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012280755 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,756 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013127462 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,759 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017507304 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,761 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010343004 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,763 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008909472 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,767 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011687776 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,768 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 51577.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,810 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0394, MBytesReceived = 0.0026, ave received req MBytes = 0, secs waited = 0.064
MBytes/sec sent = 2.2237, MBytesSent = 0.1445, ave sent req MBytes = 0.0009, secs waited = 0.064
INFO    2018-08-08 13:58:14,810 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,848 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,848 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 12844 , message bytes = 163149 , Memory (free/total/max) = 51571.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,854 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,874 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,876 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:58:14,881 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,897 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave4_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=3, port=30003)
WARN    2018-08-08 13:58:14,938 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,962 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,963 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,963 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.116
MBytes/sec sent = 0.012, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.116
INFO    2018-08-08 13:58:14,966 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,968 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,972 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,979 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002799836 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001406448 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003793657 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004869804 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006153687 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006717981 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00334188 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008502622 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005574482 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006594651 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003449921 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 51533.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,988 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,988 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 51533.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,991 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,009 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,012 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:58:15,015 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,025 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,039 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,076 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,081 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,083 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,329 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,330 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4802 vertices using 1 threads
INFO    2018-08-08 13:58:17,333 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,583 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,583 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,587 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/3_worker
INFO    2018-08-08 13:58:17,592 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300a9 closed
INFO    2018-08-08 13:58:17,593 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,595 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,598 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,807 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,811 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000003_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,833 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000003_0 is allowed to commit now
INFO    2018-08-08 13:58:21,843 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000003_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000003
INFO    2018-08-08 13:58:21,862 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000003_0' done.
INFO    2018-08-08 13:58:21,866 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000003_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128638
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=41933
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=171
		CPU time spent (ms)=21160
		Physical memory (bytes) snapshot=3399200768
		Virtual memory (bytes) snapshot=58966020096
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000006 on graphalytics-giraph-slave5_46217
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:19980
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10423 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 359 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 127,150,749.00
               min = 16.00
               max = 238976.00
              mean = 133281.71
            stddev = 65693.02
            median = 147613.00
              75% <= 182656.00
              95% <= 230528.00
              98% <= 238976.00
              99% <= 238976.00
            99.9% <= 238976.00
             count = 954

  remote-requests:
    count = 0

  requests-received:
             count = 954
         mean rate = 91.39 requests/s
     1-minute rate = 79.80 requests/s
     5-minute rate = 77.90 requests/s
    15-minute rate = 77.57 requests/s

  requests-sent:
             count = 342
         mean rate = 32.77 requests/s
     1-minute rate = 32.41 requests/s
     5-minute rate = 32.56 requests/s
    15-minute rate = 32.59 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 8,456.00
               min = 16.00
               max = 1473.00
              mean = 24.73
            stddev = 79.93
            median = 16.00
              75% <= 16.00
              95% <= 53.00
              98% <= 89.00
              99% <= 89.00
            99.9% <= 1473.00
             count = 342

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 10423

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 359

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1432 ms
  compute all partitions: 1024 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 875 ms
  time to first message: 402561 us
  wait on requests time: 253445 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 875

  compute-all-ms:
    value = 1024

  compute-per-partition-ms:
               sum = 5,259.00
               min = 9.00
               max = 343.00
              mean = 159.36
            stddev = 133.59
            median = 213.00
              75% <= 295.50
              95% <= 317.10
              98% <= 343.00
              99% <= 343.00
            99.9% <= 343.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 64179641

  messages-sent:
    count = 7933338

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.718120805369128

  processing-per-thread-ms:
               sum = 5,259.00
               min = 314.00
               max = 668.00
              mean = 478.09
            stddev = 123.17
            median = 531.00
              75% <= 576.00
              95% <= 668.00
              98% <= 668.00
              99% <= 668.00
            99.9% <= 668.00
             count = 11

  received-bytes:
               sum = 59,181,137.00
               min = 16.00
               max = 379520.00
              mean = 76958.57
            stddev = 94802.66
            median = 25344.00
              75% <= 132416.00
              95% <= 238976.00
              98% <= 323840.00
              99% <= 372262.40
            99.9% <= 379520.00
             count = 769

  remote-requests:
    count = 275

  requests-received:
             count = 769
         mean rate = 525.86 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 601
         mean rate = 410.97 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 59,183,776.00
               min = 16.00
               max = 527361.00
              mean = 98475.50
            stddev = 186013.26
            median = 25.00
              75% <= 518.00
              95% <= 474798.20
              98% <= 507345.16
              99% <= 525054.36
            99.9% <= 527361.00
             count = 601

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 1432

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 1456

  time-to-first-message-ms:
    value = 402561

  total-requests:
    value = 298

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 253445

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 652 ms
  compute all partitions: 313 ms
  time spent in gc: 66 ms
  bytes transferred in out-of-core: 0
  network communication time: 345 ms
  time to first message: 193502 us
  wait on requests time: 225404 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 345

  compute-all-ms:
    value = 313

  compute-per-partition-ms:
               sum = 2,100.00
               min = 11.00
               max = 143.00
              mean = 63.64
            stddev = 56.22
            median = 33.00
              75% <= 135.00
              95% <= 143.00
              98% <= 143.00
              99% <= 143.00
            99.9% <= 143.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 62418025

  messages-sent:
    count = 7713340

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.666666666666666

  processing-per-thread-ms:
               sum = 2,100.00
               min = 167.00
               max = 275.00
              mean = 190.91
            stddev = 30.19
            median = 184.00
              75% <= 200.00
              95% <= 275.00
              98% <= 275.00
              99% <= 275.00
            99.9% <= 275.00
             count = 11

  received-bytes:
               sum = 57,718,522.00
               min = 16.00
               max = 363904.00
              mean = 81986.54
            stddev = 95606.42
            median = 44206.50
              75% <= 139142.75
              95% <= 256160.00
              98% <= 307238.40
              99% <= 327673.70
            99.9% <= 363904.00
             count = 704

  remote-requests:
    count = 277

  requests-received:
             count = 704
         mean rate = 1031.59 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 602
         mean rate = 881.27 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 57,559,586.00
               min = 16.00
               max = 528821.00
              mean = 95613.93
            stddev = 180217.53
            median = 53.00
              75% <= 568.75
              95% <= 458827.40
              98% <= 524424.68
              99% <= 525941.04
            99.9% <= 528821.00
             count = 602

  superstep-gc-time-ms:
    count = 66

  superstep-time-ms:
    value = 652

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 414

  time-to-first-message-ms:
    value = 193502

  total-requests:
    value = 300

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 225404

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 196 ms
  compute all partitions: 32 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 49255 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 32

  compute-per-partition-ms:
               sum = 142.00
               min = 1.00
               max = 18.00
              mean = 4.30
            stddev = 4.61
            median = 2.00
              75% <= 5.50
              95% <= 15.90
              98% <= 18.00
              99% <= 18.00
            99.9% <= 18.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 149312

  messages-sent:
    count = 11448

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 141.00
               min = 3.00
               max = 23.00
              mean = 12.82
            stddev = 5.88
            median = 11.00
              75% <= 18.00
              95% <= 23.00
              98% <= 23.00
              99% <= 23.00
            99.9% <= 23.00
             count = 11

  received-bytes:
               sum = 159,668.00
               min = 16.00
               max = 8419.00
              mean = 543.09
            stddev = 1281.68
            median = 16.00
              75% <= 100.00
              95% <= 3469.50
              98% <= 5575.40
              99% <= 6268.55
            99.9% <= 8419.00
             count = 294

  remote-requests:
    count = 264

  requests-received:
             count = 294
         mean rate = 1291.64 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 548
         mean rate = 2407.55 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 146,443.00
               min = 16.00
               max = 1617.00
              mean = 267.23
            stddev = 358.86
            median = 71.00
              75% <= 396.25
              95% <= 1100.80
              98% <= 1361.08
              99% <= 1459.28
            99.9% <= 1617.00
             count = 548

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 196

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 38

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 286

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 49255

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 107 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 186 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 28.00
               min = 0.00
               max = 2.00
              mean = 0.85
            stddev = 0.62
            median = 1.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 28.00
               min = 0.00
               max = 6.00
              mean = 2.55
            stddev = 2.30
            median = 2.00
              75% <= 5.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 904.94
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 390.90 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 390.88 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 107

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 186

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 97.51576147520339

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:68310
Log Contents:
2018-08-08 13:58:00,453 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,516 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,516 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,518 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,518 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,696 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:00,924 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:01,111 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,582 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,595 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,744 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,759 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,789 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,790 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,798 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,806 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,806 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 4 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave5
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000006:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000006/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000006:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000006/tmp
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,812 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000006
INFO    2018-08-08 13:58:01,813 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,826 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,827 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,833 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300b1, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,834 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:01,949 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:01,970 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:02,031 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave5/10.164.0.7:30004 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:02,036 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:02,036 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:02,057 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:02,067 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:02,071 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,074 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,081 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave5_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=4, port=30004)
INFO    2018-08-08 13:58:02,305 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,395 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,404 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,406 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,406 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,407 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,408 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,409 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,410 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,425 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,426 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,499 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,552 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043542735 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041852538 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041263 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044537272 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042645976 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05194841 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03962056 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038764354 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04077255 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037353817 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03812227 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,557 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0034, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.049
MBytes/sec sent = 0.0052, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.049
INFO    2018-08-08 13:58:02,559 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,563 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001014976 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,564 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003477043 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002980699 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006008065 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,566 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002874278 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003107077 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001188238 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00257304 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,569 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004330613 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,571 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003938818 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,571 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002919683 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,572 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0095, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:58:02,572 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:58:12,356 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,359 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,396 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,401 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50197.57M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,402 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 9.833
MBytes/sec sent = 0, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 9.834
INFO    2018-08-08 13:58:12,402 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,409 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 9 more tasks to send their aggregator data, task ids: [1, 2, 3, 5, 6, 7, 9, 10, 13]
INFO    2018-08-08 13:58:12,433 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:58:12,434 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50197.57M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,444 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,484 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,489 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@39ab59f8,outgoing=org.apache.giraph.conf.DefaultMessageClasses@64e92d61)
WARN    2018-08-08 13:58:12,494 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,508 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,509 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,512 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave5_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=4, port=30004)
INFO    2018-08-08 13:58:12,555 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,555 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,555 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,556 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.122
MBytes/sec sent = 0.0114, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.122
INFO    2018-08-08 13:58:12,561 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,564 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,565 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:58:12,569 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 9 more tasks to send their aggregator data, task ids: [5, 6, 7, 8, 9, 10, 11, 12, 13]
INFO    2018-08-08 13:58:12,577 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,915 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.31883907 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.31 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,926 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3428472 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.34 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,960 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3682638 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.36 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,963 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.38099837 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.38 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,981 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.39264816 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.39 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,125 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.53593767 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.53 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,147 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.55272394 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.55 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,153 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.5713586 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.57 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,167 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.57972836 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.58 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,172 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.59275264 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.59 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,253 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.672446 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.67 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,602 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 49652.53M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,856 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0045, MBytesReceived = 0.0042, ave received req MBytes = 0, secs waited = 0.939
MBytes/sec sent = 60.0366, MBytesSent = 56.4344, ave sent req MBytes = 0.2052, secs waited = 0.939
INFO    2018-08-08 13:58:13,856 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,935 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:58:13,936 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 7933338 , message bytes = 64179641 , Memory (free/total/max) = 49446.92M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,940 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,959 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,961 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@127d7908,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6b9c69a9)
INFO    2018-08-08 13:58:13,969 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,971 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave5_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=4, port=30004)
INFO    2018-08-08 13:58:13,992 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,993 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,993 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,994 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0003, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.058
MBytes/sec sent = 0.0238, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.058
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:13,998 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:13,999 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:58:14,002 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,177 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16925259 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,177 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16876581 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,180 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17680067 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,187 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18268618 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,192 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17818333 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,196 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18496557 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,195 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.19079307 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,195 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.19165283 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,210 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2025729 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,213 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2019289 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,287 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.27807528 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,315 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 48799.61M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,426 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 66ms
INFO    2018-08-08 13:58:14,541 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0117, MBytesReceived = 0.0042, ave received req MBytes = 0, secs waited = 0.359
MBytes/sec sent = 152.4597, MBytesSent = 54.8855, ave sent req MBytes = 0.1981, secs waited = 0.359
INFO    2018-08-08 13:58:14,541 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,621 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,621 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7713340 , message bytes = 62418025 , Memory (free/total/max) = 51663.02M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,625 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,644 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,646 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4bd2f0dc,outgoing=org.apache.giraph.conf.DefaultMessageClasses@2e647e59)
INFO    2018-08-08 13:58:14,654 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,667 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave5_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=4, port=30004)
WARN    2018-08-08 13:58:14,707 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,730 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.109
MBytes/sec sent = 0.0128, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.109
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,733 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,735 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,745 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009421653 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,747 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004464353 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,748 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010899262 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,751 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01176962 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,752 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013054012 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,754 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013005169 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,756 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014415621 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,759 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.019153697 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,761 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.023060532 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,763 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.024963465 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,763 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013586078 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,768 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 51569.91M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,818 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0584, MBytesReceived = 0.004, ave received req MBytes = 0, secs waited = 0.068
MBytes/sec sent = 1.9227, MBytesSent = 0.1327, ave sent req MBytes = 0.0005, secs waited = 0.069
INFO    2018-08-08 13:58:14,818 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,850 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,850 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 11448 , message bytes = 149312 , Memory (free/total/max) = 51569.91M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,856 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,875 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,878 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:58:14,883 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,898 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave5_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=4, port=30004)
WARN    2018-08-08 13:58:14,940 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,965 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.115
MBytes/sec sent = 0.0121, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.115
INFO    2018-08-08 13:58:14,967 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,970 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,973 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,979 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005519823 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003941044 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004606066 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005368246 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00340287 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006551129 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005080619 secs for 9 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003853085 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002144037 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001230177 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,984 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002157819 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,984 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 51493.10M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,984 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0122, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.014
MBytes/sec sent = 0.0679, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.014
INFO    2018-08-08 13:58:14,984 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,990 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,990 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 51493.10M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,995 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,011 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,013 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:58:15,017 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,017 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,017 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,023 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,040 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,078 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,082 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,084 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,328 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,328 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4676 vertices using 1 threads
INFO    2018-08-08 13:58:17,331 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,586 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,586 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,592 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/4_worker
INFO    2018-08-08 13:58:17,597 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300b1 closed
INFO    2018-08-08 13:58:17,597 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,599 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,603 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,814 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,816 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000004_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,838 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000004_0 is allowed to commit now
INFO    2018-08-08 13:58:21,847 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000004_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000004
INFO    2018-08-08 13:58:21,878 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000004_0' done.
INFO    2018-08-08 13:58:21,883 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000004_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128638
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=40868
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=167
		CPU time spent (ms)=26540
		Physical memory (bytes) snapshot=3445440512
		Virtual memory (bytes) snapshot=58940289024
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000009 on graphalytics-giraph-slave6_36387
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:19974
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10680 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 314 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 125,853,696.00
               min = 16.00
               max = 238976.00
              mean = 145159.97
            stddev = 66765.57
            median = 164509.00
              75% <= 182656.00
              95% <= 235776.00
              98% <= 238976.00
              99% <= 238976.00
            99.9% <= 238976.00
             count = 867

  remote-requests:
    count = 0

  requests-received:
             count = 867
         mean rate = 81.06 requests/s
     1-minute rate = 73.73 requests/s
     5-minute rate = 72.36 requests/s
    15-minute rate = 72.12 requests/s

  requests-sent:
             count = 340
         mean rate = 31.79 requests/s
     1-minute rate = 31.66 requests/s
     5-minute rate = 31.77 requests/s
    15-minute rate = 31.79 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 8,424.00
               min = 16.00
               max = 1473.00
              mean = 24.78
            stddev = 80.17
            median = 16.00
              75% <= 16.00
              95% <= 53.00
              98% <= 89.00
              99% <= 89.00
            99.9% <= 1473.00
             count = 340

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 10680

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 314

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1430 ms
  compute all partitions: 750 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 977 ms
  time to first message: 277506 us
  wait on requests time: 503831 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 977

  compute-all-ms:
    value = 750

  compute-per-partition-ms:
               sum = 2,616.00
               min = 12.00
               max = 189.00
              mean = 79.27
            stddev = 72.49
            median = 34.00
              75% <= 172.00
              95% <= 188.30
              98% <= 189.00
              99% <= 189.00
            99.9% <= 189.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 63520731

  messages-sent:
    count = 7849840

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.612456747404845

  processing-per-thread-ms:
               sum = 2,616.00
               min = 203.00
               max = 276.00
              mean = 237.82
            stddev = 28.17
            median = 225.00
              75% <= 267.00
              95% <= 276.00
              98% <= 276.00
              99% <= 276.00
            99.9% <= 276.00
             count = 11

  received-bytes:
               sum = 58,653,524.00
               min = 16.00
               max = 381056.00
              mean = 75004.51
            stddev = 90701.84
            median = 30976.00
              75% <= 131072.00
              95% <= 239360.00
              98% <= 307591.68
              99% <= 328463.36
            99.9% <= 381056.00
             count = 782

  remote-requests:
    count = 267

  requests-received:
             count = 782
         mean rate = 535.35 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 594
         mean rate = 406.69 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 58,646,404.00
               min = 16.00
               max = 527769.00
              mean = 98731.32
            stddev = 185525.02
            median = 16.00
              75% <= 486.75
              95% <= 479470.00
              98% <= 503674.20
              99% <= 512108.60
            99.9% <= 527769.00
             count = 594

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 1430

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 588

  time-to-first-message-ms:
    value = 277506

  total-requests:
    value = 289

  wait-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  wait-requests-us:
    value = 503831

  worker-context-post-superstep:
    value = 10

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 652 ms
  compute all partitions: 407 ms
  time spent in gc: 74 ms
  bytes transferred in out-of-core: 0
  network communication time: 272 ms
  time to first message: 288707 us
  wait on requests time: 153328 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 272

  compute-all-ms:
    value = 407

  compute-per-partition-ms:
               sum = 3,111.00
               min = 8.00
               max = 227.00
              mean = 94.27
            stddev = 92.01
            median = 44.00
              75% <= 218.50
              95% <= 226.30
              98% <= 227.00
              99% <= 227.00
            99.9% <= 227.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 61589285

  messages-sent:
    count = 7608563

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.849829351535837

  processing-per-thread-ms:
               sum = 3,111.00
               min = 249.00
               max = 319.00
              mean = 282.82
            stddev = 21.17
            median = 288.00
              75% <= 299.00
              95% <= 319.00
              98% <= 319.00
              99% <= 319.00
            99.9% <= 319.00
             count = 11

  received-bytes:
               sum = 57,219,379.00
               min = 16.00
               max = 386816.00
              mean = 90680.47
            stddev = 106697.40
            median = 45245.00
              75% <= 182656.00
              95% <= 305228.80
              98% <= 338304.00
              99% <= 376197.12
            99.9% <= 386816.00
             count = 631

  remote-requests:
    count = 270

  requests-received:
             count = 631
         mean rate = 925.04 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 595
         mean rate = 872.23 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 56,863,284.00
               min = 16.00
               max = 528817.00
              mean = 95568.54
            stddev = 181821.60
            median = 16.00
              75% <= 533.00
              95% <= 467734.60
              98% <= 497306.28
              99% <= 524385.48
            99.9% <= 528817.00
             count = 595

  superstep-gc-time-ms:
    count = 74

  superstep-time-ms:
    value = 652

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 348

  time-to-first-message-ms:
    value = 288707

  total-requests:
    value = 293

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 153328

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 197 ms
  compute all partitions: 34 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 49098 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 34

  compute-per-partition-ms:
               sum = 157.00
               min = 2.00
               max = 14.00
              mean = 4.76
            stddev = 3.48
            median = 3.00
              75% <= 4.50
              95% <= 14.00
              98% <= 14.00
              99% <= 14.00
            99.9% <= 14.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 159144

  messages-sent:
    count = 12354

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 157.00
               min = 6.00
               max = 21.00
              mean = 14.27
            stddev = 5.08
            median = 14.00
              75% <= 20.00
              95% <= 21.00
              98% <= 21.00
              99% <= 21.00
            99.9% <= 21.00
             count = 11

  received-bytes:
               sum = 159,580.00
               min = 16.00
               max = 8661.00
              mean = 593.23
            stddev = 1457.26
            median = 16.00
              75% <= 192.00
              95% <= 3590.00
              98% <= 6408.80
              99% <= 8085.70
            99.9% <= 8661.00
             count = 269

  remote-requests:
    count = 264

  requests-received:
             count = 269
         mean rate = 1176.94 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 547
         mean rate = 2392.70 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 155,290.00
               min = 16.00
               max = 1473.00
              mean = 283.89
            stddev = 358.68
            median = 89.00
              75% <= 412.00
              95% <= 1045.00
              98% <= 1101.48
              99% <= 1163.08
            99.9% <= 1473.00
             count = 547

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 197

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 44

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 286

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 49098

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 107 ms
  compute all partitions: 14 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 248 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 14

  compute-per-partition-ms:
               sum = 21.00
               min = 0.00
               max = 1.00
              mean = 0.64
            stddev = 0.49
            median = 1.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 21.00
               min = 0.00
               max = 4.00
              mean = 1.91
            stddev = 1.58
            median = 2.00
              75% <= 4.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.36
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 377.44 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 384.56 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 107

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 248

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 97.49027512369365

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:68284
Log Contents:
2018-08-08 13:58:00,358 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,418 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,418 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,419 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,420 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,584 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:00,788 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:00,956 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,377 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,389 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,527 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,540 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,565 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,565 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,573 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,579 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,579 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 7 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,586 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,586 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave6
INFO    2018-08-08 13:58:01,586 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,586 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,586 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,586 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000009:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000009/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,587 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000009:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,587 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000009/tmp
INFO    2018-08-08 13:58:01,587 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,587 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,587 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,587 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,587 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,587 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,587 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000009
INFO    2018-08-08 13:58:01,588 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,599 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,600 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,606 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300a8, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,607 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:01,712 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:01,728 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:01,781 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave6/10.164.0.8:30007 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:01,786 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:01,786 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:01,803 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:01,816 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:01,819 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:01,829 [main-EventThread] org.apache.giraph.bsp.BspService  - process: applicationAttemptChanged signaled
WARN    2018-08-08 13:58:01,844 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:01,848 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave6_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007)
INFO    2018-08-08 13:58:02,307 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,396 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,405 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,407 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,408 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,410 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,410 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,412 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,421 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,422 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,425 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,431 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,496 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,538 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04104911 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048946265 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,552 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048360605 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047522318 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047156632 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046478823 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,554 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04590563 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,554 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045303456 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,554 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044855297 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,554 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044248287 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,556 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043644395 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,557 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0027, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.131
MBytes/sec sent = 0.0097, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.132
INFO    2018-08-08 13:58:02,558 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,562 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004348742 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,563 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 7.99924E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,564 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003844359 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 8.50488E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,566 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006215221 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,566 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003666586 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,566 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003129222 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,566 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005531297 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00342941 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,569 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003364427 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,569 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002728781 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,569 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0238, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.01
INFO    2018-08-08 13:58:02,569 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:58:12,357 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,359 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,402 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,405 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50197.35M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,406 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 9.847
MBytes/sec sent = 0, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 9.847
INFO    2018-08-08 13:58:12,406 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,413 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 7 more tasks to send their aggregator data, task ids: [1, 2, 3, 5, 6, 9, 10]
INFO    2018-08-08 13:58:12,435 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:58:12,435 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50197.35M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,448 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,485 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,491 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@111610e6,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4ad4936c)
INFO    2018-08-08 13:58:12,511 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,511 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,514 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave6_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007)
INFO    2018-08-08 13:58:12,560 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,561 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,561 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,562 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.127
MBytes/sec sent = 0.011, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.127
INFO    2018-08-08 13:58:12,565 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,566 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,570 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 10 more tasks to send their aggregator data, task ids: [1, 3, 4, 5, 6, 8, 9, 10, 12, 13]
INFO    2018-08-08 13:58:12,570 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:58:12,584 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,807 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.21368003 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,812 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.20569842 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,820 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.21710286 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,825 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.22240362 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.22 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,825 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.23149948 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.23 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,838 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.221859 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.22 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,860 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.27171046 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.27 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,860 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.27367663 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.27 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,862 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2671189 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,869 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.26495016 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,873 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.28201473 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,335 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 49614.65M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,839 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0039, MBytesReceived = 0.0041, ave received req MBytes = 0, secs waited = 1.028
MBytes/sec sent = 54.3455, MBytesSent = 55.9216, ave sent req MBytes = 0.2102, secs waited = 1.028
INFO    2018-08-08 13:58:13,839 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,936 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:58:13,937 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 7849840 , message bytes = 63520731 , Memory (free/total/max) = 49435.21M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,942 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,960 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,962 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@6622a690,outgoing=org.apache.giraph.conf.DefaultMessageClasses@30b9eadd)
INFO    2018-08-08 13:58:13,969 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,972 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave6_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007)
INFO    2018-08-08 13:58:13,995 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,995 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,995 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,996 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0003, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.059
MBytes/sec sent = 0.0234, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.059
INFO    2018-08-08 13:58:13,999 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,001 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,003 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,262 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2514539 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.25 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,270 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.26536164 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,274 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.26296517 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,279 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2752262 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.27 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,286 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.27359024 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.27 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,296 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.29194796 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,300 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.28996488 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,304 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2890743 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,310 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3043123 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.30 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,314 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.30890566 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.31 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,332 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.32000357 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.32 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,411 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 48757.67M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,518 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 74ms
INFO    2018-08-08 13:58:14,564 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0041, ave received req MBytes = 0, secs waited = 0.29
MBytes/sec sent = 186.3265, MBytesSent = 54.221, ave sent req MBytes = 0.2016, secs waited = 0.29
INFO    2018-08-08 13:58:14,564 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,622 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,622 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7608563 , message bytes = 61589285 , Memory (free/total/max) = 51649.61M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,626 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,645 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,648 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@2c42b421,outgoing=org.apache.giraph.conf.DefaultMessageClasses@51e37590)
INFO    2018-08-08 13:58:14,653 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,666 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave6_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007)
WARN    2018-08-08 13:58:14,709 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,730 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,730 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,730 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,731 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.109
MBytes/sec sent = 0.0128, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.109
INFO    2018-08-08 13:58:14,733 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,734 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,737 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,749 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010707519 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,749 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007664452 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,749 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01033298 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,752 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014400483 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,754 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014281344 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,756 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014963079 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,757 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015379135 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,758 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01860846 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,760 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.022906465 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,762 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.02215449 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,763 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.02207828 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,771 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 51556.50M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,820 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0575, MBytesReceived = 0.004, ave received req MBytes = 0, secs waited = 0.069
MBytes/sec sent = 2.016, MBytesSent = 0.1411, ave sent req MBytes = 0.0005, secs waited = 0.069
INFO    2018-08-08 13:58:14,820 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,851 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,851 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 12354 , message bytes = 159144 , Memory (free/total/max) = 51550.10M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,856 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,876 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,879 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@65f00478,outgoing=org.apache.giraph.conf.DefaultMessageClasses@2424686b)
INFO    2018-08-08 13:58:14,884 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,899 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave6_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=7, port=30007)
INFO    2018-08-08 13:58:14,906 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,941 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,965 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,966 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,966 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,966 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.115
MBytes/sec sent = 0.0121, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.115
INFO    2018-08-08 13:58:14,968 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,971 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,974 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,979 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002565861 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003177294 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002354136 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001400179 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002053158 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 9.73337E-4 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005103204 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003025108 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004105921 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004493325 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,988 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00674117 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,989 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 51473.29M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,989 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0096, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.018
MBytes/sec sent = 0.0536, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.018
INFO    2018-08-08 13:58:14,989 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,991 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0661, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.2101, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,991 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 51473.29M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,996 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,012 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,015 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@77bb0ab5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@f2c488)
INFO    2018-08-08 13:58:15,019 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,020 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,020 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,025 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,042 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,079 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,083 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,086 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,329 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,329 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4745 vertices using 1 threads
INFO    2018-08-08 13:58:17,333 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,587 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,587 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,593 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/7_worker
INFO    2018-08-08 13:58:17,596 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300a8 closed
INFO    2018-08-08 13:58:17,596 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,598 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,602 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,812 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,815 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000007_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,835 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000007_0 is allowed to commit now
INFO    2018-08-08 13:58:21,843 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000007_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000007
INFO    2018-08-08 13:58:21,859 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000007_0' done.
INFO    2018-08-08 13:58:21,863 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000007_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128638
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=41475
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=162
		CPU time spent (ms)=24720
		Physical memory (bytes) snapshot=3491622912
		Virtual memory (bytes) snapshot=58948800512
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000014 on graphalytics-giraph-slave7_43383
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:19975
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10397 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 335 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 124,814,298.00
               min = 16.00
               max = 238976.00
              mean = 139457.32
            stddev = 66856.25
            median = 159261.00
              75% <= 182656.00
              95% <= 235776.00
              98% <= 238976.00
              99% <= 238976.00
            99.9% <= 238976.00
             count = 895

  remote-requests:
    count = 0

  requests-received:
             count = 895
         mean rate = 85.96 requests/s
     1-minute rate = 76.64 requests/s
     5-minute rate = 75.18 requests/s
    15-minute rate = 74.93 requests/s

  requests-sent:
             count = 338
         mean rate = 32.47 requests/s
     1-minute rate = 32.18 requests/s
     5-minute rate = 32.35 requests/s
    15-minute rate = 32.38 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 8,392.00
               min = 16.00
               max = 1473.00
              mean = 24.83
            stddev = 80.41
            median = 16.00
              75% <= 16.00
              95% <= 53.00
              98% <= 89.00
              99% <= 89.00
            99.9% <= 1473.00
             count = 338

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 10397

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 335

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1434 ms
  compute all partitions: 949 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 918 ms
  time to first message: 320704 us
  wait on requests time: 289278 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 918

  compute-all-ms:
    value = 949

  compute-per-partition-ms:
               sum = 4,027.00
               min = 14.00
               max = 246.00
              mean = 122.03
            stddev = 98.15
            median = 100.00
              75% <= 237.50
              95% <= 246.00
              98% <= 246.00
              99% <= 246.00
            99.9% <= 246.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 22

  message-bytes-sent:
    count = 62982688

  messages-sent:
    count = 7784325

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.534246575342466

  processing-per-thread-ms:
               sum = 4,024.00
               min = 278.00
               max = 470.00
              mean = 365.82
            stddev = 73.59
            median = 370.00
              75% <= 449.00
              95% <= 470.00
              98% <= 470.00
              99% <= 470.00
            99.9% <= 470.00
             count = 11

  received-bytes:
               sum = 58,204,109.00
               min = 16.00
               max = 390400.00
              mean = 73028.99
            stddev = 92226.45
            median = 29568.00
              75% <= 131072.00
              95% <= 262144.00
              98% <= 326190.08
              99% <= 372014.08
            99.9% <= 390400.00
             count = 797

  remote-requests:
    count = 270

  requests-received:
             count = 797
         mean rate = 543.99 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 594
         mean rate = 405.42 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 58,175,679.00
               min = 16.00
               max = 526717.00
              mean = 97938.85
            stddev = 183990.13
            median = 16.00
              75% <= 479.75
              95% <= 467881.00
              98% <= 501435.80
              99% <= 524429.00
            99.9% <= 526717.00
             count = 594

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 1434

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 2913

  time-to-first-message-ms:
    value = 320704

  total-requests:
    value = 292

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 289278

  worker-context-post-superstep:
    value = 10

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 651 ms
  compute all partitions: 511 ms
  time spent in gc: 73 ms
  bytes transferred in out-of-core: 0
  network communication time: 277 ms
  time to first message: 282143 us
  wait on requests time: 48508 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 277

  compute-all-ms:
    value = 511

  compute-per-partition-ms:
               sum = 3,167.00
               min = 12.00
               max = 238.00
              mean = 95.97
            stddev = 96.10
            median = 46.00
              75% <= 225.00
              95% <= 235.90
              98% <= 238.00
              99% <= 238.00
            99.9% <= 238.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 61431929

  messages-sent:
    count = 7590778

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.718120805369128

  processing-per-thread-ms:
               sum = 3,167.00
               min = 256.00
               max = 328.00
              mean = 287.91
            stddev = 22.15
            median = 293.00
              75% <= 302.00
              95% <= 328.00
              98% <= 328.00
              99% <= 328.00
            99.9% <= 328.00
             count = 11

  received-bytes:
               sum = 56,748,520.00
               min = 16.00
               max = 384128.00
              mean = 92274.02
            stddev = 110650.32
            median = 20096.00
              75% <= 194304.00
              95% <= 315264.00
              98% <= 352322.56
              99% <= 366653.44
            99.9% <= 384128.00
             count = 615

  remote-requests:
    count = 275

  requests-received:
             count = 615
         mean rate = 902.82 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 600
         mean rate = 880.82 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 56,743,535.00
               min = 16.00
               max = 527597.00
              mean = 94572.56
            stddev = 178469.62
            median = 39.00
              75% <= 531.25
              95% <= 447913.40
              98% <= 510467.16
              99% <= 525417.72
            99.9% <= 527597.00
             count = 600

  superstep-gc-time-ms:
    count = 73

  superstep-time-ms:
    value = 651

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 592

  time-to-first-message-ms:
    value = 282143

  total-requests:
    value = 298

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 48508

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 197 ms
  compute all partitions: 31 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 50390 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 31

  compute-per-partition-ms:
               sum = 115.00
               min = 1.00
               max = 15.00
              mean = 3.48
            stddev = 3.57
            median = 2.00
              75% <= 3.50
              95% <= 12.20
              98% <= 15.00
              99% <= 15.00
            99.9% <= 15.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 20

  message-bytes-sent:
    count = 160019

  messages-sent:
    count = 12755

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 115.00
               min = 0.00
               max = 16.00
              mean = 10.45
            stddev = 5.34
            median = 13.00
              75% <= 15.00
              95% <= 16.00
              98% <= 16.00
              99% <= 16.00
            99.9% <= 16.00
             count = 11

  received-bytes:
               sum = 159,009.00
               min = 16.00
               max = 10821.00
              mean = 521.34
            stddev = 1185.19
            median = 32.00
              75% <= 433.00
              95% <= 2628.90
              98% <= 4753.64
              99% <= 6607.58
            99.9% <= 10821.00
             count = 305

  remote-requests:
    count = 240

  requests-received:
             count = 305
         mean rate = 1331.68 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 526
         mean rate = 2296.66 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 120

  sent-bytes:
               sum = 156,341.00
               min = 16.00
               max = 1825.00
              mean = 297.23
            stddev = 445.51
            median = 53.00
              75% <= 394.75
              95% <= 1468.80
              98% <= 1645.88
              99% <= 1755.92
            99.9% <= 1825.00
             count = 526

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 197

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 6

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 260

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 50390

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 107 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 232 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 41.00
               min = 0.00
               max = 2.00
              mean = 1.24
            stddev = 0.61
            median = 1.00
              75% <= 2.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 41.00
               min = 0.00
               max = 6.00
              mean = 3.73
            stddev = 2.05
            median = 3.00
              75% <= 6.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.58
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 382.48 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 389.98 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.70
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 107

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 232

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 97.16757041404426

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:68335
Log Contents:
2018-08-08 13:58:00,451 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,517 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,517 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,519 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,519 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,698 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:00,932 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:01,126 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,597 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,609 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,767 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,782 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,812 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,813 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,823 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,830 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,830 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 12 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,836 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,836 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave7
INFO    2018-08-08 13:58:01,836 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,836 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,836 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,836 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000014:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000014/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,837 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000014:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,837 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000014/tmp
INFO    2018-08-08 13:58:01,837 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,837 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,837 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,837 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,837 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,837 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,837 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000014
INFO    2018-08-08 13:58:01,838 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,852 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,853 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,859 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300b2, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,861 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:01,978 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:01,996 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:02,055 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave7/10.164.0.9:30012 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:02,061 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:02,062 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:02,083 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:02,094 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:02,099 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,102 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,108 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave7_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=12, port=30012)
INFO    2018-08-08 13:58:02,306 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,394 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,404 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,407 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,408 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,408 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,409 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,421 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,422 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,425 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,427 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,428 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,430 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,432 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,432 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,497 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,551 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04438599 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,551 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.053542737 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,551 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04580956 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0446666 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043921284 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043229166 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042751666 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,553 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042000417 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,554 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04097669 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,554 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03982794 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,554 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04039319 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,557 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0027, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.13
MBytes/sec sent = 0.0098, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.13
INFO    2018-08-08 13:58:02,558 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,563 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004514802 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,564 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003193137 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,564 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003451628 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,565 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003068705 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,566 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003840813 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001263058 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003454075 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,567 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00286343 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,568 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 8.73316E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,569 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002484509 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,570 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006947968 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,571 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.014, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0219, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.011
INFO    2018-08-08 13:58:02,572 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:58:12,356 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,359 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,394 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,398 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50213.41M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,398 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 9.838
MBytes/sec sent = 0, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 9.838
INFO    2018-08-08 13:58:12,398 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,406 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 10 more tasks to send their aggregator data, task ids: [1, 2, 3, 5, 6, 7, 9, 10, 11, 13]
INFO    2018-08-08 13:58:12,433 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:12,433 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50213.41M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,442 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,484 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,488 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@39ab59f8,outgoing=org.apache.giraph.conf.DefaultMessageClasses@64e92d61)
WARN    2018-08-08 13:58:12,493 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,505 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,505 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,508 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave7_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=12, port=30012)
INFO    2018-08-08 13:58:12,563 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,563 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,563 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,565 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.131
MBytes/sec sent = 0.0106, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.132
INFO    2018-08-08 13:58:12,567 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,569 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,573 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 4 more tasks to send their aggregator data, task ids: [5, 9, 10, 13]
INFO    2018-08-08 13:58:12,579 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,869 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.28847677 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,873 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2803443 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,895 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.30026382 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.30 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,900 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.31430975 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.31 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,910 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.31576183 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.31 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,960 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.37795475 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.37 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,964 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.37472957 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.37 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,006 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.4177182 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.41 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,036 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.45164287 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.45 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,052 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.4658071 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.46 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,056 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.47411025 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.47 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,530 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 49672.13M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,819 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0044, MBytesReceived = 0.0041, ave received req MBytes = 0, secs waited = 0.941
MBytes/sec sent = 58.8886, MBytesSent = 55.4731, ave sent req MBytes = 0.2055, secs waited = 0.941
INFO    2018-08-08 13:58:13,819 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,934 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:58:13,935 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 7784325 , message bytes = 62982688 , Memory (free/total/max) = 49440.34M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,940 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,959 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,960 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@127d7908,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6b9c69a9)
INFO    2018-08-08 13:58:13,969 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,971 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave7_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=12, port=30012)
INFO    2018-08-08 13:58:13,996 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,996 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,996 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.061
MBytes/sec sent = 0.0227, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.061
INFO    2018-08-08 13:58:13,999 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,000 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,001 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,263 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.26038334 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,268 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.25873634 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,274 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.26571956 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.26 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,287 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.28388426 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,293 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.28945947 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.28 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,302 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.30046457 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.30 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,306 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2942478 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,310 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2979302 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.30 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,315 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.30368954 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.30 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,317 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.30976227 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.31 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,333 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3296966 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.33 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,511 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 73ms
INFO    2018-08-08 13:58:14,513 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 51652.75M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,561 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0142, MBytesReceived = 0.0042, ave received req MBytes = 0, secs waited = 0.294
MBytes/sec sent = 183.4144, MBytesSent = 54.1072, ave sent req MBytes = 0.1968, secs waited = 0.294
INFO    2018-08-08 13:58:14,562 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,620 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,621 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7590778 , message bytes = 61431929 , Memory (free/total/max) = 51563.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,625 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,643 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,646 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4bd2f0dc,outgoing=org.apache.giraph.conf.DefaultMessageClasses@2e647e59)
INFO    2018-08-08 13:58:14,653 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,664 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave7_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=12, port=30012)
INFO    2018-08-08 13:58:14,674 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,707 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,730 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.109
MBytes/sec sent = 0.0128, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.109
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,733 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,735 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,745 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006507454 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,745 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005166169 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,748 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010646823 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,750 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008786626 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,754 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014095077 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,756 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017417748 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,756 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017055472 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,758 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015950521 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,760 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014039541 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,762 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.016026959 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,763 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010662446 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,767 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 51463.56M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,817 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0509, MBytesReceived = 0.0037, ave received req MBytes = 0, secs waited = 0.071
MBytes/sec sent = 1.9733, MBytesSent = 0.1421, ave sent req MBytes = 0.0006, secs waited = 0.071
INFO    2018-08-08 13:58:14,818 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,850 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,850 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 12755 , message bytes = 160019 , Memory (free/total/max) = 51463.56M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,855 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,875 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,878 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:58:14,883 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,898 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave7_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=12, port=30012)
INFO    2018-08-08 13:58:14,904 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,940 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,965 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.115
MBytes/sec sent = 0.0121, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.115
INFO    2018-08-08 13:58:14,969 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,970 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,973 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,981 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002671572 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006022648 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007712917 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002227453 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004278852 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,981 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005112994 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007513534 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004238331 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004773918 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006033093 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006867388 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,983 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 51386.76M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,983 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:58:14,983 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,989 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,990 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 51386.76M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,994 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,010 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,013 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:58:15,017 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,017 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,017 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,025 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,040 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,077 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,082 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,084 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,329 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,329 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4645 vertices using 1 threads
INFO    2018-08-08 13:58:17,333 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,582 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,583 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,586 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/12_worker
INFO    2018-08-08 13:58:17,592 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300b2 closed
INFO    2018-08-08 13:58:17,592 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,594 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,598 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,812 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,815 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000012_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,840 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000012_0 is allowed to commit now
INFO    2018-08-08 13:58:21,851 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000012_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000012
INFO    2018-08-08 13:58:21,875 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000012_0' done.
INFO    2018-08-08 13:58:21,880 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000012_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128639
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=40608
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=166
		CPU time spent (ms)=27910
		Physical memory (bytes) snapshot=3475390464
		Virtual memory (bytes) snapshot=58886815744
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000011 on graphalytics-giraph-slave8_41519
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:20056
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10410 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 272 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 6

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 8.571428571428571

  received-bytes:
               sum = 125,598,406.00
               min = 16.00
               max = 239360.00
              mean = 127123.89
            stddev = 73712.00
            median = 147613.00
              75% <= 182656.00
              95% <= 235776.00
              98% <= 238976.00
              99% <= 238976.00
            99.9% <= 239360.00
             count = 988

  remote-requests:
    count = 64

  requests-received:
             count = 988
         mean rate = 94.74 requests/s
     1-minute rate = 85.32 requests/s
     5-minute rate = 83.80 requests/s
    15-minute rate = 83.53 requests/s

  requests-sent:
             count = 405
         mean rate = 38.84 requests/s
     1-minute rate = 44.15 requests/s
     5-minute rate = 45.14 requests/s
    15-minute rate = 45.31 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 31,137,649.00
               min = 16.00
               max = 524573.00
              mean = 76883.08
            stddev = 182923.14
            median = 16.00
              75% <= 25.00
              95% <= 524573.00
              98% <= 524573.00
              99% <= 524573.00
            99.9% <= 524573.00
             count = 405

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 10410

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 70

  wait-requests-us:
    value = 272

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1429 ms
  compute all partitions: 884 ms
  time spent in gc: 62 ms
  bytes transferred in out-of-core: 0
  network communication time: 937 ms
  time to first message: 317098 us
  wait on requests time: 369611 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 937

  compute-all-ms:
    value = 884

  compute-per-partition-ms:
               sum = 5,271.00
               min = 10.00
               max = 605.00
              mean = 159.73
            stddev = 151.37
            median = 184.00
              75% <= 202.50
              95% <= 544.80
              98% <= 605.00
              99% <= 605.00
            99.9% <= 605.00
             count = 33

  gc-per-thread-ms:
               sum = 434.00
               min = 0.00
               max = 62.00
              mean = 39.45
            stddev = 31.28
            median = 62.00
              75% <= 62.00
              95% <= 62.00
              98% <= 62.00
              99% <= 62.00
            99.9% <= 62.00
             count = 11

  local-requests:
    count = 24

  message-bytes-sent:
    count = 64783265

  messages-sent:
    count = 8007153

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.894736842105263

  processing-per-thread-ms:
               sum = 4,835.00
               min = 218.00
               max = 761.00
              mean = 439.55
            stddev = 169.91
            median = 406.00
              75% <= 551.00
              95% <= 761.00
              98% <= 761.00
              99% <= 761.00
            99.9% <= 761.00
             count = 11

  received-bytes:
               sum = 59,675,686.00
               min = 16.00
               max = 378368.00
              mean = 78109.54
            stddev = 93276.86
            median = 38650.50
              75% <= 131072.00
              95% <= 262144.00
              98% <= 317900.80
              99% <= 353126.40
            99.9% <= 378368.00
             count = 764

  remote-requests:
    count = 280

  requests-received:
             count = 764
         mean rate = 523.32 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 608
         mean rate = 416.51 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 59,689,381.00
               min = 16.00
               max = 531849.00
              mean = 98173.32
            stddev = 186813.34
            median = 51.00
              75% <= 555.00
              95% <= 506866.60
              98% <= 524804.04
              99% <= 526524.72
            99.9% <= 531849.00
             count = 608

  superstep-gc-time-ms:
    count = 62

  superstep-time-ms:
    value = 1429

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 1406

  time-to-first-message-ms:
    value = 317098

  total-requests:
    value = 304

  wait-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 2.00
              mean = 0.18
            stddev = 0.60
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  wait-requests-us:
    value = 369611

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 651 ms
  compute all partitions: 312 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 328 ms
  time to first message: 183043 us
  wait on requests time: 198667 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 328

  compute-all-ms:
    value = 312

  compute-per-partition-ms:
               sum = 2,204.00
               min = 9.00
               max = 151.00
              mean = 66.79
            stddev = 59.41
            median = 32.00
              75% <= 143.50
              95% <= 150.30
              98% <= 151.00
              99% <= 151.00
            99.9% <= 151.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 63631274

  messages-sent:
    count = 7863277

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 2,204.00
               min = 166.00
               max = 228.00
              mean = 200.36
            stddev = 21.80
            median = 202.00
              75% <= 214.00
              95% <= 228.00
              98% <= 228.00
              99% <= 228.00
            99.9% <= 228.00
             count = 11

  received-bytes:
               sum = 58,155,353.00
               min = 16.00
               max = 379520.00
              mean = 88922.56
            stddev = 103339.11
            median = 35392.50
              75% <= 186208.00
              95% <= 262144.00
              98% <= 320268.80
              99% <= 357452.80
            99.9% <= 379520.00
             count = 654

  remote-requests:
    count = 276

  requests-received:
             count = 654
         mean rate = 960.23 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 601
         mean rate = 882.40 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 58,627,724.00
               min = 16.00
               max = 526277.00
              mean = 97550.29
            stddev = 182576.36
            median = 53.00
              75% <= 616.00
              95% <= 477280.60
              98% <= 523832.04
              99% <= 525347.16
            99.9% <= 526277.00
             count = 601

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 651

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 318

  time-to-first-message-ms:
    value = 183043

  total-requests:
    value = 299

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 198667

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 197 ms
  compute all partitions: 28 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 53796 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 28

  compute-per-partition-ms:
               sum = 85.00
               min = 1.00
               max = 12.00
              mean = 2.58
            stddev = 2.65
            median = 2.00
              75% <= 2.00
              95% <= 11.30
              98% <= 12.00
              99% <= 12.00
            99.9% <= 12.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 18

  message-bytes-sent:
    count = 179710

  messages-sent:
    count = 14448

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 85.00
               min = 0.00
               max = 16.00
              mean = 7.73
            stddev = 5.12
            median = 7.00
              75% <= 12.00
              95% <= 16.00
              98% <= 16.00
              99% <= 16.00
            99.9% <= 16.00
             count = 11

  received-bytes:
               sum = 160,117.00
               min = 16.00
               max = 7735.00
              mean = 505.10
            stddev = 1007.01
            median = 32.00
              75% <= 578.00
              95% <= 2516.10
              98% <= 3777.60
              99% <= 5033.64
            99.9% <= 7735.00
             count = 317

  remote-requests:
    count = 216

  requests-received:
             count = 317
         mean rate = 1381.38 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 504
         mean rate = 2196.26 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 108

  sent-bytes:
               sum = 174,034.00
               min = 16.00
               max = 2341.00
              mean = 345.31
            stddev = 503.96
            median = 16.00
              75% <= 420.50
              95% <= 1461.00
              98% <= 1740.60
              99% <= 1908.20
            99.9% <= 2341.00
             count = 504

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 197

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 19

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 234

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 53796

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 106 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 271 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 20.00
               min = 0.00
               max = 1.00
              mean = 0.61
            stddev = 0.50
            median = 1.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 20.00
               min = 0.00
               max = 4.00
              mean = 1.82
            stddev = 1.40
            median = 2.00
              75% <= 3.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 936.39
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 382.22 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 389.70 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 106

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 271

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.96565591679872

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = 0.0

  edges-loaded:
             count = 2115526
         mean rate = 133750.30 edges/s
     1-minute rate = 358150.82 edges/s
     5-minute rate = 409234.16 edges/s
    15-minute rate = 418430.05 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:69147
Log Contents:
2018-08-08 13:58:00,448 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,519 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,520 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,521 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,521 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,695 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:00,920 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:01,113 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,580 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,591 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,744 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,759 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,788 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,789 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,797 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,804 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,804 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 9 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,810 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,810 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave8
INFO    2018-08-08 13:58:01,810 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,810 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,810 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,810 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000011:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000011/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,811 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000011:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,811 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000011/tmp
INFO    2018-08-08 13:58:01,811 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,811 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,811 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,811 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,811 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,811 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,811 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000011
INFO    2018-08-08 13:58:01,811 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,824 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,824 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,831 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300b0, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,832 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:01,951 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:01,969 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:02,040 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave8/10.164.0.10:30009 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:02,045 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:02,046 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:02,070 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:02,082 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:02,086 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,089 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:02,097 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave8_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=9, port=30009)
INFO    2018-08-08 13:58:02,307 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,397 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,406 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,408 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,409 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,410 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,410 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,411 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,413 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,414 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,415 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,418 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,419 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,422 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,424 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,424 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,427 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,427 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,427 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,427 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,429 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,430 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,498 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,539 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03262532 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,539 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04052969 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,539 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.033829805 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,540 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030634688 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,540 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031251516 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,540 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031946115 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,541 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030934984 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,541 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030562587 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,542 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030683517 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,543 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030197976 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,543 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030204112 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,545 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0042, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.039
MBytes/sec sent = 0.0066, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.039
INFO    2018-08-08 13:58:02,547 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,555 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006023138 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,555 [load-0] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/dota-league.e:671088640+14808689'
INFO    2018-08-08 13:58:02,555 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005181719 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,555 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004331529 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,556 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004401352 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,556 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003762395 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,557 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00353935 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,557 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002809259 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,560 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004483465 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,561 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00301268 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,563 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004290514 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:03,406 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 1000000 edges at 614416.6913087185 edges/sec Memory (free/total/max) = 50313.15M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:04,150 [load-0] org.apache.giraph.worker.EdgeInputSplitsCallable  - readEdgeInputSplit: Loaded 2000000 edges at 843100.6931543496 edges/sec Memory (free/total/max) = 49775.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:04,236 [load-0] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=0, e=2115526)
INFO    2018-08-08 13:58:04,239 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 1.6913381 secs, (v=0, e=2115526) 0.0 vertices/sec, 1250800.2 edges/sec
INFO    2018-08-08 13:58:04,254 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0114, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.015
MBytes/sec sent = 229.5616, MBytesSent = 3.673, ave sent req MBytes = 0.3061, secs waited = 0.015
INFO    2018-08-08 13:58:04,254 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=2115526)
INFO    2018-08-08 13:58:12,357 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,360 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,407 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,410 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 49058.02M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,411 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 8.172
MBytes/sec sent = 0.4494, MBytesSent = 3.673, ave sent req MBytes = 0.3061, secs waited = 8.172
INFO    2018-08-08 13:58:12,411 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,420 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 3 more tasks to send their aggregator data, task ids: [2, 5, 10]
INFO    2018-08-08 13:58:12,434 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:58:12,434 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 49058.02M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,444 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,484 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,490 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@6813a331,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1bd81830)
WARN    2018-08-08 13:58:12,494 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,511 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,511 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,514 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave8_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=9, port=30009)
INFO    2018-08-08 13:58:12,565 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,565 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,565 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,567 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.132
MBytes/sec sent = 0.0106, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.133
INFO    2018-08-08 13:58:12,569 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,571 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,574 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 2 more tasks to send their aggregator data, task ids: [10, 13]
INFO    2018-08-08 13:58:12,582 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,881 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.22306836 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.22 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,884 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.29227608 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,891 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.29847303 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.29 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,922 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.31847915 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.32 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,031 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 62ms
INFO    2018-08-08 13:58:13,043 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.4417049 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.37 s, time spent on gc was 0.06 s)
INFO    2018-08-08 13:58:13,058 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.47452074 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.41 s, time spent on gc was 0.06 s)
INFO    2018-08-08 13:58:13,098 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.4995886 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.43 s, time spent on gc was 0.06 s)
INFO    2018-08-08 13:58:13,192 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.6039261 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.54 s, time spent on gc was 0.06 s)
INFO    2018-08-08 13:58:13,203 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.6181029 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.55 s, time spent on gc was 0.06 s)
INFO    2018-08-08 13:58:13,323 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.72556067 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.66 s, time spent on gc was 0.06 s)
INFO    2018-08-08 13:58:13,418 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.82764506 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.76 s, time spent on gc was 0.06 s)
INFO    2018-08-08 13:58:13,467 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 51181.27M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,837 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0045, MBytesReceived = 0.0043, ave received req MBytes = 0, secs waited = 0.954
MBytes/sec sent = 59.5985, MBytesSent = 56.9166, ave sent req MBytes = 0.2033, secs waited = 0.954
INFO    2018-08-08 13:58:13,837 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,935 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:58:13,936 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 8007153 , message bytes = 64783265 , Memory (free/total/max) = 50918.37M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,941 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,959 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,961 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@58faa93b,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5f212d84)
INFO    2018-08-08 13:58:13,970 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,972 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave8_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=9, port=30009)
INFO    2018-08-08 13:58:13,995 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,995 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,995 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,996 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0003, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.06
MBytes/sec sent = 0.023, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.06
INFO    2018-08-08 13:58:13,998 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,000 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,002 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,177 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16755606 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,179 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.16869949 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.17 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,188 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18475087 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,196 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.1916914 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,203 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.20087013 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,207 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.20325737 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,223 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.21552506 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,227 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.21468942 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,227 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.2169867 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,236 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.23172396 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.23 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,238 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.22929156 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.23 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,314 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50364.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,513 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0126, MBytesReceived = 0.0042, ave received req MBytes = 0, secs waited = 0.333
MBytes/sec sent = 167.3777, MBytesSent = 55.9041, ave sent req MBytes = 0.2026, secs waited = 0.333
INFO    2018-08-08 13:58:14,513 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,621 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,621 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7863277 , message bytes = 63631274 , Memory (free/total/max) = 50144.78M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,626 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,644 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,646 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@72be135f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@155d1021)
INFO    2018-08-08 13:58:14,653 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,667 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave8_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=9, port=30009)
INFO    2018-08-08 13:58:14,674 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,708 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,730 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,730 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,731 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.109
MBytes/sec sent = 0.0128, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.11
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,733 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,736 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,745 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006911223 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,746 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007906771 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,746 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003339583 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,745 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007453498 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,750 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005280228 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,750 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012663572 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,751 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009499725 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,756 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015890617 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,756 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011271923 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,756 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.016528865 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,758 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013953852 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,764 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50091.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,818 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0458, MBytesReceived = 0.0033, ave received req MBytes = 0, secs waited = 0.071
MBytes/sec sent = 2.2072, MBytesSent = 0.1589, ave sent req MBytes = 0.0007, secs waited = 0.071
INFO    2018-08-08 13:58:14,818 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,850 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,850 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 14448 , message bytes = 179710 , Memory (free/total/max) = 50091.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,856 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,875 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,878 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@40620d8e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@383f3558)
INFO    2018-08-08 13:58:14,883 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,898 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave8_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=9, port=30009)
INFO    2018-08-08 13:58:14,905 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:14,940 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,965 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.115
MBytes/sec sent = 0.0121, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.115
INFO    2018-08-08 13:58:14,967 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,970 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,973 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,979 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00439052 secs for 7 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002865291 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00206862 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003617913 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002583778 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004243897 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001694774 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005514046 secs for 7 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00176157 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003067065 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,983 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001125118 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,984 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50058.98M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,984 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0122, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.014
MBytes/sec sent = 0.0679, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.014
INFO    2018-08-08 13:58:14,984 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,990 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,990 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50058.98M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,992 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,011 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,013 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7d151a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@294bdeb4)
INFO    2018-08-08 13:58:15,017 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,017 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,017 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,022 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,040 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,078 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,082 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,085 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,326 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,326 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4767 vertices using 1 threads
INFO    2018-08-08 13:58:17,330 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,584 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,584 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,587 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/9_worker
INFO    2018-08-08 13:58:17,592 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300b0 closed
INFO    2018-08-08 13:58:17,592 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,595 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,598 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,808 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,811 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000009_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,836 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000009_0 is allowed to commit now
INFO    2018-08-08 13:58:21,845 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000009_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000009
INFO    2018-08-08 13:58:21,875 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000009_0' done.
INFO    2018-08-08 13:58:21,880 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000009_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128638
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=14808733
		HDFS: Number of bytes written=41616
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=160
		CPU time spent (ms)=28180
		Physical memory (bytes) snapshot=4170301440
		Virtual memory (bytes) snapshot=58939338752
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0013_01_000008 on graphalytics-giraph-slave9_37771
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:20035
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 10599 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 394 us

8/8/18 1:58:12 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  received-bytes:
               sum = 129,382,826.00
               min = 16.00
               max = 238976.00
              mean = 140939.90
            stddev = 68930.30
            median = 159261.00
              75% <= 182656.00
              95% <= 238976.00
              98% <= 238976.00
              99% <= 238976.00
            99.9% <= 238976.00
             count = 918

  remote-requests:
    count = 12

  requests-received:
             count = 918
         mean rate = 86.48 requests/s
     1-minute rate = 82.52 requests/s
     5-minute rate = 81.63 requests/s
    15-minute rate = 81.48 requests/s

  requests-sent:
             count = 360
         mean rate = 33.92 requests/s
     1-minute rate = 34.68 requests/s
     5-minute rate = 34.93 requests/s
    15-minute rate = 34.98 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 12

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 1,421,381.00
               min = 16.00
               max = 120335.00
              mean = 3948.28
            stddev = 21162.00
            median = 16.00
              75% <= 16.00
              95% <= 89.00
              98% <= 117179.50
              99% <= 119444.75
            99.9% <= 120335.00
             count = 360

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 10599

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 13

  wait-requests-us:
    value = 394

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 1431 ms
  compute all partitions: 823 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 644 ms
  time to first message: 525970 us
  wait on requests time: 346379 us

8/8/18 1:58:13 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 644

  compute-all-ms:
    value = 823

  compute-per-partition-ms:
               sum = 4,839.00
               min = 13.00
               max = 558.00
              mean = 146.64
            stddev = 126.48
            median = 202.00
              75% <= 218.50
              95% <= 426.40
              98% <= 558.00
              99% <= 558.00
            99.9% <= 558.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 24

  message-bytes-sent:
    count = 65371011

  messages-sent:
    count = 8079946

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.741935483870968

  processing-per-thread-ms:
               sum = 4,838.00
               min = 244.00
               max = 797.00
              mean = 439.82
            stddev = 156.38
            median = 436.00
              75% <= 486.00
              95% <= 797.00
              98% <= 797.00
              99% <= 797.00
            99.9% <= 797.00
             count = 11

  received-bytes:
               sum = 60,167,722.00
               min = 16.00
               max = 389376.00
              mean = 82196.34
            stddev = 102379.42
            median = 29289.50
              75% <= 142112.00
              95% <= 299763.20
              98% <= 367961.60
              99% <= 373934.08
            99.9% <= 389376.00
             count = 732

  remote-requests:
    count = 286

  requests-received:
             count = 732
         mean rate = 500.73 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 617
         mean rate = 422.05 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 60,185,670.00
               min = 16.00
               max = 529941.00
              mean = 97545.66
            stddev = 184845.31
            median = 53.00
              75% <= 2281.00
              95% <= 497853.80
              98% <= 525245.16
              99% <= 526511.56
            99.9% <= 529941.00
             count = 617

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 1431

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 525970

  total-requests:
    value = 310

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 346379

  worker-context-post-superstep:
    value = 46

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 652 ms
  compute all partitions: 317 ms
  time spent in gc: 67 ms
  bytes transferred in out-of-core: 0
  network communication time: 346 ms
  time to first message: 218898 us
  wait on requests time: 248213 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 346

  compute-all-ms:
    value = 317

  compute-per-partition-ms:
               sum = 2,334.00
               min = 14.00
               max = 157.00
              mean = 70.73
            stddev = 57.99
            median = 39.00
              75% <= 147.00
              95% <= 155.60
              98% <= 157.00
              99% <= 157.00
            99.9% <= 157.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 23

  message-bytes-sent:
    count = 63961822

  messages-sent:
    count = 7903858

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 2,334.00
               min = 176.00
               max = 270.00
              mean = 212.18
            stddev = 26.08
            median = 212.00
              75% <= 223.00
              95% <= 270.00
              98% <= 270.00
              99% <= 270.00
            99.9% <= 270.00
             count = 11

  received-bytes:
               sum = 58,652,788.00
               min = 16.00
               max = 386688.00
              mean = 94754.10
            stddev = 110296.70
            median = 47744.00
              75% <= 191104.00
              95% <= 316160.00
              98% <= 355712.00
              99% <= 366080.00
            99.9% <= 386688.00
             count = 619

  remote-requests:
    count = 276

  requests-received:
             count = 619
         mean rate = 908.41 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 601
         mean rate = 881.92 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 132

  sent-bytes:
               sum = 58,887,755.00
               min = 16.00
               max = 532189.00
              mean = 97982.95
            stddev = 184504.64
            median = 53.00
              75% <= 604.50
              95% <= 477105.40
              98% <= 523649.80
              99% <= 526335.80
            99.9% <= 532189.00
             count = 601

  superstep-gc-time-ms:
    count = 67

  superstep-time-ms:
    value = 652

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 336

  time-to-first-message-ms:
    value = 218898

  total-requests:
    value = 299

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 248213

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 198 ms
  compute all partitions: 30 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 50775 us

8/8/18 1:58:14 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 30

  compute-per-partition-ms:
               sum = 128.00
               min = 1.00
               max = 18.00
              mean = 3.88
            stddev = 4.87
            median = 2.00
              75% <= 3.00
              95% <= 17.30
              98% <= 18.00
              99% <= 18.00
            99.9% <= 18.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 18

  message-bytes-sent:
    count = 142566

  messages-sent:
    count = 10875

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 7.6923076923076925

  processing-per-thread-ms:
               sum = 128.00
               min = 0.00
               max = 25.00
              mean = 11.64
            stddev = 8.29
            median = 14.00
              75% <= 18.00
              95% <= 25.00
              98% <= 25.00
              99% <= 25.00
            99.9% <= 25.00
             count = 11

  received-bytes:
               sum = 163,392.00
               min = 16.00
               max = 8152.00
              mean = 689.42
            stddev = 1486.61
            median = 32.00
              75% <= 463.00
              95% <= 4138.20
              98% <= 6800.60
              99% <= 7910.64
            99.9% <= 8152.00
             count = 237

  remote-requests:
    count = 216

  requests-received:
             count = 237
         mean rate = 1035.00 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 504
         mean rate = 2200.77 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 108

  sent-bytes:
               sum = 139,219.00
               min = 16.00
               max = 1917.00
              mean = 276.23
            stddev = 438.45
            median = 16.00
              75% <= 344.75
              95% <= 1449.00
              98% <= 1533.00
              99% <= 1600.60
            99.9% <= 1917.00
             count = 504

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 198

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 5

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 234

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 50775

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 108 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 180 us

8/8/18 1:58:15 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 21.00
               min = 0.00
               max = 1.00
              mean = 0.64
            stddev = 0.49
            median = 1.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 21.00
               min = 0.00
               max = 4.00
              mean = 1.91
            stddev = 1.58
            median = 2.00
              75% <= 3.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.67
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 379.89 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 387.30 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.68
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 108

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 180

  worker-context-post-superstep:
    value = 5

  worker-context-pre-superstep:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 97.08357727440604

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:58:17 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = 0.0

  vertices-loaded:
             count = 61170
         mean rate = 3831.09 vertices/s
     1-minute rate = 10355.86 vertices/s
     5-minute rate = 11832.92 vertices/s
    15-minute rate = 12098.82 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:58:32 +0000 2018
LogLength:68681
Log Contents:
2018-08-08 13:58:00,422 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:58:00,487 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:58:00,487 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:58:00,489 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:58:00,489 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:58:00,647 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:58:00,856 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013
2018-08-08 13:58:01,018 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:58:01,449 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:58:01,460 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:58:01,598 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:58:01,612 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:58:01,639 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:58:01,639 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:58:01,648 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:58:01,654 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0013/_haltComputation
INFO    2018-08-08 13:58:01,654 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0013, 6 on graphalytics-giraph:2181
INFO    2018-08-08 13:58:01,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:58:01,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave9
INFO    2018-08-08 13:58:01,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:58:01,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:58:01,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:58:01,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000008:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000008/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:58:01,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000008:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:58:01,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000008/tmp
INFO    2018-08-08 13:58:01,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:58:01,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:58:01,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:58:01,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:58:01,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:58:01,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:58:01,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0013/container_1533735211869_0013_01_000008
INFO    2018-08-08 13:58:01,661 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3591009c
INFO    2018-08-08 13:58:01,673 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:58:01,674 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:58:01,680 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed300ab, negotiated timeout = 40000
INFO    2018-08-08 13:58:01,681 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:58:01,788 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:58:01,804 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:58:01,858 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave9/10.164.0.11:30006 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:58:01,863 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:58:01,864 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:58:01,882 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:58:01,891 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:01,894 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:01,897 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:58:01,902 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave9_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=6, port=30006)
INFO    2018-08-08 13:58:02,305 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,393 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.5337367E9
INFO    2018-08-08 13:58:02,401 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:02,402 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:02,403 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,405 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,405 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,405 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,406 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,406 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,406 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,406 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,406 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,407 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,407 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,408 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,408 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,408 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:58:02,409 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,410 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:02,416 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,416 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,417 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,418 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,420 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,423 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,424 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,424 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,429 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:58:02,496 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,537 [load-0] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/dota-league.v:0+412051'
INFO    2018-08-08 13:58:02,549 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045912016 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,549 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045374747 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,549 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046649087 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,549 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044941887 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,549 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044272304 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,550 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04442982 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,550 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04390788 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,551 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043442786 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,551 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0435205 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,551 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043037504 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,681 [load-0] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=61170, e=0)
INFO    2018-08-08 13:58:02,684 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 0.18741779 secs, (v=61170, e=0) 326383.1 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,723 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0047, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.039
MBytes/sec sent = 33.6843, MBytesSent = 1.3474, ave sent req MBytes = 0.1123, secs waited = 0.039
INFO    2018-08-08 13:58:02,724 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:58:02,727 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 8.4554E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,728 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002551687 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,728 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002308199 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,729 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00518535 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,730 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003258098 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,731 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002978742 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,732 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003640715 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,732 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002614861 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,732 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002228859 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,733 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002086573 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,735 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003101895 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:58:02,735 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:02,735 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=61170, e=0)
INFO    2018-08-08 13:58:12,356 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:58:12,360 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,403 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:58:12,407 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50133.52M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,407 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 9.674
MBytes/sec sent = 0, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 9.674
INFO    2018-08-08 13:58:12,407 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:12,413 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 6 more tasks to send their aggregator data, task ids: [2, 3, 5, 9, 10, 13]
INFO    2018-08-08 13:58:12,433 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:12,433 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50133.52M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:12,443 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:58:12,484 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:12,489 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=61170,finVtx=0,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@6813a331,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1bd81830)
WARN    2018-08-08 13:58:12,494 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:58:12,508 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,508 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:12,512 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave9_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=6, port=30006)
INFO    2018-08-08 13:58:12,553 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:12,553 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:12,553 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:12,555 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.121
MBytes/sec sent = 0.0115, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.121
INFO    2018-08-08 13:58:12,558 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:12,562 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:12,564 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:58:12,569 [main] org.apache.giraph.utils.TaskIdsPermitsBarrier  - waitForRequiredPermits: Waiting for 8 more tasks to send their aggregator data, task ids: [1, 5, 8, 9, 10, 11, 12, 13]
INFO    2018-08-08 13:58:12,579 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:58:12,833 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.24915741 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.24 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,885 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.30409372 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.30 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,909 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3177199 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.31 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,955 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.3652173 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.36 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:12,961 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.36543977 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.36 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,022 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.43983555 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.44 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,048 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.4630287 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.46 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,067 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.47904083 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.48 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,083 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.48833916 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.49 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,199 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.6047011 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.60 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,389 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.8015695 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.80 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:13,403 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 49795.53M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,750 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0048, MBytesReceived = 0.0044, ave received req MBytes = 0, secs waited = 0.915
MBytes/sec sent = 62.6526, MBytesSent = 57.3898, ave sent req MBytes = 0.2007, secs waited = 0.915
INFO    2018-08-08 13:58:13,750 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:13,934 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:58:13,935 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 8079946 , message bytes = 65371011 , Memory (free/total/max) = 49371.04M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:13,940 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:58:13,959 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:13,960 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=101706996,msgBytesCount=822969877,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@58faa93b,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5f212d84)
INFO    2018-08-08 13:58:13,968 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:13,971 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave9_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=6, port=30006)
INFO    2018-08-08 13:58:13,992 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:13,993 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:13,993 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:13,994 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0003, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.059
MBytes/sec sent = 0.0234, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.059
INFO    2018-08-08 13:58:13,997 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:13,998 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:13,998 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:58:14,001 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:58:14,189 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.17817357 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.18 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,193 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.18963178 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.19 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,207 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.19755784 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,213 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.20255853 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,217 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.20273821 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.20 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,222 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.21709691 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.21 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,225 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.22373365 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.22 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,230 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.21906465 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.22 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,234 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.22638242 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.22 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,240 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.23776957 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.24 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,275 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.271522 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.27 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,319 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 48767.82M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,426 [Service Thread] org.apache.giraph.graph.GraphTaskManager  - installGCMonitoring: name = PS Scavenge, action = end of minor GC, cause = Allocation Failure, duration = 67ms
INFO    2018-08-08 13:58:14,567 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0112, MBytesReceived = 0.0042, ave received req MBytes = 0, secs waited = 0.375
MBytes/sec sent = 149.3407, MBytesSent = 56.1521, ave sent req MBytes = 0.2034, secs waited = 0.375
INFO    2018-08-08 13:58:14,567 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,620 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:58:14,621 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7903858 , message bytes = 63961822 , Memory (free/total/max) = 51571.90M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,625 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:58:14,643 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,646 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=99147446,msgBytesCount=802477784,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@72be135f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@155d1021)
INFO    2018-08-08 13:58:14,652 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,667 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave9_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=6, port=30006)
WARN    2018-08-08 13:58:14,707 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,729 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,730 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.109
MBytes/sec sent = 0.0128, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.109
INFO    2018-08-08 13:58:14,732 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,733 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,735 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:58:14,746 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00860679 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,746 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008280248 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,750 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005787638 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,752 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015540352 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,754 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007881138 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,757 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009215522 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,758 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01943284 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,760 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.020445071 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,762 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.026506621 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.03 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,764 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017840138 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,764 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.021938909 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.02 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,767 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 51457.77M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,817 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0471, MBytesReceived = 0.0033, ave received req MBytes = 0, secs waited = 0.069
MBytes/sec sent = 1.796, MBytesSent = 0.1257, ave sent req MBytes = 0.0006, secs waited = 0.069
INFO    2018-08-08 13:58:14,817 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,850 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,850 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 10875 , message bytes = 142566 , Memory (free/total/max) = 51457.77M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,856 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:58:14,875 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:14,877 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=160153,msgBytesCount=2049368,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@40620d8e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@383f3558)
INFO    2018-08-08 13:58:14,882 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:58:14,898 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave9_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=6, port=30006)
WARN    2018-08-08 13:58:14,940 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:14,963 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:58:14,964 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.114
MBytes/sec sent = 0.0122, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.114
INFO    2018-08-08 13:58:14,966 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:58:14,969 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:58:14,973 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:58:14,979 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004557408 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002590912 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005437167 secs for 7 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004405131 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002447676 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004006596 secs for 6 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001926001 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,979 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003308108 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,980 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001024551 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003856731 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002739251 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 51374.56M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:58:14,982 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:58:14,990 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:58:14,990 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 51374.56M / 52608.00M / 52608.00M
INFO    2018-08-08 13:58:14,995 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:58:15,011 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:58:15,013 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=61170,finVtx=61170,edges=101740626,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.wcc.UndirectedWeaklyConnectedComponentsComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7d151a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@294bdeb4)
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:58:15,016 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:58:15,017 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:58:15,020 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:58:15,040 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:58:15,077 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0013/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:58:15,082 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:58:15,084 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0013/_masterJobState)
INFO    2018-08-08 13:58:17,324 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:58:17,325 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 4794 vertices using 1 threads
INFO    2018-08-08 13:58:17,328 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:58:17,585 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:58:17,585 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:58:17,592 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0013/_cleanedUpDir/6_worker
INFO    2018-08-08 13:58:17,596 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed300ab closed
INFO    2018-08-08 13:58:17,596 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:58:17,598 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:58:17,601 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:58:21,812 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:58:21,814 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0013_m_000006_0 is done. And is in the process of committing
INFO    2018-08-08 13:58:21,835 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0013_m_000006_0 is allowed to commit now
INFO    2018-08-08 13:58:21,844 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0013_m_000006_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r670326_WCC-dota-league/_temporary/1/task_1533735211869_0013_m_000006
INFO    2018-08-08 13:58:21,867 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0013_m_000006_0' done.
INFO    2018-08-08 13:58:21,871 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0013_m_000006_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128638
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=412095
		HDFS: Number of bytes written=41900
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=161
		CPU time spent (ms)=28000
		Physical memory (bytes) snapshot=3605131264
		Virtual memory (bytes) snapshot=58916618240
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0013=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0013/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog

