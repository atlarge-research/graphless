

Container: container_1533735211869_0005_01_000015 on graphalytics-giraph-slave10_46663
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19538
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 663 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 284 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,675.00
               min = 16.00
               max = 6653.00
              mean = 120.94
            stddev = 740.10
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2590.14
              99% <= 6653.00
            99.9% <= 6653.00
             count = 80

  remote-requests:
    count = 0

  requests-received:
             count = 80
         mean rate = 118.18 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 96
         mean rate = 142.02 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,520.00
               min = 16.00
               max = 1473.00
              mean = 47.08
            stddev = 149.12
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 172.04
              99% <= 1473.00
            99.9% <= 1473.00
             count = 96

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 663

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 284

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 88 ms
  compute all partitions: 17 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 239 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 17

  compute-per-partition-ms:
               sum = 64.00
               min = 0.00
               max = 5.00
              mean = 1.94
            stddev = 1.50
            median = 3.00
              75% <= 3.00
              95% <= 3.60
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 64.00
               min = 4.00
               max = 7.00
              mean = 5.82
            stddev = 0.75
            median = 6.00
              75% <= 6.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.16
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 419.53 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 427.92 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.71
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 88

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 239

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 60 ms
  compute all partitions: 6 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 195 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 6

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.27
            stddev = 0.47
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 1152.11
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 523.28 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 533.59 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.71
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 60

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 195

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 142 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 171 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.16
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 284.85 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 290.40 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.80
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 142

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 171

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 136 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 151 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.03
            stddev = 0.17
            median = 0.00
              75% <= 0.00
              95% <= 0.30
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.16
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 297.01 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 302.83 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 136

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 151

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:54 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.32784763043814

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:54 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67438
Log Contents:
2018-08-08 13:39:49,844 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,917 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,917 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,919 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,919 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:50,099 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,318 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,489 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,927 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,938 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:51,079 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:51,092 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:51,119 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:51,120 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:51,127 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:51,133 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:51,133 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 12 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave10
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000015:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000015/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000015:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000015/tmp
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000015
INFO    2018-08-08 13:39:51,140 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:51,152 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:51,152 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:51,160 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30043, negotiated timeout = 40000
INFO    2018-08-08 13:39:51,161 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,264 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,282 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,325 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave10/10.164.0.12:30012 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,330 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,330 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,352 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,361 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,364 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,367 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,372 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave10_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012)
INFO    2018-08-08 13:39:51,654 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,748 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,753 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,758 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,758 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,760 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,760 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,762 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,774 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,777 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,778 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,778 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,780 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,780 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,782 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,838 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,881 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042722616 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,892 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04739636 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,892 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04654084 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,892 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046122316 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,893 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045651007 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,893 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044648793 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,894 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044012107 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,894 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043777145 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,894 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04320298 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,895 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04258466 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,895 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041917704 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,897 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0032, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.052
MBytes/sec sent = 0.0049, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.052
INFO    2018-08-08 13:39:51,898 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,902 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003818475 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,903 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003298256 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,904 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003039311 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,905 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003060074 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,906 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003325914 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,909 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005477202 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,909 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005050572 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,910 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004531322 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,911 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005535906 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,912 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005150043 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,912 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003579766 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,913 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.012, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0187, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.013
INFO    2018-08-08 13:39:51,913 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:39:51,941 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,946 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:39:51,948 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50879.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,948 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0034, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.048
MBytes/sec sent = 0.0054, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.048
INFO    2018-08-08 13:39:51,948 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,965 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:51,966 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50879.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,978 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,017 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,022 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@79b663b3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1b812421)
WARN    2018-08-08 13:39:52,026 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,044 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,044 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,047 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave10_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012)
INFO    2018-08-08 13:39:52,076 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,076 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,076 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,077 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.111
MBytes/sec sent = 0.0125, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.111
INFO    2018-08-08 13:39:52,080 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,082 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,091 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,105 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009720989 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,105 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007574057 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,106 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012993451 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,105 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009169865 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,105 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005963259 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,105 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011661318 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,106 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005803182 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,106 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008721578 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,106 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010553921 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,106 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011135698 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,107 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008020992 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,109 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0068, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.026
MBytes/sec sent = 0.0377, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.026
INFO    2018-08-08 13:39:52,109 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,123 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.004, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:39:52,123 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,127 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,150 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,152 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:39:52,159 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,164 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave10_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012)
INFO    2018-08-08 13:39:52,190 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,190 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,190 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,191 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.067
MBytes/sec sent = 0.0207, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.067
INFO    2018-08-08 13:39:52,195 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,196 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,199 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,202 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002257067 secs for 13 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,202 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003133828 secs for 18 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,203 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002082423 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,203 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001768174 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,203 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00108051 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,203 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001778976 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,203 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001090208 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,204 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 8.59163E-4 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,205 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001596505 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,205 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001789027 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,206 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001787556 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,206 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,206 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0183, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.009
MBytes/sec sent = 0.1019, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.009
INFO    2018-08-08 13:39:52,206 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,219 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,219 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,225 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,250 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,252 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:39:52,259 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,275 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave10_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012)
INFO    2018-08-08 13:39:52,293 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,343 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,375 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,375 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,375 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,376 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.157
MBytes/sec sent = 0.0089, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.157
INFO    2018-08-08 13:39:52,379 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,380 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,384 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,388 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001511491 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,388 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001971003 secs for 11 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,388 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001064735 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,388 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 8.94956E-4 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,388 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002969658 secs for 18 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,389 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001580779 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,389 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00107579 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,390 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 9.23285E-4 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,390 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001308687 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,390 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001074604 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005671533 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,396 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50444.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,396 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0114, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.015
MBytes/sec sent = 0.0637, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.015
INFO    2018-08-08 13:39:52,396 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,402 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,402 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50444.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,406 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,432 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,435 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@27abb83e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@69e308c6)
INFO    2018-08-08 13:39:52,440 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,457 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave10_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012)
INFO    2018-08-08 13:39:52,471 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,522 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,551 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,552 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,552 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,553 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.151
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,561 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,564 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001668838 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,564 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002099331 secs for 14 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,564 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002928951 secs for 18 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,564 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00131192 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,565 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001079364 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,565 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001312329 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,566 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001192147 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,567 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001553312 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,567 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001216498 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001868939 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001815611 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50303.67M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,569 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:39:52,569 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,576 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,576 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50303.67M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,581 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,605 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,608 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@89c65d5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@faa3fed)
INFO    2018-08-08 13:39:52,612 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,612 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,612 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,615 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:52,640 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,690 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,695 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,698 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:54,919 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:54,919 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 13:39:54,923 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:54,961 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:54,961 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:54,963 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/12_worker
INFO    2018-08-08 13:39:54,965 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30043 closed
INFO    2018-08-08 13:39:54,965 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:54,967 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:54,971 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:59,185 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:59,190 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000012_0 is done. And is in the process of committing
INFO    2018-08-08 13:39:59,212 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000012_0 is allowed to commit now
INFO    2018-08-08 13:39:59,221 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000012_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000012
INFO    2018-08-08 13:39:59,237 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000012_0' done.
INFO    2018-08-08 13:39:59,242 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000012_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128858
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=91
		CPU time spent (ms)=4290
		Physical memory (bytes) snapshot=1072209920
		Virtual memory (bytes) snapshot=58894467072
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000006 on graphalytics-giraph-slave11_46641
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19551
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 678 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 314 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,826.00
               min = 16.00
               max = 6653.00
              mean = 116.98
            stddev = 722.33
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 2100.90
              99% <= 6653.00
            99.9% <= 6653.00
             count = 84

  remote-requests:
    count = 0

  requests-received:
             count = 84
         mean rate = 120.99 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 141.51 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.66
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 678

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 314

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 83 ms
  compute all partitions: 18 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 7024 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 18

  compute-per-partition-ms:
               sum = 53.00
               min = 0.00
               max = 7.00
              mean = 1.61
            stddev = 1.66
            median = 2.00
              75% <= 3.00
              95% <= 4.20
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 164

  messages-sent:
    count = 4

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 53.00
               min = 2.00
               max = 7.00
              mean = 4.82
            stddev = 1.54
            median = 5.00
              75% <= 6.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 8,975.00
               min = 16.00
               max = 6564.00
              mean = 152.12
            stddev = 849.66
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5269.00
              99% <= 6564.00
            99.9% <= 6564.00
             count = 59

  remote-requests:
    count = 4

  requests-received:
             count = 59
         mean rate = 492.04 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 59
         mean rate = 492.28 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 4

  sent-bytes:
               sum = 3,850.00
               min = 16.00
               max = 1473.00
              mean = 65.25
            stddev = 188.63
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1196.20
              99% <= 1473.00
            99.9% <= 1473.00
             count = 59

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 83

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 4

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 7024

  worker-context-post-superstep:
    value = 9

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 59 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 2999 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 13.00
               min = 0.00
               max = 8.00
              mean = 0.39
            stddev = 1.41
            median = 0.00
              75% <= 0.00
              95% <= 3.10
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 237

  messages-sent:
    count = 7

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 13.00
               min = 0.00
               max = 8.00
              mean = 1.18
            stddev = 2.48
            median = 0.00
              75% <= 2.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 9,115.00
               min = 16.00
               max = 6564.00
              mean = 147.02
            stddev = 829.55
            median = 31.00
              75% <= 62.00
              95% <= 89.00
              98% <= 4880.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 62

  remote-requests:
    count = 5

  requests-received:
             count = 62
         mean rate = 640.00 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 62
         mean rate = 646.28 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 5

  sent-bytes:
               sum = 3,960.00
               min = 16.00
               max = 1473.00
              mean = 63.87
            stddev = 184.13
            median = 20.50
              75% <= 55.25
              95% <= 89.00
              98% <= 1113.16
              99% <= 1473.00
            99.9% <= 1473.00
             count = 62

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 59

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 5

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 2999

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 144 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 181 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 3.00
              mean = 0.15
            stddev = 0.57
            median = 0.00
              75% <= 0.00
              95% <= 1.60
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 237

  messages-sent:
    count = 7

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 3.00
              mean = 0.45
            stddev = 0.93
            median = 0.00
              75% <= 1.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 9,115.00
               min = 16.00
               max = 6564.00
              mean = 147.02
            stddev = 828.83
            median = 31.00
              75% <= 62.00
              95% <= 89.00
              98% <= 4880.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 62

  remote-requests:
    count = 5

  requests-received:
             count = 62
         mean rate = 340.78 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 62
         mean rate = 340.87 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 5

  sent-bytes:
               sum = 3,960.00
               min = 16.00
               max = 1473.00
              mean = 63.87
            stddev = 184.13
            median = 20.50
              75% <= 55.25
              95% <= 89.00
              98% <= 1113.16
              99% <= 1473.00
            99.9% <= 1473.00
             count = 62

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 144

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 5

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 181

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 135 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 156 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.03
            stddev = 0.17
            median = 0.00
              75% <= 0.00
              95% <= 0.30
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.16
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 299.36 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 305.22 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 135

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 156

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.95680635282882

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67592
Log Contents:
2018-08-08 13:39:49,772 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,835 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,835 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,837 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,837 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:50,015 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,234 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,417 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,885 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,897 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:51,043 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:51,058 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:51,089 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:51,090 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:51,097 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:51,104 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:51,104 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 4 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave11
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000006:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000006/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000006:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000006/tmp
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:51,111 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000006
INFO    2018-08-08 13:39:51,112 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:51,124 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:51,125 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:51,131 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30041, negotiated timeout = 40000
INFO    2018-08-08 13:39:51,133 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,240 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,257 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,318 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave11/10.164.0.13:30004 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,323 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,324 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,345 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,355 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,359 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,362 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,367 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave11_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004)
INFO    2018-08-08 13:39:51,662 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,752 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,760 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,764 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,765 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,767 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,774 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,775 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,776 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,777 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,777 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,777 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,778 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,779 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,779 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,782 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,784 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,844 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,891 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046885435 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,906 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.055219863 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,907 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.054511543 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,908 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.055048145 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,908 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.054147206 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,909 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05378764 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,909 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05331155 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,909 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05211491 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,910 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.052613758 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,910 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.051598772 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,910 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050958674 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,912 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0027, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.128
MBytes/sec sent = 0.0099, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.128
INFO    2018-08-08 13:39:51,913 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,917 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00395906 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,918 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002949854 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,919 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.69587E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,919 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002918597 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,920 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002827963 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,920 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005022348 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,921 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0027847 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,922 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0027869 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,924 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003821845 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,925 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004172043 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,925 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003403249 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,925 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0137, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.009
MBytes/sec sent = 0.0215, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.009
INFO    2018-08-08 13:39:51,926 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:39:51,949 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,954 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,962 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,963 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,964 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0028, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.048
MBytes/sec sent = 0.0044, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.048
INFO    2018-08-08 13:39:51,964 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,973 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:51,974 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,985 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,026 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,031 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@779dfe55,outgoing=org.apache.giraph.conf.DefaultMessageClasses@323659f8)
WARN    2018-08-08 13:39:52,035 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,051 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,051 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,053 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave11_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004)
INFO    2018-08-08 13:39:52,083 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,083 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,083 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,084 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.11
MBytes/sec sent = 0.0127, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.11
INFO    2018-08-08 13:39:52,089 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,091 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,099 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,114 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00574504 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011108973 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004673531 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009473742 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012986804 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011790709 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006328348 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0109713 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007613863 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,115 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009766647 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004138336 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,118 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,125 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.009
MBytes/sec sent = 0.0175, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.009
INFO    2018-08-08 13:39:52,125 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,128 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0496, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.1576, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:39:52,129 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 4 , message bytes = 164 , Memory (free/total/max) = 50582.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,134 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,159 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,161 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@40620d8e)
INFO    2018-08-08 13:39:52,169 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,174 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave11_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004)
INFO    2018-08-08 13:39:52,198 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,198 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,199 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,200 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.071
MBytes/sec sent = 0.0195, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.071
INFO    2018-08-08 13:39:52,204 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,205 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,208 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,213 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002340336 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002998491 secs for 17 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003705621 secs for 13 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001539625 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,214 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002894725 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,214 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001505401 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,215 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00184747 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,216 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003641863 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,216 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002091222 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,217 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003142283 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,218 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009416044 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,219 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,222 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.05, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:52,222 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,228 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,228 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 7 , message bytes = 237 , Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,234 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,259 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,262 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7d151a)
INFO    2018-08-08 13:39:52,267 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,287 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave11_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004)
INFO    2018-08-08 13:39:52,302 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,352 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,384 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,384 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,384 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,385 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.157
MBytes/sec sent = 0.0089, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.157
INFO    2018-08-08 13:39:52,388 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,389 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,393 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,397 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001878162 secs for 7 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,397 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001586459 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,397 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003049364 secs for 12 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,397 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002575169 secs for 12 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,398 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005271409 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,398 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00214068 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,399 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00165478 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,401 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002062744 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,401 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002246295 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,401 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002261099 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,403 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003482168 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,404 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,404 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0127, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0416, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:39:52,404 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,411 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,411 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 7 , message bytes = 237 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,416 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,441 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,445 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@54534abf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@51745f40)
INFO    2018-08-08 13:39:52,450 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,466 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave11_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004)
INFO    2018-08-08 13:39:52,480 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,531 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,560 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,561 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,561 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,561 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:39:52,564 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,565 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,569 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,572 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001912455 secs for 5 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002674633 secs for 25 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001227912 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001417745 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001129081 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,574 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001400526 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,574 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001649112 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,575 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001575761 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,575 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001400612 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,577 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002749828 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,577 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002557636 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,578 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50146.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,578 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:39:52,578 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,585 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,585 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50146.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,590 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,614 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,617 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@37d00a23)
INFO    2018-08-08 13:39:52,620 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,621 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,621 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,624 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:52,649 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,699 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,704 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,707 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:54,927 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:54,928 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:39:54,931 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:55,112 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:55,112 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:55,114 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/4_worker
INFO    2018-08-08 13:39:55,117 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30041 closed
INFO    2018-08-08 13:39:55,117 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:55,119 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:55,122 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:59,333 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:59,337 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000004_0 is done. And is in the process of committing
INFO    2018-08-08 13:39:59,359 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000004_0 is allowed to commit now
INFO    2018-08-08 13:39:59,367 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000004_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000004
INFO    2018-08-08 13:39:59,383 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000004_0' done.
INFO    2018-08-08 13:39:59,388 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000004_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=94
		CPU time spent (ms)=4650
		Physical memory (bytes) snapshot=1105350656
		Virtual memory (bytes) snapshot=58879307776
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000005 on graphalytics-giraph-slave12_33893
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19546
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 596 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 311 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,809.00
               min = 16.00
               max = 6653.00
              mean = 118.18
            stddev = 726.62
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2213.96
              99% <= 6653.00
            99.9% <= 6653.00
             count = 83

  remote-requests:
    count = 0

  requests-received:
             count = 83
         mean rate = 136.01 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 160.93 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.64
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 596

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 311

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 88 ms
  compute all partitions: 17 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 7970 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 17

  compute-per-partition-ms:
               sum = 58.00
               min = 0.00
               max = 6.00
              mean = 1.76
            stddev = 1.60
            median = 2.00
              75% <= 2.50
              95% <= 5.30
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 123

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 58.00
               min = 4.00
               max = 7.00
              mean = 5.27
            stddev = 0.94
            median = 5.00
              75% <= 6.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 8,821.00
               min = 16.00
               max = 6564.00
              mean = 160.38
            stddev = 882.64
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 5787.00
              99% <= 6564.00
            99.9% <= 6564.00
             count = 55

  remote-requests:
    count = 3

  requests-received:
             count = 55
         mean rate = 445.34 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 55
         mean rate = 444.76 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,756.00
               min = 16.00
               max = 1473.00
              mean = 68.29
            stddev = 195.12
            median = 46.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1306.92
              99% <= 1473.00
            99.9% <= 1473.00
             count = 55

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 88

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 7970

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 58 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 156 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 7.00
               min = 0.00
               max = 5.00
              mean = 0.21
            stddev = 0.89
            median = 0.00
              75% <= 0.00
              95% <= 2.20
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 123

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 7.00
               min = 0.00
               max = 5.00
              mean = 0.64
            stddev = 1.50
            median = 0.00
              75% <= 1.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,959.00
               min = 16.00
               max = 6564.00
              mean = 154.47
            stddev = 857.23
            median = 31.00
              75% <= 62.00
              95% <= 89.00
              98% <= 5398.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 58

  remote-requests:
    count = 3

  requests-received:
             count = 58
         mean rate = 592.39 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 590.07 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,804.00
               min = 16.00
               max = 1473.00
              mean = 65.59
            stddev = 190.26
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 58

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 156

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 140 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1561 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 9.00
               min = 0.00
               max = 6.00
              mean = 0.27
            stddev = 1.07
            median = 0.00
              75% <= 0.00
              95% <= 2.50
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 123

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 9.00
               min = 0.00
               max = 6.00
              mean = 0.82
            stddev = 1.83
            median = 0.00
              75% <= 1.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,959.00
               min = 16.00
               max = 6653.00
              mean = 157.18
            stddev = 876.25
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5602.76
              99% <= 6653.00
            99.9% <= 6653.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 322.84 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 328.55 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,804.00
               min = 16.00
               max = 1473.00
              mean = 65.59
            stddev = 190.26
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 140

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1561

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 136 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 155 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.57
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 296.96 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 302.76 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.75
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 136

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 155

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.9568049461012

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67575
Log Contents:
2018-08-08 13:39:49,811 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,876 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,876 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,878 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,878 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:50,058 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,295 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,493 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,960 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,972 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:51,123 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:51,137 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:51,166 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:51,167 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:51,176 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:51,183 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:51,183 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 3 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave12
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000005:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000005/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000005:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000005/tmp
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:51,190 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000005
INFO    2018-08-08 13:39:51,191 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:51,206 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:51,207 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:51,213 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30044, negotiated timeout = 40000
INFO    2018-08-08 13:39:51,214 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,325 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,343 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,390 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave12/10.164.0.14:30003 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,396 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,397 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,420 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,430 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,434 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,437 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,443 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave12_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=3, port=30003)
INFO    2018-08-08 13:39:51,656 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,746 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,754 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,754 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,756 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,757 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,760 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,767 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,767 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,776 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,781 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,847 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,886 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037981015 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,886 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.029306352 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,886 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030078463 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,886 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028108014 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,886 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028596932 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,887 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.02781213 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,888 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.027430177 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,888 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.02789622 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,888 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.02622065 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,888 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.026766157 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,889 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.025718477 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,892 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0047, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.035
MBytes/sec sent = 0.0073, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.036
INFO    2018-08-08 13:39:51,893 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,898 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004433407 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,898 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003580204 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0038413 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003181492 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 7.50572E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,902 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00391157 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,903 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002951995 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,904 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005923962 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,904 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003293812 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,905 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002972818 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,906 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003492241 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,907 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0129, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0202, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.012
INFO    2018-08-08 13:39:51,907 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:39:51,943 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,947 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,955 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,957 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,957 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0027, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.062
MBytes/sec sent = 0.0042, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.062
INFO    2018-08-08 13:39:51,957 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,967 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:51,967 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,979 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,019 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,024 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@779dfe55,outgoing=org.apache.giraph.conf.DefaultMessageClasses@323659f8)
WARN    2018-08-08 13:39:52,029 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,043 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,044 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,047 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave12_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=3, port=30003)
INFO    2018-08-08 13:39:52,076 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,077 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,077 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,078 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.11
MBytes/sec sent = 0.0127, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.11
INFO    2018-08-08 13:39:52,083 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,084 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,092 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,107 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004870615 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,107 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007660775 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,107 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013029575 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,107 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008960703 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006785956 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012446915 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01228244 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00688786 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011548568 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,110 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006970328 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,110 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011983359 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,111 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,119 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0046, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0132, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.009
INFO    2018-08-08 13:39:52,119 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,124 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0331, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.1051, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:39:52,125 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 3 , message bytes = 123 , Memory (free/total/max) = 50582.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,129 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,153 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,155 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@40620d8e)
INFO    2018-08-08 13:39:52,163 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,168 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave12_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=3, port=30003)
INFO    2018-08-08 13:39:52,192 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,192 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,192 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,193 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.068
MBytes/sec sent = 0.0204, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.068
INFO    2018-08-08 13:39:52,198 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,199 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,202 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,206 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002099956 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,207 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001675918 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,206 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003293703 secs for 19 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,206 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002866682 secs for 13 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,207 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001603211 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001807897 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001621262 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006511004 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001424143 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,211 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00275047 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,211 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002734354 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,212 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0114, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.0329, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:39:52,212 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,222 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,222 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 3 , message bytes = 123 , Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,228 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,252 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,255 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7d151a)
INFO    2018-08-08 13:39:52,265 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,283 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave12_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=3, port=30003)
INFO    2018-08-08 13:39:52,296 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,346 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,379 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,379 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,379 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,381 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.159
MBytes/sec sent = 0.0088, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.159
INFO    2018-08-08 13:39:52,383 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,384 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,386 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,390 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003220152 secs for 22 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,390 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00271817 secs for 10 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,391 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003288483 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002868367 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003240076 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001841541 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002550436 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001736912 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003004829 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008317461 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,396 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002587541 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,397 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,398 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0114, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.0329, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:39:52,398 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,405 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,405 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 3 , message bytes = 123 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,411 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,435 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,438 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@54534abf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@51745f40)
INFO    2018-08-08 13:39:52,442 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,460 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave12_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=3, port=30003)
INFO    2018-08-08 13:39:52,473 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,525 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,554 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,554 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,554 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,555 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:39:52,558 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,559 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,563 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,566 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002569623 secs for 21 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,566 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001341037 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,566 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001765781 secs for 11 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,567 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001455665 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,567 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0012428 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001313233 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001374926 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001272261 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001198102 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 9.00775E-4 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002425533 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50146.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,571 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0849, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.011
INFO    2018-08-08 13:39:52,571 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,578 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,579 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50146.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,584 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,608 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,611 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@37d00a23)
INFO    2018-08-08 13:39:52,614 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,614 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,614 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,617 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:52,643 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,693 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,698 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,701 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:54,921 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:54,921 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:39:54,925 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:55,105 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:55,105 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:55,107 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/3_worker
INFO    2018-08-08 13:39:55,109 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30044 closed
INFO    2018-08-08 13:39:55,109 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:55,111 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:55,116 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:59,327 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:59,332 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000003_0 is done. And is in the process of committing
INFO    2018-08-08 13:39:59,357 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000003_0 is allowed to commit now
INFO    2018-08-08 13:39:59,366 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000003_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000003
INFO    2018-08-08 13:39:59,386 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000003_0' done.
INFO    2018-08-08 13:39:59,391 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000003_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=93
		CPU time spent (ms)=4960
		Physical memory (bytes) snapshot=1115398144
		Virtual memory (bytes) snapshot=58910601216
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000016 on graphalytics-giraph-slave13_40615
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19538
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 645 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 482 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,675.00
               min = 16.00
               max = 6653.00
              mean = 125.65
            stddev = 756.57
            median = 16.00
              75% <= 53.00
              95% <= 90.10
              98% <= 3025.32
              99% <= 6653.00
            99.9% <= 6653.00
             count = 77

  remote-requests:
    count = 0

  requests-received:
             count = 77
         mean rate = 116.74 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 96
         mean rate = 145.80 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,520.00
               min = 16.00
               max = 1473.00
              mean = 47.08
            stddev = 149.12
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 172.04
              99% <= 1473.00
            99.9% <= 1473.00
             count = 96

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 645

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 482

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 89 ms
  compute all partitions: 17 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 295 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 17

  compute-per-partition-ms:
               sum = 65.00
               min = 0.00
               max = 4.00
              mean = 1.97
            stddev = 1.61
            median = 3.00
              75% <= 3.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 65.00
               min = 3.00
               max = 7.00
              mean = 5.91
            stddev = 1.31
            median = 6.00
              75% <= 7.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 1027.81
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 416.64 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 423.64 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 89

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 295

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 58 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 208 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 6.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.39
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 6.00
               min = 0.00
               max = 2.00
              mean = 0.55
            stddev = 0.93
            median = 0.00
              75% <= 2.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 927.27
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 547.76 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 558.59 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.72
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 58

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 208

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 145 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 154 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 1.00
              mean = 0.15
            stddev = 0.36
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.45
            stddev = 0.82
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.16
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 282.40 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 288.05 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 145

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 154

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 137 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 187 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.12
            stddev = 0.42
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 3.00
              mean = 0.36
            stddev = 0.92
            median = 0.00
              75% <= 0.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 974.18
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 296.80 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 302.61 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.68
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 137

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 187

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:54 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.32769409409406

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:54 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67427
Log Contents:
2018-08-08 13:39:49,812 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,880 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,880 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,882 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,882 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:50,060 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,286 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,470 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,920 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,932 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:51,076 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:51,089 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:51,117 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:51,118 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:51,126 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:51,133 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:51,133 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 13 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave13
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:51,139 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000016:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000016/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:51,140 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000016:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:51,140 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000016/tmp
INFO    2018-08-08 13:39:51,140 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:51,140 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:51,140 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:51,140 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:51,140 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:51,140 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:51,140 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000016
INFO    2018-08-08 13:39:51,140 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:51,154 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:51,154 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:51,161 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30042, negotiated timeout = 40000
INFO    2018-08-08 13:39:51,162 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,276 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,294 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,344 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave13/10.164.0.15:30013 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,349 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,350 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,371 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,381 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,384 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,387 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,394 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave13_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013)
INFO    2018-08-08 13:39:51,657 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,744 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,755 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,756 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,758 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,760 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,760 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,774 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,776 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,776 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,777 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,785 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,847 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,899 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.051392723 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,899 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042034708 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,899 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04072792 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,899 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04144401 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,899 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042652417 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,899 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04394143 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,899 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044990305 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04039704 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039648812 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038956687 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03821381 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,904 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0034, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.049
MBytes/sec sent = 0.0052, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.05
INFO    2018-08-08 13:39:51,905 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,910 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005077275 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,910 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003711051 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,911 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003426175 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,912 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004001233 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,913 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003972159 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,914 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00387792 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,914 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003142658 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,915 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002680693 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,917 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004578158 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,917 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003314385 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,918 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002966202 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,918 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0092, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0143, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:51,918 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:39:51,943 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,948 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:39:51,950 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50879.61M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,950 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0012, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.036
MBytes/sec sent = 0.0019, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.036
INFO    2018-08-08 13:39:51,951 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,968 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:51,968 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50879.61M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,981 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,020 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,025 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@79b663b3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1b812421)
WARN    2018-08-08 13:39:52,029 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,046 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,046 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,048 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave13_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013)
INFO    2018-08-08 13:39:52,080 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,080 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,080 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,082 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.113
MBytes/sec sent = 0.0123, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.114
INFO    2018-08-08 13:39:52,084 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,085 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,095 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,111 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007958762 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005144733 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012008871 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00834111 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006090507 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007117387 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,113 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014878667 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,113 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007693441 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011691844 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010716069 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,113 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013669689 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50738.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,114 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0063, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.028
MBytes/sec sent = 0.0351, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.028
INFO    2018-08-08 13:39:52,114 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,126 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:39:52,126 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,130 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,153 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,155 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:39:52,165 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,168 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave13_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013)
INFO    2018-08-08 13:39:52,193 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,193 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,193 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,194 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.068
MBytes/sec sent = 0.0204, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.068
INFO    2018-08-08 13:39:52,198 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,199 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,202 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,206 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003815252 secs for 10 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,206 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002822791 secs for 12 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,206 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003365491 secs for 11 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,206 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002108742 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,207 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002743079 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,207 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002223248 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,207 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001916985 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001534131 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001113368 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001568429 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002090018 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50598.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,211 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0849, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.011
INFO    2018-08-08 13:39:52,211 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,222 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,223 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50598.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,229 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,252 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,254 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:39:52,260 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,281 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave13_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013)
INFO    2018-08-08 13:39:52,296 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,346 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,378 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,378 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,378 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,379 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.156
MBytes/sec sent = 0.0089, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.156
INFO    2018-08-08 13:39:52,381 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,383 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,383 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 13:39:52,386 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,391 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002097826 secs for 21 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,391 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001808361 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,391 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00386751 secs for 9 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,391 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00155521 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,391 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001506398 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001662148 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001322677 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 8.92687E-4 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001282899 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001013634 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002234594 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50444.40M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,395 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0849, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.011
INFO    2018-08-08 13:39:52,395 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,405 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,405 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50444.40M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,411 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,434 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,437 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@27abb83e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@69e308c6)
INFO    2018-08-08 13:39:52,442 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,460 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave13_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013)
INFO    2018-08-08 13:39:52,474 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,525 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,555 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.151
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.151
INFO    2018-08-08 13:39:52,559 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,560 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,564 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,568 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002441542 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003806605 secs for 19 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00296774 secs for 11 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00291637 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,570 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003135202 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,570 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002586909 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002232836 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003287912 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002888458 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,575 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003413345 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,575 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00376885 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,575 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50303.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,576 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0114, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.015
MBytes/sec sent = 0.0637, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.016
INFO    2018-08-08 13:39:52,576 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,579 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,579 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50303.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,587 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,608 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,611 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@89c65d5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@faa3fed)
INFO    2018-08-08 13:39:52,614 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,614 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,614 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,617 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
WARN    2018-08-08 13:39:52,693 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,698 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,701 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:54,721 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:54,721 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 13:39:54,725 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:54,759 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:54,759 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:54,761 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/13_worker
INFO    2018-08-08 13:39:54,763 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30042 closed
INFO    2018-08-08 13:39:54,763 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:54,765 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:54,769 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:58,981 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:58,985 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000013_0 is done. And is in the process of committing
INFO    2018-08-08 13:39:59,012 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000013_0 is allowed to commit now
INFO    2018-08-08 13:39:59,021 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000013_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000013
INFO    2018-08-08 13:39:59,039 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000013_0' done.
INFO    2018-08-08 13:39:59,045 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000013_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128858
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=91
		CPU time spent (ms)=4450
		Physical memory (bytes) snapshot=1098846208
		Virtual memory (bytes) snapshot=58922151936
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000004 on graphalytics-giraph-slave14_35219
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19548
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 918 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 319 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 10.0

  received-bytes:
               sum = 10,076.00
               min = 16.00
               max = 6653.00
              mean = 104.96
            stddev = 676.44
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 587.18
              99% <= 6653.00
            99.9% <= 6653.00
             count = 96

  remote-requests:
    count = 9

  requests-received:
             count = 96
         mean rate = 103.04 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 108
         mean rate = 116.02 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 9

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 5,063.00
               min = 16.00
               max = 1473.00
              mean = 46.88
            stddev = 140.65
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 89.00
              99% <= 1348.44
            99.9% <= 1473.00
             count = 108

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 918

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 10

  wait-requests-us:
    value = 319

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 86 ms
  compute all partitions: 15 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 5576 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 15

  compute-per-partition-ms:
               sum = 57.00
               min = 0.00
               max = 6.00
              mean = 1.73
            stddev = 1.34
            median = 2.00
              75% <= 3.00
              95% <= 3.90
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 82

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 56.00
               min = 3.00
               max = 6.00
              mean = 5.09
            stddev = 1.04
            median = 5.00
              75% <= 6.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,897.00
               min = 16.00
               max = 6564.00
              mean = 158.88
            stddev = 967.38
            median = 31.00
              75% <= 80.00
              95% <= 89.00
              98% <= 5657.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 56

  remote-requests:
    count = 2

  requests-received:
             count = 56
         mean rate = 453.57 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 453.38 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,742.00
               min = 16.00
               max = 1473.00
              mean = 66.82
            stddev = 193.55
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 86

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 5576

  worker-context-post-superstep:
    value = 9

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 58 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 567 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 11.00
               min = 0.00
               max = 6.00
              mean = 0.33
            stddev = 1.08
            median = 0.00
              75% <= 0.00
              95% <= 2.50
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 139

  messages-sent:
    count = 4

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 11.00
               min = 0.00
               max = 6.00
              mean = 1.00
            stddev = 1.84
            median = 0.00
              75% <= 2.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,975.00
               min = 16.00
               max = 6564.00
              mean = 154.74
            stddev = 856.95
            median = 31.00
              75% <= 68.75
              95% <= 89.00
              98% <= 5398.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 58

  remote-requests:
    count = 3

  requests-received:
             count = 58
         mean rate = 600.21 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 600.24 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,820.00
               min = 16.00
               max = 1473.00
              mean = 65.86
            stddev = 190.39
            median = 20.50
              75% <= 55.25
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 58

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 567

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 143 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 907 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 6.00
               min = 0.00
               max = 3.00
              mean = 0.18
            stddev = 0.58
            median = 0.00
              75% <= 0.00
              95% <= 1.60
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 139

  messages-sent:
    count = 4

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 6.00
               min = 0.00
               max = 3.00
              mean = 0.55
            stddev = 0.93
            median = 0.00
              75% <= 1.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 8,975.00
               min = 16.00
               max = 6564.00
              mean = 154.74
            stddev = 856.86
            median = 31.00
              75% <= 68.75
              95% <= 89.00
              98% <= 5398.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 58

  remote-requests:
    count = 3

  requests-received:
             count = 58
         mean rate = 324.19 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 324.18 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,820.00
               min = 16.00
               max = 1473.00
              mean = 65.86
            stddev = 190.25
            median = 20.50
              75% <= 55.25
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 143

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 907

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 137 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 198 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.12
            stddev = 0.33
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.67
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 904.90
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 302.03 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 302.01 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 137

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 198

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.95679921767427

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = 0.0

  vertices-loaded:
             count = 10
         mean rate = 2.36 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67889
Log Contents:
2018-08-08 13:39:49,666 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,724 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,724 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,726 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,726 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:49,893 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,101 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,265 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,685 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,696 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:50,828 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:50,842 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:50,870 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:50,871 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:50,878 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:50,884 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:50,885 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 2 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:50,890 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:50,890 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave14
INFO    2018-08-08 13:39:50,890 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:50,890 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:50,891 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:50,891 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000004:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000004/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:50,891 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000004:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:50,891 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000004/tmp
INFO    2018-08-08 13:39:50,891 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:50,891 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:50,891 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:50,891 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:50,891 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:50,891 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:50,891 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000004
INFO    2018-08-08 13:39:50,892 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:50,904 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:50,905 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:50,911 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30038, negotiated timeout = 40000
INFO    2018-08-08 13:39:50,912 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,011 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,026 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,077 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave14/10.164.0.16:30002 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,082 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,083 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,100 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,113 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,116 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,127 [main-EventThread] org.apache.giraph.bsp.BspService  - process: applicationAttemptChanged signaled
WARN    2018-08-08 13:39:51,139 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:51,145 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave14_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=2, port=30002)
INFO    2018-08-08 13:39:51,656 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,741 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,748 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,750 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,751 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,752 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,752 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,753 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,753 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,753 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,753 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,753 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,753 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,755 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,755 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,755 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,755 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,760 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,774 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,775 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,775 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,775 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,775 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,842 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,885 [load-0] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/example-directed.v:0+21'
INFO    2018-08-08 13:39:51,900 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.051007688 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050335523 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.049970414 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.049459055 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0488941 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04830247 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047794215 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047386117 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04696907 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046798263 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,908 [load-0] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=10, e=0)
INFO    2018-08-08 13:39:51,909 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 0.06639636 secs, (v=10, e=0) 150.61066 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,917 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.008
MBytes/sec sent = 0.0515, MBytesSent = 0.0005, ave sent req MBytes = 0.0001, secs waited = 0.008
INFO    2018-08-08 13:39:51,918 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,921 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 8.19749E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,922 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002398428 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,922 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.042E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,923 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002511512 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,924 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005136057 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,924 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00230178 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,924 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002023152 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,926 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002724691 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,926 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002394529 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,926 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002327688 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,928 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003477296 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,929 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0209, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 13:39:51,929 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=10, e=0)
INFO    2018-08-08 13:39:51,944 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,948 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,955 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,957 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,957 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.003, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.035
MBytes/sec sent = 0.0046, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.035
INFO    2018-08-08 13:39:51,957 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,969 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:51,969 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,978 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,021 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,026 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@794b435f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@38f2e97e)
INFO    2018-08-08 13:39:52,043 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,043 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,047 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave14_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=2, port=30002)
INFO    2018-08-08 13:39:52,079 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,079 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,079 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,081 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.112
MBytes/sec sent = 0.0124, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.112
INFO    2018-08-08 13:39:52,085 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,086 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,095 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,109 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006947224 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011100828 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010519527 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006712364 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012475868 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00555506 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,110 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008650582 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009315589 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,110 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010118055 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,110 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007981072 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,110 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006295796 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,111 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,117 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0044, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0125, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 13:39:52,117 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,124 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,125 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 2 , message bytes = 82 , Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,130 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,155 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,157 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27ead29e)
INFO    2018-08-08 13:39:52,166 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,170 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave14_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=2, port=30002)
INFO    2018-08-08 13:39:52,194 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,194 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,194 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,195 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.07
MBytes/sec sent = 0.0198, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.07
INFO    2018-08-08 13:39:52,199 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,200 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,204 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,209 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002307091 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001736705 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001081236 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003025652 secs for 9 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00354796 secs for 16 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001731756 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001218721 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,211 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001118621 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002029625 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007930572 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003181588 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,214 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.049, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,214 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,224 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,224 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 4 , message bytes = 139 , Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,229 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,255 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,257 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@56febdc)
INFO    2018-08-08 13:39:52,263 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,283 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave14_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=2, port=30002)
INFO    2018-08-08 13:39:52,298 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,348 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,379 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,380 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,380 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,381 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.157
MBytes/sec sent = 0.0089, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.157
INFO    2018-08-08 13:39:52,384 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,385 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,388 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,393 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002558715 secs for 24 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002106473 secs for 7 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00124062 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001648859 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001214108 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001798969 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001539586 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005471644 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001439714 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,396 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001757884 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,397 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00244992 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,397 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,399 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0114, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0294, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:52,399 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,406 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,406 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 4 , message bytes = 139 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,411 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,436 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,439 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@712ca57b,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4564e94b)
INFO    2018-08-08 13:39:52,444 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,462 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave14_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=2, port=30002)
INFO    2018-08-08 13:39:52,476 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,527 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,557 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.151
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.151
INFO    2018-08-08 13:39:52,559 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,561 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,565 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,569 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003174933 secs for 16 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002335413 secs for 12 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001924847 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001382487 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001532049 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,570 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001755801 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001975593 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001503901 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001186049 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001062492 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002013428 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50146.87M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,573 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0849, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.011
INFO    2018-08-08 13:39:52,573 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,581 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,581 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50146.87M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,586 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,610 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,613 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7af1cd63,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4351171a)
INFO    2018-08-08 13:39:52,616 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,616 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,616 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,619 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:52,645 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,695 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,700 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,702 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:54,923 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:54,923 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:39:54,926 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:55,097 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:55,098 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:55,099 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/2_worker
INFO    2018-08-08 13:39:55,101 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30038 closed
INFO    2018-08-08 13:39:55,101 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:55,103 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:55,107 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:59,320 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:59,324 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000002_0 is done. And is in the process of committing
INFO    2018-08-08 13:39:59,348 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000002_0 is allowed to commit now
INFO    2018-08-08 13:39:59,357 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000002_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000002
INFO    2018-08-08 13:39:59,374 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000002_0' done.
INFO    2018-08-08 13:39:59,379 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000002_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=65
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=91
		CPU time spent (ms)=4290
		Physical memory (bytes) snapshot=1105039360
		Virtual memory (bytes) snapshot=58880126976
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000003 on graphalytics-giraph-slave15_37797
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19540
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 796 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 358 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,675.00
               min = 16.00
               max = 6653.00
              mean = 119.44
            stddev = 735.55
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2452.04
              99% <= 6653.00
            99.9% <= 6653.00
             count = 81

  remote-requests:
    count = 0

  requests-received:
             count = 81
         mean rate = 99.92 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 96
         mean rate = 118.60 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,520.00
               min = 16.00
               max = 1473.00
              mean = 47.08
            stddev = 149.11
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 172.04
              99% <= 1473.00
            99.9% <= 1473.00
             count = 96

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 796

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 358

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 86 ms
  compute all partitions: 21 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 258 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 21

  compute-per-partition-ms:
               sum = 67.00
               min = 0.00
               max = 5.00
              mean = 2.03
            stddev = 1.85
            median = 2.00
              75% <= 4.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 64.00
               min = 2.00
               max = 8.00
              mean = 5.82
            stddev = 1.83
            median = 6.00
              75% <= 7.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 1010.11
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 423.31 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 421.88 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 86

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.27
            stddev = 0.47
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 258

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 59 ms
  compute all partitions: 13 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 568 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 13

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.15
            stddev = 0.44
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 4.00
              mean = 0.45
            stddev = 1.21
            median = 0.00
              75% <= 0.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 909.81
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 540.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 541.02 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 59

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 568

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 144 ms
  compute all partitions: 12 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 196 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 12

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.15
            stddev = 0.44
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 3.00
              mean = 0.45
            stddev = 0.93
            median = 0.00
              75% <= 1.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 930.21
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 282.92 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 288.54 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 144

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 196

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 135 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 153 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.12
            stddev = 0.48
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.81
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 904.77
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 303.30 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 303.40 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 135

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 153

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:54 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.2974375147019

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:54 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67418
Log Contents:
2018-08-08 13:39:49,700 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,760 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,760 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,762 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,762 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:49,929 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,147 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,328 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,777 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,789 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:50,926 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:50,941 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:50,970 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:50,970 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:50,978 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:50,984 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:50,984 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 1 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:50,990 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:50,990 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave15
INFO    2018-08-08 13:39:50,990 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:50,990 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:50,990 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:50,990 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000003:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000003/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:50,990 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000003:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:50,990 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000003/tmp
INFO    2018-08-08 13:39:50,990 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:50,990 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:50,990 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:50,991 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:50,991 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:50,991 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:50,991 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000003
INFO    2018-08-08 13:39:50,991 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:51,003 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:51,004 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:51,011 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3003a, negotiated timeout = 40000
INFO    2018-08-08 13:39:51,012 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,120 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,136 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,190 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave15/10.164.0.17:30001 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,195 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,196 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,217 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,227 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,231 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,233 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,239 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave15_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001)
INFO    2018-08-08 13:39:51,653 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,740 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,750 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,750 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,751 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,753 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,754 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,755 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,756 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,756 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,756 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,760 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,767 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,769 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,840 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,892 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043092567 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,892 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.051121384 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,893 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040639143 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,892 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042123154 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,892 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0414456 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,893 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040259812 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,893 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03956484 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,893 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038310193 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,894 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037924033 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,894 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.035114292 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,894 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03723315 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,897 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0034, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.048
MBytes/sec sent = 0.0054, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.048
INFO    2018-08-08 13:39:51,898 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,903 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004010536 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,903 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00290172 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,904 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001311371 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,906 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004193053 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,907 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005789011 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,908 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005270619 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,909 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004575292 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,909 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004516378 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,909 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00356292 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,911 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003933201 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,911 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003212542 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,912 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0092, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0143, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:51,912 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:39:51,941 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,946 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:39:51,947 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50863.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,948 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0011, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.04
MBytes/sec sent = 0.0017, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.04
INFO    2018-08-08 13:39:51,948 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,965 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:51,965 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50863.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,978 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,017 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,021 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5d28bcd5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7882c44a)
WARN    2018-08-08 13:39:52,026 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,042 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,042 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,044 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave15_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001)
INFO    2018-08-08 13:39:52,074 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,074 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,074 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,076 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.111
MBytes/sec sent = 0.0125, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.111
INFO    2018-08-08 13:39:52,081 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,082 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,092 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,107 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003727326 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,107 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01158413 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01304903 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,111 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015055612 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,111 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009543544 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,111 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006829328 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,111 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011125785 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,110 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013131276 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,110 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012283565 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,110 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009846933 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015668197 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50710.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,115 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0055, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.032
MBytes/sec sent = 0.0309, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.032
INFO    2018-08-08 13:39:52,115 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,119 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0397, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.1261, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:52,120 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50710.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,125 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,150 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,152 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@65f00478,outgoing=org.apache.giraph.conf.DefaultMessageClasses@2424686b)
INFO    2018-08-08 13:39:52,161 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,165 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave15_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001)
INFO    2018-08-08 13:39:52,189 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,189 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,189 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,190 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.07
MBytes/sec sent = 0.0198, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.07
INFO    2018-08-08 13:39:52,194 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,196 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,199 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,205 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005378149 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,205 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006277488 secs for 25 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,205 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005037683 secs for 5 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,206 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001445256 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,206 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004027326 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,206 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00503888 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003372626 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002641885 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003930887 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00284939 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003827195 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,213 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0108, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.016
MBytes/sec sent = 0.0566, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.017
INFO    2018-08-08 13:39:52,213 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,219 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,219 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,225 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,250 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,253 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@77bb0ab5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@f2c488)
INFO    2018-08-08 13:39:52,259 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,278 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave15_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001)
INFO    2018-08-08 13:39:52,293 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,343 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,375 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,375 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,375 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,376 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.157
MBytes/sec sent = 0.0089, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.157
INFO    2018-08-08 13:39:52,379 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,380 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,384 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,389 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003203719 secs for 22 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,389 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002793101 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,389 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004511778 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,389 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002319954 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,390 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001725415 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,390 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001580524 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0025643 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00264963 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001676213 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002401434 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,396 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003031941 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,397 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,397 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0108, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.016
MBytes/sec sent = 0.0599, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.016
INFO    2018-08-08 13:39:52,397 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,402 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,403 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,408 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,432 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,435 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@1a1ed4e5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@667e34b1)
INFO    2018-08-08 13:39:52,440 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,457 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave15_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001)
INFO    2018-08-08 13:39:52,471 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,522 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,551 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,552 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,552 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,553 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,557 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,560 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,565 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003562284 secs for 11 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,565 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004535551 secs for 22 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,565 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002815855 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,565 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003346602 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,566 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003081261 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,567 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003199742 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,567 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001383724 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002698874 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003610688 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004019874 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002746235 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,572 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0122, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.014
MBytes/sec sent = 0.0679, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.014
INFO    2018-08-08 13:39:52,572 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,576 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,576 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,581 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,605 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,609 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@381cad29,outgoing=org.apache.giraph.conf.DefaultMessageClasses@988246e)
INFO    2018-08-08 13:39:52,612 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,612 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,612 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,615 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:52,640 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,690 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,695 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,698 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:54,919 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:54,919 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 13:39:54,923 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:54,959 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:54,959 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:54,961 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/1_worker
INFO    2018-08-08 13:39:54,963 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3003a closed
INFO    2018-08-08 13:39:54,963 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:54,965 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:54,970 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:59,184 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:59,190 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000001_0 is done. And is in the process of committing
INFO    2018-08-08 13:39:59,217 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000001_0 is allowed to commit now
INFO    2018-08-08 13:39:59,227 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000001_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000001
INFO    2018-08-08 13:39:59,250 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000001_0' done.
INFO    2018-08-08 13:39:59,256 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000001_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=100
		CPU time spent (ms)=4580
		Physical memory (bytes) snapshot=1094660096
		Virtual memory (bytes) snapshot=58909003776
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000001 on graphalytics-giraph-slave1_33157
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:2275
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/11/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Aug 08, 2018 1:39:45 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver as a provider class
Aug 08, 2018 1:39:45 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
Aug 08, 2018 1:39:45 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices as a root resource class
Aug 08, 2018 1:39:45 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.9 09/02/2011 11:17 AM'
Aug 08, 2018 1:39:45 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
Aug 08, 2018 1:39:45 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
Aug 08, 2018 1:39:46 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices to GuiceManagedComponentProvider with the scope "PerRequest"
log4j:WARN No appenders could be found for logger (org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:117517
Log Contents:
2018-08-08 13:39:43,309 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1533735211869_0005_000001
2018-08-08 13:39:43,525 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens:
2018-08-08 13:39:43,525 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 5 cluster_timestamp: 1533735211869 } attemptId: 1 } keyId: -63235253)
2018-08-08 13:39:43,755 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Using mapred newApiCommitter.
2018-08-08 13:39:43,758 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config null
2018-08-08 13:39:43,852 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:44,365 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is org.apache.giraph.io.internal.WrappedVertexOutputFormat$2
2018-08-08 13:39:44,509 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler
2018-08-08 13:39:44,510 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher
2018-08-08 13:39:44,511 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher
2018-08-08 13:39:44,511 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher
2018-08-08 13:39:44,512 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler
2018-08-08 13:39:44,516 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher
2018-08-08 13:39:44,517 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter
2018-08-08 13:39:44,517 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter
2018-08-08 13:39:44,546 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 13:39:44,563 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 13:39:44,577 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 13:39:44,585 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled
2018-08-08 13:39:44,620 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler
2018-08-08 13:39:44,679 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:44,735 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:44,735 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MRAppMaster metrics system started
2018-08-08 13:39:44,742 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for job_1533735211869_0005 to jobTokenSecretManager
2018-08-08 13:39:44,836 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing job_1533735211869_0005 because: not enabled; too many maps; too much RAM;
2018-08-08 13:39:44,850 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job job_1533735211869_0005 = 0. Number of splits = 14
2018-08-08 13:39:44,850 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job job_1533735211869_0005 = 0
2018-08-08 13:39:44,850 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0005Job Transitioned from NEW to INITED
2018-08-08 13:39:44,851 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job job_1533735211869_0005.
2018-08-08 13:39:44,872 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2018-08-08 13:39:44,880 INFO [Socket Reader #1 for port 33035] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 33035
2018-08-08 13:39:44,918 INFO [main] org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server
2018-08-08 13:39:44,918 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-08-08 13:39:44,919 INFO [IPC Server listener on 33035] org.apache.hadoop.ipc.Server: IPC Server listener on 33035: starting
2018-08-08 13:39:44,920 INFO [main] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at graphalytics-giraph-slave1/10.164.0.3:33035
2018-08-08 13:39:44,976 INFO [main] org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-08-08 13:39:44,982 INFO [main] org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-08-08 13:39:44,985 INFO [main] org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined
2018-08-08 13:39:44,990 INFO [main] org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-08-08 13:39:44,994 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce
2018-08-08 13:39:44,994 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static
2018-08-08 13:39:44,996 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /mapreduce/*
2018-08-08 13:39:44,996 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-08-08 13:39:45,203 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-08-08 13:39:45,205 INFO [main] org.apache.hadoop.http.HttpServer2: Jetty bound to port 36075
2018-08-08 13:39:45,205 INFO [main] org.mortbay.log: jetty-6.1.26
2018-08-08 13:39:45,231 INFO [main] org.mortbay.log: Extract jar:file:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar!/webapps/mapreduce to /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000001/tmp/Jetty_0_0_0_0_36075_mapreduce____.o7al9u/webapp
2018-08-08 13:39:46,095 INFO [main] org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:36075
2018-08-08 13:39:46,095 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Web app mapreduce started at 36075
2018-08-08 13:39:46,098 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: JOB_CREATE job_1533735211869_0005
2018-08-08 13:39:46,100 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 3000
2018-08-08 13:39:46,101 INFO [Socket Reader #1 for port 43583] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 43583
2018-08-08 13:39:46,108 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-08-08 13:39:46,109 INFO [IPC Server listener on 43583] org.apache.hadoop.ipc.Server: IPC Server listener on 43583: starting
2018-08-08 13:39:46,142 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true
2018-08-08 13:39:46,142 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: maxTaskFailuresPerNode is 3
2018-08-08 13:39:46,142 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: blacklistDisablePercent is 33
2018-08-08 13:39:46,174 INFO [main] org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at graphalytics-giraph/10.164.0.2:8030
2018-08-08 13:39:46,232 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: maxContainerCapability: <memory:57344, vCores:32>
2018-08-08 13:39:46,232 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: queue: default
2018-08-08 13:39:46,236 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500
2018-08-08 13:39:46,236 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: The thread pool initial size is 10
2018-08-08 13:39:46,238 INFO [main] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2018-08-08 13:39:46,244 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0005Job Transitioned from INITED to SETUP
2018-08-08 13:39:46,246 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_SETUP
2018-08-08 13:39:46,277 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0005Job Transitioned from SETUP to RUNNING
2018-08-08 13:39:46,292 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000000 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,292 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000001 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,292 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000002 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,292 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000003 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,292 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000004 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,293 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000005 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,293 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000006 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,293 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000007 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,293 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000008 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,293 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000009 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,293 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000010 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,294 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000011 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,294 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000012 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,295 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000013 Task Transitioned from NEW to SCHEDULED
2018-08-08 13:39:46,296 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,296 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000001_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,296 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000002_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,296 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000003_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,297 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000004_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,297 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000005_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,297 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000006_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,297 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000007_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,297 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000008_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,297 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000009_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,297 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000010_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,297 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000011_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,297 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000012_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,298 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000013_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 13:39:46,299 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1533735211869_0005, File: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0005/job_1533735211869_0005_1.jhist
2018-08-08 13:39:46,299 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: mapResourceRequest:<memory:57344, vCores:1>
2018-08-08 13:39:47,235 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:14 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:39:47,264 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1533735211869_0005: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:858112, vCores:1> knownNMs=15
2018-08-08 13:39:48,289 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 14
2018-08-08 13:39:48,290 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave3 to /default-rack
2018-08-08 13:39:48,290 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave15 to /default-rack
2018-08-08 13:39:48,290 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave14 to /default-rack
2018-08-08 13:39:48,291 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave12 to /default-rack
2018-08-08 13:39:48,291 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave11 to /default-rack
2018-08-08 13:39:48,291 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave9 to /default-rack
2018-08-08 13:39:48,291 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave7 to /default-rack
2018-08-08 13:39:48,291 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave5 to /default-rack
2018-08-08 13:39:48,291 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave2 to /default-rack
2018-08-08 13:39:48,291 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave4 to /default-rack
2018-08-08 13:39:48,291 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave8 to /default-rack
2018-08-08 13:39:48,291 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave6 to /default-rack
2018-08-08 13:39:48,291 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave10 to /default-rack
2018-08-08 13:39:48,291 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave13 to /default-rack
2018-08-08 13:39:48,292 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000002 to attempt_1533735211869_0005_m_000000_0
2018-08-08 13:39:48,293 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000003 to attempt_1533735211869_0005_m_000001_0
2018-08-08 13:39:48,293 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000004 to attempt_1533735211869_0005_m_000002_0
2018-08-08 13:39:48,293 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000005 to attempt_1533735211869_0005_m_000003_0
2018-08-08 13:39:48,293 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000006 to attempt_1533735211869_0005_m_000004_0
2018-08-08 13:39:48,293 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000007 to attempt_1533735211869_0005_m_000005_0
2018-08-08 13:39:48,294 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000008 to attempt_1533735211869_0005_m_000006_0
2018-08-08 13:39:48,294 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000009 to attempt_1533735211869_0005_m_000007_0
2018-08-08 13:39:48,294 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000010 to attempt_1533735211869_0005_m_000008_0
2018-08-08 13:39:48,294 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000011 to attempt_1533735211869_0005_m_000009_0
2018-08-08 13:39:48,294 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000012 to attempt_1533735211869_0005_m_000010_0
2018-08-08 13:39:48,294 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000013 to attempt_1533735211869_0005_m_000011_0
2018-08-08 13:39:48,294 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000015 to attempt_1533735211869_0005_m_000012_0
2018-08-08 13:39:48,294 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0005_01_000016 to attempt_1533735211869_0005_m_000013_0
2018-08-08 13:39:48,295 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:14 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:39:48,327 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave3 to /default-rack
2018-08-08 13:39:48,341 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-jar file on the remote FS is hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0005/job.jar
2018-08-08 13:39:48,343 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0005/job.xml
2018-08-08 13:39:48,344 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Adding #0 tokens and #1 secret keys for NM use for launching container
2018-08-08 13:39:48,344 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Size of containertokens_dob is 1
2018-08-08 13:39:48,344 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Putting shuffle token in serviceData
2018-08-08 13:39:48,363 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,365 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave15 to /default-rack
2018-08-08 13:39:48,366 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,366 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave14 to /default-rack
2018-08-08 13:39:48,366 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,367 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave12 to /default-rack
2018-08-08 13:39:48,367 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000003_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,367 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave11 to /default-rack
2018-08-08 13:39:48,367 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000004_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,368 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave9 to /default-rack
2018-08-08 13:39:48,368 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000005_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,368 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave7 to /default-rack
2018-08-08 13:39:48,368 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000006_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,368 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave5 to /default-rack
2018-08-08 13:39:48,369 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000007_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,369 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave2 to /default-rack
2018-08-08 13:39:48,369 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000008_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,369 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave4 to /default-rack
2018-08-08 13:39:48,370 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000009_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,370 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave8 to /default-rack
2018-08-08 13:39:48,371 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000010_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,371 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave6 to /default-rack
2018-08-08 13:39:48,371 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000011_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,372 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave10 to /default-rack
2018-08-08 13:39:48,372 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000012_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,372 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave13 to /default-rack
2018-08-08 13:39:48,372 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000013_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 13:39:48,375 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000002 taskAttempt attempt_1533735211869_0005_m_000000_0
2018-08-08 13:39:48,375 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000003 taskAttempt attempt_1533735211869_0005_m_000001_0
2018-08-08 13:39:48,375 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000004 taskAttempt attempt_1533735211869_0005_m_000002_0
2018-08-08 13:39:48,376 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000005 taskAttempt attempt_1533735211869_0005_m_000003_0
2018-08-08 13:39:48,377 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000007 taskAttempt attempt_1533735211869_0005_m_000005_0
2018-08-08 13:39:48,378 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000006 taskAttempt attempt_1533735211869_0005_m_000004_0
2018-08-08 13:39:48,378 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000008 taskAttempt attempt_1533735211869_0005_m_000006_0
2018-08-08 13:39:48,379 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000010 taskAttempt attempt_1533735211869_0005_m_000008_0
2018-08-08 13:39:48,379 INFO [ContainerLauncher Event Handler] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Setting ContainerLauncher pool size to 21 as number-of-nodes to talk to is 11
2018-08-08 13:39:48,379 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000009 taskAttempt attempt_1533735211869_0005_m_000007_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000011 taskAttempt attempt_1533735211869_0005_m_000009_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000012 taskAttempt attempt_1533735211869_0005_m_000010_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000009_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000001_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000002_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000005_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000000_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000007_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000004_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000013 taskAttempt attempt_1533735211869_0005_m_000011_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000010_0
2018-08-08 13:39:48,381 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000011_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000015 taskAttempt attempt_1533735211869_0005_m_000012_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000003_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000008_0
2018-08-08 13:39:48,380 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000006_0
2018-08-08 13:39:48,381 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000012_0
2018-08-08 13:39:48,382 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave4:46069
2018-08-08 13:39:48,382 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0005_01_000016 taskAttempt attempt_1533735211869_0005_m_000013_0
2018-08-08 13:39:48,382 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0005_m_000013_0
2018-08-08 13:39:48,399 INFO [ContainerLauncher #13] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave13:40615
2018-08-08 13:39:48,401 INFO [ContainerLauncher #12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave10:46663
2018-08-08 13:39:48,403 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave7:43383
2018-08-08 13:39:48,405 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave2:43787
2018-08-08 13:39:48,407 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave12:33893
2018-08-08 13:39:48,408 INFO [ContainerLauncher #11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave6:36387
2018-08-08 13:39:48,410 INFO [ContainerLauncher #10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave8:41519
2018-08-08 13:39:48,410 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave11:46641
2018-08-08 13:39:48,411 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave5:46217
2018-08-08 13:39:48,414 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave3:42077
2018-08-08 13:39:48,417 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave9:37771
2018-08-08 13:39:48,418 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave14:35219
2018-08-08 13:39:48,419 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave15:37797
2018-08-08 13:39:48,493 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000004_0 : 13562
2018-08-08 13:39:48,493 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000002_0 : 13562
2018-08-08 13:39:48,494 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000004_0] using containerId: [container_1533735211869_0005_01_000006 on NM: [graphalytics-giraph-slave11:46641]
2018-08-08 13:39:48,493 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000012_0 : 13562
2018-08-08 13:39:48,493 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000010_0 : 13562
2018-08-08 13:39:48,493 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000007_0 : 13562
2018-08-08 13:39:48,493 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000009_0 : 13562
2018-08-08 13:39:48,493 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000003_0 : 13562
2018-08-08 13:39:48,493 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000008_0 : 13562
2018-08-08 13:39:48,493 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000006_0 : 13562
2018-08-08 13:39:48,493 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000013_0 : 13562
2018-08-08 13:39:48,493 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000001_0 : 13562
2018-08-08 13:39:48,493 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000000_0 : 13562
2018-08-08 13:39:48,493 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000011_0 : 13562
2018-08-08 13:39:48,496 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0005_m_000005_0 : 13562
2018-08-08 13:39:48,497 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000004_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,498 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000002_0] using containerId: [container_1533735211869_0005_01_000004 on NM: [graphalytics-giraph-slave14:35219]
2018-08-08 13:39:48,498 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000002_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,498 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000012_0] using containerId: [container_1533735211869_0005_01_000015 on NM: [graphalytics-giraph-slave10:46663]
2018-08-08 13:39:48,498 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000012_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,498 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000010_0] using containerId: [container_1533735211869_0005_01_000012 on NM: [graphalytics-giraph-slave8:41519]
2018-08-08 13:39:48,499 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000010_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,499 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000007_0] using containerId: [container_1533735211869_0005_01_000009 on NM: [graphalytics-giraph-slave5:46217]
2018-08-08 13:39:48,499 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000007_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,499 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000009_0] using containerId: [container_1533735211869_0005_01_000011 on NM: [graphalytics-giraph-slave4:46069]
2018-08-08 13:39:48,499 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000009_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,499 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000003_0] using containerId: [container_1533735211869_0005_01_000005 on NM: [graphalytics-giraph-slave12:33893]
2018-08-08 13:39:48,499 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000003_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,499 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000008_0] using containerId: [container_1533735211869_0005_01_000010 on NM: [graphalytics-giraph-slave2:43787]
2018-08-08 13:39:48,499 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000008_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,499 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000006_0] using containerId: [container_1533735211869_0005_01_000008 on NM: [graphalytics-giraph-slave7:43383]
2018-08-08 13:39:48,499 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000006_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,500 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000013_0] using containerId: [container_1533735211869_0005_01_000016 on NM: [graphalytics-giraph-slave13:40615]
2018-08-08 13:39:48,500 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000013_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,500 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000001_0] using containerId: [container_1533735211869_0005_01_000003 on NM: [graphalytics-giraph-slave15:37797]
2018-08-08 13:39:48,500 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000001_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,501 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000000_0] using containerId: [container_1533735211869_0005_01_000002 on NM: [graphalytics-giraph-slave3:42077]
2018-08-08 13:39:48,501 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,501 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000011_0] using containerId: [container_1533735211869_0005_01_000013 on NM: [graphalytics-giraph-slave6:36387]
2018-08-08 13:39:48,501 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000011_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,501 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0005_m_000005_0] using containerId: [container_1533735211869_0005_01_000007 on NM: [graphalytics-giraph-slave9:37771]
2018-08-08 13:39:48,501 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000005_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 13:39:48,502 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000004 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,502 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000002 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,502 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000012 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,502 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000010 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,502 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000007 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,502 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000009 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,502 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000003 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,502 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000008 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,502 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000006 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,502 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000013 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,502 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000001 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,503 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000000 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,503 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000011 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:48,503 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000005 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 13:39:49,298 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1533735211869_0005: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:55296, vCores:1> knownNMs=15
2018-08-08 13:39:50,013 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,031 INFO [IPC Server handler 0 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000004 asked for a task
2018-08-08 13:39:50,032 INFO [IPC Server handler 0 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000004 given task: attempt_1533735211869_0005_m_000002_0
2018-08-08 13:39:50,065 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,072 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,075 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,077 INFO [IPC Server handler 1 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000003 asked for a task
2018-08-08 13:39:50,078 INFO [IPC Server handler 1 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000003 given task: attempt_1533735211869_0005_m_000001_0
2018-08-08 13:39:50,084 INFO [IPC Server handler 2 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000012 asked for a task
2018-08-08 13:39:50,085 INFO [IPC Server handler 2 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000012 given task: attempt_1533735211869_0005_m_000010_0
2018-08-08 13:39:50,087 INFO [IPC Server handler 3 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000002 asked for a task
2018-08-08 13:39:50,087 INFO [IPC Server handler 3 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000002 given task: attempt_1533735211869_0005_m_000000_0
2018-08-08 13:39:50,096 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,098 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,108 INFO [IPC Server handler 4 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000010 asked for a task
2018-08-08 13:39:50,108 INFO [IPC Server handler 4 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000010 given task: attempt_1533735211869_0005_m_000008_0
2018-08-08 13:39:50,110 INFO [IPC Server handler 5 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000008 asked for a task
2018-08-08 13:39:50,110 INFO [IPC Server handler 5 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000008 given task: attempt_1533735211869_0005_m_000006_0
2018-08-08 13:39:50,123 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,128 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,134 INFO [IPC Server handler 0 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000007 asked for a task
2018-08-08 13:39:50,135 INFO [IPC Server handler 0 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000007 given task: attempt_1533735211869_0005_m_000005_0
2018-08-08 13:39:50,137 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,139 INFO [IPC Server handler 1 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000013 asked for a task
2018-08-08 13:39:50,139 INFO [IPC Server handler 1 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000013 given task: attempt_1533735211869_0005_m_000011_0
2018-08-08 13:39:50,145 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,148 INFO [IPC Server handler 2 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000009 asked for a task
2018-08-08 13:39:50,148 INFO [IPC Server handler 2 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000009 given task: attempt_1533735211869_0005_m_000007_0
2018-08-08 13:39:50,157 INFO [IPC Server handler 3 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000006 asked for a task
2018-08-08 13:39:50,157 INFO [IPC Server handler 3 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000006 given task: attempt_1533735211869_0005_m_000004_0
2018-08-08 13:39:50,198 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,200 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,209 INFO [IPC Server handler 4 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000005 asked for a task
2018-08-08 13:39:50,209 INFO [IPC Server handler 4 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000005 given task: attempt_1533735211869_0005_m_000003_0
2018-08-08 13:39:50,212 INFO [IPC Server handler 6 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000016 asked for a task
2018-08-08 13:39:50,213 INFO [IPC Server handler 6 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000016 given task: attempt_1533735211869_0005_m_000013_0
2018-08-08 13:39:50,237 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,248 INFO [IPC Server handler 12 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000015 asked for a task
2018-08-08 13:39:50,248 INFO [IPC Server handler 12 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000015 given task: attempt_1533735211869_0005_m_000012_0
2018-08-08 13:39:50,276 INFO [Socket Reader #1 for port 43583] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0005 (auth:SIMPLE)
2018-08-08 13:39:50,289 INFO [IPC Server handler 14 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0005_m_000011 asked for a task
2018-08-08 13:39:50,289 INFO [IPC Server handler 14 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0005_m_000011 given task: attempt_1533735211869_0005_m_000009_0
2018-08-08 13:39:56,682 INFO [IPC Server handler 5 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000002_0 is : 1.0
2018-08-08 13:39:56,750 INFO [IPC Server handler 15 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000010_0 is : 1.0
2018-08-08 13:39:56,777 INFO [IPC Server handler 16 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000001_0 is : 1.0
2018-08-08 13:39:56,809 INFO [IPC Server handler 13 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000000_0 is : 1.0
2018-08-08 13:39:56,831 INFO [IPC Server handler 17 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000005_0 is : 1.0
2018-08-08 13:39:56,838 INFO [IPC Server handler 11 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000008_0 is : 1.0
2018-08-08 13:39:56,840 INFO [IPC Server handler 18 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000006_0 is : 1.0
2018-08-08 13:39:56,855 INFO [IPC Server handler 19 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000011_0 is : 1.0
2018-08-08 13:39:56,865 INFO [IPC Server handler 20 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000004_0 is : 1.0
2018-08-08 13:39:56,867 INFO [IPC Server handler 21 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000007_0 is : 1.0
2018-08-08 13:39:56,915 INFO [IPC Server handler 22 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000013_0 is : 1.0
2018-08-08 13:39:56,926 INFO [IPC Server handler 23 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000012_0 is : 1.0
2018-08-08 13:39:56,951 INFO [IPC Server handler 24 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000003_0 is : 1.0
2018-08-08 13:39:57,022 INFO [IPC Server handler 25 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000009_0 is : 1.0
2018-08-08 13:39:58,985 INFO [IPC Server handler 25 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000013_0 is : 1.0
2018-08-08 13:39:59,008 INFO [IPC Server handler 26 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000013_0
2018-08-08 13:39:59,010 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000013_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,010 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000013_0 given a go for committing the task output.
2018-08-08 13:39:59,012 INFO [IPC Server handler 28 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000013_0
2018-08-08 13:39:59,012 INFO [IPC Server handler 28 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000013_0:true
2018-08-08 13:39:59,037 INFO [IPC Server handler 27 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000013_0 is : 1.0
2018-08-08 13:39:59,039 INFO [IPC Server handler 29 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000013_0
2018-08-08 13:39:59,041 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000013_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:39:59,042 INFO [ContainerLauncher #14] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000016 taskAttempt attempt_1533735211869_0005_m_000013_0
2018-08-08 13:39:59,043 INFO [ContainerLauncher #14] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000013_0
2018-08-08 13:39:59,043 INFO [ContainerLauncher #14] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave13:40615
2018-08-08 13:39:59,062 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000013_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:39:59,071 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000013_0
2018-08-08 13:39:59,072 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000013 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:39:59,076 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 1
2018-08-08 13:39:59,137 INFO [IPC Server handler 0 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000007_0 is : 1.0
2018-08-08 13:39:59,162 INFO [IPC Server handler 4 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000007_0
2018-08-08 13:39:59,165 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000007_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,165 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000007_0 given a go for committing the task output.
2018-08-08 13:39:59,165 INFO [IPC Server handler 6 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000007_0
2018-08-08 13:39:59,165 INFO [IPC Server handler 6 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000007_0:true
2018-08-08 13:39:59,191 INFO [IPC Server handler 12 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000007_0 is : 1.0
2018-08-08 13:39:59,191 INFO [IPC Server handler 14 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000001_0 is : 1.0
2018-08-08 13:39:59,191 INFO [IPC Server handler 10 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000012_0 is : 1.0
2018-08-08 13:39:59,196 INFO [IPC Server handler 5 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000007_0
2018-08-08 13:39:59,197 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000007_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:39:59,198 INFO [ContainerLauncher #15] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000009 taskAttempt attempt_1533735211869_0005_m_000007_0
2018-08-08 13:39:59,198 INFO [ContainerLauncher #15] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000007_0
2018-08-08 13:39:59,198 INFO [ContainerLauncher #15] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave5:46217
2018-08-08 13:39:59,210 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000007_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:39:59,210 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000007_0
2018-08-08 13:39:59,210 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000007 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:39:59,210 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 2
2018-08-08 13:39:59,214 INFO [IPC Server handler 9 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000012_0
2018-08-08 13:39:59,215 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000012_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,215 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000012_0 given a go for committing the task output.
2018-08-08 13:39:59,216 INFO [IPC Server handler 15 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000012_0
2018-08-08 13:39:59,216 INFO [IPC Server handler 15 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000012_0:true
2018-08-08 13:39:59,218 INFO [IPC Server handler 16 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000001_0
2018-08-08 13:39:59,219 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000001_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,219 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000001_0 given a go for committing the task output.
2018-08-08 13:39:59,220 INFO [IPC Server handler 8 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000001_0
2018-08-08 13:39:59,220 INFO [IPC Server handler 8 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000001_0:true
2018-08-08 13:39:59,238 INFO [IPC Server handler 7 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000012_0 is : 1.0
2018-08-08 13:39:59,240 INFO [IPC Server handler 13 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000009_0 is : 1.0
2018-08-08 13:39:59,240 INFO [IPC Server handler 17 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000012_0
2018-08-08 13:39:59,242 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000012_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:39:59,243 INFO [ContainerLauncher #16] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000015 taskAttempt attempt_1533735211869_0005_m_000012_0
2018-08-08 13:39:59,244 INFO [ContainerLauncher #16] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000012_0
2018-08-08 13:39:59,244 INFO [ContainerLauncher #16] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave10:46663
2018-08-08 13:39:59,245 INFO [IPC Server handler 11 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000010_0 is : 1.0
2018-08-08 13:39:59,250 INFO [IPC Server handler 18 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000001_0 is : 1.0
2018-08-08 13:39:59,252 INFO [IPC Server handler 19 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000001_0
2018-08-08 13:39:59,253 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000001_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:39:59,254 INFO [ContainerLauncher #17] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000003 taskAttempt attempt_1533735211869_0005_m_000001_0
2018-08-08 13:39:59,254 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000012_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:39:59,254 INFO [ContainerLauncher #17] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000001_0
2018-08-08 13:39:59,254 INFO [ContainerLauncher #17] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave15:37797
2018-08-08 13:39:59,254 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000012_0
2018-08-08 13:39:59,255 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000012 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:39:59,257 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 3
2018-08-08 13:39:59,264 INFO [IPC Server handler 21 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000009_0
2018-08-08 13:39:59,265 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000009_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,265 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000009_0 given a go for committing the task output.
2018-08-08 13:39:59,266 INFO [IPC Server handler 20 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000010_0
2018-08-08 13:39:59,267 INFO [IPC Server handler 22 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000009_0
2018-08-08 13:39:59,268 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000010_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,268 INFO [IPC Server handler 23 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000010_0
2018-08-08 13:39:59,268 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000001_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:39:59,268 INFO [IPC Server handler 22 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000009_0:true
2018-08-08 13:39:59,268 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000010_0 given a go for committing the task output.
2018-08-08 13:39:59,268 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000001_0
2018-08-08 13:39:59,269 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000001 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:39:59,269 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 4
2018-08-08 13:39:59,293 INFO [IPC Server handler 24 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000009_0 is : 1.0
2018-08-08 13:39:59,295 INFO [IPC Server handler 25 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000009_0
2018-08-08 13:39:59,296 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000009_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:39:59,297 INFO [ContainerLauncher #18] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000011 taskAttempt attempt_1533735211869_0005_m_000009_0
2018-08-08 13:39:59,297 INFO [ContainerLauncher #18] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000009_0
2018-08-08 13:39:59,297 INFO [ContainerLauncher #18] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave4:46069
2018-08-08 13:39:59,308 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000009_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:39:59,308 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000009_0
2018-08-08 13:39:59,309 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000009 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:39:59,309 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 5
2018-08-08 13:39:59,321 INFO [IPC Server handler 26 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000002_0 is : 1.0
2018-08-08 13:39:59,326 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:14 AssignedReds:0 CompletedMaps:5 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:39:59,329 INFO [IPC Server handler 28 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000011_0 is : 1.0
2018-08-08 13:39:59,331 INFO [IPC Server handler 27 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000004_0 is : 1.0
2018-08-08 13:39:59,331 INFO [IPC Server handler 29 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000003_0 is : 1.0
2018-08-08 13:39:59,335 INFO [IPC Server handler 0 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000006_0 is : 1.0
2018-08-08 13:39:59,336 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000016
2018-08-08 13:39:59,336 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000015
2018-08-08 13:39:59,336 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000009
2018-08-08 13:39:59,336 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000003
2018-08-08 13:39:59,336 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000013_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:39:59,336 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:10 AssignedReds:0 CompletedMaps:5 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:39:59,337 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000012_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:39:59,337 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000007_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:39:59,337 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000001_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:39:59,340 INFO [IPC Server handler 1 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000008_0 is : 1.0
2018-08-08 13:39:59,345 INFO [IPC Server handler 2 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000002_0
2018-08-08 13:39:59,345 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000002_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,345 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000002_0 given a go for committing the task output.
2018-08-08 13:39:59,346 INFO [IPC Server handler 3 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000002_0
2018-08-08 13:39:59,346 INFO [IPC Server handler 3 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000002_0:true
2018-08-08 13:39:59,352 INFO [IPC Server handler 4 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000004_0
2018-08-08 13:39:59,352 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000004_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,353 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000004_0 given a go for committing the task output.
2018-08-08 13:39:59,353 INFO [IPC Server handler 6 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000011_0
2018-08-08 13:39:59,353 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000011_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,353 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000011_0 given a go for committing the task output.
2018-08-08 13:39:59,354 INFO [IPC Server handler 12 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000004_0
2018-08-08 13:39:59,354 INFO [IPC Server handler 12 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000004_0:true
2018-08-08 13:39:59,354 INFO [IPC Server handler 14 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000011_0
2018-08-08 13:39:59,354 INFO [IPC Server handler 14 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000011_0:true
2018-08-08 13:39:59,356 INFO [IPC Server handler 10 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000003_0
2018-08-08 13:39:59,357 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000003_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,357 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000003_0 given a go for committing the task output.
2018-08-08 13:39:59,358 INFO [IPC Server handler 5 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000003_0
2018-08-08 13:39:59,358 INFO [IPC Server handler 5 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000003_0:true
2018-08-08 13:39:59,358 INFO [IPC Server handler 5 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000006_0
2018-08-08 13:39:59,358 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000006_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,358 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000006_0 given a go for committing the task output.
2018-08-08 13:39:59,360 INFO [IPC Server handler 15 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000006_0
2018-08-08 13:39:59,360 INFO [IPC Server handler 15 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000006_0:true
2018-08-08 13:39:59,363 INFO [IPC Server handler 16 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000008_0
2018-08-08 13:39:59,363 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000008_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,364 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000008_0 given a go for committing the task output.
2018-08-08 13:39:59,365 INFO [IPC Server handler 8 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000008_0
2018-08-08 13:39:59,365 INFO [IPC Server handler 8 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000008_0:true
2018-08-08 13:39:59,371 INFO [IPC Server handler 7 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000002_0 is : 1.0
2018-08-08 13:39:59,373 INFO [IPC Server handler 17 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000002_0
2018-08-08 13:39:59,373 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000002_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:39:59,374 INFO [ContainerLauncher #19] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000004 taskAttempt attempt_1533735211869_0005_m_000002_0
2018-08-08 13:39:59,374 INFO [ContainerLauncher #19] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000002_0
2018-08-08 13:39:59,374 INFO [ContainerLauncher #19] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave14:35219
2018-08-08 13:39:59,376 INFO [IPC Server handler 13 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000004_0 is : 1.0
2018-08-08 13:39:59,378 INFO [IPC Server handler 11 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000004_0
2018-08-08 13:39:59,378 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000004_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:39:59,378 INFO [IPC Server handler 18 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000011_0 is : 1.0
2018-08-08 13:39:59,378 INFO [ContainerLauncher #20] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000006 taskAttempt attempt_1533735211869_0005_m_000004_0
2018-08-08 13:39:59,379 INFO [ContainerLauncher #20] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000004_0
2018-08-08 13:39:59,379 INFO [ContainerLauncher #20] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave11:46641
2018-08-08 13:39:59,380 INFO [IPC Server handler 19 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000011_0
2018-08-08 13:39:59,380 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000011_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:39:59,382 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000013 taskAttempt attempt_1533735211869_0005_m_000011_0
2018-08-08 13:39:59,383 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000011_0
2018-08-08 13:39:59,383 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave6:36387
2018-08-08 13:39:59,384 INFO [IPC Server handler 21 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000003_0 is : 1.0
2018-08-08 13:39:59,385 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000002_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:39:59,387 INFO [IPC Server handler 22 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000003_0
2018-08-08 13:39:59,387 INFO [IPC Server handler 20 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000006_0 is : 1.0
2018-08-08 13:39:59,387 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000002_0
2018-08-08 13:39:59,387 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000002 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:39:59,387 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 6
2018-08-08 13:39:59,387 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000003_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:39:59,389 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000005 taskAttempt attempt_1533735211869_0005_m_000003_0
2018-08-08 13:39:59,391 INFO [IPC Server handler 23 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000006_0
2018-08-08 13:39:59,392 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000003_0
2018-08-08 13:39:59,392 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000006_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:39:59,392 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave12:33893
2018-08-08 13:39:59,392 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000008 taskAttempt attempt_1533735211869_0005_m_000006_0
2018-08-08 13:39:59,393 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000006_0
2018-08-08 13:39:59,393 INFO [IPC Server handler 24 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000008_0 is : 1.0
2018-08-08 13:39:59,394 INFO [ContainerLauncher #12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave7:43383
2018-08-08 13:39:59,395 INFO [IPC Server handler 25 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000008_0
2018-08-08 13:39:59,395 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000008_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:39:59,395 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000010 taskAttempt attempt_1533735211869_0005_m_000008_0
2018-08-08 13:39:59,396 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000004_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:39:59,396 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000008_0
2018-08-08 13:39:59,396 INFO [ContainerLauncher #10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave2:43787
2018-08-08 13:39:59,396 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000011_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:39:59,397 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000004_0
2018-08-08 13:39:59,397 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000004 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:39:59,397 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000011_0
2018-08-08 13:39:59,397 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000011 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:39:59,397 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 7
2018-08-08 13:39:59,397 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 8
2018-08-08 13:39:59,405 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000003_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:39:59,405 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000003_0
2018-08-08 13:39:59,405 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000003 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:39:59,406 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 9
2018-08-08 13:39:59,406 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000006_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:39:59,406 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000006_0
2018-08-08 13:39:59,406 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000006 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:39:59,406 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 10
2018-08-08 13:39:59,409 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000008_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:39:59,409 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000008_0
2018-08-08 13:39:59,409 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000008 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:39:59,409 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 11
2018-08-08 13:39:59,426 INFO [IPC Server handler 26 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000005_0 is : 1.0
2018-08-08 13:39:59,448 INFO [IPC Server handler 28 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0005_m_000005_0
2018-08-08 13:39:59,449 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000005_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 13:39:59,449 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0005_m_000005_0 given a go for committing the task output.
2018-08-08 13:39:59,450 INFO [IPC Server handler 27 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000005_0
2018-08-08 13:39:59,450 INFO [IPC Server handler 27 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000005_0:true
2018-08-08 13:39:59,475 INFO [IPC Server handler 29 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000005_0 is : 1.0
2018-08-08 13:39:59,477 INFO [IPC Server handler 0 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000005_0
2018-08-08 13:39:59,477 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000005_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:39:59,477 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000007 taskAttempt attempt_1533735211869_0005_m_000005_0
2018-08-08 13:39:59,478 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000005_0
2018-08-08 13:39:59,478 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave9:37771
2018-08-08 13:39:59,487 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000005_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:39:59,487 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000005_0
2018-08-08 13:39:59,487 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000005 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:39:59,487 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 12
2018-08-08 13:39:59,771 INFO [IPC Server handler 1 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000010_0 is : 1.0
2018-08-08 13:39:59,839 INFO [IPC Server handler 2 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000000_0 is : 1.0
2018-08-08 13:40:00,270 INFO [IPC Server handler 3 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0005_m_000010_0
2018-08-08 13:40:00,270 INFO [IPC Server handler 3 on 43583] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0005_m_000010_0:true
2018-08-08 13:40:00,300 INFO [IPC Server handler 4 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000010_0 is : 1.0
2018-08-08 13:40:00,302 INFO [IPC Server handler 6 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000010_0
2018-08-08 13:40:00,302 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000010_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:40:00,303 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000012 taskAttempt attempt_1533735211869_0005_m_000010_0
2018-08-08 13:40:00,303 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000010_0
2018-08-08 13:40:00,303 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave8:41519
2018-08-08 13:40:00,314 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000010_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:40:00,315 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000010_0
2018-08-08 13:40:00,315 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000010 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:40:00,315 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 13
2018-08-08 13:40:00,337 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:10 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:40:00,340 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000004
2018-08-08 13:40:00,340 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000005
2018-08-08 13:40:00,340 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000011
2018-08-08 13:40:00,340 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000006
2018-08-08 13:40:00,340 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000013
2018-08-08 13:40:00,340 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000008
2018-08-08 13:40:00,340 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000010
2018-08-08 13:40:00,340 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000007
2018-08-08 13:40:00,340 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:2 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:40:00,340 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000002_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:40:00,340 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000003_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:40:00,340 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000009_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:40:00,340 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000004_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:40:00,340 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000011_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:40:00,340 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000006_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:40:00,340 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000008_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:40:00,340 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000005_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:40:01,343 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0005_01_000012
2018-08-08 13:40:01,343 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:40:01,344 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0005_m_000010_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 13:40:01,781 INFO [IPC Server handler 2 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000000_0 is : 1.0
2018-08-08 13:40:01,812 INFO [IPC Server handler 9 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0005_m_000000_0 is : 1.0
2018-08-08 13:40:01,814 INFO [IPC Server handler 3 on 43583] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0005_m_000000_0
2018-08-08 13:40:01,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000000_0 TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 13:40:01,814 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0005_01_000002 taskAttempt attempt_1533735211869_0005_m_000000_0
2018-08-08 13:40:01,815 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0005_m_000000_0
2018-08-08 13:40:01,815 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave3:42077
2018-08-08 13:40:01,827 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0005_m_000000_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 13:40:01,827 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0005_m_000000_0
2018-08-08 13:40:01,827 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0005_m_000000 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 13:40:01,827 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 14
2018-08-08 13:40:01,829 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0005Job Transitioned from RUNNING to COMMITTING
2018-08-08 13:40:01,830 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_COMMIT
2018-08-08 13:40:01,974 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Calling handler for JobFinishedEvent 
2018-08-08 13:40:01,975 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0005Job Transitioned from COMMITTING to SUCCEEDED
2018-08-08 13:40:01,976 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: We are finishing cleanly so this is the last retry
2018-08-08 13:40:01,976 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true
2018-08-08 13:40:01,976 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: RMCommunicator notified that shouldUnregistered is: true
2018-08-08 13:40:01,976 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true
2018-08-08 13:40:01,976 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true
2018-08-08 13:40:01,976 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
2018-08-08 13:40:01,977 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0
2018-08-08 13:40:02,112 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0005/job_1533735211869_0005_1.jhist to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0005-1533735581811-hduser-GraphalyticsBenchmark%3A+CommunityDetectionLPJob-1533735601971-14-0-SUCCEEDED-default-1533735586240.jhist_tmp
2018-08-08 13:40:02,210 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0005-1533735581811-hduser-GraphalyticsBenchmark%3A+CommunityDetectionLPJob-1533735601971-14-0-SUCCEEDED-default-1533735586240.jhist_tmp
2018-08-08 13:40:02,214 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0005/job_1533735211869_0005_1_conf.xml to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0005_conf.xml_tmp
2018-08-08 13:40:02,317 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0005_conf.xml_tmp
2018-08-08 13:40:02,323 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0005.summary_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0005.summary
2018-08-08 13:40:02,325 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0005_conf.xml_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0005_conf.xml
2018-08-08 13:40:02,328 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0005-1533735581811-hduser-GraphalyticsBenchmark%3A+CommunityDetectionLPJob-1533735601971-14-0-SUCCEEDED-default-1533735586240.jhist_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0005-1533735581811-hduser-GraphalyticsBenchmark%3A+CommunityDetectionLPJob-1533735601971-14-0-SUCCEEDED-default-1533735586240.jhist
2018-08-08 13:40:02,330 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()
2018-08-08 13:40:02,336 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Setting job diagnostics to 
2018-08-08 13:40:02,338 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: History url is http://graphalytics-giraph-slave1:19888/jobhistory/job/job_1533735211869_0005
2018-08-08 13:40:02,348 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Waiting for application to be successfully unregistered.
2018-08-08 13:40:03,350 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 13:40:03,351 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://graphalytics-giraph:9000 /tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0005
2018-08-08 13:40:03,354 INFO [Thread-94] org.apache.hadoop.ipc.Server: Stopping server on 43583
2018-08-08 13:40:03,356 INFO [IPC Server listener on 43583] org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 43583
2018-08-08 13:40:03,358 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
End of LogType:syslog



Container: container_1533735211869_0005_01_000010 on graphalytics-giraph-slave2_43787
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19543
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 738 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 278 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,775.00
               min = 16.00
               max = 6653.00
              mean = 119.21
            stddev = 731.02
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2344.52
              99% <= 6653.00
            99.9% <= 6653.00
             count = 82

  remote-requests:
    count = 0

  requests-received:
             count = 82
         mean rate = 108.69 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 130.17 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.66
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 738

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 278

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 87 ms
  compute all partitions: 16 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 2742 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 16

  compute-per-partition-ms:
               sum = 50.00
               min = 0.00
               max = 6.00
              mean = 1.52
            stddev = 1.56
            median = 2.00
              75% <= 3.00
              95% <= 3.90
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 50.00
               min = 2.00
               max = 6.00
              mean = 4.55
            stddev = 1.57
            median = 5.00
              75% <= 6.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,789.00
               min = 16.00
               max = 6653.00
              mean = 169.02
            stddev = 970.33
            median = 16.00
              75% <= 80.00
              95% <= 89.00
              98% <= 6259.16
              99% <= 6653.00
            99.9% <= 6653.00
             count = 52

  remote-requests:
    count = 1

  requests-received:
             count = 52
         mean rate = 421.14 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 428.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,664.00
               min = 16.00
               max = 1473.00
              mean = 69.13
            stddev = 198.77
            median = 25.00
              75% <= 71.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 87

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 2742

  worker-context-post-superstep:
    value = 9

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 58 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 210 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 11.00
               min = 0.00
               max = 5.00
              mean = 0.33
            stddev = 0.92
            median = 0.00
              75% <= 0.00
              95% <= 2.20
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 11.00
               min = 0.00
               max = 5.00
              mean = 1.00
            stddev = 1.84
            median = 0.00
              75% <= 2.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,835.00
               min = 16.00
               max = 6653.00
              mean = 166.70
            stddev = 911.27
            median = 16.00
              75% <= 71.00
              95% <= 89.00
              98% <= 6127.88
              99% <= 6653.00
            99.9% <= 6653.00
             count = 53

  remote-requests:
    count = 1

  requests-received:
             count = 53
         mean rate = 561.25 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 54
         mean rate = 571.98 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,680.00
               min = 16.00
               max = 1473.00
              mean = 68.15
            stddev = 196.99
            median = 20.50
              75% <= 62.00
              95% <= 89.00
              98% <= 1334.60
              99% <= 1473.00
            99.9% <= 1473.00
             count = 54

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 58

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 210

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 145 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 365 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 7.00
               min = 0.00
               max = 5.00
              mean = 0.21
            stddev = 0.89
            median = 0.00
              75% <= 0.00
              95% <= 2.20
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 7.00
               min = 0.00
               max = 5.00
              mean = 0.64
            stddev = 1.50
            median = 0.00
              75% <= 1.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,835.00
               min = 16.00
               max = 6653.00
              mean = 166.70
            stddev = 908.59
            median = 16.00
              75% <= 71.00
              95% <= 89.00
              98% <= 6127.88
              99% <= 6653.00
            99.9% <= 6653.00
             count = 53

  remote-requests:
    count = 1

  requests-received:
             count = 53
         mean rate = 292.78 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 54
         mean rate = 298.18 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,680.00
               min = 16.00
               max = 1473.00
              mean = 68.15
            stddev = 197.02
            median = 20.50
              75% <= 62.00
              95% <= 89.00
              98% <= 1334.60
              99% <= 1473.00
            99.9% <= 1473.00
             count = 54

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 145

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 365

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 135 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 166 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.28
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 297.22 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 303.03 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.71
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 135

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 166

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.9566315125375

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67531
Log Contents:
2018-08-08 13:39:49,739 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,802 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,802 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,803 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,804 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:49,971 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,187 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,371 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,838 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,849 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:50,999 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:51,013 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:51,042 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:51,043 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:51,051 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:51,057 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:51,057 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 8 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:51,063 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:51,063 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave2
INFO    2018-08-08 13:39:51,063 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:51,063 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:51,063 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:51,064 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000010:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000010/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:51,064 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000010:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:51,064 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000010/tmp
INFO    2018-08-08 13:39:51,064 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:51,064 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:51,064 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:51,064 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:51,064 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:51,064 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:51,064 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000010
INFO    2018-08-08 13:39:51,065 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:51,078 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:51,079 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:51,085 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3003d, negotiated timeout = 40000
INFO    2018-08-08 13:39:51,086 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,196 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,213 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,252 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave2/10.164.0.4:30008 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,258 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,259 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,281 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,294 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,301 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,304 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,314 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave2_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008)
INFO    2018-08-08 13:39:51,662 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,749 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,760 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,761 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,763 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,767 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,767 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,767 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,767 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,774 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,774 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,776 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,776 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,777 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,781 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,782 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,849 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,901 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05115696 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0447672 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044092737 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04195339 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04343926 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,902 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041550897 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,902 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040719252 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,902 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0398336 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,902 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0393006 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,903 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038870256 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,903 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03872681 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,906 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0028, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.124
MBytes/sec sent = 0.0102, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.124
INFO    2018-08-08 13:39:51,907 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,911 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003862869 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,912 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003185789 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,912 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.79714E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,913 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002605974 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,917 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.007121596 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,917 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005148139 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,917 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004651634 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,918 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004576146 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,918 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004172939 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,919 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003936016 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,919 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003365901 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,920 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.014, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0219, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.011
INFO    2018-08-08 13:39:51,920 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:39:51,948 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,953 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,962 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,964 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,964 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.003, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.055
MBytes/sec sent = 0.0047, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.055
INFO    2018-08-08 13:39:51,964 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,973 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:51,973 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,985 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,024 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,029 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@779dfe55,outgoing=org.apache.giraph.conf.DefaultMessageClasses@323659f8)
WARN    2018-08-08 13:39:52,034 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,047 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,047 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,051 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave2_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008)
INFO    2018-08-08 13:39:52,082 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,082 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,082 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,084 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.111
MBytes/sec sent = 0.0125, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.111
INFO    2018-08-08 13:39:52,088 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,090 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,099 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,113 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005850627 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,113 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006588684 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,113 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008978392 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005544411 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004386461 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012717678 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,113 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010816506 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007878298 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009092835 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003681316 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010916504 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,117 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,119 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0088, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:52,119 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,129 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:52,130 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50582.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,134 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,158 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,160 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@40620d8e)
INFO    2018-08-08 13:39:52,170 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,173 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave2_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008)
INFO    2018-08-08 13:39:52,197 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,197 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,198 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,199 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.068
MBytes/sec sent = 0.0201, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.069
INFO    2018-08-08 13:39:52,203 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,204 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,207 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,212 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003657866 secs for 15 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002493128 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00496223 secs for 16 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002922729 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,214 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004275546 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,214 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001551346 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,214 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006648494 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,215 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002653754 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,215 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003698264 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,216 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002360636 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,217 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003495747 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,218 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50428.39M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,218 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.011, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:39:52,218 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,227 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,228 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50428.39M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,234 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,258 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,260 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7d151a)
INFO    2018-08-08 13:39:52,265 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,288 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave2_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008)
INFO    2018-08-08 13:39:52,301 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,351 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,383 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,383 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,383 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,384 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.156
MBytes/sec sent = 0.0089, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.156
INFO    2018-08-08 13:39:52,387 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,388 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,391 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,396 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001910733 secs for 7 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,396 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002469076 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,396 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00289689 secs for 18 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,396 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001274341 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,397 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001583853 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,398 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001829814 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,398 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001997289 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,399 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001241018 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,399 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006655531 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,399 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001313682 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,401 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002420974 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,401 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,402 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0146, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:39:52,402 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,411 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,411 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50287.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,416 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,440 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,443 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@54534abf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@51745f40)
INFO    2018-08-08 13:39:52,448 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,467 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave2_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008)
INFO    2018-08-08 13:39:52,479 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,530 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,559 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,559 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,559 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,560 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.149
MBytes/sec sent = 0.0094, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.149
INFO    2018-08-08 13:39:52,563 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,566 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,568 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,572 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003396567 secs for 24 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0017046 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002499689 secs for 9 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001662145 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 9.58175E-4 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,574 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001421102 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,575 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001431614 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,575 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001161608 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,576 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 9.83091E-4 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,576 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001209024 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,578 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002635761 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,578 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50146.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,579 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:39:52,579 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,583 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,584 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50146.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,589 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,613 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,616 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@37d00a23)
INFO    2018-08-08 13:39:52,620 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,620 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,620 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,623 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:52,648 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,698 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,703 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,706 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:54,927 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:54,927 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:39:54,930 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:55,119 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:55,120 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:55,121 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/8_worker
INFO    2018-08-08 13:39:55,123 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3003d closed
INFO    2018-08-08 13:39:55,123 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:55,125 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:55,129 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:59,341 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:59,345 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000008_0 is done. And is in the process of committing
INFO    2018-08-08 13:39:59,369 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000008_0 is allowed to commit now
INFO    2018-08-08 13:39:59,378 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000008_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000008
INFO    2018-08-08 13:39:59,399 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000008_0' done.
INFO    2018-08-08 13:39:59,405 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000008_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=95
		CPU time spent (ms)=4910
		Physical memory (bytes) snapshot=1117802496
		Virtual memory (bytes) snapshot=58895503360
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000002 on graphalytics-giraph-slave3_42077
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:08 +0000 2018
LogLength:6755
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
superstep time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave9_5
  largest: 0 ms from graphalytics-giraph-slave9_5
compute all partitions
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave9_5
  largest: 0 ms from graphalytics-giraph-slave9_5
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave9_5
  largest: 0 ms from graphalytics-giraph-slave9_5
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave9_5
  largest: 0 us from graphalytics-giraph-slave9_5
wait requests time
  mean: 317.84615384615387 us
  smallest: 482 us from graphalytics-giraph-slave13_13
  largest: 266 us from graphalytics-giraph-slave9_5
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_5
  largest: 0 bytes from graphalytics-giraph-slave9_5
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_5
  largest: 0 bytes from graphalytics-giraph-slave9_5
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave9_5
  largest: 100.0 % from graphalytics-giraph-slave9_5

--- METRICS: superstep 0 ---
superstep time
  mean: 86.15384615384616 ms
  smallest: 89 ms from graphalytics-giraph-slave13_13
  largest: 83 ms from graphalytics-giraph-slave9_5
compute all partitions
  mean: 17.46153846153846 ms
  smallest: 21 ms from graphalytics-giraph-slave15_1
  largest: 15 ms from graphalytics-giraph-slave14_2
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave9_5
  largest: 0 ms from graphalytics-giraph-slave9_5
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave9_5
  largest: 0 us from graphalytics-giraph-slave9_5
wait requests time
  mean: 2564.0 us
  smallest: 7970 us from graphalytics-giraph-slave12_3
  largest: 239 us from graphalytics-giraph-slave10_12
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_5
  largest: 0 bytes from graphalytics-giraph-slave9_5
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_5
  largest: 0 bytes from graphalytics-giraph-slave9_5
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave9_5
  largest: 100.0 % from graphalytics-giraph-slave9_5

--- METRICS: superstep 1 ---
superstep time
  mean: 58.61538461538461 ms
  smallest: 60 ms from graphalytics-giraph-slave9_5
  largest: 56 ms from graphalytics-giraph-slave4_9
compute all partitions
  mean: 9.846153846153847 ms
  smallest: 16 ms from graphalytics-giraph-slave4_9
  largest: 6 ms from graphalytics-giraph-slave10_12
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave9_5
  largest: 0 ms from graphalytics-giraph-slave9_5
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave9_5
  largest: 0 us from graphalytics-giraph-slave9_5
wait requests time
  mean: 922.9230769230769 us
  smallest: 4385 us from graphalytics-giraph-slave9_5
  largest: 156 us from graphalytics-giraph-slave12_3
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_5
  largest: 0 bytes from graphalytics-giraph-slave9_5
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_5
  largest: 0 bytes from graphalytics-giraph-slave9_5
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave9_5
  largest: 100.0 % from graphalytics-giraph-slave9_5

--- METRICS: superstep 2 ---
superstep time
  mean: 143.15384615384616 ms
  smallest: 145 ms from graphalytics-giraph-slave2_8
  largest: 140 ms from graphalytics-giraph-slave12_3
compute all partitions
  mean: 10.23076923076923 ms
  smallest: 14 ms from graphalytics-giraph-slave4_9
  largest: 6 ms from graphalytics-giraph-slave8_10
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave9_5
  largest: 0 ms from graphalytics-giraph-slave9_5
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave9_5
  largest: 0 us from graphalytics-giraph-slave9_5
wait requests time
  mean: 525.0769230769231 us
  smallest: 1561 us from graphalytics-giraph-slave12_3
  largest: 154 us from graphalytics-giraph-slave13_13
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_5
  largest: 0 bytes from graphalytics-giraph-slave9_5
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_5
  largest: 0 bytes from graphalytics-giraph-slave9_5
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave9_5
  largest: 100.0 % from graphalytics-giraph-slave9_5

--- METRICS: superstep 3 ---
superstep time
  mean: 135.6153846153846 ms
  smallest: 137 ms from graphalytics-giraph-slave14_2
  largest: 134 ms from graphalytics-giraph-slave6_11
compute all partitions
  mean: 8.461538461538462 ms
  smallest: 12 ms from graphalytics-giraph-slave6_11
  largest: 6 ms from graphalytics-giraph-slave5_7
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave9_5
  largest: 0 ms from graphalytics-giraph-slave9_5
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave9_5
  largest: 0 us from graphalytics-giraph-slave9_5
wait requests time
  mean: 177.76923076923077 us
  smallest: 232 us from graphalytics-giraph-slave7_6
  largest: 151 us from graphalytics-giraph-slave10_12
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_5
  largest: 0 bytes from graphalytics-giraph-slave9_5
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave9_5
  largest: 0 bytes from graphalytics-giraph-slave9_5
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave9_5
  largest: 100.0 % from graphalytics-giraph-slave9_5
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:08 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:08 +0000 2018
LogLength:55639
Log Contents:
2018-08-08 13:39:49,706 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,771 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,771 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,772 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,773 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:49,944 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,162 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,354 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,819 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,830 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:50,978 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:50,992 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:51,021 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:51,021 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceMaster (master thread)...
INFO    2018-08-08 13:39:51,029 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:51,036 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:51,036 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 0 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:51,041 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave3
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000002:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000002/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000002:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000002/tmp
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:51,042 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000002
INFO    2018-08-08 13:39:51,043 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.master.BspServiceMaster@780ec4a5
INFO    2018-08-08 13:39:51,056 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:51,057 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:51,064 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3003b, negotiated timeout = 40000
INFO    2018-08-08 13:39:51,065 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,073 [main] org.apache.giraph.graph.GraphTaskManager  - map: No need to do anything when not a worker
INFO    2018-08-08 13:39:51,074 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for MASTER_ONLY
INFO    2018-08-08 13:39:51,102 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - becomeMaster: First child is '/_hadoopBsp/job_1533735211869_0005/_masterElectionDir/graphalytics-giraph-slave3_00000000000' and my bid is '/_hadoopBsp/job_1533735211869_0005/_masterElectionDir/graphalytics-giraph-slave3_00000000000'
INFO    2018-08-08 13:39:51,126 [main-EventThread] org.apache.giraph.bsp.BspService  - process: applicationAttemptChanged signaled
INFO    2018-08-08 13:39:51,215 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,234 [org.apache.giraph.master.MasterThread] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,286 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave3/10.164.0.5:30000 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,292 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,293 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,296 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - becomeMaster: I am now the master!
INFO    2018-08-08 13:39:51,298 [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,574 [org.apache.giraph.master.MasterThread] org.apache.giraph.io.formats.GiraphFileInputFormat  - Total input paths to process : 1
INFO    2018-08-08 13:39:51,589 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - generateVERTEXInputSplits: Got 1 input splits for 143 input threads
WARN    2018-08-08 13:39:51,589 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - createVERTEXInputSplits: Number of inputSplits=1 < 143=total number of input threads, some threads will be not used
INFO    2018-08-08 13:39:51,609 [org.apache.giraph.master.MasterThread] org.apache.giraph.io.formats.GiraphFileInputFormat  - Total input paths to process : 1
INFO    2018-08-08 13:39:51,613 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - generateEDGEInputSplits: Got 1 input splits for 143 input threads
WARN    2018-08-08 13:39:51,613 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - createEDGEInputSplits: Number of inputSplits=1 < 143=total number of input threads, some threads will be not used
INFO    2018-08-08 13:39:51,645 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,646 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,647 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,647 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,649 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,649 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,649 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,649 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,649 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,650 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,650 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,650 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,650 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,654 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,654 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - computePartitionCount: Creating 429 partitions.
INFO    2018-08-08 13:39:51,671 [org.apache.giraph.master.MasterThread] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.timeout is deprecated. Instead, use mapreduce.task.timeout
INFO    2018-08-08 13:39:51,672 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep -1 on path /_hadoopBsp/job_1533735211869_0005/_inputSplitsWorkerDoneDir
INFO    2018-08-08 13:39:51,756 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,774 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,774 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,784 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,865 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0008, ave received req MBytes = 0.0002, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,945 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep -1 on path /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerFinishedDir
INFO    2018-08-08 13:39:52,015 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) on superstep = -1
INFO    2018-08-08 13:39:52,020 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep -1 took 0.407 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 0
WARN    2018-08-08 13:39:52,029 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,067 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,068 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:39:52,070 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=7, port=30007):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=6, port=30006):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=5, port=30005):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=2, port=30002):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004):(v=1, e=4),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=3, port=30003):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=10, port=30010):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=11, port=30011):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009):(v=1, e=1),]
INFO    2018-08-08 13:39:52,070 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009) - 1
INFO    2018-08-08 13:39:52,070 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 1, Min: Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012) - 0, Max: Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004) - 4
INFO    2018-08-08 13:39:52,076 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 0 on path /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerFinishedDir
INFO    2018-08-08 13:39:52,149 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) on superstep = 0
INFO    2018-08-08 13:39:52,153 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 0 took 0.133 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 1
INFO    2018-08-08 13:39:52,187 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,187 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:39:52,187 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=7, port=30007):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=6, port=30006):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=5, port=30005):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004):(v=1, e=4),Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=2, port=30002):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=3, port=30003):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=10, port=30010):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=11, port=30011):(v=1, e=0),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009):(v=1, e=1),]
INFO    2018-08-08 13:39:52,187 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009) - 1
INFO    2018-08-08 13:39:52,187 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 1, Min: Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012) - 0, Max: Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004) - 4
INFO    2018-08-08 13:39:52,193 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 1 on path /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerFinishedDir
INFO    2018-08-08 13:39:52,249 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) on superstep = 1
INFO    2018-08-08 13:39:52,253 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0
INFO    2018-08-08 13:39:52,348 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 1 took 0.195 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 2
INFO    2018-08-08 13:39:52,373 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,373 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:39:52,373 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=7, port=30007):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=6, port=30006):(v=1, e=5),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=5, port=30005):(v=1, e=5),Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=2, port=30002):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004):(v=1, e=5),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=3, port=30003):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=10, port=30010):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=11, port=30011):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009):(v=1, e=3),]
INFO    2018-08-08 13:39:52,373 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009) - 1
INFO    2018-08-08 13:39:52,373 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 2, Min: Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012) - 0, Max: Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004) - 5
INFO    2018-08-08 13:39:52,379 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 2 on path /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerFinishedDir
INFO    2018-08-08 13:39:52,429 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) on superstep = 2
INFO    2018-08-08 13:39:52,435 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1
INFO    2018-08-08 13:39:52,527 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 2 took 0.179 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 3
INFO    2018-08-08 13:39:52,549 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,549 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 13:39:52,550 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=7, port=30007):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=6, port=30006):(v=1, e=5),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=8, port=30008):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=5, port=30005):(v=1, e=5),Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave14 hostOrIp=graphalytics-giraph-slave14, MRtaskID=2, port=30002):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004):(v=1, e=5),Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=3, port=30003):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=10, port=30010):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=11, port=30011):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009):(v=1, e=3),]
INFO    2018-08-08 13:39:52,550 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009) - 1
INFO    2018-08-08 13:39:52,550 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 2, Min: Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=12, port=30012) - 0, Max: Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=4, port=30004) - 5
INFO    2018-08-08 13:39:52,567 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 3 on path /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerFinishedDir
INFO    2018-08-08 13:39:52,606 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) on superstep = 3
INFO    2018-08-08 13:39:52,608 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2
INFO    2018-08-08 13:39:52,695 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 3 took 0.168 seconds ended with state ALL_SUPERSTEPS_DONE and is now on superstep 4
INFO    2018-08-08 13:39:52,696 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - setJobState: {"_applicationAttemptKey":-1,"_stateKey":"FINISHED","_superstepKey":-1} on superstep 4
INFO    2018-08-08 13:39:52,699 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - setJobState: {"_applicationAttemptKey":-1,"_stateKey":"FINISHED","_superstepKey":-1}
INFO    2018-08-08 13:39:52,706 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/0_master
INFO    2018-08-08 13:39:52,708 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Node /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir already exists, no need to create.
INFO    2018-08-08 13:39:52,709 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 1 of 14 desired children from /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir
INFO    2018-08-08 13:39:52,709 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir to change since only got 1 nodes.
INFO    2018-08-08 13:39:54,762 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:39:54,764 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 2 of 14 desired children from /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir
INFO    2018-08-08 13:39:54,764 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir to change since only got 2 nodes.
INFO    2018-08-08 13:39:54,915 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:39:54,917 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 3 of 14 desired children from /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir
INFO    2018-08-08 13:39:54,917 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir to change since only got 3 nodes.
INFO    2018-08-08 13:39:54,964 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:39:54,966 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 5 of 14 desired children from /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir
INFO    2018-08-08 13:39:54,966 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir to change since only got 5 nodes.
INFO    2018-08-08 13:39:55,014 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:39:55,016 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 6 of 14 desired children from /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir
INFO    2018-08-08 13:39:55,016 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir to change since only got 6 nodes.
INFO    2018-08-08 13:39:55,022 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:39:55,023 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 7 of 14 desired children from /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir
INFO    2018-08-08 13:39:55,023 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir to change since only got 7 nodes.
INFO    2018-08-08 13:39:55,098 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:39:55,100 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 8 of 14 desired children from /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir
INFO    2018-08-08 13:39:55,100 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir to change since only got 8 nodes.
INFO    2018-08-08 13:39:55,106 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:39:55,108 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 11 of 14 desired children from /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir
INFO    2018-08-08 13:39:55,108 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir to change since only got 11 nodes.
INFO    2018-08-08 13:39:55,109 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:39:55,111 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 12 of 14 desired children from /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir
INFO    2018-08-08 13:39:55,111 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir to change since only got 12 nodes.
INFO    2018-08-08 13:39:55,117 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:39:55,119 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 13 of 14 desired children from /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir
INFO    2018-08-08 13:39:55,119 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir to change since only got 13 nodes.
INFO    2018-08-08 13:39:55,202 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:39:55,204 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 14 of 14 desired children from /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir
INFO    2018-08-08 13:39:55,204 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanupZooKeeper: Removing the following path and all children - /_hadoopBsp/job_1533735211869_0005 from ZooKeeper list graphalytics-giraph:2181
INFO    2018-08-08 13:39:55,294 [main-EventThread] org.apache.giraph.bsp.BspService  - process: masterElectionChildrenChanged signaled
INFO    2018-08-08 13:39:55,302 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 13:39:55,349 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanup: Removed HDFS checkpoint directory (_bsp/_checkpoints//job_1533735211869_0005) with return = false since the job GraphalyticsBenchmark: CommunityDetectionLPJob succeeded 
INFO    2018-08-08 13:39:55,350 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:55,353 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:57,558 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:57,558 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:57,561 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:40:01,774 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:40:01,777 [org.apache.giraph.master.MasterThread] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3003b closed
INFO    2018-08-08 13:40:01,777 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:40:01,777 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - setup: Took 0.067 seconds.
INFO    2018-08-08 13:40:01,777 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - input superstep: Took 0.407 seconds.
INFO    2018-08-08 13:40:01,777 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 0: Took 0.133 seconds.
INFO    2018-08-08 13:40:01,777 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 1: Took 0.195 seconds.
INFO    2018-08-08 13:40:01,777 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 2: Took 0.179 seconds.
INFO    2018-08-08 13:40:01,777 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 3: Took 0.168 seconds.
INFO    2018-08-08 13:40:01,778 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - shutdown: Took 9.083 seconds.
INFO    2018-08-08 13:40:01,778 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - total: Took 10.232 seconds.
INFO    2018-08-08 13:40:01,778 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Joined with master thread
INFO    2018-08-08 13:40:01,782 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000000_0 is done. And is in the process of committing
INFO    2018-08-08 13:40:01,814 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000000_0' done.
INFO    2018-08-08 13:40:01,819 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000000_0: Counters: 49
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=87
		CPU time spent (ms)=4910
		Physical memory (bytes) snapshot=1094070272
		Virtual memory (bytes) snapshot=58938998784
		Total committed heap usage (bytes)=55163486208
	Giraph Stats
		Aggregate bytes loaded from local disks (out-of-core)=0
		Aggregate bytes stored to local disks (out-of-core)=0
		Aggregate edges=30
		Aggregate finished vertices=10
		Aggregate sent message bytes=3285
		Aggregate sent messages=85
		Aggregate vertices=10
		Current master task partition=0
		Current workers=13
		Last checkpointed superstep=0
		Lowest percentage of graph in memory so far (out-of-core)=100
		Sent message bytes=0
		Sent messages=0
		Superstep=4
	Giraph Timers
		Initialize (ms)=473
		Input superstep (ms)=407
		Setup (ms)=67
		Shutdown (ms)=9082
		Superstep 0 DirectedCommunityDetectionLPComputation (ms)=133
		Superstep 1 DirectedCommunityDetectionLPComputation (ms)=195
		Superstep 2 DirectedCommunityDetectionLPComputation (ms)=179
		Superstep 3 DirectedCommunityDetectionLPComputation (ms)=168
		Total (ms)=10232
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000011 on graphalytics-giraph-slave4_46069
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19550
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 511 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 309 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,775.00
               min = 16.00
               max = 6653.00
              mean = 112.36
            stddev = 709.93
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1691.72
              99% <= 6653.00
            99.9% <= 6653.00
             count = 87

  remote-requests:
    count = 0

  requests-received:
             count = 87
         mean rate = 165.06 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 186.36 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.66
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 511

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 309

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 84 ms
  compute all partitions: 18 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 534 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 18

  compute-per-partition-ms:
               sum = 63.00
               min = 0.00
               max = 6.00
              mean = 1.91
            stddev = 1.84
            median = 2.00
              75% <= 3.00
              95% <= 4.60
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 59.00
               min = 2.00
               max = 7.00
              mean = 5.36
            stddev = 1.57
            median = 6.00
              75% <= 6.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 8,881.00
               min = 16.00
               max = 6653.00
              mean = 164.46
            stddev = 901.33
            median = 31.00
              75% <= 62.00
              95% <= 89.00
              98% <= 5996.60
              99% <= 6653.00
            99.9% <= 6653.00
             count = 54

  remote-requests:
    count = 1

  requests-received:
             count = 54
         mean rate = 447.89 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 55
         mean rate = 454.41 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,696.00
               min = 16.00
               max = 1473.00
              mean = 67.20
            stddev = 195.32
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1306.92
              99% <= 1473.00
            99.9% <= 1473.00
             count = 55

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 84

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.36
            stddev = 0.50
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 534

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 56 ms
  compute all partitions: 16 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 181 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 16

  compute-per-partition-ms:
               sum = 12.00
               min = 0.00
               max = 8.00
              mean = 0.36
            stddev = 1.41
            median = 0.00
              75% <= 0.00
              95% <= 3.10
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 123

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 12.00
               min = 0.00
               max = 8.00
              mean = 1.09
            stddev = 2.47
            median = 0.00
              75% <= 1.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 8,959.00
               min = 16.00
               max = 6653.00
              mean = 157.18
            stddev = 876.24
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5602.76
              99% <= 6653.00
            99.9% <= 6653.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 584.77 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 595.64 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,804.00
               min = 16.00
               max = 1473.00
              mean = 65.59
            stddev = 190.28
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 56

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 181

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 141 ms
  compute all partitions: 14 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 215 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 14

  compute-per-partition-ms:
               sum = 18.00
               min = 0.00
               max = 7.00
              mean = 0.55
            stddev = 1.42
            median = 0.00
              75% <= 0.00
              95% <= 4.20
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 123

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 18.00
               min = 0.00
               max = 7.00
              mean = 1.64
            stddev = 2.46
            median = 0.00
              75% <= 4.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 8,959.00
               min = 16.00
               max = 6653.00
              mean = 157.18
            stddev = 877.09
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5602.76
              99% <= 6653.00
            99.9% <= 6653.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 320.51 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 326.37 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,804.00
               min = 16.00
               max = 1473.00
              mean = 65.59
            stddev = 190.26
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 141

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 215

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 135 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 196 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.25
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 297.94 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 303.68 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.70
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 135

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 196

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.95680163956617

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67577
Log Contents:
2018-08-08 13:39:49,869 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,939 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,939 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,941 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,941 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:50,130 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,361 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,561 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:51,031 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:51,045 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:51,204 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:51,219 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:51,248 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:51,249 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:51,257 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:51,264 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:51,264 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 9 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:51,270 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:51,270 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave4
INFO    2018-08-08 13:39:51,270 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:51,270 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:51,270 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:51,270 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000011:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000011/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:51,271 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000011:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:51,271 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000011/tmp
INFO    2018-08-08 13:39:51,271 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:51,271 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:51,271 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:51,271 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:51,271 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:51,271 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:51,271 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000011
INFO    2018-08-08 13:39:51,271 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:51,285 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:51,285 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:51,292 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30045, negotiated timeout = 40000
INFO    2018-08-08 13:39:51,293 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,411 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,429 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,476 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave4/10.164.0.6:30009 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,480 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,481 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,504 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,515 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,518 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,521 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,528 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave4_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009)
INFO    2018-08-08 13:39:51,656 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,746 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,754 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,756 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,758 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,760 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,760 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,767 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,773 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,779 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,782 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,851 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,900 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041081943 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048803568 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042130142 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040569432 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039945792 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039181292 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038692504 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,902 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03805301 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,903 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038603276 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,904 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038561653 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,904 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0383698 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,906 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0035, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.048
MBytes/sec sent = 0.0054, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.048
INFO    2018-08-08 13:39:51,907 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,913 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005025531 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,914 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004367022 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,915 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004294914 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,916 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003480748 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,917 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00424068 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,919 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00138755 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,919 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003041035 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,920 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005167233 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,922 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003570028 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,924 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004613654 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,925 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004284024 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,926 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0065, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0102, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 13:39:51,926 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:39:51,942 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,948 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,957 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,958 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,959 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0012, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.039
MBytes/sec sent = 0.0018, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.039
INFO    2018-08-08 13:39:51,959 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,965 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0331, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.1051, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:39:51,965 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,978 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,018 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,023 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@779dfe55,outgoing=org.apache.giraph.conf.DefaultMessageClasses@323659f8)
WARN    2018-08-08 13:39:52,027 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,044 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,045 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,047 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave4_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009)
INFO    2018-08-08 13:39:52,075 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,075 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,076 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,077 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.111
MBytes/sec sent = 0.0125, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.111
INFO    2018-08-08 13:39:52,082 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,083 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,093 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,108 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007248356 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006122695 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00669542 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012078818 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008029918 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012213069 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013537237 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004975439 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009334248 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011336947 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012194708 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,111 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,112 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0146, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,112 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,122 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:39:52,123 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50582.09M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,127 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,151 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,153 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@40620d8e)
INFO    2018-08-08 13:39:52,164 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,167 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave4_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009)
INFO    2018-08-08 13:39:52,191 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,191 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,191 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,192 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.069
MBytes/sec sent = 0.0201, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.069
INFO    2018-08-08 13:39:52,197 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,198 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,200 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,206 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005605107 secs for 23 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,206 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004218031 secs for 9 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005085367 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005095712 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003355974 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004455034 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,211 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00199638 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,211 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010037541 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,216 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00587629 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,216 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005599875 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,217 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005505091 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,217 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,217 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0219, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:39:52,217 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,220 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0496, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.1576, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:39:52,220 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 3 , message bytes = 123 , Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,226 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,251 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,254 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7d151a)
INFO    2018-08-08 13:39:52,263 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,284 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave4_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009)
INFO    2018-08-08 13:39:52,294 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,344 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,376 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,376 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,377 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,377 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.157
MBytes/sec sent = 0.0089, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.157
INFO    2018-08-08 13:39:52,380 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,381 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,385 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,392 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005307329 secs for 14 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005870663 secs for 11 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00453253 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006282217 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00825219 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001855096 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006144656 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003011521 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,396 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002255112 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,398 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004169012 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,400 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003335137 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,400 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,400 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0065, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0188, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 13:39:52,400 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,403 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0496, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.1576, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:39:52,404 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 3 , message bytes = 123 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,409 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,433 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,436 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@54534abf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@51745f40)
INFO    2018-08-08 13:39:52,442 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,461 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave4_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=9, port=30009)
INFO    2018-08-08 13:39:52,472 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,523 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,552 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,553 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,553 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,554 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.149
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:39:52,557 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,559 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,562 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,566 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003123994 secs for 10 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,566 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002043024 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,566 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002731928 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,566 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003920699 secs for 19 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001549851 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001230504 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003869405 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,570 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002537303 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,570 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002091496 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002673413 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,574 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003071392 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,574 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50146.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,574 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 13:39:52,574 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,577 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0496, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.1576, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:39:52,577 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50146.88M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,582 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,607 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,610 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@37d00a23)
INFO    2018-08-08 13:39:52,614 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,614 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,614 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,617 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:52,641 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,691 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,697 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,700 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:54,821 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:54,821 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:39:54,825 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:55,009 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:55,009 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:55,011 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/9_worker
INFO    2018-08-08 13:39:55,013 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30045 closed
INFO    2018-08-08 13:39:55,013 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:55,016 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:55,020 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:59,234 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:59,240 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000009_0 is done. And is in the process of committing
INFO    2018-08-08 13:39:59,266 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000009_0 is allowed to commit now
INFO    2018-08-08 13:39:59,275 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000009_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000009
INFO    2018-08-08 13:39:59,293 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000009_0' done.
INFO    2018-08-08 13:39:59,298 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000009_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=97
		CPU time spent (ms)=5210
		Physical memory (bytes) snapshot=1145307136
		Virtual memory (bytes) snapshot=58936012800
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000009 on graphalytics-giraph-slave5_46217
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19548
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 693 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 390 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,792.00
               min = 16.00
               max = 6653.00
              mean = 116.57
            stddev = 722.32
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 2065.90
              99% <= 6653.00
            99.9% <= 6653.00
             count = 84

  remote-requests:
    count = 0

  requests-received:
             count = 84
         mean rate = 118.73 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 138.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.66
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 693

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 390

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 88 ms
  compute all partitions: 18 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1655 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 18

  compute-per-partition-ms:
               sum = 57.00
               min = 0.00
               max = 6.00
              mean = 1.73
            stddev = 1.58
            median = 2.00
              75% <= 3.00
              95% <= 3.90
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 82

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 57.00
               min = 2.00
               max = 6.00
              mean = 5.18
            stddev = 1.25
            median = 6.00
              75% <= 6.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,805.00
               min = 16.00
               max = 6653.00
              mean = 166.13
            stddev = 925.99
            median = 16.00
              75% <= 71.00
              95% <= 89.00
              98% <= 6127.88
              99% <= 6653.00
            99.9% <= 6653.00
             count = 53

  remote-requests:
    count = 2

  requests-received:
             count = 53
         mean rate = 423.57 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 54
         mean rate = 431.59 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,710.00
               min = 16.00
               max = 1473.00
              mean = 68.70
            stddev = 196.94
            median = 35.50
              75% <= 62.00
              95% <= 89.00
              98% <= 1334.60
              99% <= 1473.00
            99.9% <= 1473.00
             count = 54

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 88

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1655

  worker-context-post-superstep:
    value = 6

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 57 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 201 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 10.00
               min = 0.00
               max = 4.00
              mean = 0.30
            stddev = 0.77
            median = 0.00
              75% <= 0.00
              95% <= 1.90
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 82

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 10.00
               min = 0.00
               max = 4.00
              mean = 0.91
            stddev = 1.45
            median = 0.00
              75% <= 2.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,897.00
               min = 16.00
               max = 6653.00
              mean = 161.76
            stddev = 892.44
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5865.32
              99% <= 6653.00
            99.9% <= 6653.00
             count = 55

  remote-requests:
    count = 2

  requests-received:
             count = 55
         mean rate = 571.81 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 582.08 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,742.00
               min = 16.00
               max = 1473.00
              mean = 66.82
            stddev = 193.55
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 57

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 201

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 144 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1198 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 4.00
              mean = 0.15
            stddev = 0.71
            median = 0.00
              75% <= 0.00
              95% <= 1.90
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 82

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 4.00
              mean = 0.45
            stddev = 1.21
            median = 0.00
              75% <= 0.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,897.00
               min = 16.00
               max = 6653.00
              mean = 161.76
            stddev = 896.42
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5865.32
              99% <= 6653.00
            99.9% <= 6653.00
             count = 55

  remote-requests:
    count = 2

  requests-received:
             count = 55
         mean rate = 306.58 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 311.97 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,742.00
               min = 16.00
               max = 1473.00
              mean = 66.82
            stddev = 193.55
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 144

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1198

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 136 ms
  compute all partitions: 6 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 197 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 6

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.16
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 297.70 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 303.54 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.71
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 136

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 197

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:54 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.95663116448117

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:54 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67548
Log Contents:
2018-08-08 13:39:49,760 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,827 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,828 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,830 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,830 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:50,007 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,222 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,405 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,878 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,889 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:51,036 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:51,051 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:51,079 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:51,080 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:51,087 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:51,094 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:51,094 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 7 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave5
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000009:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000009/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000009:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000009/tmp
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:51,100 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000009
INFO    2018-08-08 13:39:51,101 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:51,113 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:51,114 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:51,120 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30040, negotiated timeout = 40000
INFO    2018-08-08 13:39:51,121 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,231 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,248 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,298 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave5/10.164.0.7:30007 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,303 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,304 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,324 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,334 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,337 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,340 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,348 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave5_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=7, port=30007)
INFO    2018-08-08 13:39:51,658 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,743 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,752 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,754 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,755 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,756 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,758 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,768 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,774 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,782 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,841 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,885 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04380101 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,897 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048787344 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,897 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047969293 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,898 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047668677 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,898 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047349587 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,898 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046765447 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,898 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04611662 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,899 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046047483 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,899 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045632266 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04512717 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04476426 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0032, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.052
MBytes/sec sent = 0.0049, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.053
INFO    2018-08-08 13:39:51,902 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,906 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001210537 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,907 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 7.47103E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,908 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005216878 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,908 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002632543 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,910 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005354476 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,912 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004730889 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,912 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004313106 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,913 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005038024 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,915 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005808859 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,915 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005019573 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,916 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004365372 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,916 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0129, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0202, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.012
INFO    2018-08-08 13:39:51,917 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:39:51,944 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,948 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,956 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,958 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,958 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.054
MBytes/sec sent = 0.0048, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.054
INFO    2018-08-08 13:39:51,958 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,968 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:51,968 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,980 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,020 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,025 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@779dfe55,outgoing=org.apache.giraph.conf.DefaultMessageClasses@323659f8)
WARN    2018-08-08 13:39:52,030 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,042 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,042 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,046 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave5_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=7, port=30007)
INFO    2018-08-08 13:39:52,077 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,078 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,078 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,080 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.111
MBytes/sec sent = 0.0125, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.112
INFO    2018-08-08 13:39:52,084 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,085 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,094 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,108 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005399999 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008112117 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010448425 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00500688 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012328648 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007365054 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005985233 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00878845 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006721713 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010764194 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009291894 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,113 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,115 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0146, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:39:52,115 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,125 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:52,126 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 2 , message bytes = 82 , Memory (free/total/max) = 50582.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,129 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,154 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,156 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@40620d8e)
INFO    2018-08-08 13:39:52,166 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,169 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave5_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=7, port=30007)
INFO    2018-08-08 13:39:52,193 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,193 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,193 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,194 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.068
MBytes/sec sent = 0.0204, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.068
INFO    2018-08-08 13:39:52,199 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,200 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,203 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,208 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004028301 secs for 15 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002848932 secs for 11 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003542808 secs for 6 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002594992 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001495887 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006312667 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002052224 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003238892 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004343417 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003500501 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004279656 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,214 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50441.19M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,214 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0175, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:52,214 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,223 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,223 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 2 , message bytes = 82 , Memory (free/total/max) = 50428.39M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,230 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,253 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,256 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7d151a)
INFO    2018-08-08 13:39:52,263 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,283 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave5_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=7, port=30007)
INFO    2018-08-08 13:39:52,296 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,347 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,380 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,380 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,380 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,381 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.158
MBytes/sec sent = 0.0088, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.158
INFO    2018-08-08 13:39:52,384 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,384 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,388 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,393 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001241167 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002502385 secs for 21 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002008346 secs for 9 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001842933 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001423216 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00192037 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,396 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001235219 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,397 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007468356 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,398 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003152401 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,398 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002678564 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,399 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002765622 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,399 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,400 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0102, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0292, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,400 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,406 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,407 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 2 , message bytes = 82 , Memory (free/total/max) = 50287.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,412 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,435 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,438 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@54534abf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@51745f40)
INFO    2018-08-08 13:39:52,444 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,462 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave5_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=7, port=30007)
INFO    2018-08-08 13:39:52,474 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,526 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,555 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,557 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:39:52,559 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,560 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,564 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,567 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003016085 secs for 19 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,567 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002230119 secs for 11 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,567 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001707658 secs for 3 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001748682 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001232849 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001393447 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001242152 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001294172 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00289266 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,570 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 9.07537E-4 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,570 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001027362 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50146.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,571 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0166, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0926, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.01
INFO    2018-08-08 13:39:52,571 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,579 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,580 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50146.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,585 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,609 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,612 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@37d00a23)
INFO    2018-08-08 13:39:52,615 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,615 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,615 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,619 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:52,643 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,694 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,699 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,702 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:54,723 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:54,724 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:39:54,727 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:54,913 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:54,913 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:54,915 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/7_worker
INFO    2018-08-08 13:39:54,917 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30040 closed
INFO    2018-08-08 13:39:54,917 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:54,919 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:54,923 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:59,134 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:59,138 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000007_0 is done. And is in the process of committing
INFO    2018-08-08 13:39:59,165 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000007_0 is allowed to commit now
INFO    2018-08-08 13:39:59,175 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000007_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000007
INFO    2018-08-08 13:39:59,196 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000007_0' done.
INFO    2018-08-08 13:39:59,201 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000007_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=89
		CPU time spent (ms)=4720
		Physical memory (bytes) snapshot=1108283392
		Virtual memory (bytes) snapshot=58881138688
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000013 on graphalytics-giraph-slave6_36387
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19550
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 715 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 283 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,729.00
               min = 16.00
               max = 6653.00
              mean = 114.46
            stddev = 718.16
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1934.84
              99% <= 6653.00
            99.9% <= 6653.00
             count = 85

  remote-requests:
    count = 0

  requests-received:
             count = 85
         mean rate = 116.66 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 97
         mean rate = 133.33 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,536.00
               min = 16.00
               max = 1473.00
              mean = 46.76
            stddev = 148.40
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 144.36
              99% <= 1473.00
            99.9% <= 1473.00
             count = 97

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 715

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 283

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 88 ms
  compute all partitions: 19 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 499 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 19

  compute-per-partition-ms:
               sum = 60.00
               min = 0.00
               max = 5.00
              mean = 1.82
            stddev = 1.60
            median = 2.00
              75% <= 3.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 60.00
               min = 4.00
               max = 6.00
              mean = 5.45
            stddev = 0.69
            median = 6.00
              75% <= 6.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,865.00
               min = 16.00
               max = 6653.00
              mean = 167.26
            stddev = 910.31
            median = 46.00
              75% <= 71.00
              95% <= 89.00
              98% <= 6127.88
              99% <= 6653.00
            99.9% <= 6653.00
             count = 53

  remote-requests:
    count = 0

  requests-received:
             count = 53
         mean rate = 431.22 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 54
         mean rate = 439.19 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,650.00
               min = 16.00
               max = 1473.00
              mean = 67.59
            stddev = 197.17
            median = 16.00
              75% <= 62.00
              95% <= 89.00
              98% <= 1334.60
              99% <= 1473.00
            99.9% <= 1473.00
             count = 54

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 88

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 499

  worker-context-post-superstep:
    value = 11

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 60 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1183 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 13.00
               min = 0.00
               max = 8.00
              mean = 0.39
            stddev = 1.41
            median = 0.00
              75% <= 0.00
              95% <= 3.10
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 82

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 13.00
               min = 0.00
               max = 8.00
              mean = 1.18
            stddev = 2.48
            median = 0.00
              75% <= 2.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 8,897.00
               min = 16.00
               max = 6653.00
              mean = 161.76
            stddev = 1110.18
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5865.32
              99% <= 6653.00
            99.9% <= 6653.00
             count = 55

  remote-requests:
    count = 2

  requests-received:
             count = 55
         mean rate = 564.49 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 574.68 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,742.00
               min = 16.00
               max = 1473.00
              mean = 66.82
            stddev = 193.55
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 60

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1183

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 143 ms
  compute all partitions: 12 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 236 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 12

  compute-per-partition-ms:
               sum = 11.00
               min = 0.00
               max = 6.00
              mean = 0.33
            stddev = 1.08
            median = 0.00
              75% <= 0.00
              95% <= 2.50
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 82

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 11.00
               min = 0.00
               max = 7.00
              mean = 1.00
            stddev = 2.14
            median = 0.00
              75% <= 2.00
              95% <= 7.00
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 11

  received-bytes:
               sum = 8,897.00
               min = 16.00
               max = 6653.00
              mean = 161.76
            stddev = 892.39
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5865.32
              99% <= 6653.00
            99.9% <= 6653.00
             count = 55

  remote-requests:
    count = 2

  requests-received:
             count = 55
         mean rate = 306.50 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 312.05 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,742.00
               min = 16.00
               max = 1473.00
              mean = 66.82
            stddev = 193.55
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 143

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 236

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 134 ms
  compute all partitions: 12 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 195 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 12

  compute-per-partition-ms:
               sum = 7.00
               min = 0.00
               max = 2.00
              mean = 0.21
            stddev = 0.55
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 7.00
               min = 0.00
               max = 3.00
              mean = 0.64
            stddev = 1.21
            median = 0.00
              75% <= 1.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 974.56
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 300.03 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 305.94 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 134

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 195

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.2244407069074

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67420
Log Contents:
2018-08-08 13:39:49,763 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,827 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,827 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,829 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,829 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:50,001 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,217 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,401 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,867 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,879 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:51,023 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:51,038 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:51,065 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:51,066 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:51,073 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:51,080 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:51,080 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 11 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:51,085 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:51,085 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave6
INFO    2018-08-08 13:39:51,085 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:51,085 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:51,085 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:51,085 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000013:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000013/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:51,086 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000013:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:51,086 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000013/tmp
INFO    2018-08-08 13:39:51,086 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:51,086 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:51,086 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:51,086 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:51,086 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:51,086 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:51,086 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000013
INFO    2018-08-08 13:39:51,086 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:51,098 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:51,099 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:51,105 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3003f, negotiated timeout = 40000
INFO    2018-08-08 13:39:51,106 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,212 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,229 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,278 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave6/10.164.0.8:30011 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,283 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,284 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,305 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,315 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,318 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,321 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,327 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave6_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=11, port=30011)
INFO    2018-08-08 13:39:51,661 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,746 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,756 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,758 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,759 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,767 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,768 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,775 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,776 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,777 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,777 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,785 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,845 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,905 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05167175 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,905 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.052740887 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,905 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050236743 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,905 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050904326 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,905 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05943617 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,906 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04986895 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,906 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.049258552 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,906 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04832497 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,907 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047703456 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,907 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047459166 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,908 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04691278 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,910 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0026, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.135
MBytes/sec sent = 0.0094, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.135
INFO    2018-08-08 13:39:51,910 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,915 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004157696 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,916 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003291964 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,916 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002621209 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,917 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003040956 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,918 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003395807 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,918 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00300902 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,919 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00317067 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,919 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002921365 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,920 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003317462 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,921 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003258375 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,922 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003823002 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,924 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0129, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0202, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.012
INFO    2018-08-08 13:39:51,924 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:39:51,947 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,951 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:39:51,953 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50863.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,953 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.004, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.041
MBytes/sec sent = 0.0062, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.041
INFO    2018-08-08 13:39:51,953 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,971 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:51,971 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50863.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,983 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,023 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,028 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@79b663b3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1b812421)
WARN    2018-08-08 13:39:52,033 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,048 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,048 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,051 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave6_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=11, port=30011)
INFO    2018-08-08 13:39:52,083 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,083 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,083 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,084 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.113
MBytes/sec sent = 0.0123, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.113
INFO    2018-08-08 13:39:52,087 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,088 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,097 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,112 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013405202 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011105029 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00845287 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,113 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009526491 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012459254 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007392589 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010027019 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011832546 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008425168 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007779158 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007140675 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,117 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,117 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0063, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.028
MBytes/sec sent = 0.0351, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.028
INFO    2018-08-08 13:39:52,117 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,128 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:52,129 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,132 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,157 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,158 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:39:52,167 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,171 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave6_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=11, port=30011)
INFO    2018-08-08 13:39:52,196 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,196 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,196 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,197 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.068
MBytes/sec sent = 0.0204, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.068
INFO    2018-08-08 13:39:52,202 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,203 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,206 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,211 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003833111 secs for 18 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,211 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002489848 secs for 12 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,211 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002228541 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,211 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002027066 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001630251 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001947834 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002318 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,214 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001884497 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,214 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001244859 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,215 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001983095 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,217 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009375882 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,218 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,219 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0102, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0292, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,219 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,226 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,226 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 2 , message bytes = 82 , Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,233 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,256 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,259 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:39:52,266 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,285 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave6_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=11, port=30011)
INFO    2018-08-08 13:39:52,300 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,350 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,383 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,383 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,383 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,384 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.158
MBytes/sec sent = 0.0088, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.158
INFO    2018-08-08 13:39:52,387 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,387 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,390 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,395 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003134299 secs for 15 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002806619 secs for 13 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,396 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002508289 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,397 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003525972 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,397 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002842084 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,399 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002313353 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,399 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002079817 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,399 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008775652 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,401 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001433661 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,402 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002327228 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,401 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002556708 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,403 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,403 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0175, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:52,403 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,409 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,409 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 2 , message bytes = 82 , Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,415 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,438 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,442 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@27abb83e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@69e308c6)
INFO    2018-08-08 13:39:52,448 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,466 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave6_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=11, port=30011)
INFO    2018-08-08 13:39:52,477 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,529 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,558 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,559 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,559 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,560 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.151
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.151
INFO    2018-08-08 13:39:52,562 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,564 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,567 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,572 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003100215 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004368063 secs for 14 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004889073 secs for 15 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003958672 secs for 4 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,574 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003725871 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,574 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001759789 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,576 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002582549 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,576 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002528293 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,576 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002210983 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,577 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001762312 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,579 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002959149 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,580 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50287.67M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,580 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0108, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.016
MBytes/sec sent = 0.0599, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.016
INFO    2018-08-08 13:39:52,580 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,582 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0661, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.2101, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,583 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.67M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,588 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,612 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,615 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@89c65d5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@faa3fed)
INFO    2018-08-08 13:39:52,618 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,618 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,618 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,620 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:52,646 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,697 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,702 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,705 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:54,925 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:54,925 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:39:54,928 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:55,107 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:55,108 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:55,109 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/11_worker
INFO    2018-08-08 13:39:55,112 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3003f closed
INFO    2018-08-08 13:39:55,112 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:55,114 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:55,118 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:59,330 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:59,334 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000011_0 is done. And is in the process of committing
INFO    2018-08-08 13:39:59,357 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000011_0 is allowed to commit now
INFO    2018-08-08 13:39:59,366 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000011_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000011
INFO    2018-08-08 13:39:59,383 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000011_0' done.
INFO    2018-08-08 13:39:59,389 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000011_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128858
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=5
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=97
		CPU time spent (ms)=4730
		Physical memory (bytes) snapshot=1099677696
		Virtual memory (bytes) snapshot=58878439424
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000008 on graphalytics-giraph-slave7_43383
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19548
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 721 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 268 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,809.00
               min = 16.00
               max = 6653.00
              mean = 114.06
            stddev = 714.12
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1822.28
              99% <= 6653.00
            99.9% <= 6653.00
             count = 86

  remote-requests:
    count = 0

  requests-received:
             count = 86
         mean rate = 116.74 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 133.19 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.67
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 721

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 268

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 83 ms
  compute all partitions: 19 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1852 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 19

  compute-per-partition-ms:
               sum = 63.00
               min = 0.00
               max = 7.00
              mean = 1.91
            stddev = 1.84
            median = 3.00
              75% <= 3.00
              95% <= 6.30
              98% <= 7.00
              99% <= 7.00
            99.9% <= 7.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 123

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 61.00
               min = 3.00
               max = 9.00
              mean = 5.55
            stddev = 1.51
            median = 6.00
              75% <= 6.00
              95% <= 9.00
              98% <= 9.00
              99% <= 9.00
            99.9% <= 9.00
             count = 11

  received-bytes:
               sum = 8,959.00
               min = 16.00
               max = 6653.00
              mean = 157.18
            stddev = 876.58
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5602.76
              99% <= 6653.00
            99.9% <= 6653.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 479.77 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 488.11 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,804.00
               min = 16.00
               max = 1473.00
              mean = 65.59
            stddev = 190.33
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 83

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 1852

  worker-context-post-superstep:
    value = 10

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 59 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 373 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 9.00
               min = 0.00
               max = 6.00
              mean = 0.27
            stddev = 1.07
            median = 0.00
              75% <= 0.00
              95% <= 2.50
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 221

  messages-sent:
    count = 6

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 9.00
               min = 0.00
               max = 6.00
              mean = 0.82
            stddev = 1.83
            median = 0.00
              75% <= 1.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 9,099.00
               min = 16.00
               max = 6653.00
              mean = 149.16
            stddev = 865.22
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5077.64
              99% <= 6653.00
            99.9% <= 6653.00
             count = 61

  remote-requests:
    count = 5

  requests-received:
             count = 61
         mean rate = 631.08 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 62
         mean rate = 641.39 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 5

  sent-bytes:
               sum = 3,944.00
               min = 16.00
               max = 1473.00
              mean = 63.61
            stddev = 184.16
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1113.16
              99% <= 1473.00
            99.9% <= 1473.00
             count = 62

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 59

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 5

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 373

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 143 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 172 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 6.00
               min = 0.00
               max = 2.00
              mean = 0.18
            stddev = 0.46
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 221

  messages-sent:
    count = 6

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 6.00
               min = 0.00
               max = 2.00
              mean = 0.55
            stddev = 0.82
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 9,099.00
               min = 16.00
               max = 6653.00
              mean = 149.16
            stddev = 891.38
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5077.64
              99% <= 6653.00
            99.9% <= 6653.00
             count = 61

  remote-requests:
    count = 5

  requests-received:
             count = 61
         mean rate = 336.51 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 62
         mean rate = 341.99 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 5

  sent-bytes:
               sum = 3,944.00
               min = 16.00
               max = 1473.00
              mean = 63.61
            stddev = 184.16
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1113.16
              99% <= 1473.00
            99.9% <= 1473.00
             count = 62

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 143

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 5

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 172

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 135 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 232 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.16
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 300.10 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 305.97 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.68
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 135

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 232

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.95663117898351

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67564
Log Contents:
2018-08-08 13:39:49,721 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,783 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,783 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,785 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,785 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:49,959 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,184 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,383 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,845 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,856 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:51,003 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:51,018 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:51,047 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:51,048 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:51,055 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:51,062 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:51,062 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 6 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:51,068 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:51,068 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave7
INFO    2018-08-08 13:39:51,068 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:51,068 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:51,068 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:51,068 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000008:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000008/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:51,069 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000008:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:51,069 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000008/tmp
INFO    2018-08-08 13:39:51,069 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:51,069 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:51,069 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:51,069 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:51,069 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:51,069 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:51,069 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000008
INFO    2018-08-08 13:39:51,069 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:51,083 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:51,083 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:51,090 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3003e, negotiated timeout = 40000
INFO    2018-08-08 13:39:51,092 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,202 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,219 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,268 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave7/10.164.0.9:30006 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,273 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,274 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,297 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,307 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,310 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,313 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,319 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave7_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=6, port=30006)
INFO    2018-08-08 13:39:51,657 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,744 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,755 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,756 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,759 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,767 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,770 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,773 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,773 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,774 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,774 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,777 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,779 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,842 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,895 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.052979216 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,895 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04625141 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,896 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04522655 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,896 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044456072 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,896 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043819003 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,896 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043132227 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,897 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043033853 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,898 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043140527 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,898 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042227704 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,898 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04270511 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,898 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04126937 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0033, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.05
MBytes/sec sent = 0.0051, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.05
INFO    2018-08-08 13:39:51,901 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,906 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00420202 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,906 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002929296 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,907 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002466772 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,908 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002385558 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,909 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003271719 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,910 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003470772 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,913 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005249167 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,913 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004977084 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,914 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002959604 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,914 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004109343 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,914 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004393898 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,916 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0129, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0202, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.012
INFO    2018-08-08 13:39:51,916 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:39:51,944 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,948 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,956 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,958 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,958 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.054
MBytes/sec sent = 0.0048, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.054
INFO    2018-08-08 13:39:51,958 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,968 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:51,968 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.80M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,980 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,020 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,025 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@779dfe55,outgoing=org.apache.giraph.conf.DefaultMessageClasses@323659f8)
WARN    2018-08-08 13:39:52,030 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,047 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,047 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,050 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave7_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=6, port=30006)
INFO    2018-08-08 13:39:52,080 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,080 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,081 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,082 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.114
MBytes/sec sent = 0.0122, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.114
INFO    2018-08-08 13:39:52,084 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,085 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,094 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,109 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005368081 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006537708 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012976892 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,110 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012432369 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011636557 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005982611 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008156681 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009653635 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007315145 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010861961 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017707856 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,116 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0219, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 13:39:52,116 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,124 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 13:39:52,125 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 3 , message bytes = 123 , Memory (free/total/max) = 50582.00M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,129 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,153 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,156 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@40620d8e)
INFO    2018-08-08 13:39:52,165 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,169 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave7_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=6, port=30006)
INFO    2018-08-08 13:39:52,193 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,194 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,194 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,195 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.07
MBytes/sec sent = 0.0198, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.07
INFO    2018-08-08 13:39:52,199 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,200 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,202 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,207 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002550336 secs for 6 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,207 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003029797 secs for 14 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003697592 secs for 12 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002251913 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002095973 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,208 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001574393 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001493032 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002091812 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007492238 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001292691 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003275987 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50428.39M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,214 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0469, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:52,214 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,223 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,223 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 6 , message bytes = 221 , Memory (free/total/max) = 50428.39M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,230 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,253 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,256 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7d151a)
INFO    2018-08-08 13:39:52,262 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,283 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave7_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=6, port=30006)
INFO    2018-08-08 13:39:52,296 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,347 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,378 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,379 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,379 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,380 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.157
MBytes/sec sent = 0.0089, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.157
INFO    2018-08-08 13:39:52,382 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,384 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,387 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,392 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003262078 secs for 21 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002117772 secs for 9 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001509354 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001469494 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00323878 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,392 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004854289 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001050944 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002143537 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001454168 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,398 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002802189 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,399 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003146282 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,399 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,400 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0095, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.0293, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 13:39:52,400 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,405 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,405 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 6 , message bytes = 221 , Memory (free/total/max) = 50287.59M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,411 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,435 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,439 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@54534abf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@51745f40)
INFO    2018-08-08 13:39:52,445 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,463 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave7_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=6, port=30006)
INFO    2018-08-08 13:39:52,474 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,525 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,555 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,555 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,555 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.151
MBytes/sec sent = 0.0092, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.151
INFO    2018-08-08 13:39:52,559 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,560 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,564 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,568 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002576481 secs for 13 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003393829 secs for 20 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002313126 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002087207 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,570 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003481631 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00395437 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003443353 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003935436 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003462595 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003497712 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003236675 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50146.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,573 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 13:39:52,573 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,579 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,579 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50146.79M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,587 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,609 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,612 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@37d00a23)
INFO    2018-08-08 13:39:52,615 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,615 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,615 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,617 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:52,643 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,693 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,699 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,702 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:54,921 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:54,922 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:39:54,926 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:55,105 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:55,105 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:55,107 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/6_worker
INFO    2018-08-08 13:39:55,109 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3003e closed
INFO    2018-08-08 13:39:55,109 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:55,111 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:55,115 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:59,328 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:59,335 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000006_0 is done. And is in the process of committing
INFO    2018-08-08 13:39:59,360 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000006_0 is allowed to commit now
INFO    2018-08-08 13:39:59,370 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000006_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000006
INFO    2018-08-08 13:39:59,392 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000006_0' done.
INFO    2018-08-08 13:39:59,398 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000006_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=100
		CPU time spent (ms)=4810
		Physical memory (bytes) snapshot=1075200000
		Virtual memory (bytes) snapshot=58878132224
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000012 on graphalytics-giraph-slave8_41519
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19541
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 836 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 270 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,775.00
               min = 16.00
               max = 6653.00
              mean = 130.33
            stddev = 764.26
            median = 25.00
              75% <= 54.00
              95% <= 91.20
              98% <= 3323.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 75

  remote-requests:
    count = 0

  requests-received:
             count = 75
         mean rate = 88.29 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 115.50 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.69
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 836

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 270

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 87 ms
  compute all partitions: 16 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 4124 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 16

  compute-per-partition-ms:
               sum = 53.00
               min = 0.00
               max = 5.00
              mean = 1.61
            stddev = 1.33
            median = 2.00
              75% <= 2.00
              95% <= 4.30
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 53.00
               min = 4.00
               max = 5.00
              mean = 4.82
            stddev = 0.40
            median = 5.00
              75% <= 5.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,789.00
               min = 16.00
               max = 6653.00
              mean = 169.02
            stddev = 917.30
            median = 16.00
              75% <= 80.00
              95% <= 89.00
              98% <= 6259.16
              99% <= 6653.00
            99.9% <= 6653.00
             count = 52

  remote-requests:
    count = 1

  requests-received:
             count = 52
         mean rate = 421.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 429.73 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,664.00
               min = 16.00
               max = 1473.00
              mean = 69.13
            stddev = 198.77
            median = 25.00
              75% <= 71.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 87

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 4124

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 60 ms
  compute all partitions: 6 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 772 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 6

  compute-per-partition-ms:
               sum = 8.00
               min = 0.00
               max = 4.00
              mean = 0.24
            stddev = 0.75
            median = 0.00
              75% <= 0.00
              95% <= 1.90
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 8.00
               min = 0.00
               max = 5.00
              mean = 0.73
            stddev = 1.49
            median = 0.00
              75% <= 1.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,835.00
               min = 16.00
               max = 6653.00
              mean = 166.70
            stddev = 909.82
            median = 16.00
              75% <= 71.00
              95% <= 89.00
              98% <= 6127.88
              99% <= 6653.00
            99.9% <= 6653.00
             count = 53

  remote-requests:
    count = 1

  requests-received:
             count = 53
         mean rate = 544.80 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 54
         mean rate = 555.07 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,680.00
               min = 16.00
               max = 1473.00
              mean = 68.15
            stddev = 197.02
            median = 20.50
              75% <= 62.00
              95% <= 89.00
              98% <= 1334.60
              99% <= 1473.00
            99.9% <= 1473.00
             count = 54

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 60

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 772

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 144 ms
  compute all partitions: 6 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1313 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 6

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 4.00
              mean = 0.15
            stddev = 0.71
            median = 0.00
              75% <= 0.00
              95% <= 1.90
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 41

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 4.00
              mean = 0.45
            stddev = 1.21
            median = 0.00
              75% <= 0.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,835.00
               min = 16.00
               max = 6653.00
              mean = 166.70
            stddev = 908.84
            median = 16.00
              75% <= 71.00
              95% <= 89.00
              98% <= 6127.88
              99% <= 6653.00
            99.9% <= 6653.00
             count = 53

  remote-requests:
    count = 1

  requests-received:
             count = 53
         mean rate = 295.44 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 54
         mean rate = 301.00 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,680.00
               min = 16.00
               max = 1473.00
              mean = 68.15
            stddev = 197.02
            median = 20.50
              75% <= 62.00
              95% <= 89.00
              98% <= 1334.60
              99% <= 1473.00
            99.9% <= 1473.00
             count = 54

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 144

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1313

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 136 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 161 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.97
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 296.44 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 302.25 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.71
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 136

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 161

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 94.95680017482916

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67539
Log Contents:
2018-08-08 13:39:49,725 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,783 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,783 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,785 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,785 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:49,948 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,154 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,323 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,752 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,763 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:50,904 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:50,917 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:50,944 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:50,944 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:50,952 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:50,958 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:50,958 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 10 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:50,963 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave8
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000012:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000012/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000012:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000012/tmp
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:50,964 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000012
INFO    2018-08-08 13:39:50,965 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:50,977 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:50,977 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:50,984 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30039, negotiated timeout = 40000
INFO    2018-08-08 13:39:50,985 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,091 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,108 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,158 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave8/10.164.0.10:30010 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,162 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,163 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,182 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,192 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,195 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,197 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,203 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave8_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=10, port=30010)
INFO    2018-08-08 13:39:51,658 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,743 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,751 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,752 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,754 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,755 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,755 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,755 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,758 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,758 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,762 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,764 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,766 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,771 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,772 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,775 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,776 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,776 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,776 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,777 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,778 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,842 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,900 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05739659 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.051852494 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05119166 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05069494 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.050168015 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04964143 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,901 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04911136 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,902 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048529644 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,902 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048122313 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,902 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047749095 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,902 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047279704 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,904 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.003, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.055
MBytes/sec sent = 0.0047, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.055
INFO    2018-08-08 13:39:51,905 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,909 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003117754 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,910 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 9.66518E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,910 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002790808 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,911 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002620954 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,914 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006099004 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,915 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.007875274 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,915 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00511905 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,915 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004694825 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,915 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004342247 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,916 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004321518 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,916 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004118187 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,917 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0168, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0238, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.01
INFO    2018-08-08 13:39:51,917 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 13:39:51,945 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,949 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,956 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 13:39:51,957 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,958 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0033, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.051
MBytes/sec sent = 0.005, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.051
INFO    2018-08-08 13:39:51,958 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,969 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:51,970 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,981 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,021 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,026 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@779dfe55,outgoing=org.apache.giraph.conf.DefaultMessageClasses@323659f8)
WARN    2018-08-08 13:39:52,031 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,042 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,042 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,046 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave8_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=10, port=30010)
INFO    2018-08-08 13:39:52,081 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,081 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,081 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,082 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.112
MBytes/sec sent = 0.0124, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.112
INFO    2018-08-08 13:39:52,085 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,086 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,094 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,108 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008698435 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007613946 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009832094 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01046625 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012086036 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007312602 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009636818 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006439437 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008464131 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,108 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006901614 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,109 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006309579 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,116 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0019, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.0055, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 13:39:52,116 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,124 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,125 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,129 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,155 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,156 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4c060c8f,outgoing=org.apache.giraph.conf.DefaultMessageClasses@40620d8e)
INFO    2018-08-08 13:39:52,164 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,169 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave8_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=10, port=30010)
INFO    2018-08-08 13:39:52,194 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,195 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,195 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,196 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.071
MBytes/sec sent = 0.0195, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.071
INFO    2018-08-08 13:39:52,200 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,201 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,205 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,209 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00176654 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002459179 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,209 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001475416 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00305617 secs for 18 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002623399 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001691299 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,210 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001663356 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002378932 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002011422 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006053597 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001716461 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,213 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0219, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,213 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,224 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,224 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,229 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,254 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,257 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3b8ee898,outgoing=org.apache.giraph.conf.DefaultMessageClasses@7d151a)
INFO    2018-08-08 13:39:52,263 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,283 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave8_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=10, port=30010)
INFO    2018-08-08 13:39:52,298 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,348 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,380 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,380 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,380 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,382 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.158
MBytes/sec sent = 0.0088, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.158
INFO    2018-08-08 13:39:52,385 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,385 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,388 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,392 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002561949 secs for 17 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001481576 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002026048 secs for 9 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00146444 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,393 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001104778 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001498216 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00126182 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001117394 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001993008 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006340215 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001747109 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,396 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,397 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0146, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,397 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,407 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,407 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 1 , message bytes = 41 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,412 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,436 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,439 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@54534abf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@51745f40)
INFO    2018-08-08 13:39:52,444 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,462 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave8_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=10, port=30010)
INFO    2018-08-08 13:39:52,475 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,527 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,556 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,557 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:39:52,560 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,561 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,565 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,568 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002486425 secs for 19 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001846668 secs for 12 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001559454 secs for 2 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,568 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00132588 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001135869 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001736791 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002706833 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00277296 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002685782 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003287895 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003066786 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50146.87M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,573 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0849, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.011
INFO    2018-08-08 13:39:52,573 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,580 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,580 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50146.87M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,585 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,610 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,613 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@3c2772d1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@37d00a23)
INFO    2018-08-08 13:39:52,616 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,616 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,616 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,619 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:52,644 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,695 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,700 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,702 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:54,823 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:54,823 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:39:54,827 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:55,021 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:55,021 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:55,023 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/10_worker
INFO    2018-08-08 13:39:55,025 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30039 closed
INFO    2018-08-08 13:39:55,025 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:55,027 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:55,030 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:59,243 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:59,246 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000010_0 is done. And is in the process of committing
INFO    2018-08-08 13:40:00,272 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000010_0 is allowed to commit now
INFO    2018-08-08 13:40:00,283 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000010_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000010
INFO    2018-08-08 13:40:00,303 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000010_0' done.
INFO    2018-08-08 13:40:00,310 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000010_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128858
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=89
		CPU time spent (ms)=4470
		Physical memory (bytes) snapshot=1099632640
		Virtual memory (bytes) snapshot=58895904768
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0005_01_000007 on graphalytics-giraph-slave9_37771
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:19549
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 733 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 266 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  received-bytes:
               sum = 10,051.00
               min = 16.00
               max = 6653.00
              mean = 108.08
            stddev = 686.77
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 977.00
              99% <= 6653.00
            99.9% <= 6653.00
             count = 93

  remote-requests:
    count = 8

  requests-received:
             count = 93
         mean rate = 124.28 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 107
         mean rate = 143.16 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 5,098.00
               min = 16.00
               max = 1473.00
              mean = 47.64
            stddev = 141.44
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 95.72
              99% <= 1362.92
            99.9% <= 1473.00
             count = 107

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 733

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 8

  wait-requests-us:
    value = 266

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 83 ms
  compute all partitions: 16 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 564 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 16

  compute-per-partition-ms:
               sum = 58.00
               min = 0.00
               max = 5.00
              mean = 1.76
            stddev = 1.70
            median = 2.00
              75% <= 3.00
              95% <= 4.30
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 58.00
               min = 1.00
               max = 8.00
              mean = 5.27
            stddev = 2.15
            median = 6.00
              75% <= 7.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 9,003.00
               min = 16.00
               max = 6564.00
              mean = 157.95
            stddev = 864.76
            median = 46.00
              75% <= 71.00
              95% <= 89.00
              98% <= 5528.00
              99% <= 6564.00
            99.9% <= 6564.00
             count = 57

  remote-requests:
    count = 0

  requests-received:
             count = 57
         mean rate = 476.68 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 57
         mean rate = 476.67 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,698.00
               min = 16.00
               max = 1473.00
              mean = 64.88
            stddev = 192.12
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1251.56
              99% <= 1473.00
            99.9% <= 1473.00
             count = 57

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 83

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 564

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 60 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 4385 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 11.00
               min = 0.00
               max = 8.00
              mean = 0.33
            stddev = 1.41
            median = 0.00
              75% <= 0.00
              95% <= 3.10
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 205

  messages-sent:
    count = 5

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 11.00
               min = 0.00
               max = 8.00
              mean = 1.00
            stddev = 2.41
            median = 0.00
              75% <= 1.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 9,083.00
               min = 16.00
               max = 6564.00
              mean = 146.50
            stddev = 833.41
            median = 31.00
              75% <= 53.00
              95% <= 89.00
              98% <= 4880.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 62

  remote-requests:
    count = 5

  requests-received:
             count = 62
         mean rate = 638.38 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 62
         mean rate = 638.60 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 5

  sent-bytes:
               sum = 3,928.00
               min = 16.00
               max = 1473.00
              mean = 63.35
            stddev = 184.16
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1113.16
              99% <= 1473.00
            99.9% <= 1473.00
             count = 62

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 60

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 5

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 4385

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 143 ms
  compute all partitions: 12 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 157 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 12

  compute-per-partition-ms:
               sum = 8.00
               min = 0.00
               max = 6.00
              mean = 0.24
            stddev = 1.06
            median = 0.00
              75% <= 0.00
              95% <= 2.50
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 205

  messages-sent:
    count = 5

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 8.00
               min = 0.00
               max = 6.00
              mean = 0.73
            stddev = 1.79
            median = 0.00
              75% <= 1.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 9,083.00
               min = 16.00
               max = 6564.00
              mean = 146.50
            stddev = 828.89
            median = 31.00
              75% <= 53.00
              95% <= 89.00
              98% <= 4880.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 62

  remote-requests:
    count = 5

  requests-received:
             count = 62
         mean rate = 344.86 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 62
         mean rate = 344.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 5

  sent-bytes:
               sum = 3,928.00
               min = 16.00
               max = 1473.00
              mean = 63.35
            stddev = 184.16
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1113.16
              99% <= 1473.00
            99.9% <= 1473.00
             count = 62

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 143

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 5

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 157

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 3 ---
  superstep time: 136 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 164 us

8/8/18 1:39:52 PM ==============================================================
giraph.superstep.3:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.03
            stddev = 0.17
            median = 0.00
              75% <= 0.00
              95% <= 0.30
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.37
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 904.77
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 303.05 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 302.81 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.71
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 136

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 164

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.22444175107636

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 1:39:55 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = 0.0

  edges-loaded:
             count = 17
         mean rate = 4.05 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 13:40:09 +0000 2018
LogLength:67778
Log Contents:
2018-08-08 13:39:49,766 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 13:39:49,827 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 13:39:49,827 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 13:39:49,829 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 13:39:49,829 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 13:39:49,996 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 13:39:50,209 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005
2018-08-08 13:39:50,386 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 13:39:50,828 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 13:39:50,840 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 13:39:50,984 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 13:39:50,997 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 13:39:51,026 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 13:39:51,027 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 13:39:51,037 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 13:39:51,047 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0005/_haltComputation
INFO    2018-08-08 13:39:51,047 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0005, 5 on graphalytics-giraph:2181
INFO    2018-08-08 13:39:51,055 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 13:39:51,055 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave9
INFO    2018-08-08 13:39:51,055 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 13:39:51,055 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 13:39:51,055 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 13:39:51,055 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000007:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000007/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 13:39:51,055 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000007:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 13:39:51,055 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000007/tmp
INFO    2018-08-08 13:39:51,056 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 13:39:51,056 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 13:39:51,056 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 13:39:51,056 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 13:39:51,056 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 13:39:51,056 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 13:39:51,056 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0005/container_1533735211869_0005_01_000007
INFO    2018-08-08 13:39:51,056 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@5aabbb29
INFO    2018-08-08 13:39:51,071 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 13:39:51,072 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 13:39:51,078 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3003c, negotiated timeout = 40000
INFO    2018-08-08 13:39:51,079 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 13:39:51,188 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 13:39:51,205 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 13:39:51,259 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave9/10.164.0.11:30005 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 13:39:51,264 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 13:39:51,265 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 13:39:51,286 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 13:39:51,296 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:51,302 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,305 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir already exists!
INFO    2018-08-08 13:39:51,311 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave9_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=5, port=30005)
INFO    2018-08-08 13:39:51,659 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,744 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53373555E9
INFO    2018-08-08 13:39:51,754 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:51,756 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:51,756 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,757 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,759 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,760 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,761 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,763 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,764 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,765 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,768 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,769 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:51,771 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,774 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,775 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,776 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,777 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,777 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,787 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 13:39:51,844 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,889 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043864023 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,889 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03764838 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,889 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036962207 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,889 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036217224 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,889 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03562647 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,890 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.035702694 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,890 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03453614 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,890 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03522359 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,891 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.034281585 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,891 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.033861578 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,891 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.033365414 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,893 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0039, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.042
MBytes/sec sent = 0.0061, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.042
INFO    2018-08-08 13:39:51,895 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 13:39:51,900 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 8.71226E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,900 [load-0] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/example-directed.e:0+70'
INFO    2018-08-08 13:39:51,900 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002924974 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,902 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003692685 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,902 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005989318 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,903 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003527588 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,904 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003818142 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,905 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003321777 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,907 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003676548 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,907 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003828824 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,908 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003430701 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 13:39:51,923 [load-0] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=0, e=17)
INFO    2018-08-08 13:39:51,925 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 0.029942047 secs, (v=0, e=17) 0.0 vertices/sec, 567.7634 edges/sec
INFO    2018-08-08 13:39:51,939 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0081, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.014
MBytes/sec sent = 0.0331, MBytesSent = 0.0005, ave sent req MBytes = 0.0001, secs waited = 0.014
INFO    2018-08-08 13:39:51,939 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=17)
INFO    2018-08-08 13:39:51,946 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 13:39:51,950 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 13:39:51,952 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50863.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,952 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0044, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.027
MBytes/sec sent = 0.0177, MBytesSent = 0.0005, ave sent req MBytes = 0.0001, secs waited = 0.027
INFO    2018-08-08 13:39:51,952 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:51,970 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:51,971 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50863.69M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:51,982 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 13:39:52,023 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,028 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=10,finVtx=0,edges=17,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@79b663b3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1b812421)
WARN    2018-08-08 13:39:52,032 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 13:39:52,051 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,051 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,054 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave9_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=5, port=30005)
INFO    2018-08-08 13:39:52,080 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,080 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,080 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,081 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.11
MBytes/sec sent = 0.0127, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.11
INFO    2018-08-08 13:39:52,085 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,088 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,097 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 13:39:52,111 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009750293 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009218371 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,111 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004326277 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,111 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007296645 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,113 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006981007 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,111 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003640261 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,111 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011135754 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007647133 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009322581 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,112 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013393911 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,113 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011135934 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,114 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,115 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.007, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.026
MBytes/sec sent = 0.0377, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.026
INFO    2018-08-08 13:39:52,115 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,125 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,126 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,131 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 13:39:52,156 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,158 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=10,finVtx=0,edges=17,msgCount=17,msgBytesCount=697,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@49b07ee3,outgoing=org.apache.giraph.conf.DefaultMessageClasses@352e612e)
INFO    2018-08-08 13:39:52,166 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,170 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave9_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=5, port=30005)
INFO    2018-08-08 13:39:52,195 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,195 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,195 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,196 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.07
MBytes/sec sent = 0.0198, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.07
INFO    2018-08-08 13:39:52,201 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,202 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,207 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 13:39:52,211 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001542858 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,211 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002264258 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,211 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00316587 secs for 22 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,211 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002768791 secs for 8 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,212 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001844741 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002660894 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,213 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001705372 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,215 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002678053 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,215 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003099011 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,215 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002657082 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,217 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009574803 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,217 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,222 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0127, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0366, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 13:39:52,222 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,225 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,226 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 5 , message bytes = 205 , Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,232 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 13:39:52,256 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,259 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5300f14a,outgoing=org.apache.giraph.conf.DefaultMessageClasses@1f86099a)
INFO    2018-08-08 13:39:52,265 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,284 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave9_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=5, port=30005)
INFO    2018-08-08 13:39:52,299 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,349 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,381 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,381 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,381 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,383 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.156
MBytes/sec sent = 0.0089, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.157
INFO    2018-08-08 13:39:52,385 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,386 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,389 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 13:39:52,394 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002839908 secs for 15 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001962925 secs for 7 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,394 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002361101 secs for 10 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001799248 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001391498 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,395 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001165334 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,396 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001491732 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,398 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00784055 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,401 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0029113 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,401 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004219444 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,401 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005029212 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,402 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,402 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0439, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 13:39:52,402 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,408 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 13:39:52,408 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 5 , message bytes = 205 , Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,414 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 13:39:52,438 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,441 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=10,finVtx=0,edges=30,msgCount=34,msgBytesCount=1294,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@27abb83e,outgoing=org.apache.giraph.conf.DefaultMessageClasses@69e308c6)
INFO    2018-08-08 13:39:52,446 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class org.apache.hadoop.io.LongWritable and no combiner
INFO    2018-08-08 13:39:52,463 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=3 with /_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/3/_workerHealthyDir/graphalytics-giraph-slave9_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=5, port=30005)
INFO    2018-08-08 13:39:52,477 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,528 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,557 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave3, MRtaskID=0, port=30000)
INFO    2018-08-08 13:39:52,557 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 13:39:52,557 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 13:39:52,558 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.15
MBytes/sec sent = 0.0093, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.15
INFO    2018-08-08 13:39:52,560 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 13:39:52,562 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 13:39:52,566 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 3
INFO    2018-08-08 13:39:52,569 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001905119 secs for 11 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001413924 secs for 1 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,570 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001212617 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,569 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002669238 secs for 21 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001356297 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,571 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001354601 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001570721 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001121542 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,572 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001415508 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,573 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001213957 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,574 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001777934 secs for 0 partitions on superstep 3.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 13:39:52,574 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 3 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,574 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0849, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.011
INFO    2018-08-08 13:39:52,574 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 13:39:52,582 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 13:39:52,582 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 3, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 13:39:52,587 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=3
INFO    2018-08-08 13:39:52,611 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 13:39:52,614 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 3 with global stats (vtx=10,finVtx=10,edges=30,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.cdlp.DirectedCommunityDetectionLPComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@89c65d5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@faa3fed)
INFO    2018-08-08 13:39:52,618 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 13:39:52,618 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 13:39:52,618 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 13:39:52,621 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 13:39:52,646 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 13:39:52,696 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0005/_applicationAttemptsDir/0/_superstepDir/2/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 13:39:52,702 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 13:39:52,704 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0005/_masterJobState)
INFO    2018-08-08 13:39:55,025 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 13:39:55,025 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 13:39:55,029 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 13:39:55,201 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 13:39:55,202 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 13:39:55,205 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0005/_cleanedUpDir/5_worker
INFO    2018-08-08 13:39:55,207 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3003c closed
INFO    2018-08-08 13:39:55,207 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 13:39:55,209 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 13:39:55,213 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 13:39:59,425 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 13:39:59,429 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0005_m_000005_0 is done. And is in the process of committing
INFO    2018-08-08 13:39:59,453 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0005_m_000005_0 is allowed to commit now
INFO    2018-08-08 13:39:59,462 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0005_m_000005_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r761165_CDLP-example-directed/_temporary/1/task_1533735211869_0005_m_000005
INFO    2018-08-08 13:39:59,479 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0005_m_000005_0' done.
INFO    2018-08-08 13:39:59,484 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0005_m_000005_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128857
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=114
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=85
		CPU time spent (ms)=4720
		Physical memory (bytes) snapshot=1101062144
		Virtual memory (bytes) snapshot=58903384064
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0005=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0005/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog

