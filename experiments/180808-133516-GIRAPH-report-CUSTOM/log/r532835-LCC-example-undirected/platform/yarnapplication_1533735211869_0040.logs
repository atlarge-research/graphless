

Container: container_1533735211869_0040_01_000004 on graphalytics-giraph-slave10_46663
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15674
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 617 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 324 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,675.00
               min = 16.00
               max = 6653.00
              mean = 124.04
            stddev = 749.78
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2845.88
              99% <= 6653.00
            99.9% <= 6653.00
             count = 78

  remote-requests:
    count = 0

  requests-received:
             count = 78
         mean rate = 123.53 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 96
         mean rate = 152.33 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,520.00
               min = 16.00
               max = 1473.00
              mean = 47.08
            stddev = 149.11
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 172.04
              99% <= 1473.00
            99.9% <= 1473.00
             count = 96

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 617

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 324

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 92 ms
  compute all partitions: 19 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 207 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 19

  compute-per-partition-ms:
               sum = 58.00
               min = 0.00
               max = 3.00
              mean = 1.76
            stddev = 1.18
            median = 2.00
              75% <= 3.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 56.00
               min = 2.00
               max = 6.00
              mean = 5.09
            stddev = 1.38
            median = 6.00
              75% <= 6.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 909.97
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 425.99 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 426.21 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 92

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 207

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 55 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 163 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.27
            stddev = 0.47
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 906.89
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 598.55 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 598.41 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 55

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 163

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 122 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 176 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.12
            stddev = 0.33
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.67
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 904.87
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 343.51 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 343.49 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 122

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 176

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.59549911178811

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:59994
Log Contents:
2018-08-08 15:25:05,283 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,348 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,348 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,350 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,350 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,539 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,766 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:05,954 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,424 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,436 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,584 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,599 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,628 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,629 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,637 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,644 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,644 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 1 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,650 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,650 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave10
INFO    2018-08-08 15:25:06,650 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,650 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,650 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,650 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000004:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000004/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,651 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000004:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,651 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000004/tmp
INFO    2018-08-08 15:25:06,651 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,651 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,651 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,651 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,651 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,651 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,651 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000004
INFO    2018-08-08 15:25:06,652 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,666 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,666 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,672 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30229, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,673 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,791 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,808 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,870 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave10/10.164.0.12:30001 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,876 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,877 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:06,897 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:06,907 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:06,910 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,912 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,918 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave10_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=1, port=30001)
INFO    2018-08-08 15:25:07,141 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,232 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,241 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,243 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,243 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,244 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,246 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,247 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,247 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,258 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,261 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,263 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,264 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,264 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,264 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,265 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,265 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,266 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,267 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,269 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,273 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,274 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,329 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,382 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.052272096 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,393 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.056443047 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,394 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.055724163 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,394 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.055231135 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,394 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.054461904 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,394 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.053617436 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,395 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05350416 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,396 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05227946 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,396 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.052808687 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,396 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05200634 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,397 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05223716 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0028, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.124
MBytes/sec sent = 0.0102, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.124
INFO    2018-08-08 15:25:07,400 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,404 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001007551 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,406 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004078428 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,406 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003501401 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,408 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 8.43858E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,410 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005613054 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,410 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005184536 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,410 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004626503 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,411 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.01085645 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,411 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003568816 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,411 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004356594 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,411 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003442992 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,412 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0238, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.01
INFO    2018-08-08 15:25:07,412 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 15:25:07,446 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,450 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 15:25:07,452 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50879.69M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,453 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0033, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.05
MBytes/sec sent = 0.0051, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.051
INFO    2018-08-08 15:25:07,453 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,473 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,474 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50879.69M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,483 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,518 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,522 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4ad4936c,outgoing=org.apache.giraph.conf.DefaultMessageClasses@29d37757)
WARN    2018-08-08 15:25:07,525 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,544 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,544 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,548 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave10_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=1, port=30001)
INFO    2018-08-08 15:25:07,580 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,580 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,580 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,581 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.107
MBytes/sec sent = 0.013, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.107
INFO    2018-08-08 15:25:07,583 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,585 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 15:25:07,598 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,613 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004519346 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,613 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009677478 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,614 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012881614 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,614 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008151264 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,614 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006464546 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,614 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011041092 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,614 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011764525 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,614 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007011029 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,614 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013564586 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,614 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009072461 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,613 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005326934 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,618 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.029
MBytes/sec sent = 0.034, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.029
INFO    2018-08-08 15:25:07,618 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,627 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,628 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,633 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,651 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,653 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27ead29e)
INFO    2018-08-08 15:25:07,662 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,666 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave10_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=1, port=30001)
INFO    2018-08-08 15:25:07,688 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,688 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,688 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,689 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.061
MBytes/sec sent = 0.0227, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.061
INFO    2018-08-08 15:25:07,691 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,695 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,695 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 15:25:07,699 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,703 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0030396 secs for 14 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,703 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002234219 secs for 12 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,703 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002034637 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,704 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002286034 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,704 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00204576 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,704 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002151296 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,705 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002324228 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,705 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001928877 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,706 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00112509 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,706 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002557466 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,707 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002361265 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,708 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 15:25:07,708 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,716 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,716 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,719 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,740 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,743 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@56febdc)
INFO    2018-08-08 15:25:07,750 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,772 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave10_1 and workerInfo= Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=1, port=30001)
WARN    2018-08-08 15:25:07,821 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,844 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,844 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,845 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,846 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.129
MBytes/sec sent = 0.0108, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.13
INFO    2018-08-08 15:25:07,851 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,852 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,855 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,860 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002156198 secs for 18 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,860 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001637756 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,860 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004496961 secs for 13 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,861 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001754114 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,861 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001661996 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,862 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001650622 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,862 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001367275 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001284749 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003373929 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002764325 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00241361 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50444.48M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,865 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 15:25:07,866 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50444.48M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,875 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,895 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,898 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@712ca57b,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4564e94b)
INFO    2018-08-08 15:25:07,902 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,902 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,902 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,905 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
WARN    2018-08-08 15:25:07,969 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,974 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,978 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,209 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,209 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 15:25:10,213 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,248 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,248 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,250 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/1_worker
INFO    2018-08-08 15:25:10,252 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30229 closed
INFO    2018-08-08 15:25:10,252 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,254 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,258 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,470 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,478 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000001_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:15,517 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000001_0 is allowed to commit now
INFO    2018-08-08 15:25:15,526 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000001_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000001
INFO    2018-08-08 15:25:15,544 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000001_0' done.
INFO    2018-08-08 15:25:15,549 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000001_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128720
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=96
		CPU time spent (ms)=4300
		Physical memory (bytes) snapshot=1067098112
		Virtual memory (bytes) snapshot=58878320640
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000010 on graphalytics-giraph-slave11_46641
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15691
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 633 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 368 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,838.00
               min = 16.00
               max = 6653.00
              mean = 113.08
            stddev = 709.92
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1710.72
              99% <= 6653.00
            99.9% <= 6653.00
             count = 87

  remote-requests:
    count = 0

  requests-received:
             count = 87
         mean rate = 133.96 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 151.30 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.66
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 633

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 368

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 91 ms
  compute all partitions: 20 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 5144 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 20

  compute-per-partition-ms:
               sum = 45.00
               min = 0.00
               max = 10.00
              mean = 1.36
            stddev = 1.90
            median = 1.00
              75% <= 2.00
              95% <= 5.80
              98% <= 10.00
              99% <= 10.00
            99.9% <= 10.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 435

  messages-sent:
    count = 5

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 45.00
               min = 0.00
               max = 10.00
              mean = 4.09
            stddev = 2.55
            median = 4.00
              75% <= 5.00
              95% <= 10.00
              98% <= 10.00
              99% <= 10.00
            99.9% <= 10.00
             count = 11

  received-bytes:
               sum = 9,141.00
               min = 16.00
               max = 6653.00
              mean = 152.35
            stddev = 855.35
            median = 16.00
              75% <= 74.00
              95% <= 89.00
              98% <= 5208.92
              99% <= 6653.00
            99.9% <= 6653.00
             count = 60

  remote-requests:
    count = 5

  requests-received:
             count = 60
         mean rate = 484.72 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 61
         mean rate = 492.94 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 5

  sent-bytes:
               sum = 4,142.00
               min = 16.00
               max = 1473.00
              mean = 67.90
            stddev = 185.66
            median = 25.00
              75% <= 89.00
              95% <= 92.00
              98% <= 1141.56
              99% <= 1473.00
            99.9% <= 1473.00
             count = 61

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 91

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 5

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 5144

  worker-context-post-superstep:
    value = 9

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 53 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 238 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 9.00
               min = 0.00
               max = 3.00
              mean = 0.27
            stddev = 0.67
            median = 0.00
              75% <= 0.00
              95% <= 2.30
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 156

  messages-sent:
    count = 4

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 9.00
               min = 0.00
               max = 3.00
              mean = 0.82
            stddev = 1.25
            median = 0.00
              75% <= 2.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 9,057.00
               min = 16.00
               max = 6653.00
              mean = 150.95
            stddev = 854.12
            median = 30.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5208.92
              99% <= 6653.00
            99.9% <= 6653.00
             count = 60

  remote-requests:
    count = 4

  requests-received:
             count = 60
         mean rate = 706.71 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 61
         mean rate = 719.86 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 4

  sent-bytes:
               sum = 3,874.00
               min = 16.00
               max = 1473.00
              mean = 63.51
            stddev = 185.69
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1140.84
              99% <= 1473.00
            99.9% <= 1473.00
             count = 61

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 53

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 4

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 238

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 125 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 168 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 933.04
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 334.64 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 341.09 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.70
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 125

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 168

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.25477844143145

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:60172
Log Contents:
2018-08-08 15:25:05,296 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,363 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,363 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,365 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,365 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,544 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,762 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:05,951 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,425 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,437 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,595 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,610 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,639 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,640 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,648 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,655 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,655 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 7 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave11
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000010:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000010/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000010:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000010/tmp
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,661 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000010
INFO    2018-08-08 15:25:06,662 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,674 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,675 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,680 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3022a, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,682 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,797 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,814 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,858 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave11/10.164.0.13:30007 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,863 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,863 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:06,886 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:06,897 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:06,899 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,902 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,908 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave11_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007)
INFO    2018-08-08 15:25:07,150 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,239 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,248 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,250 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,251 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,254 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,257 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,258 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,258 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,261 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,261 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,261 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,261 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,263 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,266 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,266 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,267 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,268 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,268 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,269 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,271 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,273 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,278 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,347 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,388 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03331671 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040121384 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.032944508 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.032803856 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,390 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031858496 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,391 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031892274 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,391 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030387191 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,391 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.02958074 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,391 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028821755 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,391 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028158853 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,392 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.027518524 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,393 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.114
MBytes/sec sent = 0.0111, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.115
INFO    2018-08-08 15:25:07,394 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,399 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00396961 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,399 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002425888 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002273536 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,401 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00242058 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002763292 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,403 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0028827 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,403 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002483747 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00294165 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,405 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002847594 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,406 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002351278 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,409 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005227737 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,409 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 15:25:07,409 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 15:25:07,451 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,456 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,466 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,468 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50738.85M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,468 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0004, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.063
INFO    2018-08-08 15:25:07,468 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,479 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,479 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.85M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,490 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,524 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,528 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
WARN    2018-08-08 15:25:07,531 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,547 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,547 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,550 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave11_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007)
INFO    2018-08-08 15:25:07,588 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,589 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,589 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,591 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.111
MBytes/sec sent = 0.0125, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.111
INFO    2018-08-08 15:25:07,595 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,596 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,603 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,616 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006285672 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007356066 secs for 7 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005591111 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002899753 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009119579 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004033998 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009778621 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011396063 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005581073 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00517782 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,622 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017141476 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,624 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50598.04M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,629 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0109, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0627, MBytesSent = 0.0004, ave sent req MBytes = 0.0001, secs waited = 0.006
INFO    2018-08-08 15:25:07,629 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,632 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0661, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.2101, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,633 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 5 , message bytes = 435 , Memory (free/total/max) = 50598.04M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,639 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,657 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,660 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 15:25:07,669 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,673 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave11_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007)
INFO    2018-08-08 15:25:07,695 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,695 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,695 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,696 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0219, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.063
INFO    2018-08-08 15:25:07,698 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,702 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,707 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,712 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003001635 secs for 8 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004721135 secs for 9 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003892717 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,713 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00449636 secs for 9 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,713 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003531757 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,714 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002408782 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,715 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001396209 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,715 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002321985 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,715 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001435644 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,715 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001352547 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,717 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002336121 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,718 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50457.24M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,718 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0102, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.028, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 15:25:07,718 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,722 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0397, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.1261, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 15:25:07,722 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 4 , message bytes = 156 , Memory (free/total/max) = 50457.24M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,728 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,747 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,750 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 15:25:07,755 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,778 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave11_7 and workerInfo= Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007)
INFO    2018-08-08 15:25:07,784 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,827 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,851 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,851 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,851 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,852 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.13
MBytes/sec sent = 0.0107, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.13
INFO    2018-08-08 15:25:07,856 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,857 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,862 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,865 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001563916 secs for 5 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003108644 secs for 14 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002204087 secs for 14 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001397408 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001509736 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001378658 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002642312 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00277682 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002488516 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,871 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002465971 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,873 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002663106 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,873 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50303.63M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,873 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0114, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.015
MBytes/sec sent = 0.0637, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.015
INFO    2018-08-08 15:25:07,873 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,880 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0248, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.0788, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 15:25:07,880 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50303.63M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,885 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,901 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,904 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 15:25:07,908 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,908 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,908 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,911 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:07,932 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,975 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,979 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,984 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,215 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,215 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 15:25:10,218 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,363 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,363 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,366 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/7_worker
INFO    2018-08-08 15:25:10,368 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3022a closed
INFO    2018-08-08 15:25:10,368 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,369 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,372 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,582 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,590 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000007_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:14,614 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000007_0 is allowed to commit now
INFO    2018-08-08 15:25:14,623 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000007_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000007
INFO    2018-08-08 15:25:14,640 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000007_0' done.
INFO    2018-08-08 15:25:14,645 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000007_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128720
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=6
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=98
		CPU time spent (ms)=4600
		Physical memory (bytes) snapshot=1099636736
		Virtual memory (bytes) snapshot=58922496000
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000013 on graphalytics-giraph-slave12_33893
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15681
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 569 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 359 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,790.00
               min = 16.00
               max = 6653.00
              mean = 117.95
            stddev = 726.63
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2213.96
              99% <= 6653.00
            99.9% <= 6653.00
             count = 83

  remote-requests:
    count = 0

  requests-received:
             count = 83
         mean rate = 141.94 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 168.05 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.64
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 569

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 359

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 92 ms
  compute all partitions: 18 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 3318 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 18

  compute-per-partition-ms:
               sum = 35.00
               min = 0.00
               max = 8.00
              mean = 1.06
            stddev = 1.60
            median = 1.00
              75% <= 2.00
              95% <= 4.50
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 126

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 35.00
               min = 0.00
               max = 8.00
              mean = 3.18
            stddev = 2.09
            median = 3.00
              75% <= 4.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 8,965.00
               min = 16.00
               max = 6653.00
              mean = 163.00
            stddev = 892.29
            median = 16.00
              75% <= 89.00
              95% <= 89.60
              98% <= 5865.68
              99% <= 6653.00
            99.9% <= 6653.00
             count = 55

  remote-requests:
    count = 2

  requests-received:
             count = 55
         mean rate = 443.63 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 450.06 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,786.00
               min = 16.00
               max = 1473.00
              mean = 67.61
            stddev = 193.61
            median = 20.50
              75% <= 68.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 92

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 3318

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 52 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 278 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 7.00
               min = 0.00
               max = 3.00
              mean = 0.21
            stddev = 0.60
            median = 0.00
              75% <= 0.00
              95% <= 1.60
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 78

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 7.00
               min = 0.00
               max = 4.00
              mean = 0.64
            stddev = 1.29
            median = 0.00
              75% <= 1.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,893.00
               min = 16.00
               max = 6653.00
              mean = 161.69
            stddev = 891.98
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5865.32
              99% <= 6653.00
            99.9% <= 6653.00
             count = 55

  remote-requests:
    count = 2

  requests-received:
             count = 55
         mean rate = 643.15 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 654.45 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,738.00
               min = 16.00
               max = 1473.00
              mean = 66.75
            stddev = 193.65
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 52

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 278

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 122 ms
  compute all partitions: 12 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 219 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 12

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.98
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 337.39 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 343.83 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.70
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 122

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 219

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.22444510111843

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:60145
Log Contents:
2018-08-08 15:25:05,354 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,421 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,421 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,423 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,423 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,602 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,832 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:06,019 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,472 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,484 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,634 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,648 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,678 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,679 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,688 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,695 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,695 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 10 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,701 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,701 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave12
INFO    2018-08-08 15:25:06,701 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,701 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,701 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,701 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000013:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000013/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,702 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000013:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,702 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000013/tmp
INFO    2018-08-08 15:25:06,702 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,702 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,702 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,702 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,702 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,702 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,702 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000013
INFO    2018-08-08 15:25:06,702 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,716 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,717 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,723 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3022c, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,724 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,842 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,860 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,915 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave12/10.164.0.14:30010 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,921 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,922 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:06,946 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:06,957 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:06,960 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,963 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,969 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave12_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=10, port=30010)
INFO    2018-08-08 15:25:07,144 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,235 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,246 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,247 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,248 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,249 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,249 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,251 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,257 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,257 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,257 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,258 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,263 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,264 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,267 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,268 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,270 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,270 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,275 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,343 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,397 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.053082567 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,397 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04552159 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,397 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04492335 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,397 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04275305 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042575534 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041449104 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040790588 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,399 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040406097 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,399 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039834972 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,399 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038890608 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,399 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038118456 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,401 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0033, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.05
MBytes/sec sent = 0.0051, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.05
INFO    2018-08-08 15:25:07,402 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,407 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004120871 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,408 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004218551 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,410 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004940683 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,410 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003001259 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,411 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003414566 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,412 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003696266 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,413 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00247571 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,413 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002613432 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,415 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003339709 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,416 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003368548 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,417 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00238787 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,418 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 15:25:07,418 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 15:25:07,448 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,453 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,461 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,463 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,463 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0006, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.048
MBytes/sec sent = 0.001, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.048
INFO    2018-08-08 15:25:07,463 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,475 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,476 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,485 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,520 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,525 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
WARN    2018-08-08 15:25:07,528 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,543 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,543 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,545 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave12_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=10, port=30010)
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,587 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.111
MBytes/sec sent = 0.0125, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.111
INFO    2018-08-08 15:25:07,590 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,591 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,601 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,614 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011083173 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,614 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008998495 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007578533 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006945078 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010368117 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002884483 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003785861 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008710444 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00307845 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006731397 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010801842 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,620 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.08M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,624 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0216, MBytesSent = 0.0001, ave sent req MBytes = 0.0001, secs waited = 0.005
INFO    2018-08-08 15:25:07,624 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,629 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,630 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 2 , message bytes = 126 , Memory (free/total/max) = 50582.08M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,635 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,653 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,655 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 15:25:07,666 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,669 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave12_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=10, port=30010)
INFO    2018-08-08 15:25:07,692 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,692 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,692 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0219, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.063
INFO    2018-08-08 15:25:07,697 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,698 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,701 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,706 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003065471 secs for 12 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,706 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002648198 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,706 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003542193 secs for 16 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,706 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002389161 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,707 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00212382 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,707 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005237794 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00226558 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001464874 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001530343 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001883412 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002162311 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,714 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,714 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0044, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.012, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 15:25:07,714 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,719 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.0
MBytes/sec sent = 0.0238, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,719 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 2 , message bytes = 78 , Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,724 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,743 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,746 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 15:25:07,753 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,774 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave12_10 and workerInfo= Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=10, port=30010)
INFO    2018-08-08 15:25:07,780 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,824 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,847 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,847 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,848 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.129
MBytes/sec sent = 0.0108, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.13
INFO    2018-08-08 15:25:07,853 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,854 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,858 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,864 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005780493 secs for 23 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002443221 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003217266 secs for 10 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004167724 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003857783 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003225421 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003131925 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002799615 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00480008 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005353931 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002365746 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0108, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.016
MBytes/sec sent = 0.0599, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.016
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,875 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0397, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.1261, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 15:25:07,875 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,881 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,897 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,900 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 15:25:07,904 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,904 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,904 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,907 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:07,928 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,971 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,976 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,980 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,011 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,012 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 15:25:10,016 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,183 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,184 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,186 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/10_worker
INFO    2018-08-08 15:25:10,188 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3022c closed
INFO    2018-08-08 15:25:10,188 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,192 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,195 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,407 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,411 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000010_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:15,440 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000010_0 is allowed to commit now
INFO    2018-08-08 15:25:15,451 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000010_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000010
INFO    2018-08-08 15:25:15,468 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000010_0' done.
INFO    2018-08-08 15:25:15,473 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000010_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128721
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=6
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=88
		CPU time spent (ms)=4800
		Physical memory (bytes) snapshot=1108062208
		Virtual memory (bytes) snapshot=58911797248
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000008 on graphalytics-giraph-slave13_40615
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15681
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 629 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 319 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,790.00
               min = 16.00
               max = 6653.00
              mean = 116.55
            stddev = 722.34
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2083.40
              99% <= 6653.00
            99.9% <= 6653.00
             count = 84

  remote-requests:
    count = 0

  requests-received:
             count = 84
         mean rate = 130.34 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 152.32 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.69
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 629

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 319

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 88 ms
  compute all partitions: 19 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1813 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 19

  compute-per-partition-ms:
               sum = 53.00
               min = 0.00
               max = 9.00
              mean = 1.61
            stddev = 1.82
            median = 2.00
              75% <= 3.00
              95% <= 4.80
              98% <= 9.00
              99% <= 9.00
            99.9% <= 9.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 126

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 53.00
               min = 2.00
               max = 9.00
              mean = 4.82
            stddev = 1.78
            median = 5.00
              75% <= 5.00
              95% <= 9.00
              98% <= 9.00
              99% <= 9.00
            99.9% <= 9.00
             count = 11

  received-bytes:
               sum = 8,957.00
               min = 16.00
               max = 6564.00
              mean = 159.95
            stddev = 871.87
            median = 34.50
              75% <= 87.75
              95% <= 89.00
              98% <= 5657.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 56

  remote-requests:
    count = 2

  requests-received:
             count = 56
         mean rate = 470.49 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 469.73 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,786.00
               min = 16.00
               max = 1473.00
              mean = 67.61
            stddev = 193.52
            median = 20.50
              75% <= 68.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 88

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1813

  worker-context-post-superstep:
    value = 9

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 55 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 284 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 6.00
               min = 0.00
               max = 3.00
              mean = 0.18
            stddev = 0.58
            median = 0.00
              75% <= 0.00
              95% <= 1.60
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 78

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 6.00
               min = 0.00
               max = 3.00
              mean = 0.55
            stddev = 1.04
            median = 0.00
              75% <= 1.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 8,893.00
               min = 16.00
               max = 6564.00
              mean = 158.80
            stddev = 872.31
            median = 30.00
              75% <= 80.00
              95% <= 89.00
              98% <= 5657.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 56

  remote-requests:
    count = 2

  requests-received:
             count = 56
         mean rate = 647.39 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 647.28 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,738.00
               min = 16.00
               max = 1473.00
              mean = 66.75
            stddev = 193.62
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 55

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 284

  worker-context-post-superstep:
    value = 3

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 123 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 168 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.12
            stddev = 0.33
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.67
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 904.77
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 345.07 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 345.08 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 123

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 168

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.25487157550171

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:60145
Log Contents:
2018-08-08 15:25:05,344 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,405 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,405 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,407 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,407 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,580 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,793 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:05,967 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,432 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,443 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,599 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,613 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,639 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,640 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,647 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,653 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,654 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 5 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,659 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,659 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave13
INFO    2018-08-08 15:25:06,659 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,659 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,659 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,659 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000008:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000008/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,659 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000008:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,659 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000008/tmp
INFO    2018-08-08 15:25:06,659 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,659 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,660 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000008
INFO    2018-08-08 15:25:06,660 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,673 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,673 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,679 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3022b, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,680 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,790 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,807 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,864 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave13/10.164.0.15:30005 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,869 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,869 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:06,889 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:06,899 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:06,902 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,904 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,911 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave13_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=5, port=30005)
INFO    2018-08-08 15:25:07,145 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,234 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,245 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,246 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,248 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,248 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,252 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,257 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,261 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,263 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,265 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,266 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,266 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,267 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,272 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,277 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,330 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,387 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05578248 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.049520355 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04946475 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04888958 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047459356 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046809074 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044143483 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043992087 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043252014 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042678356 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,391 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043315977 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,392 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0029, MBytesReceived = 0.0004, ave received req MBytes = 0, secs waited = 0.12
MBytes/sec sent = 0.0106, MBytesSent = 0.0013, ave sent req MBytes = 0.0001, secs waited = 0.12
INFO    2018-08-08 15:25:07,393 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,397 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003649834 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,399 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004381981 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,399 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003747187 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003485608 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,401 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003256401 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003821749 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003510084 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002238402 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004261898 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,405 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003168304 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,406 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003049839 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,407 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0092, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0143, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 15:25:07,407 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 15:25:07,450 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,454 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,463 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,465 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,465 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0007, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0011, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.063
INFO    2018-08-08 15:25:07,465 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,477 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,477 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,487 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,521 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,526 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
WARN    2018-08-08 15:25:07,529 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,546 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,547 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,551 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave13_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=5, port=30005)
INFO    2018-08-08 15:25:07,584 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,586 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.109
MBytes/sec sent = 0.0128, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.109
INFO    2018-08-08 15:25:07,589 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,593 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,603 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,617 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006998497 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011649321 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006491587 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005946594 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010881246 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012842258 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004945648 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01016445 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010154805 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00412663 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,621 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012115505 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,622 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50598.09M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,624 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0102, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0432, MBytesSent = 0.0001, ave sent req MBytes = 0.0001, secs waited = 0.002
INFO    2018-08-08 15:25:07,624 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,630 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,630 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 2 , message bytes = 126 , Memory (free/total/max) = 50598.09M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,633 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,654 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,656 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 15:25:07,665 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,667 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave13_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=5, port=30005)
INFO    2018-08-08 15:25:07,692 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,694 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.064
MBytes/sec sent = 0.0216, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.064
INFO    2018-08-08 15:25:07,698 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,699 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,703 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,707 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001995975 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,707 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00342064 secs for 17 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,707 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002476313 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004535908 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001669381 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001929123 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002948472 secs for 10 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001631337 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00287937 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001681772 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,714 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002906658 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,714 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50457.29M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,715 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0044, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.012, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 15:25:07,715 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,720 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,720 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 2 , message bytes = 78 , Memory (free/total/max) = 50457.29M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,725 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,744 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,747 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 15:25:07,754 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,775 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave13_5 and workerInfo= Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=5, port=30005)
INFO    2018-08-08 15:25:07,781 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,825 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,848 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,848 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,848 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.129
MBytes/sec sent = 0.0108, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.129
INFO    2018-08-08 15:25:07,853 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,855 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,859 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,864 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002237049 secs for 3 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00269962 secs for 11 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004445593 secs for 19 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002051692 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001689833 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001876906 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001679556 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001829031 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001535618 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001250827 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,870 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002759583 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0108, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.016
MBytes/sec sent = 0.0599, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.016
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,877 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,878 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,883 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,899 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,901 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 15:25:07,905 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,905 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,905 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,907 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:07,929 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,972 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,977 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,982 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,211 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,211 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 15:25:10,215 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,370 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,370 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,373 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/5_worker
INFO    2018-08-08 15:25:10,374 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3022b closed
INFO    2018-08-08 15:25:10,375 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,377 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,380 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,592 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,596 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000005_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:14,622 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000005_0 is allowed to commit now
INFO    2018-08-08 15:25:14,631 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000005_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000005
INFO    2018-08-08 15:25:14,650 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000005_0' done.
INFO    2018-08-08 15:25:14,655 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000005_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128720
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=6
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=98
		CPU time spent (ms)=4630
		Physical memory (bytes) snapshot=1080225792
		Virtual memory (bytes) snapshot=58903130112
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000003 on graphalytics-giraph-slave14_35219
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:5560
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
superstep time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave5_9
  largest: 0 ms from graphalytics-giraph-slave5_9
compute all partitions
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave5_9
  largest: 0 ms from graphalytics-giraph-slave5_9
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave5_9
  largest: 0 ms from graphalytics-giraph-slave5_9
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave5_9
  largest: 0 us from graphalytics-giraph-slave5_9
wait requests time
  mean: 381.3076923076923 us
  smallest: 551 us from graphalytics-giraph-slave7_11
  largest: 319 us from graphalytics-giraph-slave13_5
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave5_9
  largest: 0 bytes from graphalytics-giraph-slave5_9
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave5_9
  largest: 0 bytes from graphalytics-giraph-slave5_9
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave5_9
  largest: 100.0 % from graphalytics-giraph-slave5_9

--- METRICS: superstep 0 ---
superstep time
  mean: 90.3076923076923 ms
  smallest: 94 ms from graphalytics-giraph-slave6_13
  largest: 86 ms from graphalytics-giraph-slave7_11
compute all partitions
  mean: 18.307692307692307 ms
  smallest: 21 ms from graphalytics-giraph-slave4_8
  largest: 15 ms from graphalytics-giraph-slave6_13
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave5_9
  largest: 0 ms from graphalytics-giraph-slave5_9
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave5_9
  largest: 0 us from graphalytics-giraph-slave5_9
wait requests time
  mean: 1878.923076923077 us
  smallest: 5922 us from graphalytics-giraph-slave2_4
  largest: 207 us from graphalytics-giraph-slave10_1
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave5_9
  largest: 0 bytes from graphalytics-giraph-slave5_9
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave5_9
  largest: 0 bytes from graphalytics-giraph-slave5_9
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave5_9
  largest: 100.0 % from graphalytics-giraph-slave5_9

--- METRICS: superstep 1 ---
superstep time
  mean: 54.61538461538461 ms
  smallest: 57 ms from graphalytics-giraph-slave6_13
  largest: 52 ms from graphalytics-giraph-slave12_10
compute all partitions
  mean: 9.615384615384615 ms
  smallest: 13 ms from graphalytics-giraph-slave15_6
  largest: 7 ms from graphalytics-giraph-slave6_13
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave5_9
  largest: 0 ms from graphalytics-giraph-slave5_9
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave5_9
  largest: 0 us from graphalytics-giraph-slave5_9
wait requests time
  mean: 230.76923076923077 us
  smallest: 515 us from graphalytics-giraph-slave4_8
  largest: 158 us from graphalytics-giraph-slave7_11
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave5_9
  largest: 0 bytes from graphalytics-giraph-slave5_9
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave5_9
  largest: 0 bytes from graphalytics-giraph-slave5_9
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave5_9
  largest: 100.0 % from graphalytics-giraph-slave5_9

--- METRICS: superstep 2 ---
superstep time
  mean: 122.61538461538461 ms
  smallest: 125 ms from graphalytics-giraph-slave11_7
  largest: 119 ms from graphalytics-giraph-slave1_2
compute all partitions
  mean: 10.23076923076923 ms
  smallest: 12 ms from graphalytics-giraph-slave12_10
  largest: 8 ms from graphalytics-giraph-slave9_12
network communication time
  mean: 0.0 ms
  smallest: 0 ms from graphalytics-giraph-slave5_9
  largest: 0 ms from graphalytics-giraph-slave5_9
time to first message
  mean: 0.0 us
  smallest: 0 us from graphalytics-giraph-slave5_9
  largest: 0 us from graphalytics-giraph-slave5_9
wait requests time
  mean: 222.3846153846154 us
  smallest: 551 us from graphalytics-giraph-slave1_2
  largest: 166 us from graphalytics-giraph-slave2_4
bytes loaded from disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave5_9
  largest: 0 bytes from graphalytics-giraph-slave5_9
bytes stored to disk
  mean: 0.0 bytes
  smallest: 0 bytes from graphalytics-giraph-slave5_9
  largest: 0 bytes from graphalytics-giraph-slave5_9
graph in mem
  mean: 100.0 %
  smallest: 100.0 % from graphalytics-giraph-slave5_9
  largest: 100.0 % from graphalytics-giraph-slave5_9
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:53960
Log Contents:
2018-08-08 15:25:05,277 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,342 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,342 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,344 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,344 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,517 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,733 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:05,904 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,315 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,325 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,459 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,473 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,499 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,500 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceMaster (master thread)...
INFO    2018-08-08 15:25:06,507 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,513 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,513 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 0 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave14
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000003:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000003/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,519 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000003:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,519 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000003/tmp
INFO    2018-08-08 15:25:06,519 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,519 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,519 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,519 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,519 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,519 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,519 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000003
INFO    2018-08-08 15:25:06,519 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.master.BspServiceMaster@3574e198
INFO    2018-08-08 15:25:06,531 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,532 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,538 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30224, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,539 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,546 [main] org.apache.giraph.graph.GraphTaskManager  - map: No need to do anything when not a worker
INFO    2018-08-08 15:25:06,546 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for MASTER_ONLY
INFO    2018-08-08 15:25:06,565 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - becomeMaster: First child is '/_hadoopBsp/job_1533735211869_0040/_masterElectionDir/graphalytics-giraph-slave14_00000000000' and my bid is '/_hadoopBsp/job_1533735211869_0040/_masterElectionDir/graphalytics-giraph-slave14_00000000000'
INFO    2018-08-08 15:25:06,618 [main-EventThread] org.apache.giraph.bsp.BspService  - process: applicationAttemptChanged signaled
INFO    2018-08-08 15:25:06,667 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,683 [org.apache.giraph.master.MasterThread] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,733 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave14/10.164.0.16:30000 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,738 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,739 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:06,742 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - becomeMaster: I am now the master!
INFO    2018-08-08 15:25:06,744 [org.apache.giraph.master.MasterThread] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:07,083 [org.apache.giraph.master.MasterThread] org.apache.giraph.io.formats.GiraphFileInputFormat  - Total input paths to process : 1
INFO    2018-08-08 15:25:07,095 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - generateVERTEXInputSplits: Got 1 input splits for 143 input threads
WARN    2018-08-08 15:25:07,095 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - createVERTEXInputSplits: Number of inputSplits=1 < 143=total number of input threads, some threads will be not used
INFO    2018-08-08 15:25:07,110 [org.apache.giraph.master.MasterThread] org.apache.giraph.io.formats.GiraphFileInputFormat  - Total input paths to process : 1
INFO    2018-08-08 15:25:07,112 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - generateEDGEInputSplits: Got 1 input splits for 143 input threads
WARN    2018-08-08 15:25:07,112 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - createEDGEInputSplits: Number of inputSplits=1 < 143=total number of input threads, some threads will be not used
INFO    2018-08-08 15:25:07,134 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,136 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,136 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,136 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,137 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,137 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,138 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,138 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,138 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,138 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,138 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,138 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,138 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,142 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,143 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - computePartitionCount: Creating 429 partitions.
INFO    2018-08-08 15:25:07,159 [org.apache.giraph.master.MasterThread] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.timeout is deprecated. Instead, use mapreduce.task.timeout
INFO    2018-08-08 15:25:07,246 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,252 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,257 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,258 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,263 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,266 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,267 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,268 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,271 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,276 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,351 [netty-server-worker-9] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0003, ave received req MBytes = 0.0003, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,414 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 8 out of 13 workers finished on superstep -1 on path /_hadoopBsp/job_1533735211869_0040/_inputSplitsWorkerDoneDir
INFO    2018-08-08 15:25:07,417 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: Waiting on [graphalytics-giraph-slave8_3, graphalytics-giraph-slave12_10, graphalytics-giraph-slave10_1, graphalytics-giraph-slave2_4, graphalytics-giraph-slave9_12]
INFO    2018-08-08 15:25:07,495 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 13 out of 13 workers finished on superstep -1 on path /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerFinishedDir
INFO    2018-08-08 15:25:07,495 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: Waiting on []
INFO    2018-08-08 15:25:07,516 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) on superstep = -1
INFO    2018-08-08 15:25:07,520 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep -1 took 0.407 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 0
WARN    2018-08-08 15:25:07,528 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,574 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,575 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 15:25:07,576 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=10, port=30010):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=6, port=30006):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007):(v=1, e=5),Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=5, port=30005):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=11, port=30011):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=4, port=30004):(v=1, e=4),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=9, port=30009):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=3, port=30003):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008):(v=1, e=2),]
INFO    2018-08-08 15:25:07,577 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008) - 1
INFO    2018-08-08 15:25:07,577 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 1, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002) - 0, Max: Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007) - 5
INFO    2018-08-08 15:25:07,585 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 0 on path /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerFinishedDir
INFO    2018-08-08 15:25:07,650 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) on superstep = 0
INFO    2018-08-08 15:25:07,653 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 0 took 0.133 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 1
INFO    2018-08-08 15:25:07,685 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,685 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 15:25:07,685 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=10, port=30010):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=6, port=30006):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007):(v=1, e=5),Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=5, port=30005):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=11, port=30011):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=4, port=30004):(v=1, e=4),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=9, port=30009):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=3, port=30003):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008):(v=1, e=2),]
INFO    2018-08-08 15:25:07,686 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008) - 1
INFO    2018-08-08 15:25:07,686 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 1, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002) - 0, Max: Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007) - 5
INFO    2018-08-08 15:25:07,732 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 13 out of 13 workers finished on superstep 1 on path /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerFinishedDir
INFO    2018-08-08 15:25:07,732 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: Waiting on []
INFO    2018-08-08 15:25:07,740 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) on superstep = 1
INFO    2018-08-08 15:25:07,743 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0
INFO    2018-08-08 15:25:07,825 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 1 took 0.172 seconds ended with state THIS_SUPERSTEP_DONE and is now on superstep 2
INFO    2018-08-08 15:25:07,842 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,842 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionBalancer  - balancePartitionsAcrossWorkers: Using algorithm static
INFO    2018-08-08 15:25:07,843 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: [Worker(hostname=graphalytics-giraph-slave12 hostOrIp=graphalytics-giraph-slave12, MRtaskID=10, port=30010):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=6, port=30006):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007):(v=1, e=5),Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=12, port=30012):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave13 hostOrIp=graphalytics-giraph-slave13, MRtaskID=5, port=30005):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=11, port=30011):(v=1, e=1),Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=13, port=30013):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=4, port=30004):(v=1, e=4),Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=9, port=30009):(v=1, e=3),Worker(hostname=graphalytics-giraph-slave10 hostOrIp=graphalytics-giraph-slave10, MRtaskID=1, port=30001):(v=0, e=0),Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=3, port=30003):(v=1, e=2),Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008):(v=1, e=2),]
INFO    2018-08-08 15:25:07,843 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Vertices - Mean: 0, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002) - 0, Max: Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008) - 1
INFO    2018-08-08 15:25:07,843 [org.apache.giraph.master.MasterThread] org.apache.giraph.partition.PartitionUtils  - analyzePartitionStats: Edges - Mean: 1, Min: Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002) - 0, Max: Worker(hostname=graphalytics-giraph-slave11 hostOrIp=graphalytics-giraph-slave11, MRtaskID=7, port=30007) - 5
INFO    2018-08-08 15:25:07,848 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - barrierOnWorkerList: 0 out of 13 workers finished on superstep 2 on path /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerFinishedDir
INFO    2018-08-08 15:25:07,895 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - aggregateWorkerStats: Aggregation found (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) on superstep = 2
INFO    2018-08-08 15:25:07,897 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - coordinateSuperstep: Cleaning up old Superstep /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1
INFO    2018-08-08 15:25:07,972 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - masterThread: Coordination of superstep 2 took 0.147 seconds ended with state ALL_SUPERSTEPS_DONE and is now on superstep 3
INFO    2018-08-08 15:25:07,974 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - setJobState: {"_applicationAttemptKey":-1,"_stateKey":"FINISHED","_superstepKey":-1} on superstep 3
INFO    2018-08-08 15:25:07,976 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - setJobState: {"_applicationAttemptKey":-1,"_stateKey":"FINISHED","_superstepKey":-1}
INFO    2018-08-08 15:25:07,985 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/0_master
INFO    2018-08-08 15:25:07,986 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Node /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir already exists, no need to create.
INFO    2018-08-08 15:25:07,987 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 1 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:07,987 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 1 nodes.
INFO    2018-08-08 15:25:10,178 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,180 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 2 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,180 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 2 nodes.
INFO    2018-08-08 15:25:10,186 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,187 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 3 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,187 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 3 nodes.
INFO    2018-08-08 15:25:10,246 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,248 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 4 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,248 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 4 nodes.
INFO    2018-08-08 15:25:10,249 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,250 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 5 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,250 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 5 nodes.
INFO    2018-08-08 15:25:10,252 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,253 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 6 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,253 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 6 nodes.
INFO    2018-08-08 15:25:10,256 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,257 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 7 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,257 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 7 nodes.
INFO    2018-08-08 15:25:10,268 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,268 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 8 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,268 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 8 nodes.
INFO    2018-08-08 15:25:10,278 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,279 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 9 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,279 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 9 nodes.
INFO    2018-08-08 15:25:10,288 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,288 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 10 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,288 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 10 nodes.
INFO    2018-08-08 15:25:10,362 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,364 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 11 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,364 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 11 nodes.
INFO    2018-08-08 15:25:10,369 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,369 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 12 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,369 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 12 nodes.
INFO    2018-08-08 15:25:10,371 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,372 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 13 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,372 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanedUpZooKeeper: Waiting for the children of /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir to change since only got 13 nodes.
INFO    2018-08-08 15:25:10,376 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,376 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanUpZooKeeper: Got 14 of 14 desired children from /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir
INFO    2018-08-08 15:25:10,376 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanupZooKeeper: Removing the following path and all children - /_hadoopBsp/job_1533735211869_0040 from ZooKeeper list graphalytics-giraph:2181
INFO    2018-08-08 15:25:10,481 [main-EventThread] org.apache.giraph.bsp.BspService  - process: masterElectionChildrenChanged signaled
INFO    2018-08-08 15:25:10,491 [main-EventThread] org.apache.giraph.bsp.BspService  - process: cleanedUpChildrenChanged signaled
INFO    2018-08-08 15:25:10,544 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.BspServiceMaster  - cleanup: Removed HDFS checkpoint directory (_bsp/_checkpoints//job_1533735211869_0040) with return = false since the job GraphalyticsBenchmark: LocalClusteringCoefficientJob succeeded 
INFO    2018-08-08 15:25:10,545 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:10,548 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:12,753 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:12,753 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:12,762 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:16,975 [org.apache.giraph.master.MasterThread] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:16,978 [org.apache.giraph.master.MasterThread] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30224 closed
INFO    2018-08-08 15:25:16,978 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:16,978 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - setup: Took 0.053 seconds.
INFO    2018-08-08 15:25:16,979 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - input superstep: Took 0.407 seconds.
INFO    2018-08-08 15:25:16,979 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 0: Took 0.133 seconds.
INFO    2018-08-08 15:25:16,979 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 1: Took 0.172 seconds.
INFO    2018-08-08 15:25:16,979 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - superstep 2: Took 0.147 seconds.
INFO    2018-08-08 15:25:16,979 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - shutdown: Took 9.006 seconds.
INFO    2018-08-08 15:25:16,979 [org.apache.giraph.master.MasterThread] org.apache.giraph.master.MasterThread  - total: Took 9.919 seconds.
INFO    2018-08-08 15:25:16,979 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Joined with master thread
INFO    2018-08-08 15:25:16,983 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000000_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:17,016 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000000_0' done.
INFO    2018-08-08 15:25:17,022 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000000_0: Counters: 48
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128720
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=83
		CPU time spent (ms)=4210
		Physical memory (bytes) snapshot=1103056896
		Virtual memory (bytes) snapshot=58931253248
		Total committed heap usage (bytes)=55163486208
	Giraph Stats
		Aggregate bytes loaded from local disks (out-of-core)=0
		Aggregate bytes stored to local disks (out-of-core)=0
		Aggregate edges=24
		Aggregate finished vertices=9
		Aggregate sent message bytes=2578
		Aggregate sent messages=46
		Aggregate vertices=9
		Current master task partition=0
		Current workers=13
		Last checkpointed superstep=0
		Lowest percentage of graph in memory so far (out-of-core)=100
		Sent message bytes=0
		Sent messages=0
		Superstep=3
	Giraph Timers
		Initialize (ms)=515
		Input superstep (ms)=407
		Setup (ms)=53
		Shutdown (ms)=9005
		Superstep 0 UndirectedLocalClusteringCoefficientComputation (ms)=133
		Superstep 1 UndirectedLocalClusteringCoefficientComputation (ms)=172
		Superstep 2 UndirectedLocalClusteringCoefficientComputation (ms)=147
		Total (ms)=9919
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000009 on graphalytics-giraph-slave15_37797
========================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15691
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 717 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 438 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,806.00
               min = 16.00
               max = 6653.00
              mean = 115.36
            stddev = 718.06
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1926.92
              99% <= 6653.00
            99.9% <= 6653.00
             count = 85

  remote-requests:
    count = 0

  requests-received:
             count = 85
         mean rate = 115.96 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 133.89 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.63
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 717

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 438

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 90 ms
  compute all partitions: 20 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1365 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 20

  compute-per-partition-ms:
               sum = 44.00
               min = 0.00
               max = 10.00
              mean = 1.33
            stddev = 1.95
            median = 1.00
              75% <= 2.00
              95% <= 5.80
              98% <= 10.00
              99% <= 10.00
            99.9% <= 10.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 213

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 44.00
               min = 0.00
               max = 10.00
              mean = 4.00
            stddev = 2.62
            median = 4.00
              75% <= 5.00
              95% <= 10.00
              98% <= 10.00
              99% <= 10.00
            99.9% <= 10.00
             count = 11

  received-bytes:
               sum = 9,073.00
               min = 16.00
               max = 6653.00
              mean = 159.18
            stddev = 876.27
            median = 16.00
              75% <= 86.50
              95% <= 89.30
              98% <= 5603.24
              99% <= 6653.00
            99.9% <= 6653.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 462.16 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 470.45 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,894.00
               min = 16.00
               max = 1473.00
              mean = 67.14
            stddev = 190.27
            median = 20.50
              75% <= 76.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 90

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1365

  worker-context-post-superstep:
    value = 9

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 53 ms
  compute all partitions: 13 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 166 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 13

  compute-per-partition-ms:
               sum = 6.00
               min = 0.00
               max = 2.00
              mean = 0.18
            stddev = 0.46
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 117

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 6.00
               min = 0.00
               max = 2.00
              mean = 0.55
            stddev = 0.93
            median = 0.00
              75% <= 2.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,953.00
               min = 16.00
               max = 6653.00
              mean = 157.07
            stddev = 894.24
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5602.76
              99% <= 6653.00
            99.9% <= 6653.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 679.08 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 691.07 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,798.00
               min = 16.00
               max = 1473.00
              mean = 65.48
            stddev = 190.27
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 53

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 166

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 123 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 205 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 1.00
              mean = 0.15
            stddev = 0.36
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.45
            stddev = 0.82
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.18
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 336.14 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 342.72 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.68
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 123

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 205

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.25487111142662

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:60154
Log Contents:
2018-08-08 15:25:05,237 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,306 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,306 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,309 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,309 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,490 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,709 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:05,892 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,340 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,353 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,506 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,520 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,547 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,548 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,555 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,562 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,562 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 6 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave15
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000009:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000009/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000009:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000009/tmp
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,568 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000009
INFO    2018-08-08 15:25:06,569 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,581 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,582 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,587 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30225, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,589 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,698 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,714 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,775 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave15/10.164.0.17:30006 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,780 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,781 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:06,801 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:06,811 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:06,814 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,817 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,823 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave15_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=6, port=30006)
INFO    2018-08-08 15:25:07,147 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,234 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,245 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,247 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,248 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,248 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,252 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,264 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,268 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,268 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,269 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,270 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,270 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,271 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,271 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,272 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,272 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,277 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,342 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,384 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04064124 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,384 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03304263 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,384 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.032318577 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,384 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.033845562 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,384 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03199414 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,385 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031411126 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,385 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031200469 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030757671 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03014828 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.029453255 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.031029684 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0042, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.039
MBytes/sec sent = 0.0066, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.039
INFO    2018-08-08 15:25:07,391 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,397 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005404708 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,397 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004655294 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004067296 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001022731 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004520604 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004222641 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00366546 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,401 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006495469 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,401 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003235883 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005453378 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004496373 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,405 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 15:25:07,405 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 15:25:07,450 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,455 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,466 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,468 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,469 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.068
MBytes/sec sent = 0.0003, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.068
INFO    2018-08-08 15:25:07,469 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,477 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,478 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,488 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,521 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,526 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
WARN    2018-08-08 15:25:07,529 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,546 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,546 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,551 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave15_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=6, port=30006)
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,586 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,586 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,587 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.109
MBytes/sec sent = 0.0128, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.109
INFO    2018-08-08 15:25:07,589 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,593 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,602 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,616 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008729645 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007184483 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011073743 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004800735 secs for 7 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002393316 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004481811 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008931445 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004239553 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013049355 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007953917 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,622 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.015925946 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,623 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50598.09M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,625 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0725, MBytesSent = 0.0002, ave sent req MBytes = 0.0001, secs waited = 0.002
INFO    2018-08-08 15:25:07,625 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,630 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,631 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 3 , message bytes = 213 , Memory (free/total/max) = 50598.09M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,637 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,655 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,658 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 15:25:07,668 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,671 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave15_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=6, port=30006)
INFO    2018-08-08 15:25:07,692 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,694 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0219, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.063
INFO    2018-08-08 15:25:07,699 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,700 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,703 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,708 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001909279 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004517805 secs for 5 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003621445 secs for 10 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004252147 secs for 15 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002910738 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001456411 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003066357 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,713 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001140513 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,713 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001322146 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,714 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001068839 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,717 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003495981 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,717 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50444.49M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,717 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0057, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.0157, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 15:25:07,717 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,719 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0661, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.2101, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,720 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 3 , message bytes = 117 , Memory (free/total/max) = 50444.49M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,726 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,744 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,748 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 15:25:07,754 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,776 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave15_6 and workerInfo= Worker(hostname=graphalytics-giraph-slave15 hostOrIp=graphalytics-giraph-slave15, MRtaskID=6, port=30006)
INFO    2018-08-08 15:25:07,782 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,825 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,851 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.13
MBytes/sec sent = 0.0107, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.131
INFO    2018-08-08 15:25:07,855 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,856 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,859 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,864 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004093309 secs for 14 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002700969 secs for 13 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002320069 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001698578 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002056034 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001677291 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002013154 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001941258 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002429443 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001657 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001836458 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,870 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,870 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 15:25:07,870 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,877 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0248, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.0788, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.007
INFO    2018-08-08 15:25:07,877 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,882 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,899 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,901 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 15:25:07,905 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,905 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,905 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,908 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:07,930 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,973 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,977 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,982 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,112 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,112 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 15:25:10,116 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,286 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,286 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,289 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/6_worker
INFO    2018-08-08 15:25:10,291 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30225 closed
INFO    2018-08-08 15:25:10,291 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,293 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,297 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,512 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,516 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000006_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:14,541 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000006_0 is allowed to commit now
INFO    2018-08-08 15:25:14,552 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000006_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000006
INFO    2018-08-08 15:25:14,576 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000006_0' done.
INFO    2018-08-08 15:25:14,581 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000006_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128720
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=21
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=90
		CPU time spent (ms)=4910
		Physical memory (bytes) snapshot=1088479232
		Virtual memory (bytes) snapshot=58910060544
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000005 on graphalytics-giraph-slave1_33157
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15676
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 777 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 344 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,675.00
               min = 16.00
               max = 6653.00
              mean = 112.50
            stddev = 714.11
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1803.78
              99% <= 6653.00
            99.9% <= 6653.00
             count = 86

  remote-requests:
    count = 0

  requests-received:
             count = 86
         mean rate = 108.56 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 96
         mean rate = 121.29 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,520.00
               min = 16.00
               max = 1473.00
              mean = 47.08
            stddev = 149.12
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 172.04
              99% <= 1473.00
            99.9% <= 1473.00
             count = 96

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 777

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 344

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 90 ms
  compute all partitions: 19 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 258 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 19

  compute-per-partition-ms:
               sum = 52.00
               min = 0.00
               max = 3.00
              mean = 1.58
            stddev = 1.39
            median = 2.00
              75% <= 3.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 50.00
               min = 2.00
               max = 6.00
              mean = 4.55
            stddev = 1.59
            median = 5.00
              75% <= 6.00
              95% <= 6.00
              98% <= 6.00
              99% <= 6.00
            99.9% <= 6.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 922.01
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 418.84 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 418.79 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 90

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 258

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 55 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 262 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 924.69
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 603.68 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 603.65 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.68
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 55

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 262

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 119 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 551 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.12
            stddev = 0.33
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.81
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 922.00
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 345.95 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 345.66 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 119

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 551

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.56476572424246

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:59961
Log Contents:
2018-08-08 15:25:05,229 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,287 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,287 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,289 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,289 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,459 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,679 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:05,857 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,306 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,318 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,456 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,470 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,496 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,497 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,505 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,511 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,512 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 2 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,517 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,517 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave1
INFO    2018-08-08 15:25:06,517 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,517 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,517 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,517 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000005:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000005/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000005:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000005/tmp
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,518 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000005
INFO    2018-08-08 15:25:06,519 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,532 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,533 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,538 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30223, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,540 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,648 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,665 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,716 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave1/10.164.0.3:30002 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,721 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,722 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:06,742 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:06,752 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:06,755 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,758 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,763 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave1_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002)
INFO    2018-08-08 15:25:07,145 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,234 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,245 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,246 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,247 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,248 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,251 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,251 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,252 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,258 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,260 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,264 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,268 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,277 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,335 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,384 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048405252 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,385 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041502155 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04090695 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040143277 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0391694 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03853285 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.038407125 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037734948 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036902893 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036309533 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03707075 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,390 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0036, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.045
MBytes/sec sent = 0.0057, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.045
INFO    2018-08-08 15:25:07,391 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,395 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004302739 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,396 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003683205 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,396 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001085547 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,397 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002932972 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003208008 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005010567 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,399 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002683315 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003686419 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004143672 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.006025944 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,406 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004493074 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,406 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 15:25:07,406 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 15:25:07,450 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,455 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 15:25:07,457 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50863.52M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,457 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0005, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.056
MBytes/sec sent = 0.0008, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.056
INFO    2018-08-08 15:25:07,457 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,478 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 15:25:07,478 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50863.52M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,491 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,522 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,527 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4ad4936c,outgoing=org.apache.giraph.conf.DefaultMessageClasses@29d37757)
WARN    2018-08-08 15:25:07,530 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,550 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,551 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,553 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave1_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002)
INFO    2018-08-08 15:25:07,584 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,586 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.108
MBytes/sec sent = 0.0129, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.108
INFO    2018-08-08 15:25:07,588 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,592 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,593 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 15:25:07,603 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,619 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011943065 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005098656 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011048862 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009507212 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007724499 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003738202 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005675608 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004596702 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010399279 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.014089128 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012704694 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,623 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50722.72M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,623 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0061, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.029
MBytes/sec sent = 0.034, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.029
INFO    2018-08-08 15:25:07,624 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,630 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,631 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.72M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,637 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,655 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,658 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27ead29e)
INFO    2018-08-08 15:25:07,668 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,671 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave1_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002)
INFO    2018-08-08 15:25:07,692 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,694 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0219, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.063
INFO    2018-08-08 15:25:07,696 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,700 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,703 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,707 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002410029 secs for 12 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,707 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003552291 secs for 21 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,707 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001940656 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003342054 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001941781 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002347491 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002017364 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00392328 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00157479 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,711 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001865718 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,713 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003415435 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,714 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50569.12M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,714 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 15:25:07,714 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,723 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0031, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0048, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 15:25:07,723 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50569.12M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,727 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,745 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,749 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@56febdc)
INFO    2018-08-08 15:25:07,756 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,776 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave1_2 and workerInfo= Worker(hostname=graphalytics-giraph-slave1 hostOrIp=graphalytics-giraph-slave1, MRtaskID=2, port=30002)
WARN    2018-08-08 15:25:07,826 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,848 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,850 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.127
MBytes/sec sent = 0.011, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.127
INFO    2018-08-08 15:25:07,855 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,856 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,859 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,864 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004261149 secs for 12 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002751786 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002221673 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003314693 secs for 15 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001675675 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001185057 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001680635 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00123996 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001216821 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,868 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001622784 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,870 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003415124 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,870 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50428.31M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.014
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,875 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,875 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50428.31M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,879 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,899 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,902 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@712ca57b,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4564e94b)
INFO    2018-08-08 15:25:07,907 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,907 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,907 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,910 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:07,930 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,973 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,978 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,982 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,215 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,215 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 15:25:10,219 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,256 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,256 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,258 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/2_worker
INFO    2018-08-08 15:25:10,260 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30223 closed
INFO    2018-08-08 15:25:10,261 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,263 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,267 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,481 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,486 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000002_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:15,524 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000002_0 is allowed to commit now
INFO    2018-08-08 15:25:15,534 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000002_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000002
INFO    2018-08-08 15:25:15,552 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000002_0' done.
INFO    2018-08-08 15:25:15,558 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000002_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128720
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=99
		CPU time spent (ms)=4350
		Physical memory (bytes) snapshot=1075335168
		Virtual memory (bytes) snapshot=58876010496
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000007 on graphalytics-giraph-slave2_43787
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15697
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 697 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 361 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 11.11111111111111

  received-bytes:
               sum = 10,053.00
               min = 16.00
               max = 6653.00
              mean = 103.64
            stddev = 672.78
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 438.92
              99% <= 6653.00
            99.9% <= 6653.00
             count = 97

  remote-requests:
    count = 8

  requests-received:
             count = 97
         mean rate = 136.33 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 107
         mean rate = 150.58 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 5,129.00
               min = 16.00
               max = 1473.00
              mean = 47.93
            stddev = 141.51
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 105.80
              99% <= 1363.88
            99.9% <= 1473.00
             count = 107

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 697

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 9

  wait-requests-us:
    value = 361

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 91 ms
  compute all partitions: 15 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 5922 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 15

  compute-per-partition-ms:
               sum = 39.00
               min = 0.00
               max = 8.00
              mean = 1.18
            stddev = 1.53
            median = 1.00
              75% <= 1.50
              95% <= 4.50
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 316

  messages-sent:
    count = 4

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 39.00
               min = 0.00
               max = 8.00
              mean = 3.55
            stddev = 2.25
            median = 4.00
              75% <= 5.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 9,125.00
               min = 16.00
               max = 6564.00
              mean = 152.08
            stddev = 842.54
            median = 34.50
              75% <= 76.00
              95% <= 89.00
              98% <= 5139.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 60

  remote-requests:
    count = 4

  requests-received:
             count = 60
         mean rate = 493.12 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 60
         mean rate = 493.18 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 4

  sent-bytes:
               sum = 4,018.00
               min = 16.00
               max = 1473.00
              mean = 66.97
            stddev = 187.14
            median = 20.50
              75% <= 84.00
              95% <= 89.00
              98% <= 1168.52
              99% <= 1473.00
            99.9% <= 1473.00
             count = 60

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 91

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 4

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 5922

  worker-context-post-superstep:
    value = 9

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 56 ms
  compute all partitions: 9 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 203 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 9

  compute-per-partition-ms:
               sum = 7.00
               min = 0.00
               max = 3.00
              mean = 0.21
            stddev = 0.60
            median = 0.00
              75% <= 0.00
              95% <= 1.60
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 156

  messages-sent:
    count = 4

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 7.00
               min = 0.00
               max = 3.00
              mean = 0.64
            stddev = 1.03
            median = 0.00
              75% <= 1.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 11

  received-bytes:
               sum = 9,013.00
               min = 16.00
               max = 6564.00
              mean = 150.22
            stddev = 858.71
            median = 30.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5139.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 60

  remote-requests:
    count = 4

  requests-received:
             count = 60
         mean rate = 685.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 60
         mean rate = 685.74 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 4

  sent-bytes:
               sum = 3,858.00
               min = 16.00
               max = 1473.00
              mean = 64.30
            stddev = 187.15
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1168.52
              99% <= 1473.00
            99.9% <= 1473.00
             count = 60

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 56

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 4

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 203

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 124 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 166 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 3.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.29
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 905.92
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 342.70 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 342.69 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.71
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 124

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 166

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.22444871220276

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = 0.0

  edges-loaded:
             count = 24
         mean rate = 6.64 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:60523
Log Contents:
2018-08-08 15:25:05,324 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,383 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,383 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,386 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,386 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,553 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,766 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:05,948 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,389 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,401 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,540 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,554 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,583 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,583 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,592 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,599 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,599 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 4 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave2
INFO    2018-08-08 15:25:06,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000007:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000007/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000007:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,605 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000007/tmp
INFO    2018-08-08 15:25:06,606 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,606 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,606 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,606 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,606 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,606 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,606 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000007
INFO    2018-08-08 15:25:06,606 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,619 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,620 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,625 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30226, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,626 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,729 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,744 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,796 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave2/10.164.0.4:30004 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,801 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,802 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:06,823 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:06,832 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:06,835 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,838 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,845 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave2_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=4, port=30004)
INFO    2018-08-08 15:25:07,146 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,233 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,242 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,244 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,245 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,247 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,247 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,247 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,247 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,248 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,248 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,248 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,249 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,249 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,249 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,249 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,257 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,261 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,261 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,267 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,270 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,337 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,385 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041480612 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,385 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0404992 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,385 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047537353 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,385 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039988495 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039781373 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039495748 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03886442 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03794873 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03817887 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.037874386 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03787146 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0036, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.045
MBytes/sec sent = 0.0057, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.045
INFO    2018-08-08 15:25:07,390 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,394 [load-0] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/example-undirected.e:0+49'
INFO    2018-08-08 15:25:07,395 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003011542 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,395 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002776558 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,396 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003126328 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,397 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003459364 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003233899 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002149665 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,399 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002656831 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002507323 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003237569 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004155681 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,416 [load-0] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=0, e=24)
INFO    2018-08-08 15:25:07,417 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 0.02655258 secs, (v=0, e=24) 0.0 vertices/sec, 903.86694 edges/sec
INFO    2018-08-08 15:25:07,436 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0064, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.018
MBytes/sec sent = 0.0277, MBytesSent = 0.0005, ave sent req MBytes = 0.0001, secs waited = 0.018
INFO    2018-08-08 15:25:07,437 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=24)
INFO    2018-08-08 15:25:07,451 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,455 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,463 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,464 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,465 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0026, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.047
MBytes/sec sent = 0.011, MBytesSent = 0.0005, ave sent req MBytes = 0.0001, secs waited = 0.047
INFO    2018-08-08 15:25:07,465 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,478 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,479 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,489 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,523 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,528 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
WARN    2018-08-08 15:25:07,531 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,545 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,545 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,548 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave2_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=4, port=30004)
INFO    2018-08-08 15:25:07,586 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,587 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,587 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,588 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.109
MBytes/sec sent = 0.0128, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.109
INFO    2018-08-08 15:25:07,590 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,594 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,594 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 15:25:07,604 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,615 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004023241 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001881967 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007534995 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005248489 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005850898 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003354497 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007036298 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003964468 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00997946 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008438796 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.013708621 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,620 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.09M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,626 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0087, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0458, MBytesSent = 0.0003, ave sent req MBytes = 0.0001, secs waited = 0.006
INFO    2018-08-08 15:25:07,626 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,632 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,632 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 4 , message bytes = 316 , Memory (free/total/max) = 50582.09M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,635 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,656 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,658 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 15:25:07,665 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,667 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave2_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=4, port=30004)
INFO    2018-08-08 15:25:07,694 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,694 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,695 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,696 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0219, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.064
INFO    2018-08-08 15:25:07,697 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,701 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,705 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,709 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002955528 secs for 15 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002091084 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001829121 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002493892 secs for 10 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004333911 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00147184 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00201588 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,711 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001842492 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001850004 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001440253 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,714 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003028323 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,715 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,715 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0102, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.028, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 15:25:07,715 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,721 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,722 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 4 , message bytes = 156 , Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,724 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,746 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,749 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 15:25:07,755 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,777 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave2_4 and workerInfo= Worker(hostname=graphalytics-giraph-slave2 hostOrIp=graphalytics-giraph-slave2, MRtaskID=4, port=30004)
WARN    2018-08-08 15:25:07,827 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,850 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,850 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,850 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,851 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.129
MBytes/sec sent = 0.0108, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.129
INFO    2018-08-08 15:25:07,856 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,857 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,861 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,865 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00335636 secs for 12 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001573471 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001753186 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002418659 secs for 14 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001417947 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001959024 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 9.69731E-4 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002227346 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,868 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001125359 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,868 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002012385 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,872 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004968455 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,873 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,873 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0108, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.016
MBytes/sec sent = 0.0599, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.016
INFO    2018-08-08 15:25:07,873 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,879 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,879 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,884 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,901 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,903 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 15:25:07,907 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,907 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,907 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,909 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:07,931 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,974 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,979 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,984 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,014 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,014 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 15:25:10,017 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,178 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,178 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,181 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/4_worker
INFO    2018-08-08 15:25:10,183 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30226 closed
INFO    2018-08-08 15:25:10,183 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,186 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,189 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,400 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,405 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000004_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:14,431 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000004_0 is allowed to commit now
INFO    2018-08-08 15:25:14,441 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000004_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000004
INFO    2018-08-08 15:25:14,459 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000004_0' done.
INFO    2018-08-08 15:25:14,464 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000004_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128720
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=93
		HDFS: Number of bytes written=21
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=92
		CPU time spent (ms)=4250
		Physical memory (bytes) snapshot=1119821824
		Virtual memory (bytes) snapshot=58913042432
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000001 on graphalytics-giraph-slave3_42077
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:25 +0000 2018
LogLength:2248
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/11/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Aug 08, 2018 3:25:00 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver as a provider class
Aug 08, 2018 3:25:00 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
Aug 08, 2018 3:25:00 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices as a root resource class
Aug 08, 2018 3:25:00 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.9 09/02/2011 11:17 AM'
Aug 08, 2018 3:25:00 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
Aug 08, 2018 3:25:01 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
Aug 08, 2018 3:25:01 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices to GuiceManagedComponentProvider with the scope "PerRequest"
log4j:WARN No appenders could be found for logger (org.apache.hadoop.ipc.Server).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:25 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:25 +0000 2018
LogLength:118663
Log Contents:
2018-08-08 15:24:57,604 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1533735211869_0040_000001
2018-08-08 15:24:57,829 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens:
2018-08-08 15:24:57,829 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 40 cluster_timestamp: 1533735211869 } attemptId: 1 } keyId: -63235253)
2018-08-08 15:24:58,115 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Using mapred newApiCommitter.
2018-08-08 15:24:58,118 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config null
2018-08-08 15:24:58,200 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:24:58,695 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is org.apache.giraph.io.internal.WrappedVertexOutputFormat$2
2018-08-08 15:24:58,879 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler
2018-08-08 15:24:58,880 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher
2018-08-08 15:24:58,881 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher
2018-08-08 15:24:58,882 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher
2018-08-08 15:24:58,882 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler
2018-08-08 15:24:58,888 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher
2018-08-08 15:24:58,888 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter
2018-08-08 15:24:58,889 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter
2018-08-08 15:24:58,933 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 15:24:58,950 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 15:24:58,964 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://graphalytics-giraph:9000]
2018-08-08 15:24:58,973 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled
2018-08-08 15:24:59,036 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler
2018-08-08 15:24:59,113 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:24:59,170 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:24:59,170 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MRAppMaster metrics system started
2018-08-08 15:24:59,180 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for job_1533735211869_0040 to jobTokenSecretManager
2018-08-08 15:24:59,282 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing job_1533735211869_0040 because: not enabled; too many maps; too much RAM;
2018-08-08 15:24:59,315 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job job_1533735211869_0040 = 0. Number of splits = 14
2018-08-08 15:24:59,316 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job job_1533735211869_0040 = 0
2018-08-08 15:24:59,316 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0040Job Transitioned from NEW to INITED
2018-08-08 15:24:59,317 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job job_1533735211869_0040.
2018-08-08 15:24:59,346 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2018-08-08 15:24:59,354 INFO [Socket Reader #1 for port 41157] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 41157
2018-08-08 15:24:59,416 INFO [main] org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server
2018-08-08 15:24:59,417 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-08-08 15:24:59,417 INFO [IPC Server listener on 41157] org.apache.hadoop.ipc.Server: IPC Server listener on 41157: starting
2018-08-08 15:24:59,428 INFO [main] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at graphalytics-giraph-slave3/10.164.0.5:41157
2018-08-08 15:24:59,582 INFO [main] org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-08-08 15:24:59,599 INFO [main] org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-08-08 15:24:59,603 INFO [main] org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined
2018-08-08 15:24:59,668 INFO [main] org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-08-08 15:24:59,688 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce
2018-08-08 15:24:59,688 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static
2018-08-08 15:24:59,692 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /mapreduce/*
2018-08-08 15:24:59,692 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-08-08 15:24:59,974 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-08-08 15:24:59,975 INFO [main] org.apache.hadoop.http.HttpServer2: Jetty bound to port 33871
2018-08-08 15:24:59,975 INFO [main] org.mortbay.log: jetty-6.1.26
2018-08-08 15:25:00,055 INFO [main] org.mortbay.log: Extract jar:file:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar!/webapps/mapreduce to /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000001/tmp/Jetty_0_0_0_0_33871_mapreduce____gm2hxj/webapp
2018-08-08 15:25:01,371 INFO [main] org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:33871
2018-08-08 15:25:01,372 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Web app mapreduce started at 33871
2018-08-08 15:25:01,375 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: JOB_CREATE job_1533735211869_0040
2018-08-08 15:25:01,377 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 3000
2018-08-08 15:25:01,377 INFO [Socket Reader #1 for port 39587] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 39587
2018-08-08 15:25:01,385 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-08-08 15:25:01,385 INFO [IPC Server listener on 39587] org.apache.hadoop.ipc.Server: IPC Server listener on 39587: starting
2018-08-08 15:25:01,430 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true
2018-08-08 15:25:01,430 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: maxTaskFailuresPerNode is 3
2018-08-08 15:25:01,430 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: blacklistDisablePercent is 33
2018-08-08 15:25:01,463 INFO [main] org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at graphalytics-giraph/10.164.0.2:8030
2018-08-08 15:25:01,608 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: maxContainerCapability: <memory:57344, vCores:32>
2018-08-08 15:25:01,608 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: queue: default
2018-08-08 15:25:01,612 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500
2018-08-08 15:25:01,612 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: The thread pool initial size is 10
2018-08-08 15:25:01,645 INFO [main] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2018-08-08 15:25:01,709 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0040Job Transitioned from INITED to SETUP
2018-08-08 15:25:01,712 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_SETUP
2018-08-08 15:25:01,744 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0040Job Transitioned from SETUP to RUNNING
2018-08-08 15:25:01,754 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1533735211869_0040, File: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0040/job_1533735211869_0040_1.jhist
2018-08-08 15:25:01,766 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000000 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,767 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000001 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,767 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000002 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,767 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000003 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,767 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000004 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,768 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000005 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,768 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000006 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,768 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000007 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,769 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000008 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,769 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000009 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,769 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000010 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,769 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000011 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,770 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000012 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,770 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000013 Task Transitioned from NEW to SCHEDULED
2018-08-08 15:25:01,773 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,774 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000001_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,776 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000002_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,777 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000003_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,777 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000004_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,779 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000005_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,780 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000006_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,781 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000007_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,782 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000008_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,782 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000009_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,783 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000010_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,784 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000011_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,785 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000012_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,786 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000013_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2018-08-08 15:25:01,790 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: mapResourceRequest:<memory:57344, vCores:1>
2018-08-08 15:25:02,611 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:14 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 15:25:02,655 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1533735211869_0040: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:858112, vCores:1> knownNMs=15
2018-08-08 15:25:03,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 14
2018-08-08 15:25:03,676 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave14 to /default-rack
2018-08-08 15:25:03,677 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave10 to /default-rack
2018-08-08 15:25:03,677 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave1 to /default-rack
2018-08-08 15:25:03,678 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave8 to /default-rack
2018-08-08 15:25:03,678 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave2 to /default-rack
2018-08-08 15:25:03,678 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave13 to /default-rack
2018-08-08 15:25:03,678 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave15 to /default-rack
2018-08-08 15:25:03,678 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave11 to /default-rack
2018-08-08 15:25:03,678 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave4 to /default-rack
2018-08-08 15:25:03,678 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave5 to /default-rack
2018-08-08 15:25:03,678 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave12 to /default-rack
2018-08-08 15:25:03,678 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave7 to /default-rack
2018-08-08 15:25:03,678 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave9 to /default-rack
2018-08-08 15:25:03,678 INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave6 to /default-rack
2018-08-08 15:25:03,680 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000003 to attempt_1533735211869_0040_m_000000_0
2018-08-08 15:25:03,681 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000004 to attempt_1533735211869_0040_m_000001_0
2018-08-08 15:25:03,681 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000005 to attempt_1533735211869_0040_m_000002_0
2018-08-08 15:25:03,682 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000006 to attempt_1533735211869_0040_m_000003_0
2018-08-08 15:25:03,682 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000007 to attempt_1533735211869_0040_m_000004_0
2018-08-08 15:25:03,682 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000008 to attempt_1533735211869_0040_m_000005_0
2018-08-08 15:25:03,682 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000009 to attempt_1533735211869_0040_m_000006_0
2018-08-08 15:25:03,682 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000010 to attempt_1533735211869_0040_m_000007_0
2018-08-08 15:25:03,682 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000011 to attempt_1533735211869_0040_m_000008_0
2018-08-08 15:25:03,682 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000012 to attempt_1533735211869_0040_m_000009_0
2018-08-08 15:25:03,683 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000013 to attempt_1533735211869_0040_m_000010_0
2018-08-08 15:25:03,683 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000014 to attempt_1533735211869_0040_m_000011_0
2018-08-08 15:25:03,683 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000015 to attempt_1533735211869_0040_m_000012_0
2018-08-08 15:25:03,683 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1533735211869_0040_01_000016 to attempt_1533735211869_0040_m_000013_0
2018-08-08 15:25:03,684 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:14 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 15:25:03,722 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave14 to /default-rack
2018-08-08 15:25:03,739 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-jar file on the remote FS is hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0040/job.jar
2018-08-08 15:25:03,742 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0040/job.xml
2018-08-08 15:25:03,743 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Adding #0 tokens and #1 secret keys for NM use for launching container
2018-08-08 15:25:03,743 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Size of containertokens_dob is 1
2018-08-08 15:25:03,743 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Putting shuffle token in serviceData
2018-08-08 15:25:03,802 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,805 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave10 to /default-rack
2018-08-08 15:25:03,805 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,806 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave1 to /default-rack
2018-08-08 15:25:03,807 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,807 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave8 to /default-rack
2018-08-08 15:25:03,808 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000003_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,808 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave2 to /default-rack
2018-08-08 15:25:03,808 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000004_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,808 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave13 to /default-rack
2018-08-08 15:25:03,809 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000005_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,809 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave15 to /default-rack
2018-08-08 15:25:03,809 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000006_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,809 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave11 to /default-rack
2018-08-08 15:25:03,810 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000007_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,810 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave4 to /default-rack
2018-08-08 15:25:03,811 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000008_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,811 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave5 to /default-rack
2018-08-08 15:25:03,811 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000009_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,811 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave12 to /default-rack
2018-08-08 15:25:03,813 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000010_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,813 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave7 to /default-rack
2018-08-08 15:25:03,813 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000011_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave9 to /default-rack
2018-08-08 15:25:03,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000012_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved graphalytics-giraph-slave6 to /default-rack
2018-08-08 15:25:03,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000013_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2018-08-08 15:25:03,817 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000003 taskAttempt attempt_1533735211869_0040_m_000000_0
2018-08-08 15:25:03,817 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000004 taskAttempt attempt_1533735211869_0040_m_000001_0
2018-08-08 15:25:03,819 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000005 taskAttempt attempt_1533735211869_0040_m_000002_0
2018-08-08 15:25:03,819 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000007 taskAttempt attempt_1533735211869_0040_m_000004_0
2018-08-08 15:25:03,820 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000006 taskAttempt attempt_1533735211869_0040_m_000003_0
2018-08-08 15:25:03,820 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000009 taskAttempt attempt_1533735211869_0040_m_000006_0
2018-08-08 15:25:03,820 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000008 taskAttempt attempt_1533735211869_0040_m_000005_0
2018-08-08 15:25:03,821 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000010 taskAttempt attempt_1533735211869_0040_m_000007_0
2018-08-08 15:25:03,822 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000011 taskAttempt attempt_1533735211869_0040_m_000008_0
2018-08-08 15:25:03,822 INFO [ContainerLauncher Event Handler] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Setting ContainerLauncher pool size to 21 as number-of-nodes to talk to is 11
2018-08-08 15:25:03,824 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000012 taskAttempt attempt_1533735211869_0040_m_000009_0
2018-08-08 15:25:03,824 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000013 taskAttempt attempt_1533735211869_0040_m_000010_0
2018-08-08 15:25:03,824 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000014 taskAttempt attempt_1533735211869_0040_m_000011_0
2018-08-08 15:25:03,827 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000015 taskAttempt attempt_1533735211869_0040_m_000012_0
2018-08-08 15:25:03,827 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000012_0
2018-08-08 15:25:03,826 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000006_0
2018-08-08 15:25:03,826 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000003_0
2018-08-08 15:25:03,826 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000008_0
2018-08-08 15:25:03,828 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1533735211869_0040_01_000016 taskAttempt attempt_1533735211869_0040_m_000013_0
2018-08-08 15:25:03,826 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000001_0
2018-08-08 15:25:03,826 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000005_0
2018-08-08 15:25:03,826 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000000_0
2018-08-08 15:25:03,826 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000007_0
2018-08-08 15:25:03,826 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000009_0
2018-08-08 15:25:03,826 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000010_0
2018-08-08 15:25:03,826 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000002_0
2018-08-08 15:25:03,826 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000004_0
2018-08-08 15:25:03,828 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000013_0
2018-08-08 15:25:03,827 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1533735211869_0040_m_000011_0
2018-08-08 15:25:03,832 INFO [ContainerLauncher #12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave9:37771
2018-08-08 15:25:03,923 INFO [ContainerLauncher #11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave7:43383
2018-08-08 15:25:03,925 INFO [ContainerLauncher #13] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave6:36387
2018-08-08 15:25:03,930 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave2:43787
2018-08-08 15:25:03,932 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave1:33157
2018-08-08 15:25:03,935 INFO [ContainerLauncher #10] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave12:33893
2018-08-08 15:25:03,937 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave5:46217
2018-08-08 15:25:03,939 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave11:46641
2018-08-08 15:25:03,939 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave14:35219
2018-08-08 15:25:03,940 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave13:40615
2018-08-08 15:25:03,942 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave10:46663
2018-08-08 15:25:03,943 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave4:46069
2018-08-08 15:25:03,944 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave8:41519
2018-08-08 15:25:03,946 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave15:37797
2018-08-08 15:25:04,019 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000009_0 : 13562
2018-08-08 15:25:04,019 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000006_0 : 13562
2018-08-08 15:25:04,019 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000012_0 : 13562
2018-08-08 15:25:04,019 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000003_0 : 13562
2018-08-08 15:25:04,019 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000002_0 : 13562
2018-08-08 15:25:04,019 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000000_0 : 13562
2018-08-08 15:25:04,019 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000001_0 : 13562
2018-08-08 15:25:04,019 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000011_0 : 13562
2018-08-08 15:25:04,024 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000009_0] using containerId: [container_1533735211869_0040_01_000012 on NM: [graphalytics-giraph-slave5:46217]
2018-08-08 15:25:04,027 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000008_0 : 13562
2018-08-08 15:25:04,027 INFO [ContainerLauncher #13] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000013_0 : 13562
2018-08-08 15:25:04,027 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000007_0 : 13562
2018-08-08 15:25:04,029 INFO [ContainerLauncher #10] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000010_0 : 13562
2018-08-08 15:25:04,029 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000004_0 : 13562
2018-08-08 15:25:04,030 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000009_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,030 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000000_0] using containerId: [container_1533735211869_0040_01_000003 on NM: [graphalytics-giraph-slave14:35219]
2018-08-08 15:25:04,030 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,030 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000002_0] using containerId: [container_1533735211869_0040_01_000005 on NM: [graphalytics-giraph-slave1:33157]
2018-08-08 15:25:04,030 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1533735211869_0040_m_000005_0 : 13562
2018-08-08 15:25:04,030 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000002_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,031 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000003_0] using containerId: [container_1533735211869_0040_01_000006 on NM: [graphalytics-giraph-slave8:41519]
2018-08-08 15:25:04,031 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000003_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,031 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000001_0] using containerId: [container_1533735211869_0040_01_000004 on NM: [graphalytics-giraph-slave10:46663]
2018-08-08 15:25:04,031 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000001_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,032 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000012_0] using containerId: [container_1533735211869_0040_01_000015 on NM: [graphalytics-giraph-slave9:37771]
2018-08-08 15:25:04,032 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000012_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,032 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000011_0] using containerId: [container_1533735211869_0040_01_000014 on NM: [graphalytics-giraph-slave7:43383]
2018-08-08 15:25:04,032 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000011_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,032 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000006_0] using containerId: [container_1533735211869_0040_01_000009 on NM: [graphalytics-giraph-slave15:37797]
2018-08-08 15:25:04,032 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000006_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,033 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000008_0] using containerId: [container_1533735211869_0040_01_000011 on NM: [graphalytics-giraph-slave4:46069]
2018-08-08 15:25:04,033 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000008_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,033 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000013_0] using containerId: [container_1533735211869_0040_01_000016 on NM: [graphalytics-giraph-slave6:36387]
2018-08-08 15:25:04,033 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000013_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,033 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000007_0] using containerId: [container_1533735211869_0040_01_000010 on NM: [graphalytics-giraph-slave11:46641]
2018-08-08 15:25:04,034 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000007_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,034 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000010_0] using containerId: [container_1533735211869_0040_01_000013 on NM: [graphalytics-giraph-slave12:33893]
2018-08-08 15:25:04,034 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000010_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,034 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000004_0] using containerId: [container_1533735211869_0040_01_000007 on NM: [graphalytics-giraph-slave2:43787]
2018-08-08 15:25:04,034 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000004_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,034 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000009 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,034 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000000 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,035 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000002 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,035 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1533735211869_0040_m_000005_0] using containerId: [container_1533735211869_0040_01_000008 on NM: [graphalytics-giraph-slave13:40615]
2018-08-08 15:25:04,035 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000005_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2018-08-08 15:25:04,035 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000003 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,036 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000001 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,036 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000012 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,036 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000011 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,037 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000006 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,038 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000008 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,038 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000013 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,038 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000007 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,038 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000010 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,038 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000004 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,038 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000005 Task Transitioned from SCHEDULED to RUNNING
2018-08-08 15:25:04,687 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1533735211869_0040: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:55296, vCores:1> knownNMs=15
2018-08-08 15:25:05,526 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,544 INFO [IPC Server handler 0 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000015 asked for a task
2018-08-08 15:25:05,545 INFO [IPC Server handler 0 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000015 given task: attempt_1533735211869_0040_m_000012_0
2018-08-08 15:25:05,592 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,604 INFO [IPC Server handler 3 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000005 asked for a task
2018-08-08 15:25:05,604 INFO [IPC Server handler 3 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000005 given task: attempt_1533735211869_0040_m_000002_0
2018-08-08 15:25:05,625 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,635 INFO [IPC Server handler 2 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000009 asked for a task
2018-08-08 15:25:05,636 INFO [IPC Server handler 2 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000009 given task: attempt_1533735211869_0040_m_000006_0
2018-08-08 15:25:05,646 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,657 INFO [IPC Server handler 4 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000003 asked for a task
2018-08-08 15:25:05,657 INFO [IPC Server handler 4 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000003 given task: attempt_1533735211869_0040_m_000000_0
2018-08-08 15:25:05,672 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,675 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,681 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,682 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,684 INFO [IPC Server handler 5 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000010 asked for a task
2018-08-08 15:25:05,684 INFO [IPC Server handler 5 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000010 given task: attempt_1533735211869_0040_m_000007_0
2018-08-08 15:25:05,689 INFO [IPC Server handler 6 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000012 asked for a task
2018-08-08 15:25:05,689 INFO [IPC Server handler 6 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000012 given task: attempt_1533735211869_0040_m_000009_0
2018-08-08 15:25:05,693 INFO [IPC Server handler 1 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000007 asked for a task
2018-08-08 15:25:05,693 INFO [IPC Server handler 1 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000007 given task: attempt_1533735211869_0040_m_000004_0
2018-08-08 15:25:05,693 INFO [IPC Server handler 7 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000004 asked for a task
2018-08-08 15:25:05,693 INFO [IPC Server handler 7 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000004 given task: attempt_1533735211869_0040_m_000001_0
2018-08-08 15:25:05,709 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,709 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,721 INFO [IPC Server handler 8 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000016 asked for a task
2018-08-08 15:25:05,721 INFO [IPC Server handler 8 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000016 given task: attempt_1533735211869_0040_m_000013_0
2018-08-08 15:25:05,722 INFO [IPC Server handler 10 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000008 asked for a task
2018-08-08 15:25:05,722 INFO [IPC Server handler 10 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000008 given task: attempt_1533735211869_0040_m_000005_0
2018-08-08 15:25:05,732 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,737 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,745 INFO [IPC Server handler 9 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000006 asked for a task
2018-08-08 15:25:05,745 INFO [IPC Server handler 9 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000006 given task: attempt_1533735211869_0040_m_000003_0
2018-08-08 15:25:05,746 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,749 INFO [IPC Server handler 11 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000014 asked for a task
2018-08-08 15:25:05,749 INFO [IPC Server handler 11 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000014 given task: attempt_1533735211869_0040_m_000011_0
2018-08-08 15:25:05,758 INFO [IPC Server handler 12 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000013 asked for a task
2018-08-08 15:25:05,758 INFO [IPC Server handler 12 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000013 given task: attempt_1533735211869_0040_m_000010_0
2018-08-08 15:25:05,761 INFO [Socket Reader #1 for port 39587] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1533735211869_0040 (auth:SIMPLE)
2018-08-08 15:25:05,775 INFO [IPC Server handler 13 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1533735211869_0040_m_000011 asked for a task
2018-08-08 15:25:05,775 INFO [IPC Server handler 13 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1533735211869_0040_m_000011 given task: attempt_1533735211869_0040_m_000008_0
2018-08-08 15:25:12,194 INFO [IPC Server handler 15 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000012_0 is : 1.0
2018-08-08 15:25:12,299 INFO [IPC Server handler 17 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000002_0 is : 1.0
2018-08-08 15:25:12,315 INFO [IPC Server handler 18 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000000_0 is : 1.0
2018-08-08 15:25:12,332 INFO [IPC Server handler 19 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000006_0 is : 1.0
2018-08-08 15:25:12,382 INFO [IPC Server handler 20 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000004_0 is : 1.0
2018-08-08 15:25:12,410 INFO [IPC Server handler 0 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000009_0 is : 1.0
2018-08-08 15:25:12,412 INFO [IPC Server handler 3 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000007_0 is : 1.0
2018-08-08 15:25:12,420 INFO [IPC Server handler 2 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000001_0 is : 1.0
2018-08-08 15:25:12,422 INFO [IPC Server handler 4 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000005_0 is : 1.0
2018-08-08 15:25:12,438 INFO [IPC Server handler 5 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000013_0 is : 1.0
2018-08-08 15:25:12,465 INFO [IPC Server handler 6 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000010_0 is : 1.0
2018-08-08 15:25:12,497 INFO [IPC Server handler 1 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000003_0 is : 1.0
2018-08-08 15:25:12,518 INFO [IPC Server handler 7 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000011_0 is : 1.0
2018-08-08 15:25:12,541 INFO [IPC Server handler 8 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000008_0 is : 1.0
2018-08-08 15:25:14,402 INFO [IPC Server handler 24 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000004_0 is : 1.0
2018-08-08 15:25:14,412 INFO [IPC Server handler 3 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000010_0 is : 1.0
2018-08-08 15:25:14,427 INFO [IPC Server handler 2 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000004_0
2018-08-08 15:25:14,428 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000004_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,429 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000004_0 given a go for committing the task output.
2018-08-08 15:25:14,429 INFO [IPC Server handler 4 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000004_0
2018-08-08 15:25:14,430 INFO [IPC Server handler 4 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000004_0:true
2018-08-08 15:25:14,436 INFO [IPC Server handler 5 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000010_0
2018-08-08 15:25:14,438 INFO [IPC Server handler 6 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000010_0
2018-08-08 15:25:14,439 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000010_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,439 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000010_0 given a go for committing the task output.
2018-08-08 15:25:14,455 INFO [IPC Server handler 1 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000004_0 is : 1.0
2018-08-08 15:25:14,457 INFO [IPC Server handler 7 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000004_0
2018-08-08 15:25:14,460 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000004_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:14,461 INFO [ContainerLauncher #14] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000007 taskAttempt attempt_1533735211869_0040_m_000004_0
2018-08-08 15:25:14,462 INFO [ContainerLauncher #14] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000004_0
2018-08-08 15:25:14,462 INFO [ContainerLauncher #14] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave2:43787
2018-08-08 15:25:14,467 INFO [IPC Server handler 8 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000013_0 is : 1.0
2018-08-08 15:25:14,473 INFO [IPC Server handler 10 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000012_0 is : 1.0
2018-08-08 15:25:14,481 INFO [IPC Server handler 9 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000001_0 is : 1.0
2018-08-08 15:25:14,485 INFO [IPC Server handler 11 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000002_0 is : 1.0
2018-08-08 15:25:14,490 INFO [IPC Server handler 12 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000013_0
2018-08-08 15:25:14,490 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000004_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:14,492 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000013_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,492 INFO [IPC Server handler 13 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000013_0
2018-08-08 15:25:14,493 INFO [IPC Server handler 14 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000011_0 is : 1.0
2018-08-08 15:25:14,496 INFO [IPC Server handler 15 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000012_0
2018-08-08 15:25:14,497 INFO [IPC Server handler 16 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000012_0
2018-08-08 15:25:14,505 INFO [IPC Server handler 17 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000003_0 is : 1.0
2018-08-08 15:25:14,508 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000004_0
2018-08-08 15:25:14,510 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000004 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:14,510 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000013_0 given a go for committing the task output.
2018-08-08 15:25:14,511 INFO [IPC Server handler 18 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000002_0
2018-08-08 15:25:14,513 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000012_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,515 INFO [IPC Server handler 19 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000001_0
2018-08-08 15:25:14,515 INFO [IPC Server handler 21 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000006_0 is : 1.0
2018-08-08 15:25:14,515 INFO [IPC Server handler 19 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000002_0
2018-08-08 15:25:14,516 INFO [IPC Server handler 22 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000011_0
2018-08-08 15:25:14,517 INFO [IPC Server handler 22 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000001_0
2018-08-08 15:25:14,517 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 1
2018-08-08 15:25:14,519 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000002_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,519 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000012_0 given a go for committing the task output.
2018-08-08 15:25:14,520 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000001_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,522 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000011_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,522 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000002_0 given a go for committing the task output.
2018-08-08 15:25:14,522 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000001_0 given a go for committing the task output.
2018-08-08 15:25:14,522 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000011_0 given a go for committing the task output.
2018-08-08 15:25:14,522 INFO [IPC Server handler 26 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000011_0
2018-08-08 15:25:14,523 INFO [IPC Server handler 26 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000011_0:true
2018-08-08 15:25:14,527 INFO [IPC Server handler 25 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000003_0
2018-08-08 15:25:14,528 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000003_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,529 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000003_0 given a go for committing the task output.
2018-08-08 15:25:14,529 INFO [IPC Server handler 27 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000003_0
2018-08-08 15:25:14,530 INFO [IPC Server handler 27 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000003_0:true
2018-08-08 15:25:14,539 INFO [IPC Server handler 24 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000006_0
2018-08-08 15:25:14,540 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000006_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,540 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000006_0 given a go for committing the task output.
2018-08-08 15:25:14,541 INFO [IPC Server handler 28 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000006_0
2018-08-08 15:25:14,541 INFO [IPC Server handler 28 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000006_0:true
2018-08-08 15:25:14,549 INFO [IPC Server handler 29 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000011_0 is : 1.0
2018-08-08 15:25:14,551 INFO [IPC Server handler 3 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000011_0
2018-08-08 15:25:14,552 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000011_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:14,553 INFO [ContainerLauncher #15] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000014 taskAttempt attempt_1533735211869_0040_m_000011_0
2018-08-08 15:25:14,553 INFO [ContainerLauncher #15] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000011_0
2018-08-08 15:25:14,553 INFO [ContainerLauncher #15] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave7:43383
2018-08-08 15:25:14,556 INFO [IPC Server handler 0 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000003_0 is : 1.0
2018-08-08 15:25:14,560 INFO [IPC Server handler 2 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000003_0
2018-08-08 15:25:14,562 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000003_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:14,564 INFO [ContainerLauncher #16] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000006 taskAttempt attempt_1533735211869_0040_m_000003_0
2018-08-08 15:25:14,565 INFO [ContainerLauncher #16] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000003_0
2018-08-08 15:25:14,565 INFO [ContainerLauncher #16] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave8:41519
2018-08-08 15:25:14,573 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000011_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:14,573 INFO [IPC Server handler 4 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000006_0 is : 1.0
2018-08-08 15:25:14,574 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000011_0
2018-08-08 15:25:14,574 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000011 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:14,576 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 2
2018-08-08 15:25:14,576 INFO [IPC Server handler 5 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000006_0
2018-08-08 15:25:14,579 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000006_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:14,583 INFO [ContainerLauncher #17] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000009 taskAttempt attempt_1533735211869_0040_m_000006_0
2018-08-08 15:25:14,584 INFO [ContainerLauncher #17] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000006_0
2018-08-08 15:25:14,584 INFO [ContainerLauncher #17] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave15:37797
2018-08-08 15:25:14,585 INFO [IPC Server handler 6 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000007_0 is : 1.0
2018-08-08 15:25:14,586 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000003_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:14,588 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000003_0
2018-08-08 15:25:14,588 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000003 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:14,588 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 3
2018-08-08 15:25:14,595 INFO [IPC Server handler 1 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000008_0 is : 1.0
2018-08-08 15:25:14,596 INFO [IPC Server handler 7 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000005_0 is : 1.0
2018-08-08 15:25:14,598 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000006_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:14,598 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000006_0
2018-08-08 15:25:14,598 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000006 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:14,598 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 4
2018-08-08 15:25:14,601 INFO [IPC Server handler 8 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000009_0 is : 1.0
2018-08-08 15:25:14,610 INFO [IPC Server handler 10 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000007_0
2018-08-08 15:25:14,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000007_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000007_0 given a go for committing the task output.
2018-08-08 15:25:14,612 INFO [IPC Server handler 9 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000007_0
2018-08-08 15:25:14,612 INFO [IPC Server handler 9 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000007_0:true
2018-08-08 15:25:14,619 INFO [IPC Server handler 11 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000008_0
2018-08-08 15:25:14,620 INFO [IPC Server handler 12 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000005_0
2018-08-08 15:25:14,620 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000008_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,620 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000008_0 given a go for committing the task output.
2018-08-08 15:25:14,620 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000005_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,620 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000005_0 given a go for committing the task output.
2018-08-08 15:25:14,621 INFO [IPC Server handler 13 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000008_0
2018-08-08 15:25:14,621 INFO [IPC Server handler 14 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000005_0
2018-08-08 15:25:14,622 INFO [IPC Server handler 13 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000008_0:true
2018-08-08 15:25:14,622 INFO [IPC Server handler 14 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000005_0:true
2018-08-08 15:25:14,625 INFO [IPC Server handler 15 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1533735211869_0040_m_000009_0
2018-08-08 15:25:14,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000009_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2018-08-08 15:25:14,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1533735211869_0040_m_000009_0 given a go for committing the task output.
2018-08-08 15:25:14,626 INFO [IPC Server handler 16 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000009_0
2018-08-08 15:25:14,626 INFO [IPC Server handler 16 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000009_0:true
2018-08-08 15:25:14,636 INFO [IPC Server handler 17 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000007_0 is : 1.0
2018-08-08 15:25:14,638 INFO [IPC Server handler 18 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000007_0
2018-08-08 15:25:14,638 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000007_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:14,639 INFO [ContainerLauncher #18] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000010 taskAttempt attempt_1533735211869_0040_m_000007_0
2018-08-08 15:25:14,640 INFO [ContainerLauncher #18] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000007_0
2018-08-08 15:25:14,641 INFO [ContainerLauncher #18] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave11:46641
2018-08-08 15:25:14,647 INFO [IPC Server handler 20 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000005_0 is : 1.0
2018-08-08 15:25:14,650 INFO [IPC Server handler 21 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000008_0 is : 1.0
2018-08-08 15:25:14,650 INFO [IPC Server handler 23 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000005_0
2018-08-08 15:25:14,651 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000005_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:14,651 INFO [IPC Server handler 22 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000009_0 is : 1.0
2018-08-08 15:25:14,652 INFO [ContainerLauncher #19] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000008 taskAttempt attempt_1533735211869_0040_m_000005_0
2018-08-08 15:25:14,653 INFO [ContainerLauncher #19] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000005_0
2018-08-08 15:25:14,653 INFO [ContainerLauncher #19] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave13:40615
2018-08-08 15:25:14,654 INFO [IPC Server handler 19 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000008_0
2018-08-08 15:25:14,654 INFO [IPC Server handler 26 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000009_0
2018-08-08 15:25:14,654 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000008_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:14,654 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000009_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:14,656 INFO [ContainerLauncher #18] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000012 taskAttempt attempt_1533735211869_0040_m_000009_0
2018-08-08 15:25:14,656 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000007_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:14,657 INFO [ContainerLauncher #20] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000011 taskAttempt attempt_1533735211869_0040_m_000008_0
2018-08-08 15:25:14,657 INFO [ContainerLauncher #18] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000009_0
2018-08-08 15:25:14,659 INFO [ContainerLauncher #20] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000008_0
2018-08-08 15:25:14,659 INFO [ContainerLauncher #18] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave5:46217
2018-08-08 15:25:14,661 INFO [ContainerLauncher #20] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave4:46069
2018-08-08 15:25:14,662 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000007_0
2018-08-08 15:25:14,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000007 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:14,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 5
2018-08-08 15:25:14,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000005_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:14,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000005_0
2018-08-08 15:25:14,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000005 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:14,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 6
2018-08-08 15:25:14,678 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000009_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:14,678 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000009_0
2018-08-08 15:25:14,678 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000009 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:14,680 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 7
2018-08-08 15:25:14,680 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000008_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:14,680 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000008_0
2018-08-08 15:25:14,680 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000008 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:14,680 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 8
2018-08-08 15:25:14,705 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:14 AssignedReds:0 CompletedMaps:8 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 15:25:14,712 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000008
2018-08-08 15:25:14,712 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000006
2018-08-08 15:25:14,712 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000010
2018-08-08 15:25:14,712 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000011
2018-08-08 15:25:14,712 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000014
2018-08-08 15:25:14,712 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000007
2018-08-08 15:25:14,712 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000012
2018-08-08 15:25:14,712 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000009
2018-08-08 15:25:14,713 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:6 AssignedReds:0 CompletedMaps:8 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 15:25:14,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000005_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:14,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000003_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:14,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000007_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:14,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000008_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:14,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000011_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:14,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000004_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:14,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000009_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:14,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000006_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:15,224 INFO [IPC Server handler 25 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000012_0 is : 1.0
2018-08-08 15:25:15,320 INFO [IPC Server handler 27 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000002_0 is : 1.0
2018-08-08 15:25:15,341 INFO [IPC Server handler 24 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000000_0 is : 1.0
2018-08-08 15:25:15,441 INFO [IPC Server handler 28 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000010_0
2018-08-08 15:25:15,441 INFO [IPC Server handler 28 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000010_0:true
2018-08-08 15:25:15,443 INFO [IPC Server handler 29 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000001_0 is : 1.0
2018-08-08 15:25:15,454 INFO [IPC Server handler 3 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000013_0 is : 1.0
2018-08-08 15:25:15,467 INFO [IPC Server handler 0 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000010_0 is : 1.0
2018-08-08 15:25:15,469 INFO [IPC Server handler 2 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000010_0
2018-08-08 15:25:15,469 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000010_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:15,470 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000013 taskAttempt attempt_1533735211869_0040_m_000010_0
2018-08-08 15:25:15,470 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000010_0
2018-08-08 15:25:15,470 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave12:33893
2018-08-08 15:25:15,480 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000010_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:15,480 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000010_0
2018-08-08 15:25:15,480 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000010 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:15,480 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 9
2018-08-08 15:25:15,494 INFO [IPC Server handler 4 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000013_0
2018-08-08 15:25:15,494 INFO [IPC Server handler 4 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000013_0:true
2018-08-08 15:25:15,499 INFO [IPC Server handler 5 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000012_0
2018-08-08 15:25:15,500 INFO [IPC Server handler 5 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000012_0:true
2018-08-08 15:25:15,520 INFO [IPC Server handler 6 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000013_0 is : 1.0
2018-08-08 15:25:15,520 INFO [IPC Server handler 1 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000001_0
2018-08-08 15:25:15,521 INFO [IPC Server handler 1 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000001_0:true
2018-08-08 15:25:15,521 INFO [IPC Server handler 7 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000013_0
2018-08-08 15:25:15,521 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000013_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:15,522 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000016 taskAttempt attempt_1533735211869_0040_m_000013_0
2018-08-08 15:25:15,522 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000013_0
2018-08-08 15:25:15,522 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave6:36387
2018-08-08 15:25:15,523 INFO [IPC Server handler 8 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1533735211869_0040_m_000002_0
2018-08-08 15:25:15,524 INFO [IPC Server handler 8 on 39587] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1533735211869_0040_m_000002_0:true
2018-08-08 15:25:15,525 INFO [IPC Server handler 10 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000012_0 is : 1.0
2018-08-08 15:25:15,526 INFO [IPC Server handler 9 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000012_0
2018-08-08 15:25:15,526 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000012_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:15,527 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000015 taskAttempt attempt_1533735211869_0040_m_000012_0
2018-08-08 15:25:15,527 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000012_0
2018-08-08 15:25:15,527 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave9:37771
2018-08-08 15:25:15,533 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000013_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:15,533 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000013_0
2018-08-08 15:25:15,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000013 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:15,534 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 10
2018-08-08 15:25:15,538 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000012_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:15,539 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000012_0
2018-08-08 15:25:15,539 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000012 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:15,539 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 11
2018-08-08 15:25:15,546 INFO [IPC Server handler 11 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000001_0 is : 1.0
2018-08-08 15:25:15,547 INFO [IPC Server handler 12 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000001_0
2018-08-08 15:25:15,548 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000001_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:15,548 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000004 taskAttempt attempt_1533735211869_0040_m_000001_0
2018-08-08 15:25:15,549 INFO [ContainerLauncher #12] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000001_0
2018-08-08 15:25:15,549 INFO [ContainerLauncher #12] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave10:46663
2018-08-08 15:25:15,550 INFO [IPC Server handler 13 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000002_0 is : 1.0
2018-08-08 15:25:15,552 INFO [IPC Server handler 14 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000002_0
2018-08-08 15:25:15,552 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000002_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:15,553 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000005 taskAttempt attempt_1533735211869_0040_m_000002_0
2018-08-08 15:25:15,553 INFO [ContainerLauncher #11] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000002_0
2018-08-08 15:25:15,553 INFO [ContainerLauncher #11] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave1:33157
2018-08-08 15:25:15,561 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000001_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:15,563 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000001_0
2018-08-08 15:25:15,563 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000001 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:15,563 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 12
2018-08-08 15:25:15,565 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000002_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:15,566 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000002_0
2018-08-08 15:25:15,566 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000002 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:15,566 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 13
2018-08-08 15:25:15,713 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:6 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 15:25:15,715 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000004
2018-08-08 15:25:15,715 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000005
2018-08-08 15:25:15,715 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000013
2018-08-08 15:25:15,715 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000016
2018-08-08 15:25:15,715 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1533735211869_0040_01_000015
2018-08-08 15:25:15,715 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 15:25:15,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000001_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:15,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000002_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:15,716 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000010_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:15,716 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000013_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:15,716 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1533735211869_0040_m_000012_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2018-08-08 15:25:16,984 INFO [IPC Server handler 25 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000000_0 is : 1.0
2018-08-08 15:25:17,015 INFO [IPC Server handler 27 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1533735211869_0040_m_000000_0 is : 1.0
2018-08-08 15:25:17,017 INFO [IPC Server handler 24 on 39587] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1533735211869_0040_m_000000_0
2018-08-08 15:25:17,017 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000000_0 TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP
2018-08-08 15:25:17,017 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1533735211869_0040_01_000003 taskAttempt attempt_1533735211869_0040_m_000000_0
2018-08-08 15:25:17,018 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1533735211869_0040_m_000000_0
2018-08-08 15:25:17,018 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : graphalytics-giraph-slave14:35219
2018-08-08 15:25:17,027 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1533735211869_0040_m_000000_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2018-08-08 15:25:17,027 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1533735211869_0040_m_000000_0
2018-08-08 15:25:17,027 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1533735211869_0040_m_000000 Task Transitioned from RUNNING to SUCCEEDED
2018-08-08 15:25:17,028 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 14
2018-08-08 15:25:17,028 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0040Job Transitioned from RUNNING to COMMITTING
2018-08-08 15:25:17,030 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_COMMIT
2018-08-08 15:25:17,180 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Calling handler for JobFinishedEvent 
2018-08-08 15:25:17,181 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1533735211869_0040Job Transitioned from COMMITTING to SUCCEEDED
2018-08-08 15:25:17,182 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: We are finishing cleanly so this is the last retry
2018-08-08 15:25:17,182 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true
2018-08-08 15:25:17,182 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: RMCommunicator notified that shouldUnregistered is: true
2018-08-08 15:25:17,182 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true
2018-08-08 15:25:17,182 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true
2018-08-08 15:25:17,182 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
2018-08-08 15:25:17,183 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0
2018-08-08 15:25:17,318 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0040/job_1533735211869_0040_1.jhist to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0040-1533741895764-hduser-GraphalyticsBenchmark%3A+LocalClusteringCoefficientJ-1533741917178-14-0-SUCCEEDED-default-1533741901647.jhist_tmp
2018-08-08 15:25:17,393 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0040-1533741895764-hduser-GraphalyticsBenchmark%3A+LocalClusteringCoefficientJ-1533741917178-14-0-SUCCEEDED-default-1533741901647.jhist_tmp
2018-08-08 15:25:17,396 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0040/job_1533735211869_0040_1_conf.xml to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0040_conf.xml_tmp
2018-08-08 15:25:17,473 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0040_conf.xml_tmp
2018-08-08 15:25:17,477 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0040.summary_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0040.summary
2018-08-08 15:25:17,478 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0040_conf.xml_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0040_conf.xml
2018-08-08 15:25:17,480 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0040-1533741895764-hduser-GraphalyticsBenchmark%3A+LocalClusteringCoefficientJ-1533741917178-14-0-SUCCEEDED-default-1533741901647.jhist_tmp to hdfs://graphalytics-giraph:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hduser/job_1533735211869_0040-1533741895764-hduser-GraphalyticsBenchmark%3A+LocalClusteringCoefficientJ-1533741917178-14-0-SUCCEEDED-default-1533741901647.jhist
2018-08-08 15:25:17,492 INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()
2018-08-08 15:25:17,503 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Setting job diagnostics to 
2018-08-08 15:25:17,504 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: History url is http://graphalytics-giraph-slave3:19888/jobhistory/job/job_1533735211869_0040
2018-08-08 15:25:17,510 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Waiting for application to be successfully unregistered.
2018-08-08 15:25:18,512 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:13 CompletedReds:0 ContAlloc:14 ContRel:0 HostLocal:0 RackLocal:0
2018-08-08 15:25:18,513 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://graphalytics-giraph:9000 /tmp/hadoop-yarn/staging/hduser/.staging/job_1533735211869_0040
2018-08-08 15:25:18,517 INFO [Thread-94] org.apache.hadoop.ipc.Server: Stopping server on 39587
2018-08-08 15:25:18,520 INFO [IPC Server listener on 39587] org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 39587
2018-08-08 15:25:18,520 INFO [TaskHeartbeatHandler PingChecker] org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted
2018-08-08 15:25:18,520 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
End of LogType:syslog



Container: container_1533735211869_0040_01_000011 on graphalytics-giraph-slave4_46069
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15690
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 488 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 395 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,790.00
               min = 16.00
               max = 6653.00
              mean = 119.39
            stddev = 731.11
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 2377.52
              99% <= 6653.00
            99.9% <= 6653.00
             count = 82

  remote-requests:
    count = 0

  requests-received:
             count = 82
         mean rate = 162.58 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 194.76 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.64
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 488

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 395

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 88 ms
  compute all partitions: 21 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1241 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 21

  compute-per-partition-ms:
               sum = 49.00
               min = 0.00
               max = 11.00
              mean = 1.48
            stddev = 1.96
            median = 2.00
              75% <= 2.00
              95% <= 5.40
              98% <= 11.00
              99% <= 11.00
            99.9% <= 11.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 126

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 49.00
               min = 2.00
               max = 11.00
              mean = 4.45
            stddev = 2.42
            median = 4.00
              75% <= 5.00
              95% <= 11.00
              98% <= 11.00
              99% <= 11.00
            99.9% <= 11.00
             count = 11

  received-bytes:
               sum = 8,965.00
               min = 16.00
               max = 6653.00
              mean = 163.00
            stddev = 891.85
            median = 16.00
              75% <= 89.00
              95% <= 89.60
              98% <= 5865.68
              99% <= 6653.00
            99.9% <= 6653.00
             count = 55

  remote-requests:
    count = 2

  requests-received:
             count = 55
         mean rate = 460.09 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 468.48 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,786.00
               min = 16.00
               max = 1473.00
              mean = 67.61
            stddev = 193.51
            median = 20.50
              75% <= 68.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 88

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1241

  worker-context-post-superstep:
    value = 8

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 56 ms
  compute all partitions: 11 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 515 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 11

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.15
            stddev = 0.44
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 78

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 5.00
               min = 0.00
               max = 2.00
              mean = 0.45
            stddev = 0.82
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,893.00
               min = 16.00
               max = 6653.00
              mean = 161.69
            stddev = 938.37
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5865.32
              99% <= 6653.00
            99.9% <= 6653.00
             count = 55

  remote-requests:
    count = 2

  requests-received:
             count = 55
         mean rate = 644.94 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 656.78 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,738.00
               min = 16.00
               max = 1473.00
              mean = 66.75
            stddev = 193.60
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 56

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 515

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 121 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 168 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.12
            stddev = 0.33
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.67
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.16
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 336.65 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 343.28 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 121

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 168

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.22446875444584

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:60136
Log Contents:
2018-08-08 15:25:05,367 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,434 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,434 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,436 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,436 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,620 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,856 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:06,060 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,558 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,571 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,732 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,746 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,775 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,776 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,783 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,790 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,790 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 8 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,796 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,796 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave4
INFO    2018-08-08 15:25:06,796 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,796 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,797 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,797 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000011:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000011/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,797 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000011:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,797 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000011/tmp
INFO    2018-08-08 15:25:06,797 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,797 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,797 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,797 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,797 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,797 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,797 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000011
INFO    2018-08-08 15:25:06,798 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,812 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,812 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,818 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3022f, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,819 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,939 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,956 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:07,002 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave4/10.164.0.6:30008 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:07,007 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:07,008 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:07,029 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:07,041 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:07,044 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:07,046 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:07,053 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave4_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008)
INFO    2018-08-08 15:25:07,146 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,236 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,246 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,248 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,248 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,251 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,257 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,257 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,257 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,258 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,261 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,261 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,268 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,268 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,269 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,270 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,272 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,337 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,386 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048273303 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04169084 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039837435 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03979547 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03852464 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03702818 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04063324 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036439337 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.036156584 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.035408504 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03478335 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,391 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0036, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.046
MBytes/sec sent = 0.0056, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.046
INFO    2018-08-08 15:25:07,392 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,397 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003905735 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,397 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001405077 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002650722 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004180031 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003697467 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,403 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005233114 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005381353 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004916928 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004372866 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,405 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00386438 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,405 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003498448 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,407 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 15:25:07,407 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 15:25:07,450 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,455 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,467 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,469 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.90M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,470 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.067
MBytes/sec sent = 0.0004, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.067
INFO    2018-08-08 15:25:07,470 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,478 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,479 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.90M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,491 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,521 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,527 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@55120f99,outgoing=org.apache.giraph.conf.DefaultMessageClasses@794b435f)
WARN    2018-08-08 15:25:07,529 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,548 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,549 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,552 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave4_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008)
INFO    2018-08-08 15:25:07,586 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,586 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,586 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,587 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.108
MBytes/sec sent = 0.0129, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.108
INFO    2018-08-08 15:25:07,592 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,593 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,603 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,618 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011444308 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009037011 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008335945 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006298283 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003792624 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009715425 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004898533 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011078072 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005474557 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01313816 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,624 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01336624 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,625 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.10M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,626 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0102, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0432, MBytesSent = 0.0001, ave sent req MBytes = 0.0001, secs waited = 0.002
INFO    2018-08-08 15:25:07,626 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,631 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0496, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.1576, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 15:25:07,631 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 2 , message bytes = 126 , Memory (free/total/max) = 50582.10M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,637 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,655 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,658 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@73aff8f1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf)
INFO    2018-08-08 15:25:07,667 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,671 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave4_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008)
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,694 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,695 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.064
MBytes/sec sent = 0.0216, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.064
INFO    2018-08-08 15:25:07,699 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,700 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,704 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,708 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003770402 secs for 19 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002910994 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002485757 secs for 13 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00339248 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003368484 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001707664 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,711 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001965748 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002203162 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001444949 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,713 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001743808 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,715 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002781686 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,715 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50441.29M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,716 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.008
MBytes/sec sent = 0.0093, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.008
INFO    2018-08-08 15:25:07,716 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,720 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0397, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.1261, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 15:25:07,723 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 2 , message bytes = 78 , Memory (free/total/max) = 50441.29M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,727 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,744 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,747 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4a1e3ac1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5)
INFO    2018-08-08 15:25:07,754 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,776 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave4_8 and workerInfo= Worker(hostname=graphalytics-giraph-slave4 hostOrIp=graphalytics-giraph-slave4, MRtaskID=8, port=30008)
INFO    2018-08-08 15:25:07,782 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,825 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,848 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,850 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.127
MBytes/sec sent = 0.011, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.127
INFO    2018-08-08 15:25:07,855 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,856 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,859 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,863 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001725939 secs for 4 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002370654 secs for 13 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003347361 secs for 16 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001536354 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001868596 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001702066 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001650611 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001712084 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001397616 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001421196 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00319341 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,870 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50300.49M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,870 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 15:25:07,870 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,875 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,875 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50300.49M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,879 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,899 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,902 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4248ed58,outgoing=org.apache.giraph.conf.DefaultMessageClasses@712ca57b)
INFO    2018-08-08 15:25:07,906 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,906 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,906 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,908 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:07,929 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,972 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,977 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,982 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,214 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,214 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 15:25:10,217 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,368 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,368 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,370 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/8_worker
INFO    2018-08-08 15:25:10,372 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3022f closed
INFO    2018-08-08 15:25:10,372 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,374 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,377 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,589 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,596 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000008_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:14,622 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000008_0 is allowed to commit now
INFO    2018-08-08 15:25:14,632 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000008_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000008
INFO    2018-08-08 15:25:14,654 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000008_0' done.
INFO    2018-08-08 15:25:14,659 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000008_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128720
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=6
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=102
		CPU time spent (ms)=4730
		Physical memory (bytes) snapshot=1107304448
		Virtual memory (bytes) snapshot=58879852544
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000012 on graphalytics-giraph-slave5_46217
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15685
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 643 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 395 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,806.00
               min = 16.00
               max = 6653.00
              mean = 121.06
            stddev = 735.32
            median = 32.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2452.04
              99% <= 6653.00
            99.9% <= 6653.00
             count = 81

  remote-requests:
    count = 0

  requests-received:
             count = 81
         mean rate = 123.14 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 149.23 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.64
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 643

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 395

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 89 ms
  compute all partitions: 20 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 1912 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 20

  compute-per-partition-ms:
               sum = 46.00
               min = 0.00
               max = 8.00
              mean = 1.39
            stddev = 1.58
            median = 1.00
              75% <= 2.00
              95% <= 5.20
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 213

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 46.00
               min = 2.00
               max = 8.00
              mean = 4.18
            stddev = 1.47
            median = 4.00
              75% <= 4.00
              95% <= 8.00
              98% <= 8.00
              99% <= 8.00
            99.9% <= 8.00
             count = 11

  received-bytes:
               sum = 9,073.00
               min = 16.00
               max = 6653.00
              mean = 159.18
            stddev = 876.17
            median = 16.00
              75% <= 86.50
              95% <= 89.30
              98% <= 5603.24
              99% <= 6653.00
            99.9% <= 6653.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 465.44 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 473.58 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,894.00
               min = 16.00
               max = 1473.00
              mean = 67.14
            stddev = 190.22
            median = 20.50
              75% <= 76.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 89

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 1912

  worker-context-post-superstep:
    value = 10

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 54 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 165 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 11.00
               min = 0.00
               max = 4.00
              mean = 0.33
            stddev = 0.78
            median = 0.00
              75% <= 0.50
              95% <= 1.90
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 117

  messages-sent:
    count = 3

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 11.00
               min = 0.00
               max = 4.00
              mean = 1.00
            stddev = 1.41
            median = 0.00
              75% <= 2.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,953.00
               min = 16.00
               max = 6653.00
              mean = 157.07
            stddev = 893.02
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 5602.76
              99% <= 6653.00
            99.9% <= 6653.00
             count = 57

  remote-requests:
    count = 3

  requests-received:
             count = 57
         mean rate = 666.43 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 58
         mean rate = 678.20 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 3

  sent-bytes:
               sum = 3,798.00
               min = 16.00
               max = 1473.00
              mean = 65.48
            stddev = 190.27
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1223.88
              99% <= 1473.00
            99.9% <= 1473.00
             count = 58

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 54

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 3

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 165

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 123 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 265 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 5.00
               min = 0.00
               max = 1.00
              mean = 0.15
            stddev = 0.36
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.16
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 336.50 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 343.05 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 123

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 265

  worker-context-post-superstep:
    value = 2

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.22444399894009

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:60151
Log Contents:
2018-08-08 15:25:05,298 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,365 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,365 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,367 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,367 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,541 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,760 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:05,952 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,424 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,439 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,580 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,595 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,624 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,624 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,632 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,639 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,639 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 9 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave5
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000012:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000012/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000012:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000012/tmp
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,645 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000012
INFO    2018-08-08 15:25:06,646 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,658 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,659 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,664 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30227, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,665 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,778 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,794 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,850 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave5/10.164.0.7:30009 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,855 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,856 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:06,876 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:06,885 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:06,889 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,892 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,898 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave5_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=9, port=30009)
INFO    2018-08-08 15:25:07,146 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,233 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,243 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,246 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,247 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,251 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,251 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,256 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,257 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,260 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,261 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,267 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,269 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,271 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,277 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,343 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,384 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03167036 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,384 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.033193838 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,384 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.032362018 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,384 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040074233 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,385 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03194931 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,385 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03178023 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,385 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0308292 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.029978825 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.030541355 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.029610684 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.028986339 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0043, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.038
MBytes/sec sent = 0.0067, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.038
INFO    2018-08-08 15:25:07,389 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,394 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004472416 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,395 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003867983 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,395 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003239051 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,396 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002931815 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,397 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003164642 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003541741 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,399 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004323941 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004181474 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003373624 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004772959 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003965876 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,403 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0129, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0202, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.012
INFO    2018-08-08 15:25:07,403 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 15:25:07,450 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,454 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,462 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,463 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,464 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0023, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.073
MBytes/sec sent = 0.0035, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.073
INFO    2018-08-08 15:25:07,464 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,478 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,478 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,488 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,522 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,527 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@5652f555,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4fe01805)
WARN    2018-08-08 15:25:07,529 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,546 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,547 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,551 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave5_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=9, port=30009)
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,586 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.108
MBytes/sec sent = 0.0129, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.108
INFO    2018-08-08 15:25:07,589 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,593 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,604 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,618 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004757704 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006780234 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003648597 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00607101 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008485619 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011262493 secs for 5 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010327381 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009450081 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,619 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007850425 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,620 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005503009 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,624 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.017929466 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,624 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50582.08M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,626 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0725, MBytesSent = 0.0002, ave sent req MBytes = 0.0001, secs waited = 0.002
INFO    2018-08-08 15:25:07,626 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,630 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,631 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 3 , message bytes = 213 , Memory (free/total/max) = 50582.08M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,637 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,655 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,658 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@701a32,outgoing=org.apache.giraph.conf.DefaultMessageClasses@39aa45a1)
INFO    2018-08-08 15:25:07,667 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,671 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave5_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=9, port=30009)
INFO    2018-08-08 15:25:07,692 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,694 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0219, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.063
INFO    2018-08-08 15:25:07,698 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,700 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,704 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,709 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003073279 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003620978 secs for 16 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005252312 secs for 7 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002199605 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001935575 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002388231 secs for 4 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,711 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002182287 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,711 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001881444 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,711 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005854184 secs for 2 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00232608 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,714 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003126586 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,714 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,715 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0092, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.004
MBytes/sec sent = 0.0252, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 15:25:07,715 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,720 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,721 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 3 , message bytes = 117 , Memory (free/total/max) = 50441.28M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,726 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,744 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,748 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@28486680,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4d7e7435)
INFO    2018-08-08 15:25:07,754 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,776 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave5_9 and workerInfo= Worker(hostname=graphalytics-giraph-slave5 hostOrIp=graphalytics-giraph-slave5, MRtaskID=9, port=30009)
INFO    2018-08-08 15:25:07,782 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,825 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,848 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,850 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.129
MBytes/sec sent = 0.0108, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.129
INFO    2018-08-08 15:25:07,855 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,856 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,860 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,864 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002062416 secs for 10 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001657551 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002702791 secs for 14 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004285362 secs for 9 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001831673 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001855539 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001605038 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002909936 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,868 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001526133 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002545096 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,870 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002638629 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,870 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0131, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.013
MBytes/sec sent = 0.0728, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.013
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,877 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0283, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0901, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 15:25:07,877 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50287.68M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,882 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,899 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,901 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@7bc9e6ab,outgoing=org.apache.giraph.conf.DefaultMessageClasses@5488b5c5)
INFO    2018-08-08 15:25:07,905 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,905 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,905 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,909 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:07,930 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,973 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,977 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,982 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,213 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,213 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 15:25:10,217 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,375 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,375 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,377 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/9_worker
INFO    2018-08-08 15:25:10,379 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30227 closed
INFO    2018-08-08 15:25:10,379 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,382 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,385 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,597 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,601 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000009_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:14,626 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000009_0 is allowed to commit now
INFO    2018-08-08 15:25:14,635 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000009_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000009
INFO    2018-08-08 15:25:14,654 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000009_0' done.
INFO    2018-08-08 15:25:14,659 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000009_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128720
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=21
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=102
		CPU time spent (ms)=4620
		Physical memory (bytes) snapshot=1102729216
		Virtual memory (bytes) snapshot=58877001728
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000016 on graphalytics-giraph-slave6_36387
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15674
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 650 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 343 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,675.00
               min = 16.00
               max = 6653.00
              mean = 112.50
            stddev = 714.10
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 1803.78
              99% <= 6653.00
            99.9% <= 6653.00
             count = 86

  remote-requests:
    count = 0

  requests-received:
             count = 86
         mean rate = 129.38 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 96
         mean rate = 144.66 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,520.00
               min = 16.00
               max = 1473.00
              mean = 47.08
            stddev = 149.14
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 172.04
              99% <= 1473.00
            99.9% <= 1473.00
             count = 96

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 650

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 343

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 94 ms
  compute all partitions: 15 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 528 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 15

  compute-per-partition-ms:
               sum = 52.00
               min = 0.00
               max = 4.00
              mean = 1.58
            stddev = 1.39
            median = 1.00
              75% <= 3.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 48.00
               min = 3.00
               max = 5.00
              mean = 4.36
            stddev = 0.67
            median = 4.00
              75% <= 5.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 995.30
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 413.59 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 421.63 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.67
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 94

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.36
            stddev = 0.50
            median = 0.00
              75% <= 1.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 528

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 57 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 194 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.12
            stddev = 0.33
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.67
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.41
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 574.46 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 588.92 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 57

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 194

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 123 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 192 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 927.88
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 337.25 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 344.15 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 123

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 192

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.56508052668143

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:59978
Log Contents:
2018-08-08 15:25:05,336 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,399 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,399 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,401 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,401 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,578 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,807 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:06,013 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,446 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,456 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,592 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,606 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,633 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,634 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,641 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,648 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,648 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 13 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,653 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,653 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave6
INFO    2018-08-08 15:25:06,653 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,653 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,653 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,653 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000016:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000016/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,654 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000016:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,654 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000016/tmp
INFO    2018-08-08 15:25:06,654 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,654 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,654 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,654 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,654 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,654 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,654 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000016
INFO    2018-08-08 15:25:06,654 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,666 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,666 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,671 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30228, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,672 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,773 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,789 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,841 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave6/10.164.0.8:30013 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,846 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,847 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:06,867 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:06,878 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:06,880 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,883 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,889 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave6_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=13, port=30013)
INFO    2018-08-08 15:25:07,147 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,233 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,241 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,243 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,244 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,246 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,246 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,246 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,247 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,247 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,247 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,247 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,248 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,249 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,252 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,258 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,261 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,263 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,265 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,266 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,270 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,271 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,272 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,335 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,372 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.03563105 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,385 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042989448 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04232387 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042860553 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04136755 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.043717377 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04312436 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,390 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042895935 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,390 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042593993 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,390 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042006385 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,390 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041608766 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,391 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0034, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.049
MBytes/sec sent = 0.0052, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.049
INFO    2018-08-08 15:25:07,392 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,395 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002896208 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,396 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 8.03758E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,397 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002549237 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002646776 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004651914 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003452122 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003404482 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003099164 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003938401 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003215592 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,403 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00365971 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.006, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.003
INFO    2018-08-08 15:25:07,404 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 15:25:07,450 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,454 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 15:25:07,456 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50863.69M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,456 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0003, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.055
MBytes/sec sent = 0.0004, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.055
INFO    2018-08-08 15:25:07,456 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,478 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,478 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50863.69M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,488 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,522 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,527 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4ad4936c,outgoing=org.apache.giraph.conf.DefaultMessageClasses@29d37757)
WARN    2018-08-08 15:25:07,530 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,545 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,545 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,547 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave6_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=13, port=30013)
INFO    2018-08-08 15:25:07,587 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,587 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,588 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,589 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.111
MBytes/sec sent = 0.0125, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.111
INFO    2018-08-08 15:25:07,593 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,594 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,603 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,616 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010334059 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00610362 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005643282 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007541038 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006962789 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008422471 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004893105 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012151023 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010311237 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006102409 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009807485 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,620 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,620 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.007, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.025
MBytes/sec sent = 0.0392, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.025
INFO    2018-08-08 15:25:07,620 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,631 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,632 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50722.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,637 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,655 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,657 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27ead29e)
INFO    2018-08-08 15:25:07,664 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,666 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave6_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=13, port=30013)
INFO    2018-08-08 15:25:07,694 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,694 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,694 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,695 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0219, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.063
INFO    2018-08-08 15:25:07,699 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,700 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,704 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,708 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003206462 secs for 15 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002406669 secs for 12 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002015287 secs for 6 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001934852 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001457009 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002035179 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001680579 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002307214 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001448448 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,711 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001056977 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001585256 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50582.08M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,712 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.011
MBytes/sec sent = 0.0849, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.011
INFO    2018-08-08 15:25:07,712 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,721 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,721 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50582.08M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,726 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,745 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,748 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@56febdc)
INFO    2018-08-08 15:25:07,754 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,776 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave6_13 and workerInfo= Worker(hostname=graphalytics-giraph-slave6 hostOrIp=graphalytics-giraph-slave6, MRtaskID=13, port=30013)
INFO    2018-08-08 15:25:07,782 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,826 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,850 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,850 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,851 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.13
MBytes/sec sent = 0.0107, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.13
INFO    2018-08-08 15:25:07,856 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,856 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,860 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,863 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002814757 secs for 17 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001147906 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002175331 secs for 13 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001752764 secs for 2 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001365904 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001705899 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00163724 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,866 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002237225 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001483171 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 9.79745E-4 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,870 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004069321 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0122, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.014
MBytes/sec sent = 0.0679, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.014
INFO    2018-08-08 15:25:07,871 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,878 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0331, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.1051, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 15:25:07,878 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,882 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,900 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,902 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@712ca57b,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4564e94b)
INFO    2018-08-08 15:25:07,906 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,906 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,906 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,908 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:07,930 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,973 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,978 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,982 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,212 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,212 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 15:25:10,215 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,246 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,247 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,248 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/13_worker
INFO    2018-08-08 15:25:10,250 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30228 closed
INFO    2018-08-08 15:25:10,250 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,252 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,255 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,465 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,469 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000013_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:15,495 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000013_0 is allowed to commit now
INFO    2018-08-08 15:25:15,505 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000013_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000013
INFO    2018-08-08 15:25:15,522 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000013_0' done.
INFO    2018-08-08 15:25:15,527 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000013_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128721
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=90
		CPU time spent (ms)=3890
		Physical memory (bytes) snapshot=1052360704
		Virtual memory (bytes) snapshot=58893987840
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000014 on graphalytics-giraph-slave7_43383
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15675
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 509 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 551 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,774.00
               min = 16.00
               max = 6653.00
              mean = 116.36
            stddev = 722.84
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2083.40
              99% <= 6653.00
            99.9% <= 6653.00
             count = 84

  remote-requests:
    count = 0

  requests-received:
             count = 84
         mean rate = 159.68 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 98
         mean rate = 186.68 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,552.00
               min = 16.00
               max = 1473.00
              mean = 46.45
            stddev = 147.66
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 116.68
              99% <= 1473.00
            99.9% <= 1473.00
             count = 98

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 509

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 551

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 86 ms
  compute all partitions: 18 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 227 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 18

  compute-per-partition-ms:
               sum = 36.00
               min = 0.00
               max = 4.00
              mean = 1.09
            stddev = 1.07
            median = 1.00
              75% <= 2.00
              95% <= 3.30
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 36.00
               min = 0.00
               max = 5.00
              mean = 3.27
            stddev = 1.68
            median = 4.00
              75% <= 4.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,865.00
               min = 16.00
               max = 6653.00
              mean = 170.48
            stddev = 917.12
            median = 34.50
              75% <= 89.00
              95% <= 90.05
              98% <= 6259.34
              99% <= 6653.00
            99.9% <= 6653.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 436.34 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 444.85 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,634.00
               min = 16.00
               max = 1473.00
              mean = 68.57
            stddev = 198.88
            median = 16.00
              75% <= 71.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 86

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 227

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 53 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 158 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 8.00
               min = 0.00
               max = 3.00
              mean = 0.24
            stddev = 0.61
            median = 0.00
              75% <= 0.00
              95% <= 1.60
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 39

  messages-sent:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 8.00
               min = 0.00
               max = 4.00
              mean = 0.73
            stddev = 1.35
            median = 0.00
              75% <= 2.00
              95% <= 4.00
              98% <= 4.00
              99% <= 4.00
            99.9% <= 4.00
             count = 11

  received-bytes:
               sum = 8,789.00
               min = 16.00
               max = 6653.00
              mean = 169.02
            stddev = 919.05
            median = 16.00
              75% <= 80.00
              95% <= 89.00
              98% <= 6259.16
              99% <= 6653.00
            99.9% <= 6653.00
             count = 52

  remote-requests:
    count = 1

  requests-received:
             count = 52
         mean rate = 617.71 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 53
         mean rate = 629.38 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 1

  sent-bytes:
               sum = 3,662.00
               min = 16.00
               max = 1473.00
              mean = 69.09
            stddev = 198.78
            median = 25.00
              75% <= 71.00
              95% <= 89.00
              98% <= 1362.28
              99% <= 1473.00
            99.9% <= 1473.00
             count = 53

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 53

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 1

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 158

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 123 ms
  compute all partitions: 12 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 243 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 12

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 926.25
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 334.97 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 341.53 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.71
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 123

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 243

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.25485750822546

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:60141
Log Contents:
2018-08-08 15:25:05,329 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,398 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,398 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,400 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,400 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,586 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,830 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:06,030 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,527 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,540 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,703 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,719 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,750 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,751 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,759 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,767 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,767 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 11 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,773 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,773 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave7
INFO    2018-08-08 15:25:06,773 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,773 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,773 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,773 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000014:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000014/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,774 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000014:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,774 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000014/tmp
INFO    2018-08-08 15:25:06,774 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,774 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,774 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,774 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,774 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,774 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,774 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000014
INFO    2018-08-08 15:25:06,775 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,789 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,790 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,795 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3022e, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,797 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,915 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,933 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,979 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave7/10.164.0.9:30011 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,985 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,986 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:07,008 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:07,019 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:07,023 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:07,026 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:07,033 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave7_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=11, port=30011)
INFO    2018-08-08 15:25:07,145 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,234 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,245 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,248 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,248 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,250 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,252 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,252 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,258 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,262 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,263 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,264 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,266 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,266 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,267 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,274 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,274 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,276 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,276 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,277 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,279 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,333 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,387 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.052729744 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045706622 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,387 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045043573 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.044791274 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04333216 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.042358298 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04234508 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.041630726 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040212102 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,390 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.039500333 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,390 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.040859234 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,391 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0034, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.049
MBytes/sec sent = 0.0052, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.049
INFO    2018-08-08 15:25:07,392 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,396 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003641794 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,397 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003607491 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,398 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003237548 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,399 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003424672 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003377647 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,401 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002769345 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,401 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0025517 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00252125 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004082286 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0033953 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,405 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003513952 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,406 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0134, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.007
MBytes/sec sent = 0.0209, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.008
INFO    2018-08-08 15:25:07,406 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 15:25:07,447 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,452 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,462 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,463 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,464 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0016, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.066
MBytes/sec sent = 0.0025, MBytesSent = 0.0002, ave sent req MBytes = 0, secs waited = 0.066
INFO    2018-08-08 15:25:07,464 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,475 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,476 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,489 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,519 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,525 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@55120f99,outgoing=org.apache.giraph.conf.DefaultMessageClasses@794b435f)
WARN    2018-08-08 15:25:07,527 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,550 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,550 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,552 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave7_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=11, port=30011)
INFO    2018-08-08 15:25:07,584 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,584 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,586 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.11
MBytes/sec sent = 0.0127, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.11
INFO    2018-08-08 15:25:07,591 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,592 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,601 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,615 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00296977 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007388341 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004826057 secs for 7 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,616 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006627069 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011962857 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009418548 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002290173 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010060164 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00462871 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006570263 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008299101 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,620 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,620 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0065, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.027
MBytes/sec sent = 0.0364, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.027
INFO    2018-08-08 15:25:07,620 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,629 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,629 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,635 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,652 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,654 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@73aff8f1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf)
INFO    2018-08-08 15:25:07,666 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,669 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave7_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=11, port=30011)
INFO    2018-08-08 15:25:07,691 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,691 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,692 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0219, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.064
INFO    2018-08-08 15:25:07,696 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,698 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,701 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,706 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002319012 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,706 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001550754 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,706 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003164783 secs for 9 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,706 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003579753 secs for 20 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,707 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004898324 secs for 3 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,707 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001822088 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003762901 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001484125 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002304409 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004133197 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003282272 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50457.28M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,711 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0038, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.003
MBytes/sec sent = 0.0105, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.004
INFO    2018-08-08 15:25:07,711 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,718 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,718 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 1 , message bytes = 39 , Memory (free/total/max) = 50457.28M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,723 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,742 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,745 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4a1e3ac1,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5)
INFO    2018-08-08 15:25:07,751 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,773 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave7_11 and workerInfo= Worker(hostname=graphalytics-giraph-slave7 hostOrIp=graphalytics-giraph-slave7, MRtaskID=11, port=30011)
INFO    2018-08-08 15:25:07,779 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,823 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,847 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,847 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,847 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,848 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.13
MBytes/sec sent = 0.0107, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.13
INFO    2018-08-08 15:25:07,853 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,854 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,857 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,860 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002942151 secs for 24 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,861 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001381479 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,860 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002048215 secs for 8 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,861 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001771078 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,861 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001374992 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,861 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001205873 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,862 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001286618 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001474516 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001214968 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,868 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005017089 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002171343 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,870 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50316.48M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,870 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0108, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.016
MBytes/sec sent = 0.0599, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.016
INFO    2018-08-08 15:25:07,870 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,874 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,874 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50316.48M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,880 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,897 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,899 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4248ed58,outgoing=org.apache.giraph.conf.DefaultMessageClasses@712ca57b)
INFO    2018-08-08 15:25:07,903 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,903 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,903 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,905 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:07,927 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,970 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,975 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,980 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,109 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,110 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 15:25:10,113 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,264 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,265 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,267 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/11_worker
INFO    2018-08-08 15:25:10,269 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3022e closed
INFO    2018-08-08 15:25:10,269 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,271 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,274 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,487 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,491 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000011_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:14,521 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000011_0 is allowed to commit now
INFO    2018-08-08 15:25:14,531 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000011_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000011
INFO    2018-08-08 15:25:14,549 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000011_0' done.
INFO    2018-08-08 15:25:14,554 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000011_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128721
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=107
		CPU time spent (ms)=4770
		Physical memory (bytes) snapshot=1068068864
		Virtual memory (bytes) snapshot=58894344192
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000006 on graphalytics-giraph-slave8_41519
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15696
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 556 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 369 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 1

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 11.11111111111111

  received-bytes:
               sum = 10,060.00
               min = 16.00
               max = 6653.00
              mean = 101.62
            stddev = 665.81
            median = 16.00
              75% <= 53.00
              95% <= 89.00
              98% <= 180.00
              99% <= 6653.00
            99.9% <= 6653.00
             count = 99

  remote-requests:
    count = 8

  requests-received:
             count = 99
         mean rate = 172.93 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 107
         mean rate = 187.42 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 8

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 5,009.00
               min = 16.00
               max = 1473.00
              mean = 46.81
            stddev = 141.29
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 89.00
              99% <= 1362.28
            99.9% <= 1473.00
             count = 107

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 556

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 9

  wait-requests-us:
    value = 369

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 90 ms
  compute all partitions: 19 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 2270 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 19

  compute-per-partition-ms:
               sum = 36.00
               min = 0.00
               max = 9.00
              mean = 1.09
            stddev = 1.72
            median = 1.00
              75% <= 2.00
              95% <= 5.50
              98% <= 9.00
              99% <= 9.00
            99.9% <= 9.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 126

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 36.00
               min = 0.00
               max = 9.00
              mean = 3.27
            stddev = 2.69
            median = 4.00
              75% <= 4.00
              95% <= 9.00
              98% <= 9.00
              99% <= 9.00
            99.9% <= 9.00
             count = 11

  received-bytes:
               sum = 8,957.00
               min = 16.00
               max = 6564.00
              mean = 159.95
            stddev = 874.68
            median = 34.50
              75% <= 87.75
              95% <= 89.00
              98% <= 5657.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 56

  remote-requests:
    count = 2

  requests-received:
             count = 56
         mean rate = 458.87 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 457.75 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,786.00
               min = 16.00
               max = 1473.00
              mean = 67.61
            stddev = 193.51
            median = 20.50
              75% <= 68.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 90

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 2270

  worker-context-post-superstep:
    value = 7

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 54 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 197 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.12
            stddev = 0.42
            median = 0.00
              75% <= 0.00
              95% <= 1.30
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 78

  messages-sent:
    count = 2

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = 0.0

  processing-per-thread-ms:
               sum = 3.00
               min = 0.00
               max = 2.00
              mean = 0.27
            stddev = 0.65
            median = 0.00
              75% <= 0.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,893.00
               min = 16.00
               max = 6564.00
              mean = 158.80
            stddev = 872.01
            median = 30.00
              75% <= 80.00
              95% <= 89.00
              98% <= 5657.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 56

  remote-requests:
    count = 2

  requests-received:
             count = 56
         mean rate = 657.80 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 56
         mean rate = 657.57 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 2

  sent-bytes:
               sum = 3,738.00
               min = 16.00
               max = 1473.00
              mean = 66.75
            stddev = 193.59
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 1279.24
              99% <= 1473.00
            99.9% <= 1473.00
             count = 56

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 54

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 2

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 197

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 124 ms
  compute all partitions: 10 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 187 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 10

  compute-per-partition-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.06
            stddev = 0.24
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 2.00
               min = 0.00
               max = 1.00
              mean = 0.18
            stddev = 0.40
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6564.00
              mean = 168.71
            stddev = 951.97
            median = 34.50
              75% <= 89.00
              95% <= 89.00
              98% <= 6175.50
              99% <= 6564.00
            99.9% <= 6564.00
             count = 52

  remote-requests:
    count = 0

  requests-received:
             count = 52
         mean rate = 340.90 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 340.91 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 124

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 187

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.25485807381698

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = 0.0

  vertices-loaded:
             count = 9
         mean rate = 2.52 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:60511
Log Contents:
2018-08-08 15:25:05,338 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,402 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,402 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,404 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,404 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,588 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,826 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:06,033 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,503 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,515 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,671 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,685 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,714 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,715 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,723 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,730 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,730 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 3 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,735 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave8
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000006:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000006/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000006:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000006/tmp
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,736 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000006
INFO    2018-08-08 15:25:06,737 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,749 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,750 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,755 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed3022d, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,756 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,874 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,890 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,935 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave8/10.164.0.10:30003 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,940 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,941 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:06,962 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:06,973 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:06,976 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,979 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,986 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave8_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=3, port=30003)
INFO    2018-08-08 15:25:07,145 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,238 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,248 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,248 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,249 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,250 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,251 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,252 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,253 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,254 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,255 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,257 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,257 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,260 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,261 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,266 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,266 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,267 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,267 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,268 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,270 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,270 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,270 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,274 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,326 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,371 [load-0] org.apache.giraph.worker.InputSplitsCallable  - getInputSplit: Reserved input split 'hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/input/example-undirected.v:0+19'
INFO    2018-08-08 15:25:07,386 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047593888 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,386 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04895946 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.048628412 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.047182545 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,388 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046374522 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04554807 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,389 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045092806 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,391 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.04610366 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,392 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.046225686 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,392 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.045517724 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,396 [load-0] org.apache.giraph.worker.InputSplitsCallable  - loadFromInputSplit: Finished loading (v=9, e=0)
INFO    2018-08-08 15:25:07,398 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 1 input splits in 0.07029454 secs, (v=9, e=0) 128.03271 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,404 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0174, MBytesReceived = 0.0001, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0589, MBytesSent = 0.0004, ave sent req MBytes = 0.0001, secs waited = 0.006
INFO    2018-08-08 15:25:07,405 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,409 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001181833 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,409 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002615193 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,410 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.004374499 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,411 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003098062 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,412 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003276697 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,413 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002977085 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,413 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002830151 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,414 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.00263706 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,415 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.001179132 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,416 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003751198 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,417 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005258129 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,417 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0153, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0238, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.01
INFO    2018-08-08 15:25:07,417 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=9, e=0)
INFO    2018-08-08 15:25:07,450 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,454 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,465 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: Finished moving incoming edges to vertices.
INFO    2018-08-08 15:25:07,467 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,467 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0028, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.06
MBytes/sec sent = 0.0043, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.06
INFO    2018-08-08 15:25:07,467 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,477 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,477 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50738.89M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,492 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,522 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,527 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@78dc4696,outgoing=org.apache.giraph.conf.DefaultMessageClasses@502f8b57)
WARN    2018-08-08 15:25:07,530 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:07,546 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,547 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,551 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave8_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=3, port=30003)
INFO    2018-08-08 15:25:07,584 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,585 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,587 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.11
MBytes/sec sent = 0.0127, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.11
INFO    2018-08-08 15:25:07,589 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,592 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,593 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
INFO    2018-08-08 15:25:07,603 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,617 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007490049 secs for 8 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003998067 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005708573 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.012121886 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010060731 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006848206 secs for 6 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002357488 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010330562 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002389573 secs for 0 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,617 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003272112 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,622 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.01590933 secs for 1 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,622 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,624 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0102, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0432, MBytesSent = 0.0001, ave sent req MBytes = 0.0001, secs waited = 0.002
INFO    2018-08-08 15:25:07,625 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,631 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,632 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 2 , message bytes = 126 , Memory (free/total/max) = 50598.08M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,637 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,655 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,659 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@51e37590,outgoing=org.apache.giraph.conf.DefaultMessageClasses@deb3b60)
INFO    2018-08-08 15:25:07,666 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,670 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave8_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=3, port=30003)
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,694 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.062
MBytes/sec sent = 0.0223, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.062
INFO    2018-08-08 15:25:07,696 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,700 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,703 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,708 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002888623 secs for 12 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003655126 secs for 20 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004759966 secs for 1 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002521756 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,709 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0021261 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002498763 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002331474 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,711 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002276838 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,711 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002075892 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,712 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002127109 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,713 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001995909 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,714 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50457.28M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,714 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.005
MBytes/sec sent = 0.014, MBytesSent = 0.0001, ave sent req MBytes = 0, secs waited = 0.005
INFO    2018-08-08 15:25:07,714 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,720 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0283, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.006
MBytes/sec sent = 0.0901, MBytesSent = 0.0006, ave sent req MBytes = 0, secs waited = 0.006
INFO    2018-08-08 15:25:07,720 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 2 , message bytes = 78 , Memory (free/total/max) = 50457.28M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,726 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,745 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,748 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@2424686b,outgoing=org.apache.giraph.conf.DefaultMessageClasses@6ea94d6a)
INFO    2018-08-08 15:25:07,753 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,776 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave8_3 and workerInfo= Worker(hostname=graphalytics-giraph-slave8 hostOrIp=graphalytics-giraph-slave8, MRtaskID=3, port=30003)
WARN    2018-08-08 15:25:07,826 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,850 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.13
MBytes/sec sent = 0.0108, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.129
INFO    2018-08-08 15:25:07,855 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,856 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,859 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,863 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002165972 secs for 12 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001389817 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001528314 secs for 1 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003726606 secs for 20 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001515472 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001145362 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,864 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001209337 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001752441 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002568168 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,868 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002011816 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003779692 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,869 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,869 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 15:25:07,869 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,877 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,877 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50303.68M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,882 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,899 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,902 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@f2c488,outgoing=org.apache.giraph.conf.DefaultMessageClasses@54acff7d)
INFO    2018-08-08 15:25:07,906 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,906 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,906 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,909 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:07,930 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,973 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,978 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,982 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,113 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,113 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 1 vertices using 1 threads
INFO    2018-08-08 15:25:10,117 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,277 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,278 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,280 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/3_worker
INFO    2018-08-08 15:25:10,282 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed3022d closed
INFO    2018-08-08 15:25:10,282 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,284 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,288 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,502 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,506 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000003_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:14,530 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000003_0 is allowed to commit now
INFO    2018-08-08 15:25:14,539 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000003_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000003
INFO    2018-08-08 15:25:14,562 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000003_0' done.
INFO    2018-08-08 15:25:14,567 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000003_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128720
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=63
		HDFS: Number of bytes written=6
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=92
		CPU time spent (ms)=4620
		Physical memory (bytes) snapshot=1070362624
		Virtual memory (bytes) snapshot=58864705536
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog



Container: container_1533735211869_0040_01_000015 on graphalytics-giraph-slave9_37771
=======================================================================================
LogType:stderr
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:15671
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/filecache/10/job.jar/job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

--- METRICS: superstep -1 ---
  superstep time: 921 ms
  compute all partitions: 0 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 391 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.-1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 0

  local-requests:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  received-bytes:
               sum = 9,675.00
               min = 16.00
               max = 6653.00
              mean = 119.44
            stddev = 735.51
            median = 25.00
              75% <= 53.00
              95% <= 89.00
              98% <= 2452.04
              99% <= 6653.00
            99.9% <= 6653.00
             count = 81

  remote-requests:
    count = 0

  requests-received:
             count = 81
         mean rate = 86.72 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 96
         mean rate = 102.88 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 4,520.00
               min = 16.00
               max = 1473.00
              mean = 47.08
            stddev = 149.14
            median = 20.50
              75% <= 53.00
              95% <= 89.00
              98% <= 172.04
              99% <= 1473.00
            99.9% <= 1473.00
             count = 96

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 921

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-requests-us:
    value = 391

  worker-context-post-superstep:
    value = 0

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 0 ---
  superstep time: 93 ms
  compute all partitions: 15 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 221 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.0:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 15

  compute-per-partition-ms:
               sum = 48.00
               min = 0.00
               max = 3.00
              mean = 1.45
            stddev = 0.88
            median = 2.00
              75% <= 2.00
              95% <= 3.00
              98% <= 3.00
              99% <= 3.00
            99.9% <= 3.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 48.00
               min = 3.00
               max = 5.00
              mean = 4.36
            stddev = 0.92
            median = 5.00
              75% <= 5.00
              95% <= 5.00
              98% <= 5.00
              99% <= 5.00
            99.9% <= 5.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 937.48
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 415.20 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 423.21 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 93

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 221

  worker-context-post-superstep:
    value = 6

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 1 ---
  superstep time: 57 ms
  compute all partitions: 7 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 177 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.1:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 7

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.12
            stddev = 0.33
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.67
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 927.64
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 578.70 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 590.16 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.70
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 57

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  wait-requests-us:
    value = 177

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




--- METRICS: superstep 2 ---
  superstep time: 122 ms
  compute all partitions: 8 ms
  time spent in gc: 0 ms
  bytes transferred in out-of-core: 0
  network communication time: 0 ms
  time to first message: 0 us
  wait on requests time: 183 us

8/8/18 3:25:07 PM ==============================================================
giraph.superstep.2:
  communication-time-ms:
    value = 0

  compute-all-ms:
    value = 8

  compute-per-partition-ms:
               sum = 4.00
               min = 0.00
               max = 1.00
              mean = 0.12
            stddev = 0.33
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 33

  gc-per-thread-ms:
               sum = 0.00
               min = 0.00
               max = 0.00
              mean = 0.00
            stddev = 0.00
            median = 0.00
              75% <= 0.00
              95% <= 0.00
              98% <= 0.00
              99% <= 0.00
            99.9% <= 0.00
             count = 11

  local-requests:
    count = 0

  message-bytes-sent:
    count = 0

  messages-sent:
    count = 0

  ooc-bytes-load:
    count = 0

  ooc-bytes-store:
    count = 0

  percent-local-requests:
    value = NaN

  processing-per-thread-ms:
               sum = 4.00
               min = 0.00
               max = 2.00
              mean = 0.36
            stddev = 0.67
            median = 0.00
              75% <= 1.00
              95% <= 2.00
              98% <= 2.00
              99% <= 2.00
            99.9% <= 2.00
             count = 11

  received-bytes:
               sum = 8,773.00
               min = 16.00
               max = 6653.00
              mean = 172.02
            stddev = 927.88
            median = 16.00
              75% <= 89.00
              95% <= 89.00
              98% <= 6390.44
              99% <= 6653.00
            99.9% <= 6653.00
             count = 51

  remote-requests:
    count = 0

  requests-received:
             count = 51
         mean rate = 335.83 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  requests-sent:
             count = 52
         mean rate = 342.39 requests/s
     1-minute rate = 0.00 requests/s
     5-minute rate = 0.00 requests/s
    15-minute rate = 0.00 requests/s

  send-aggregators-to-master-requests:
    count = 1

  send-aggregators-to-owner-requests:
    count = 0

  send-aggregators-to-worker-requests:
    count = 12

  send-partition-current-messages-requests:
    count = 0

  send-partition-mutations-requests:
    count = 0

  send-vertex-requests:
    count = 0

  send-worker-aggregators-requests:
    count = 12

  send-worker-messages-requests:
    count = 0

  sent-bytes:
               sum = 3,618.00
               min = 16.00
               max = 1473.00
              mean = 69.58
            stddev = 200.69
            median = 20.50
              75% <= 80.00
              95% <= 89.00
              98% <= 1389.96
              99% <= 1473.00
            99.9% <= 1473.00
             count = 52

  superstep-gc-time-ms:
    count = 0

  superstep-time-ms:
    value = 122

  time-spent-waiting-on-too-many-open-requests-ms:
    count = 0

  time-to-first-message-ms:
    value = 0

  total-requests:
    value = 0

  wait-per-thread-ms:
               sum = 1.00
               min = 0.00
               max = 1.00
              mean = 0.09
            stddev = 0.30
            median = 0.00
              75% <= 0.00
              95% <= 1.00
              98% <= 1.00
              99% <= 1.00
            99.9% <= 1.00
             count = 11

  wait-requests-us:
    value = 183

  worker-context-post-superstep:
    value = 1

  worker-context-pre-superstep:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  memory-free-pct:
    value = 95.56508342715075

  worker-context-post-app:
    value = 0

  worker-context-pre-app:
    value = 0




8/8/18 3:25:10 PM ==============================================================
giraph.job:
  edges-filtered:
    count = 0

  edges-filtered-pct:
    value = NaN

  edges-loaded:
             count = 0
         mean rate = 0.00 edges/s
     1-minute rate = 0.00 edges/s
     5-minute rate = 0.00 edges/s
    15-minute rate = 0.00 edges/s

  vertices-filtered:
    count = 0

  vertices-filtered-pct:
    value = NaN

  vertices-loaded:
             count = 0
         mean rate = 0.00 vertices/s
     1-minute rate = 0.00 vertices/s
     5-minute rate = 0.00 vertices/s
    15-minute rate = 0.00 vertices/s



log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Wed Aug 08 15:25:24 +0000 2018
LogLength:59939
Log Contents:
2018-08-08 15:25:05,157 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-08-08 15:25:05,214 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-08-08 15:25:05,214 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2018-08-08 15:25:05,215 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2018-08-08 15:25:05,216 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1533735211869_0040, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5562c41e)
2018-08-08 15:25:05,381 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2018-08-08 15:25:05,613 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040
2018-08-08 15:25:05,774 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2018-08-08 15:25:06,194 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2018-08-08 15:25:06,205 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2018-08-08 15:25:06,338 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: 'org.apache.giraph.bsp.BspInputSplit, index=-1, num=-1
2018-08-08 15:25:06,351 INFO [main] org.apache.giraph.graph.GraphTaskManager: setup: Log level remains at info
INFO    2018-08-08 15:25:06,375 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
INFO    2018-08-08 15:25:06,376 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Starting up BspServiceWorker...
INFO    2018-08-08 15:25:06,383 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.job.id is deprecated. Instead, use mapreduce.job.id
INFO    2018-08-08 15:25:06,389 [main] org.apache.giraph.bsp.BspService  - BspService: Path to create to halt is /_hadoopBsp/job_1533735211869_0040/_haltComputation
INFO    2018-08-08 15:25:06,389 [main] org.apache.giraph.bsp.BspService  - BspService: Connecting to ZooKeeper with job job_1533735211869_0040, 12 on graphalytics-giraph:2181
INFO    2018-08-08 15:25:06,394 [main] org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
INFO    2018-08-08 15:25:06,394 [main] org.apache.zookeeper.ZooKeeper  - Client environment:host.name=graphalytics-giraph-slave9
INFO    2018-08-08 15:25:06,394 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_181
INFO    2018-08-08 15:25:06,394 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
INFO    2018-08-08 15:25:06,394 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/local/java/jdk1.8.0_181/jre
INFO    2018-08-08 15:25:06,394 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000015:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000015/job.jar:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/hadoop-common-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/hadoop-auth-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.7.6/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/hadoop-hdfs-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop-2.7.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-api-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-registry-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-client-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.7.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.6-tests.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.6.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.7.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar
INFO    2018-08-08 15:25:06,395 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000015:/usr/local/hadoop-2.7.6/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
INFO    2018-08-08 15:25:06,395 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000015/tmp
INFO    2018-08-08 15:25:06,395 [main] org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
INFO    2018-08-08 15:25:06,395 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
INFO    2018-08-08 15:25:06,395 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
INFO    2018-08-08 15:25:06,395 [main] org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.15.0-1015-gcp
INFO    2018-08-08 15:25:06,395 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.name=hduser
INFO    2018-08-08 15:25:06,395 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/hduser
INFO    2018-08-08 15:25:06,395 [main] org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1533735211869_0040/container_1533735211869_0040_01_000015
INFO    2018-08-08 15:25:06,395 [main] org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=graphalytics-giraph:2181 sessionTimeout=60000 watcher=org.apache.giraph.worker.BspServiceWorker@3f093abe
INFO    2018-08-08 15:25:06,407 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Opening socket connection to server graphalytics-giraph/10.164.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
INFO    2018-08-08 15:25:06,407 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Socket connection established to graphalytics-giraph/10.164.0.2:2181, initiating session
INFO    2018-08-08 15:25:06,412 [main-SendThread(graphalytics-giraph:2181)] org.apache.zookeeper.ClientCnxn  - Session establishment complete on server graphalytics-giraph/10.164.0.2:2181, sessionid = 0x100000e4ed30222, negotiated timeout = 40000
INFO    2018-08-08 15:25:06,413 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Asynchronous connection complete.
INFO    2018-08-08 15:25:06,512 [main] org.apache.giraph.comm.netty.NettyServer  - NettyServer: Using execution group with 8 threads for requestFrameDecoder.
INFO    2018-08-08 15:25:06,528 [main] org.apache.hadoop.conf.Configuration.deprecation  - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
INFO    2018-08-08 15:25:06,577 [main] org.apache.giraph.comm.netty.NettyServer  - start: Started server communication server: graphalytics-giraph-slave9/10.164.0.11:30012 with up to 11 threads on bind attempt 0 with sendBufferSize = 32768 receiveBufferSize = 524288
INFO    2018-08-08 15:25:06,582 [main] org.apache.giraph.comm.flow_control.StaticFlowControl  - StaticFlowControl: Limit number of open requests to 100 and proceed when <= 80
INFO    2018-08-08 15:25:06,582 [main] org.apache.giraph.comm.netty.NettyClient  - NettyClient: Using execution handler with 8 threads after request-encoder.
INFO    2018-08-08 15:25:06,598 [main] org.apache.giraph.graph.GraphTaskManager  - setup: Registering health of this worker...
INFO    2018-08-08 15:25:06,609 [main] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:06,611 [main] org.apache.giraph.bsp.BspService  - getApplicationAttempt: Node /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir already exists!
INFO    2018-08-08 15:25:06,619 [main-EventThread] org.apache.giraph.bsp.BspService  - process: applicationAttemptChanged signaled
WARN    2018-08-08 15:25:06,629 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir, type=NodeChildrenChanged, state=SyncConnected)
INFO    2018-08-08 15:25:06,632 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=-1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/-1/_workerHealthyDir/graphalytics-giraph-slave9_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=12, port=30012)
INFO    2018-08-08 15:25:07,146 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,229 [netty-server-worker-0] org.apache.giraph.comm.netty.handler.RequestDecoder  - decode: Server window metrics MBytes/sec received = 0, MBytesReceived = 0.0063, ave received req MBytes = 0.0063, secs waited = 1.53374195E9
INFO    2018-08-08 15:25:07,237 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,238 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,239 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,241 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,241 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,241 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,242 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,242 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,242 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,242 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,244 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,244 [netty-client-worker-1] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,244 [netty-client-worker-3] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,245 [netty-client-worker-2] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,245 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - Using Netty without authentication.
INFO    2018-08-08 15:25:07,248 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 13 connections, (13 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,251 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,252 [netty-server-worker-2] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,259 [netty-server-worker-3] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,263 [netty-server-worker-4] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,264 [netty-server-worker-5] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,265 [netty-server-worker-6] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,265 [netty-server-worker-7] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,267 [netty-server-worker-8] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,270 [netty-server-worker-9] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,271 [netty-server-worker-10] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,271 [netty-server-worker-0] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,272 [netty-server-worker-1] org.apache.giraph.comm.netty.NettyServer  - start: Using Netty without authentication.
INFO    2018-08-08 15:25:07,334 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,400 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.0655356 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.058050495 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05881773 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05954775 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.057889476 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,400 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.057430793 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,401 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.056857046 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.057014313 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.056753177 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05633976 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,402 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.05596043 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,403 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0026, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0041, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.063
INFO    2018-08-08 15:25:07,404 [main] org.apache.giraph.worker.BspServiceWorker  - loadInputSplits: Using 11 thread(s), originally 11 threads(s)
INFO    2018-08-08 15:25:07,408 [load-0] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003808497 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,409 [load-1] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003107485 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,410 [load-2] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003547302 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,410 [load-7] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 7.83981E-4 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,411 [load-4] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003145263 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,412 [load-5] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003979053 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,413 [load-6] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003835469 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,413 [load-3] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.005820579 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,413 [load-8] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.003315173 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,414 [load-9] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002724105 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,414 [load-10] org.apache.giraph.worker.InputSplitsCallable  - call: Loaded 0 input splits in 0.002621647 secs, (v=0, e=0) 0.0 vertices/sec, 0.0 edges/sec
INFO    2018-08-08 15:25:07,414 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0186, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.008
MBytes/sec sent = 0.0291, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.008
INFO    2018-08-08 15:25:07,415 [main] org.apache.giraph.worker.BspServiceWorker  - setup: Finally loaded a total of (v=0, e=0)
INFO    2018-08-08 15:25:07,449 [main-EventThread] org.apache.giraph.bsp.BspService  - process: all input splits done
INFO    2018-08-08 15:25:07,453 [main] org.apache.giraph.edge.AbstractEdgeStore  - moveEdgesToVertices: No edges to move
INFO    2018-08-08 15:25:07,455 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep -1 Memory (free/total/max) = 50863.69M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,455 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0034, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.049
MBytes/sec sent = 0.0052, MBytesSent = 0.0003, ave sent req MBytes = 0, secs waited = 0.049
INFO    2018-08-08 15:25:07,455 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,477 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0051, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,477 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep -1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50863.69M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,486 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=-1
INFO    2018-08-08 15:25:07,521 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,526 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep -1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=0,msgBytesCount=0,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@4ad4936c,outgoing=org.apache.giraph.conf.DefaultMessageClasses@29d37757)
INFO    2018-08-08 15:25:07,545 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,545 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,548 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=0 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_workerHealthyDir/graphalytics-giraph-slave9_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=12, port=30012)
INFO    2018-08-08 15:25:07,587 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,587 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,587 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,589 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.112
MBytes/sec sent = 0.0124, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.112
INFO    2018-08-08 15:25:07,593 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,594 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,602 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 0
INFO    2018-08-08 15:25:07,615 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004283234 secs for 4 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003785906 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.006133526 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009430439 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.007018149 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.011455531 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00777228 secs for 2 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.008390861 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.009112625 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.010349077 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.01 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,615 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.005484661 secs for 3 partitions on superstep 0.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,618 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 0 Memory (free/total/max) = 50710.09M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,618 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.023
MBytes/sec sent = 0.0424, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.023
INFO    2018-08-08 15:25:07,618 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,631 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.002
MBytes/sec sent = 0.0079, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.002
INFO    2018-08-08 15:25:07,631 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 0, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50710.09M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,637 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=0
INFO    2018-08-08 15:25:07,655 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,656 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 0 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=1681,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@27cbfddf,outgoing=org.apache.giraph.conf.DefaultMessageClasses@27ead29e)
INFO    2018-08-08 15:25:07,663 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,664 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=1 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_workerHealthyDir/graphalytics-giraph-slave9_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=12, port=30012)
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,693 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,694 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0002, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.063
MBytes/sec sent = 0.0219, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.063
INFO    2018-08-08 15:25:07,698 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,700 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,703 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 1
INFO    2018-08-08 15:25:07,706 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002822143 secs for 20 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,706 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001917162 secs for 8 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,706 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002208606 secs for 5 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,706 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001735312 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,707 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001455763 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,707 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001299437 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,707 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.00165109 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001352346 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001443395 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,708 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001157542 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002335013 secs for 0 partitions on superstep 1.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,710 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 1 Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,710 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0166, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.01
MBytes/sec sent = 0.0926, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.01
INFO    2018-08-08 15:25:07,710 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,720 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,720 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 1, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50569.28M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,726 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=1
INFO    2018-08-08 15:25:07,744 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,747 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 1 with global stats (vtx=9,finVtx=0,edges=24,msgCount=23,msgBytesCount=897,haltComputation=false, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@6e78fcf5,outgoing=org.apache.giraph.conf.DefaultMessageClasses@56febdc)
INFO    2018-08-08 15:25:07,752 [main] org.apache.giraph.comm.messages.InMemoryMessageStoreFactory  - newStore: Created class org.apache.giraph.comm.messages.primitives.long_id.LongByteArrayMessageStore for vertex id class org.apache.hadoop.io.LongWritable and message value class science.atlarge.graphalytics.giraph.algorithms.lcc.LocalClusteringCoefficientMessage and no combiner
INFO    2018-08-08 15:25:07,773 [main] org.apache.giraph.worker.BspServiceWorker  - registerHealth: Created my health node for attempt=0, superstep=2 with /_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/2/_workerHealthyDir/graphalytics-giraph-slave9_12 and workerInfo= Worker(hostname=graphalytics-giraph-slave9 hostOrIp=graphalytics-giraph-slave9, MRtaskID=12, port=30012)
INFO    2018-08-08 15:25:07,782 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,825 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/0/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,848 [main] org.apache.giraph.worker.BspServiceWorker  - startSuperstep: Master(hostname=graphalytics-giraph-slave14, MRtaskID=0, port=30000)
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.partition.WorkerGraphPartitionerImpl  - After updating partitionOwnerList 13 workers are available
INFO    2018-08-08 15:25:07,849 [main] org.apache.giraph.comm.netty.NettyClient  - connectAllAddresses: Successfully added 0 connections, (0 total connected) 0 failed, 0 failures total.
INFO    2018-08-08 15:25:07,850 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0001, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.13
MBytes/sec sent = 0.0107, MBytesSent = 0.0014, ave sent req MBytes = 0.0014, secs waited = 0.13
INFO    2018-08-08 15:25:07,855 [main] org.apache.giraph.worker.BspServiceWorker  - sendWorkerPartitions: Done sending all my partitions.
INFO    2018-08-08 15:25:07,856 [main] org.apache.giraph.worker.BspServiceWorker  - exchangeVertexPartitions: Done with exchange.
INFO    2018-08-08 15:25:07,859 [main] org.apache.giraph.graph.GraphTaskManager  - execute: 33 partitions to process with 11 compute thread(s), originally 11 thread(s) on superstep 2
INFO    2018-08-08 15:25:07,863 [compute-2] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.0015913 secs for 6 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-1] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002040572 secs for 12 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-3] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001237202 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-0] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003112584 secs for 15 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,863 [compute-4] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.001166905 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,865 [compute-6] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.002204557 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-7] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003353072 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,867 [compute-5] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.004440737 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,868 [compute-9] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003583289 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,868 [compute-8] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003898828 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,868 [compute-10] org.apache.giraph.graph.ComputeCallable  - call: Computation took 0.003165776 secs for 0 partitions on superstep 2.  Flushing started (time waiting on partitions was 0.00 s, time processing partitions was 0.00 s, time spent on gc was 0.00 s)
INFO    2018-08-08 15:25:07,868 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Waiting on all requests, superstep 2 Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,868 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0141, MBytesReceived = 0.0002, ave received req MBytes = 0, secs waited = 0.012
MBytes/sec sent = 0.0783, MBytesSent = 0.001, ave sent req MBytes = 0.0001, secs waited = 0.012
INFO    2018-08-08 15:25:07,868 [main] org.apache.giraph.worker.WorkerAggregatorHandler  - finishSuperstep: Start gathering aggregators, workers will send their aggregated values once they are done with superstep computation
INFO    2018-08-08 15:25:07,875 [main] org.apache.giraph.comm.netty.NettyClient  - waitAllRequests: Finished all requests. MBytes/sec received = 0.0076, MBytesReceived = 0, ave received req MBytes = 0, secs waited = 0.001
MBytes/sec sent = 0.0119, MBytesSent = 0, ave sent req MBytes = 0, secs waited = 0.001
INFO    2018-08-08 15:25:07,875 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Superstep 2, messages = 0 , message bytes = 0 , Memory (free/total/max) = 50428.48M / 52608.00M / 52608.00M
INFO    2018-08-08 15:25:07,878 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: (waiting for rest of workers) WORKER_ONLY - Attempt=0, Superstep=2
INFO    2018-08-08 15:25:07,899 [main-EventThread] org.apache.giraph.bsp.BspService  - process: superstepFinished signaled
INFO    2018-08-08 15:25:07,901 [main] org.apache.giraph.worker.BspServiceWorker  - finishSuperstep: Completed superstep 2 with global stats (vtx=9,finVtx=9,edges=24,msgCount=0,msgBytesCount=0,haltComputation=true, checkpointStatus=NONE) and classes (computation=science.atlarge.graphalytics.giraph.algorithms.lcc.UndirectedLocalClusteringCoefficientComputation,incoming=org.apache.giraph.conf.DefaultMessageClasses@712ca57b,outgoing=org.apache.giraph.conf.DefaultMessageClasses@4564e94b)
INFO    2018-08-08 15:25:07,905 [main] org.apache.giraph.graph.GraphTaskManager  - execute: BSP application done (global vertices marked done)
INFO    2018-08-08 15:25:07,905 [main] org.apache.giraph.graph.GraphTaskManager  - cleanup: Starting for WORKER_ONLY
INFO    2018-08-08 15:25:07,905 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Halting netty client
INFO    2018-08-08 15:25:07,907 [netty-client-worker-0] org.apache.giraph.comm.netty.NettyClient  - stop: reached wait threshold, 13 connections closed, releasing resources now.
INFO    2018-08-08 15:25:07,929 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent : partitionExchangeChildrenChanged (at least one worker is done sending partitions)
WARN    2018-08-08 15:25:07,973 [main-EventThread] org.apache.giraph.bsp.BspService  - process: Unknown and unprocessed event (path=/_hadoopBsp/job_1533735211869_0040/_applicationAttemptsDir/0/_superstepDir/1/_superstepFinished, type=NodeDeleted, state=SyncConnected)
INFO    2018-08-08 15:25:07,977 [main-EventThread] org.apache.giraph.worker.BspServiceWorker  - processEvent: Job state changed, checking to see if it needs to restart
INFO    2018-08-08 15:25:07,979 [main-EventThread] org.apache.giraph.bsp.BspService  - getJobState: Job state already exists (/_hadoopBsp/job_1533735211869_0040/_masterJobState)
INFO    2018-08-08 15:25:10,211 [main] org.apache.giraph.comm.netty.NettyClient  - stop: Netty client halted
INFO    2018-08-08 15:25:10,211 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Starting to save 0 vertices using 1 threads
INFO    2018-08-08 15:25:10,215 [save-vertices-0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - File Output Committer Algorithm version is 1
INFO    2018-08-08 15:25:10,248 [main] org.apache.giraph.worker.BspServiceWorker  - saveVertices: Done saving vertices.
WARN    2018-08-08 15:25:10,248 [main] org.apache.giraph.worker.BspServiceWorker  - saveEdges:   giraph.edgeOutputFormatClass => null [EdgeOutputFormat]  (class)
Make sure that the EdgeOutputFormat is not required.
INFO    2018-08-08 15:25:10,251 [main] org.apache.giraph.worker.BspServiceWorker  - cleanup: Notifying master its okay to cleanup with /_hadoopBsp/job_1533735211869_0040/_cleanedUpDir/12_worker
INFO    2018-08-08 15:25:10,253 [main] org.apache.zookeeper.ZooKeeper  - Session: 0x100000e4ed30222 closed
INFO    2018-08-08 15:25:10,253 [main-EventThread] org.apache.zookeeper.ClientCnxn  - EventThread shut down
INFO    2018-08-08 15:25:10,255 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Halting netty server
INFO    2018-08-08 15:25:10,258 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Start releasing resources
INFO    2018-08-08 15:25:14,470 [main] org.apache.giraph.comm.netty.NettyServer  - stop: Netty server halted
INFO    2018-08-08 15:25:14,475 [main] org.apache.hadoop.mapred.Task  - Task:attempt_1533735211869_0040_m_000012_0 is done. And is in the process of committing
INFO    2018-08-08 15:25:15,500 [main] org.apache.hadoop.mapred.Task  - Task attempt_1533735211869_0040_m_000012_0 is allowed to commit now
INFO    2018-08-08 15:25:15,509 [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter  - Saved output of task 'attempt_1533735211869_0040_m_000012_0' to hdfs://graphalytics-giraph:9000/user/hduser/graphalytics/giraph/output/r532835_LCC-example-undirected/_temporary/1/task_1533735211869_0040_m_000012
INFO    2018-08-08 15:25:15,526 [main] org.apache.hadoop.mapred.Task  - Task 'attempt_1533735211869_0040_m_000012_0' done.
INFO    2018-08-08 15:25:15,532 [main] org.apache.hadoop.mapred.Task  - Final Counters for attempt_1533735211869_0040_m_000012_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=128721
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=44
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=44
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=87
		CPU time spent (ms)=3760
		Physical memory (bytes) snapshot=1075970048
		Virtual memory (bytes) snapshot=58874990592
		Total committed heap usage (bytes)=55163486208
	Zookeeper base path
		/_hadoopBsp/job_1533735211869_0040=0
	Zookeeper halt node
		/_hadoopBsp/job_1533735211869_0040/_haltComputation=0
	Zookeeper server:port
		graphalytics-giraph:2181=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
End of LogType:syslog

